ID,Process ID,Process Name,Host Name,Kernel Name,Context,Stream,Block Size,Grid Size,Device,CC,Section Name,Metric Name,Metric Unit,Metric Value,Rule Name,Rule Type,Rule Description,Estimated Speedup Type,Estimated Speedup
0,45327,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(1024, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Frequency,cycle/second,"5,818,181,818.18",,,,,
0,45327,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(1024, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Frequency,cycle/second,"1,350,674,715.91",,,,,
0,45327,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(1024, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Elapsed Cycles,cycle,"7,637",,,,,
0,45327,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(1024, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Memory Throughput,%,7.69,,,,,
0,45327,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(1024, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Throughput,%,0.80,,,,,
0,45327,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(1024, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Duration,nsecond,"5,632",,,,,
0,45327,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(1024, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L1/TEX Cache Throughput,%,13.97,,,,,
0,45327,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(1024, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L2 Cache Throughput,%,5.51,,,,,
0,45327,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(1024, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Active Cycles,cycle,"4,188.93",,,,,
0,45327,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(1024, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Compute (SM) Throughput,%,7.69,,,,,
0,45327,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(1024, 1, 1)",0,7.5,SpeedOfLight,,,,SOLBottleneck,OPT,This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.,,
0,45327,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(1024, 1, 1)",0,7.5,SpeedOfLight_RooflineChart,,,,SOLFPRoofline,INF,The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved  close to 0% of this device's fp32 peak performance and 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.,,
0,45327,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(1024, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Active,inst/cycle,0.23,,,,,
0,45327,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(1024, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Elapsed,inst/cycle,0.12,,,,,
0,45327,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(1024, 1, 1)",0,7.5,Compute Workload Analysis,Issue Slots Busy,%,6.00,,,,,
0,45327,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(1024, 1, 1)",0,7.5,Compute Workload Analysis,Issued Ipc Active,inst/cycle,0.24,,,,,
0,45327,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(1024, 1, 1)",0,7.5,Compute Workload Analysis,SM Busy,%,6.00,,,,,
0,45327,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(1024, 1, 1)",0,7.5,ComputeWorkloadAnalysis,,,,HighPipeUtilization,OPT,All compute pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.,local,95.63
0,45327,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(1024, 1, 1)",0,7.5,Memory Workload Analysis,Memory Throughput,byte/second,"1,482,954,545.45",,,,,
0,45327,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(1024, 1, 1)",0,7.5,Memory Workload Analysis,Mem Busy,%,4.77,,,,,
0,45327,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(1024, 1, 1)",0,7.5,Memory Workload Analysis,Max Bandwidth,%,7.69,,,,,
0,45327,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(1024, 1, 1)",0,7.5,Memory Workload Analysis,L1/TEX Hit Rate,%,29.14,,,,,
0,45327,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(1024, 1, 1)",0,7.5,Memory Workload Analysis,L2 Hit Rate,%,95.82,,,,,
0,45327,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(1024, 1, 1)",0,7.5,Memory Workload Analysis,Mem Pipes Busy,%,7.69,,,,,
0,45327,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(1024, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Chart,,,,MemoryL2Compression,WRN,The optional metric lts__average_gcomp_input_sector_success_rate.pct could not be found. Collecting it as an additional metric could enable the rule to provide more guidance.,,
0,45327,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(1024, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for loads from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced loads and try to minimize how many cache lines need to be accessed per memory request.",global,2.249
0,45327,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(1024, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for stores from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.5 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced stores and try to minimize how many cache lines need to be accessed per memory request.",global,0.9744
0,45327,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(1024, 1, 1)",0,7.5,Scheduler Statistics,One or More Eligible,%,6.61,,,,,
0,45327,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(1024, 1, 1)",0,7.5,Scheduler Statistics,Issued Warp Per Scheduler,,0.07,,,,,
0,45327,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(1024, 1, 1)",0,7.5,Scheduler Statistics,No Eligible,%,93.39,,,,,
0,45327,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(1024, 1, 1)",0,7.5,Scheduler Statistics,Active Warps Per Scheduler,warp,2.97,,,,,
0,45327,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(1024, 1, 1)",0,7.5,Scheduler Statistics,Eligible Warps Per Scheduler,warp,0.07,,,,,
0,45327,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(1024, 1, 1)",0,7.5,SchedulerStats,,,,IssueSlotUtilization,OPT,"Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 15.1 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of 2.97 active warps per scheduler, but only an average of 0.07 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections.",local,92.31
0,45327,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(1024, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Issued Instruction,cycle,44.87,,,,,
0,45327,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(1024, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Executed Instruction,cycle,47.44,,,,,
0,45327,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(1024, 1, 1)",0,7.5,Warp State Statistics,Avg. Active Threads Per Warp,,1,,,,,
0,45327,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(1024, 1, 1)",0,7.5,Warp State Statistics,Avg. Not Predicated Off Threads Per Warp,,1,,,,,
0,45327,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(1024, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,OPT,"On average, each warp of this kernel spends 30.1 cycles being stalled waiting for a scoreboard dependency on a L1TEX (local, global, surface, texture) operation. Find the instruction producing the data being waited upon to identify the culprit. To reduce the number of cycles waiting on L1TEX data accesses verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit rates by increasing data locality (coalescing), or by changing the cache configuration. Consider moving frequently used data to shared memory. This stall type represents about 67.1% of the total average of 44.9 cycles between issuing two instructions.",global,67.13
0,45327,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(1024, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,INF,Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.,,
0,45327,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(1024, 1, 1)",0,7.5,WarpStateStats,,,,ThreadDivergence,OPT,"Instructions are executed in warps, which are groups of 32 threads. Optimal instruction throughput is achieved if all 32 threads of a warp execute the same instruction. The chosen launch configuration, early thread completion, and divergent flow control can significantly lower the number of active threads in a warp per cycle. This kernel achieves an average of 1.0 threads being active per cycle.",global,7.448
0,45327,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(1024, 1, 1)",0,7.5,Instruction Statistics,Avg. Executed Instructions Per Scheduler,inst,237.71,,,,,
0,45327,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(1024, 1, 1)",0,7.5,Instruction Statistics,Executed Instructions,inst,"13,312",,,,,
0,45327,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(1024, 1, 1)",0,7.5,Instruction Statistics,Avg. Issued Instructions Per Scheduler,inst,251.36,,,,,
0,45327,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(1024, 1, 1)",0,7.5,Instruction Statistics,Issued Instructions,inst,"14,076",,,,,
0,45327,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(1024, 1, 1)",0,7.5,InstructionStats,,,,FPInstructions,OPT,"This kernel executes 0 fused and 1024 non-fused FP32 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP32 performance could be increased by up to 50% (relative to its current performance). Check the Source page to identify where this kernel executes FP32 instructions.",global,2.183
0,45327,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(1024, 1, 1)",0,7.5,Launch Statistics,Block Size,,1,,,,,
0,45327,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(1024, 1, 1)",0,7.5,Launch Statistics,Function Cache Configuration,,CachePreferNone,,,,,
0,45327,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(1024, 1, 1)",0,7.5,Launch Statistics,Grid Size,,"1,024",,,,,
0,45327,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(1024, 1, 1)",0,7.5,Launch Statistics,Registers Per Thread,register/thread,16,,,,,
0,45327,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(1024, 1, 1)",0,7.5,Launch Statistics,Shared Memory Configuration Size,byte,"32,768",,,,,
0,45327,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(1024, 1, 1)",0,7.5,Launch Statistics,Driver Shared Memory Per Block,byte/block,0,,,,,
0,45327,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(1024, 1, 1)",0,7.5,Launch Statistics,Dynamic Shared Memory Per Block,byte/block,0,,,,,
0,45327,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(1024, 1, 1)",0,7.5,Launch Statistics,Static Shared Memory Per Block,byte/block,0,,,,,
0,45327,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(1024, 1, 1)",0,7.5,Launch Statistics,Threads,thread,"1,024",,,,,
0,45327,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(1024, 1, 1)",0,7.5,Launch Statistics,Waves Per SM,,4.57,,,,,
0,45327,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(1024, 1, 1)",0,7.5,LaunchStats,,,,LaunchConfiguration,OPT,"Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 1 threads per block. Consequently, some threads in a warp are masked off and those hardware resources are unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256 threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to kernels that frequently call __syncthreads(). See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations.",global,96.88
0,45327,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(1024, 1, 1)",0,7.5,LaunchStats,,,,LaunchConfiguration,OPT,"A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical occupancy of the kernel. This kernel launch results in 4 full waves and a partial wave of 127 thread blocks. Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for up to 20.0% of the total kernel runtime with a lower occupancy of 29.6%. Try launching a grid with no partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for a grid. See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations.",global,20.0
0,45327,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(1024, 1, 1)",0,7.5,Occupancy,Block Limit SM,block,16,,,,,
0,45327,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(1024, 1, 1)",0,7.5,Occupancy,Block Limit Registers,block,128,,,,,
0,45327,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(1024, 1, 1)",0,7.5,Occupancy,Block Limit Shared Mem,block,16,,,,,
0,45327,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(1024, 1, 1)",0,7.5,Occupancy,Block Limit Warps,block,32,,,,,
0,45327,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(1024, 1, 1)",0,7.5,Occupancy,Theoretical Active Warps per SM,warp,16,,,,,
0,45327,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(1024, 1, 1)",0,7.5,Occupancy,Theoretical Occupancy,%,50,,,,,
0,45327,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(1024, 1, 1)",0,7.5,Occupancy,Achieved Occupancy,%,35.19,,,,,
0,45327,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(1024, 1, 1)",0,7.5,Occupancy,Achieved Active Warps Per SM,warp,11.26,,,,,
0,45327,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(1024, 1, 1)",0,7.5,Occupancy,,,,AchievedOccupancy,OPT,The difference between calculated theoretical (50.0%) and measured achieved occupancy (35.2%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy.,global,29.63
0,45327,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(1024, 1, 1)",0,7.5,Occupancy,,,,TheoreticalOccupancy,OPT,The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared memory.,global,50.0
0,45327,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(1024, 1, 1)",0,7.5,Source Counters,Branch Instructions Ratio,%,0.08,,,,,
0,45327,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(1024, 1, 1)",0,7.5,Source Counters,Branch Instructions,inst,"1,024",,,,,
0,45327,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(1024, 1, 1)",0,7.5,Source Counters,Branch Efficiency,%,0,,,,,
0,45327,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(1024, 1, 1)",0,7.5,Source Counters,Avg. Divergent Branches,,0,,,,,
0,45414,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(512, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Frequency,cycle/second,"6,109,090,909.09",,,,,
0,45414,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(512, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Frequency,cycle/second,"1,406,960,227.27",,,,,
0,45414,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(512, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Elapsed Cycles,cycle,"4,979",,,,,
0,45414,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(512, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Memory Throughput,%,5.90,,,,,
0,45414,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(512, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Throughput,%,1.21,,,,,
0,45414,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(512, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Duration,nsecond,"3,520",,,,,
0,45414,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(512, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L1/TEX Cache Throughput,%,12.08,,,,,
0,45414,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(512, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L2 Cache Throughput,%,4.37,,,,,
0,45414,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(512, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Active Cycles,cycle,"2,422.36",,,,,
0,45414,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(512, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Compute (SM) Throughput,%,5.90,,,,,
0,45414,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(512, 1, 1)",0,7.5,SpeedOfLight,,,,SOLBottleneck,OPT,This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.,,
0,45414,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(512, 1, 1)",0,7.5,SpeedOfLight_RooflineChart,,,,SOLFPRoofline,INF,The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved  close to 0% of this device's fp32 peak performance and 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.,,
0,45414,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(512, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Active,inst/cycle,0.20,,,,,
0,45414,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(512, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Elapsed,inst/cycle,0.10,,,,,
0,45414,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(512, 1, 1)",0,7.5,Compute Workload Analysis,Issue Slots Busy,%,5.47,,,,,
0,45414,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(512, 1, 1)",0,7.5,Compute Workload Analysis,Issued Ipc Active,inst/cycle,0.22,,,,,
0,45414,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(512, 1, 1)",0,7.5,Compute Workload Analysis,SM Busy,%,5.47,,,,,
0,45414,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(512, 1, 1)",0,7.5,ComputeWorkloadAnalysis,,,,HighPipeUtilization,OPT,All compute pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.,local,96.23
0,45414,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(512, 1, 1)",0,7.5,Memory Workload Analysis,Memory Throughput,byte/second,"2,372,727,272.73",,,,,
0,45414,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(512, 1, 1)",0,7.5,Memory Workload Analysis,Mem Busy,%,3.64,,,,,
0,45414,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(512, 1, 1)",0,7.5,Memory Workload Analysis,Max Bandwidth,%,5.90,,,,,
0,45414,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(512, 1, 1)",0,7.5,Memory Workload Analysis,L1/TEX Hit Rate,%,26.95,,,,,
0,45414,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(512, 1, 1)",0,7.5,Memory Workload Analysis,L2 Hit Rate,%,91.26,,,,,
0,45414,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(512, 1, 1)",0,7.5,Memory Workload Analysis,Mem Pipes Busy,%,5.90,,,,,
0,45414,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(512, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Chart,,,,MemoryL2Compression,WRN,The optional metric lts__average_gcomp_input_sector_success_rate.pct could not be found. Collecting it as an additional metric could enable the rule to provide more guidance.,,
0,45414,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(512, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for loads from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced loads and try to minimize how many cache lines need to be accessed per memory request.",global,1.652
0,45414,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(512, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for stores from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.1 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced stores and try to minimize how many cache lines need to be accessed per memory request.",global,0.8006
0,45414,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(512, 1, 1)",0,7.5,Scheduler Statistics,One or More Eligible,%,6.01,,,,,
0,45414,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(512, 1, 1)",0,7.5,Scheduler Statistics,Issued Warp Per Scheduler,,0.06,,,,,
0,45414,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(512, 1, 1)",0,7.5,Scheduler Statistics,No Eligible,%,93.99,,,,,
0,45414,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(512, 1, 1)",0,7.5,Scheduler Statistics,Active Warps Per Scheduler,warp,3.20,,,,,
0,45414,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(512, 1, 1)",0,7.5,Scheduler Statistics,Eligible Warps Per Scheduler,warp,0.07,,,,,
0,45414,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(512, 1, 1)",0,7.5,SchedulerStats,,,,IssueSlotUtilization,OPT,"Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 16.6 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of 3.20 active warps per scheduler, but only an average of 0.07 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections.",local,93.99
0,45414,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(512, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Issued Instruction,cycle,53.15,,,,,
0,45414,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(512, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Executed Instruction,cycle,59.23,,,,,
0,45414,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(512, 1, 1)",0,7.5,Warp State Statistics,Avg. Active Threads Per Warp,,2,,,,,
0,45414,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(512, 1, 1)",0,7.5,Warp State Statistics,Avg. Not Predicated Off Threads Per Warp,,2,,,,,
0,45414,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(512, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,OPT,"On average, each warp of this kernel spends 27.3 cycles being stalled waiting for a scoreboard dependency on a L1TEX (local, global, surface, texture) operation. Find the instruction producing the data being waited upon to identify the culprit. To reduce the number of cycles waiting on L1TEX data accesses verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit rates by increasing data locality (coalescing), or by changing the cache configuration. Consider moving frequently used data to shared memory. This stall type represents about 51.4% of the total average of 53.2 cycles between issuing two instructions.",global,51.43
0,45414,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(512, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,INF,Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.,,
0,45414,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(512, 1, 1)",0,7.5,WarpStateStats,,,,ThreadDivergence,OPT,"Instructions are executed in warps, which are groups of 32 threads. Optimal instruction throughput is achieved if all 32 threads of a warp execute the same instruction. The chosen launch configuration, early thread completion, and divergent flow control can significantly lower the number of active threads in a warp per cycle. This kernel achieves an average of 2.0 threads being active per cycle.",global,5.534
0,45414,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(512, 1, 1)",0,7.5,Instruction Statistics,Avg. Executed Instructions Per Scheduler,inst,118.86,,,,,
0,45414,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(512, 1, 1)",0,7.5,Instruction Statistics,Executed Instructions,inst,"6,656",,,,,
0,45414,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(512, 1, 1)",0,7.5,Instruction Statistics,Avg. Issued Instructions Per Scheduler,inst,132.45,,,,,
0,45414,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(512, 1, 1)",0,7.5,Instruction Statistics,Issued Instructions,inst,"7,417",,,,,
0,45414,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(512, 1, 1)",0,7.5,InstructionStats,,,,FPInstructions,OPT,"This kernel executes 0 fused and 512 non-fused FP32 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP32 performance could be increased by up to 50% (relative to its current performance). Check the Source page to identify where this kernel executes FP32 instructions.",global,1.887
0,45414,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(512, 1, 1)",0,7.5,Launch Statistics,Block Size,,2,,,,,
0,45414,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(512, 1, 1)",0,7.5,Launch Statistics,Function Cache Configuration,,CachePreferNone,,,,,
0,45414,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(512, 1, 1)",0,7.5,Launch Statistics,Grid Size,,512,,,,,
0,45414,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(512, 1, 1)",0,7.5,Launch Statistics,Registers Per Thread,register/thread,16,,,,,
0,45414,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(512, 1, 1)",0,7.5,Launch Statistics,Shared Memory Configuration Size,byte,"32,768",,,,,
0,45414,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(512, 1, 1)",0,7.5,Launch Statistics,Driver Shared Memory Per Block,byte/block,0,,,,,
0,45414,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(512, 1, 1)",0,7.5,Launch Statistics,Dynamic Shared Memory Per Block,byte/block,0,,,,,
0,45414,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(512, 1, 1)",0,7.5,Launch Statistics,Static Shared Memory Per Block,byte/block,0,,,,,
0,45414,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(512, 1, 1)",0,7.5,Launch Statistics,Threads,thread,"1,024",,,,,
0,45414,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(512, 1, 1)",0,7.5,Launch Statistics,Waves Per SM,,2.29,,,,,
0,45414,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(512, 1, 1)",0,7.5,LaunchStats,,,,LaunchConfiguration,OPT,"Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 2 threads per block. Consequently, some threads in a warp are masked off and those hardware resources are unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256 threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to kernels that frequently call __syncthreads(). See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations.",global,93.75
0,45414,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(512, 1, 1)",0,7.5,LaunchStats,,,,LaunchConfiguration,OPT,"A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical occupancy of the kernel. This kernel launch results in 2 full waves and a partial wave of 63 thread blocks. Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for up to 33.3% of the total kernel runtime with a lower occupancy of 30.5%. Try launching a grid with no partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for a grid. See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations.",global,33.33
0,45414,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(512, 1, 1)",0,7.5,Occupancy,Block Limit SM,block,16,,,,,
0,45414,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(512, 1, 1)",0,7.5,Occupancy,Block Limit Registers,block,128,,,,,
0,45414,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(512, 1, 1)",0,7.5,Occupancy,Block Limit Shared Mem,block,16,,,,,
0,45414,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(512, 1, 1)",0,7.5,Occupancy,Block Limit Warps,block,32,,,,,
0,45414,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(512, 1, 1)",0,7.5,Occupancy,Theoretical Active Warps per SM,warp,16,,,,,
0,45414,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(512, 1, 1)",0,7.5,Occupancy,Theoretical Occupancy,%,50,,,,,
0,45414,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(512, 1, 1)",0,7.5,Occupancy,Achieved Occupancy,%,34.76,,,,,
0,45414,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(512, 1, 1)",0,7.5,Occupancy,Achieved Active Warps Per SM,warp,11.12,,,,,
0,45414,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(512, 1, 1)",0,7.5,Occupancy,,,,AchievedOccupancy,OPT,The difference between calculated theoretical (50.0%) and measured achieved occupancy (34.8%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy.,global,30.47
0,45414,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(512, 1, 1)",0,7.5,Occupancy,,,,TheoreticalOccupancy,OPT,The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared memory.,global,50.0
0,45414,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(512, 1, 1)",0,7.5,Source Counters,Branch Instructions Ratio,%,0.08,,,,,
0,45414,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(512, 1, 1)",0,7.5,Source Counters,Branch Instructions,inst,512,,,,,
0,45414,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(512, 1, 1)",0,7.5,Source Counters,Branch Efficiency,%,0,,,,,
0,45414,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(512, 1, 1)",0,7.5,Source Counters,Avg. Divergent Branches,,0,,,,,
0,45491,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(256, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Frequency,cycle/second,"5,727,272,727.27",,,,,
0,45491,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(256, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Frequency,cycle/second,"1,310,191,761.36",,,,,
0,45491,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(256, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Elapsed Cycles,cycle,"3,698",,,,,
0,45491,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(256, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Memory Throughput,%,3.96,,,,,
0,45491,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(256, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Throughput,%,1.62,,,,,
0,45491,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(256, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Duration,nsecond,"2,816",,,,,
0,45491,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(256, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L1/TEX Cache Throughput,%,8.54,,,,,
0,45491,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(256, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L2 Cache Throughput,%,2.20,,,,,
0,45491,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(256, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Active Cycles,cycle,"1,713.43",,,,,
0,45491,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(256, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Compute (SM) Throughput,%,3.96,,,,,
0,45491,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(256, 1, 1)",0,7.5,SpeedOfLight,,,,SOLBottleneck,OPT,This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.,,
0,45491,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(256, 1, 1)",0,7.5,SpeedOfLight_RooflineChart,,,,SOLFPRoofline,INF,The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved  close to 0% of this device's fp32 peak performance and 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.,,
0,45491,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(256, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Active,inst/cycle,0.14,,,,,
0,45491,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(256, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Elapsed,inst/cycle,0.06,,,,,
0,45491,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(256, 1, 1)",0,7.5,Compute Workload Analysis,Issue Slots Busy,%,4.26,,,,,
0,45491,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(256, 1, 1)",0,7.5,Compute Workload Analysis,Issued Ipc Active,inst/cycle,0.17,,,,,
0,45491,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(256, 1, 1)",0,7.5,Compute Workload Analysis,SM Busy,%,4.26,,,,,
0,45491,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(256, 1, 1)",0,7.5,ComputeWorkloadAnalysis,,,,HighPipeUtilization,OPT,All compute pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.,local,97.33
0,45491,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(256, 1, 1)",0,7.5,Memory Workload Analysis,Memory Throughput,byte/second,"2,965,909,090.91",,,,,
0,45491,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(256, 1, 1)",0,7.5,Memory Workload Analysis,Mem Busy,%,2.20,,,,,
0,45491,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(256, 1, 1)",0,7.5,Memory Workload Analysis,Max Bandwidth,%,3.96,,,,,
0,45491,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(256, 1, 1)",0,7.5,Memory Workload Analysis,L1/TEX Hit Rate,%,44.21,,,,,
0,45491,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(256, 1, 1)",0,7.5,Memory Workload Analysis,L2 Hit Rate,%,76.85,,,,,
0,45491,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(256, 1, 1)",0,7.5,Memory Workload Analysis,Mem Pipes Busy,%,3.96,,,,,
0,45491,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(256, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Chart,,,,MemoryL2Compression,WRN,The optional metric lts__average_gcomp_input_sector_success_rate.pct could not be found. Collecting it as an additional metric could enable the rule to provide more guidance.,,
0,45491,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(256, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for loads from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced loads and try to minimize how many cache lines need to be accessed per memory request.",global,0.8487
0,45491,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(256, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for stores from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced stores and try to minimize how many cache lines need to be accessed per memory request.",global,0.4329
0,45491,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(256, 1, 1)",0,7.5,Scheduler Statistics,One or More Eligible,%,5.21,,,,,
0,45491,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(256, 1, 1)",0,7.5,Scheduler Statistics,Issued Warp Per Scheduler,,0.05,,,,,
0,45491,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(256, 1, 1)",0,7.5,Scheduler Statistics,No Eligible,%,94.79,,,,,
0,45491,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(256, 1, 1)",0,7.5,Scheduler Statistics,Active Warps Per Scheduler,warp,3.07,,,,,
0,45491,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(256, 1, 1)",0,7.5,Scheduler Statistics,Eligible Warps Per Scheduler,warp,0.06,,,,,
0,45491,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(256, 1, 1)",0,7.5,SchedulerStats,,,,IssueSlotUtilization,OPT,"Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 19.2 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of 3.07 active warps per scheduler, but only an average of 0.06 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections.",local,94.79
0,45491,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(256, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Issued Instruction,cycle,58.96,,,,,
0,45491,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(256, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Executed Instruction,cycle,72.49,,,,,
0,45491,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(256, 1, 1)",0,7.5,Warp State Statistics,Avg. Active Threads Per Warp,,4,,,,,
0,45491,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(256, 1, 1)",0,7.5,Warp State Statistics,Avg. Not Predicated Off Threads Per Warp,,4,,,,,
0,45491,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(256, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,OPT,"On average, each warp of this kernel spends 25.7 cycles being stalled waiting for an immediate constant cache (IMC) miss. A read from constant memory costs one memory read from device memory only on a cache miss; otherwise, it just costs one read from the constant cache. Immediate constants are encoded into the SASS instruction as 'c[bank][offset]'. Accesses to different addresses by threads within a warp are serialized, thus the cost scales linearly with the number of unique addresses read by all threads within a warp. As such, the constant cache is best when threads in the same warp access only a few distinct locations. If all threads of a warp access the same location, then constant memory can be as fast as a register access. This stall type represents about 43.5% of the total average of 59.0 cycles between issuing two instructions.",global,43.55
0,45491,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(256, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,OPT,"On average, each warp of this kernel spends 24.9 cycles being stalled waiting for a scoreboard dependency on a L1TEX (local, global, surface, texture) operation. Find the instruction producing the data being waited upon to identify the culprit. To reduce the number of cycles waiting on L1TEX data accesses verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit rates by increasing data locality (coalescing), or by changing the cache configuration. Consider moving frequently used data to shared memory. This stall type represents about 42.2% of the total average of 59.0 cycles between issuing two instructions.",global,42.23
0,45491,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(256, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,INF,Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.,,
0,45491,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(256, 1, 1)",0,7.5,WarpStateStats,,,,ThreadDivergence,OPT,"Instructions are executed in warps, which are groups of 32 threads. Optimal instruction throughput is achieved if all 32 threads of a warp execute the same instruction. The chosen launch configuration, early thread completion, and divergent flow control can significantly lower the number of active threads in a warp per cycle. This kernel achieves an average of 4.0 threads being active per cycle.",global,3.468
0,45491,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(256, 1, 1)",0,7.5,Instruction Statistics,Avg. Executed Instructions Per Scheduler,inst,59.43,,,,,
0,45491,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(256, 1, 1)",0,7.5,Instruction Statistics,Executed Instructions,inst,"3,328",,,,,
0,45491,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(256, 1, 1)",0,7.5,Instruction Statistics,Avg. Issued Instructions Per Scheduler,inst,73.07,,,,,
0,45491,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(256, 1, 1)",0,7.5,Instruction Statistics,Issued Instructions,inst,"4,092",,,,,
0,45491,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(256, 1, 1)",0,7.5,InstructionStats,,,,FPInstructions,OPT,"This kernel executes 0 fused and 256 non-fused FP32 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP32 performance could be increased by up to 50% (relative to its current performance). Check the Source page to identify where this kernel executes FP32 instructions.",global,1.334
0,45491,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(256, 1, 1)",0,7.5,Launch Statistics,Block Size,,4,,,,,
0,45491,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(256, 1, 1)",0,7.5,Launch Statistics,Function Cache Configuration,,CachePreferNone,,,,,
0,45491,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(256, 1, 1)",0,7.5,Launch Statistics,Grid Size,,256,,,,,
0,45491,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(256, 1, 1)",0,7.5,Launch Statistics,Registers Per Thread,register/thread,16,,,,,
0,45491,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(256, 1, 1)",0,7.5,Launch Statistics,Shared Memory Configuration Size,byte,"32,768",,,,,
0,45491,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(256, 1, 1)",0,7.5,Launch Statistics,Driver Shared Memory Per Block,byte/block,0,,,,,
0,45491,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(256, 1, 1)",0,7.5,Launch Statistics,Dynamic Shared Memory Per Block,byte/block,0,,,,,
0,45491,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(256, 1, 1)",0,7.5,Launch Statistics,Static Shared Memory Per Block,byte/block,0,,,,,
0,45491,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(256, 1, 1)",0,7.5,Launch Statistics,Threads,thread,"1,024",,,,,
0,45491,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(256, 1, 1)",0,7.5,Launch Statistics,Waves Per SM,,1.14,,,,,
0,45491,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(256, 1, 1)",0,7.5,LaunchStats,,,,LaunchConfiguration,OPT,"Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 4 threads per block. Consequently, some threads in a warp are masked off and those hardware resources are unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256 threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to kernels that frequently call __syncthreads(). See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations.",global,87.5
0,45491,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(256, 1, 1)",0,7.5,LaunchStats,,,,LaunchConfiguration,OPT,"A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical occupancy of the kernel. This kernel launch results in 1 full waves and a partial wave of 31 thread blocks. Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for up to 50.0% of the total kernel runtime with a lower occupancy of 34.3%. Try launching a grid with no partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for a grid. See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations.",global,50.0
0,45491,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(256, 1, 1)",0,7.5,Occupancy,Block Limit SM,block,16,,,,,
0,45491,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(256, 1, 1)",0,7.5,Occupancy,Block Limit Registers,block,128,,,,,
0,45491,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(256, 1, 1)",0,7.5,Occupancy,Block Limit Shared Mem,block,16,,,,,
0,45491,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(256, 1, 1)",0,7.5,Occupancy,Block Limit Warps,block,32,,,,,
0,45491,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(256, 1, 1)",0,7.5,Occupancy,Theoretical Active Warps per SM,warp,16,,,,,
0,45491,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(256, 1, 1)",0,7.5,Occupancy,Theoretical Occupancy,%,50,,,,,
0,45491,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(256, 1, 1)",0,7.5,Occupancy,Achieved Occupancy,%,32.86,,,,,
0,45491,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(256, 1, 1)",0,7.5,Occupancy,Achieved Active Warps Per SM,warp,10.52,,,,,
0,45491,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(256, 1, 1)",0,7.5,Occupancy,,,,AchievedOccupancy,OPT,The difference between calculated theoretical (50.0%) and measured achieved occupancy (32.9%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy.,global,34.28
0,45491,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(256, 1, 1)",0,7.5,Occupancy,,,,TheoreticalOccupancy,OPT,The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared memory.,global,50.0
0,45491,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(256, 1, 1)",0,7.5,Source Counters,Branch Instructions Ratio,%,0.08,,,,,
0,45491,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(256, 1, 1)",0,7.5,Source Counters,Branch Instructions,inst,256,,,,,
0,45491,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(256, 1, 1)",0,7.5,Source Counters,Branch Efficiency,%,0,,,,,
0,45491,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(256, 1, 1)",0,7.5,Source Counters,Avg. Divergent Branches,,0,,,,,
0,45576,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(128, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Frequency,cycle/second,"5,408,450,704.23",,,,,
0,45576,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(128, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Frequency,cycle/second,"1,241,197,183.10",,,,,
0,45576,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(128, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Elapsed Cycles,cycle,"2,830",,,,,
0,45576,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(128, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Memory Throughput,%,2.59,,,,,
0,45576,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(128, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Throughput,%,2.12,,,,,
0,45576,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(128, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Duration,nsecond,"2,272",,,,,
0,45576,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(128, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L1/TEX Cache Throughput,%,6.22,,,,,
0,45576,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(128, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L2 Cache Throughput,%,2.57,,,,,
0,45576,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(128, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Active Cycles,cycle,"1,175.36",,,,,
0,45576,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(128, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Compute (SM) Throughput,%,2.59,,,,,
0,45576,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(128, 1, 1)",0,7.5,SpeedOfLight,,,,SOLBottleneck,OPT,"This kernel grid is too small to fill the available resources on this device, resulting in only 0.6 full waves across all SMs. Look at Launch Statistics for more details.",,
0,45576,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(128, 1, 1)",0,7.5,SpeedOfLight_RooflineChart,,,,SOLFPRoofline,INF,The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved  close to 0% of this device's fp32 peak performance and 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.,,
0,45576,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(128, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Active,inst/cycle,0.10,,,,,
0,45576,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(128, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Elapsed,inst/cycle,0.04,,,,,
0,45576,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(128, 1, 1)",0,7.5,Compute Workload Analysis,Issue Slots Busy,%,3.31,,,,,
0,45576,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(128, 1, 1)",0,7.5,Compute Workload Analysis,Issued Ipc Active,inst/cycle,0.13,,,,,
0,45576,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(128, 1, 1)",0,7.5,Compute Workload Analysis,SM Busy,%,3.31,,,,,
0,45576,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(128, 1, 1)",0,7.5,ComputeWorkloadAnalysis,,,,HighPipeUtilization,OPT,All compute pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.,local,98.06
0,45576,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(128, 1, 1)",0,7.5,Memory Workload Analysis,Memory Throughput,byte/second,"3,676,056,338.03",,,,,
0,45576,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(128, 1, 1)",0,7.5,Memory Workload Analysis,Mem Busy,%,2.57,,,,,
0,45576,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(128, 1, 1)",0,7.5,Memory Workload Analysis,Max Bandwidth,%,2.59,,,,,
0,45576,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(128, 1, 1)",0,7.5,Memory Workload Analysis,L1/TEX Hit Rate,%,12.76,,,,,
0,45576,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(128, 1, 1)",0,7.5,Memory Workload Analysis,L2 Hit Rate,%,61.40,,,,,
0,45576,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(128, 1, 1)",0,7.5,Memory Workload Analysis,Mem Pipes Busy,%,2.59,,,,,
0,45576,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(128, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Chart,,,,MemoryL2Compression,WRN,The optional metric lts__average_gcomp_input_sector_success_rate.pct could not be found. Collecting it as an additional metric could enable the rule to provide more guidance.,,
0,45576,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(128, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for loads from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.5 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced loads and try to minimize how many cache lines need to be accessed per memory request.",global,0.8271
0,45576,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(128, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for stores from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.4 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced stores and try to minimize how many cache lines need to be accessed per memory request.",global,0.4159
0,45576,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(128, 1, 1)",0,7.5,Scheduler Statistics,One or More Eligible,%,3.46,,,,,
0,45576,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(128, 1, 1)",0,7.5,Scheduler Statistics,Issued Warp Per Scheduler,,0.03,,,,,
0,45576,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(128, 1, 1)",0,7.5,Scheduler Statistics,No Eligible,%,96.54,,,,,
0,45576,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(128, 1, 1)",0,7.5,Scheduler Statistics,Active Warps Per Scheduler,warp,2.29,,,,,
0,45576,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(128, 1, 1)",0,7.5,Scheduler Statistics,Eligible Warps Per Scheduler,warp,0.04,,,,,
0,45576,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(128, 1, 1)",0,7.5,SchedulerStats,,,,IssueSlotUtilization,OPT,"Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 28.9 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of 2.29 active warps per scheduler, but only an average of 0.04 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections.",local,96.54
0,45576,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(128, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Issued Instruction,cycle,66.24,,,,,
0,45576,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(128, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Executed Instruction,cycle,86.63,,,,,
0,45576,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(128, 1, 1)",0,7.5,Warp State Statistics,Avg. Active Threads Per Warp,,8,,,,,
0,45576,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(128, 1, 1)",0,7.5,Warp State Statistics,Avg. Not Predicated Off Threads Per Warp,,8,,,,,
0,45576,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(128, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,OPT,"On average, each warp of this kernel spends 30.7 cycles being stalled waiting for an immediate constant cache (IMC) miss. A read from constant memory costs one memory read from device memory only on a cache miss; otherwise, it just costs one read from the constant cache. Immediate constants are encoded into the SASS instruction as 'c[bank][offset]'. Accesses to different addresses by threads within a warp are serialized, thus the cost scales linearly with the number of unique addresses read by all threads within a warp. As such, the constant cache is best when threads in the same warp access only a few distinct locations. If all threads of a warp access the same location, then constant memory can be as fast as a register access. This stall type represents about 46.4% of the total average of 66.2 cycles between issuing two instructions.",global,46.4
0,45576,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(128, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,OPT,"On average, each warp of this kernel spends 24.5 cycles being stalled waiting for a scoreboard dependency on a L1TEX (local, global, surface, texture) operation. Find the instruction producing the data being waited upon to identify the culprit. To reduce the number of cycles waiting on L1TEX data accesses verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit rates by increasing data locality (coalescing), or by changing the cache configuration. Consider moving frequently used data to shared memory. This stall type represents about 37.0% of the total average of 66.2 cycles between issuing two instructions.",global,37.04
0,45576,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(128, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,INF,Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.,,
0,45576,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(128, 1, 1)",0,7.5,WarpStateStats,,,,ThreadDivergence,OPT,"Instructions are executed in warps, which are groups of 32 threads. Optimal instruction throughput is achieved if all 32 threads of a warp execute the same instruction. The chosen launch configuration, early thread completion, and divergent flow control can significantly lower the number of active threads in a warp per cycle. This kernel achieves an average of 8.0 threads being active per cycle.",global,1.944
0,45576,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(128, 1, 1)",0,7.5,Instruction Statistics,Avg. Executed Instructions Per Scheduler,inst,29.71,,,,,
0,45576,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(128, 1, 1)",0,7.5,Instruction Statistics,Executed Instructions,inst,"1,664",,,,,
0,45576,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(128, 1, 1)",0,7.5,Instruction Statistics,Avg. Issued Instructions Per Scheduler,inst,38.86,,,,,
0,45576,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(128, 1, 1)",0,7.5,Instruction Statistics,Issued Instructions,inst,"2,176",,,,,
0,45576,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(128, 1, 1)",0,7.5,InstructionStats,,,,FPInstructions,OPT,"This kernel executes 0 fused and 128 non-fused FP32 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP32 performance could be increased by up to 50% (relative to its current performance). Check the Source page to identify where this kernel executes FP32 instructions.",global,0.9723
0,45576,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(128, 1, 1)",0,7.5,Launch Statistics,Block Size,,8,,,,,
0,45576,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(128, 1, 1)",0,7.5,Launch Statistics,Function Cache Configuration,,CachePreferNone,,,,,
0,45576,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(128, 1, 1)",0,7.5,Launch Statistics,Grid Size,,128,,,,,
0,45576,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(128, 1, 1)",0,7.5,Launch Statistics,Registers Per Thread,register/thread,16,,,,,
0,45576,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(128, 1, 1)",0,7.5,Launch Statistics,Shared Memory Configuration Size,byte,"32,768",,,,,
0,45576,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(128, 1, 1)",0,7.5,Launch Statistics,Driver Shared Memory Per Block,byte/block,0,,,,,
0,45576,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(128, 1, 1)",0,7.5,Launch Statistics,Dynamic Shared Memory Per Block,byte/block,0,,,,,
0,45576,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(128, 1, 1)",0,7.5,Launch Statistics,Static Shared Memory Per Block,byte/block,0,,,,,
0,45576,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(128, 1, 1)",0,7.5,Launch Statistics,Threads,thread,"1,024",,,,,
0,45576,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(128, 1, 1)",0,7.5,Launch Statistics,Waves Per SM,,0.57,,,,,
0,45576,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(128, 1, 1)",0,7.5,LaunchStats,,,,LaunchConfiguration,OPT,"Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 8 threads per block. Consequently, some threads in a warp are masked off and those hardware resources are unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256 threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to kernels that frequently call __syncthreads(). See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations.",global,75.0
0,45576,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(128, 1, 1)",0,7.5,Occupancy,Block Limit SM,block,16,,,,,
0,45576,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(128, 1, 1)",0,7.5,Occupancy,Block Limit Registers,block,128,,,,,
0,45576,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(128, 1, 1)",0,7.5,Occupancy,Block Limit Shared Mem,block,16,,,,,
0,45576,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(128, 1, 1)",0,7.5,Occupancy,Block Limit Warps,block,32,,,,,
0,45576,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(128, 1, 1)",0,7.5,Occupancy,Theoretical Active Warps per SM,warp,16,,,,,
0,45576,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(128, 1, 1)",0,7.5,Occupancy,Theoretical Occupancy,%,50,,,,,
0,45576,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(128, 1, 1)",0,7.5,Occupancy,Achieved Occupancy,%,26.73,,,,,
0,45576,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(128, 1, 1)",0,7.5,Occupancy,Achieved Active Warps Per SM,warp,8.55,,,,,
0,45576,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(128, 1, 1)",0,7.5,Occupancy,,,,AchievedOccupancy,OPT,The difference between calculated theoretical (50.0%) and measured achieved occupancy (26.7%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy.,global,46.54
0,45576,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(128, 1, 1)",0,7.5,Occupancy,,,,TheoreticalOccupancy,OPT,The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared memory.,global,50.0
0,45576,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(128, 1, 1)",0,7.5,Source Counters,Branch Instructions Ratio,%,0.08,,,,,
0,45576,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(128, 1, 1)",0,7.5,Source Counters,Branch Instructions,inst,128,,,,,
0,45576,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(128, 1, 1)",0,7.5,Source Counters,Branch Efficiency,%,0,,,,,
0,45576,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(128, 1, 1)",0,7.5,Source Counters,Avg. Divergent Branches,,0,,,,,
0,45653,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(64, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Frequency,cycle/second,"5,587,301,587.30",,,,,
0,45653,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(64, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Frequency,cycle/second,"1,300,595,238.10",,,,,
0,45653,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(64, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Elapsed Cycles,cycle,"2,637",,,,,
0,45653,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(64, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Memory Throughput,%,2.76,,,,,
0,45653,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(64, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Throughput,%,2.32,,,,,
0,45653,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(64, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Duration,nsecond,"2,016",,,,,
0,45653,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(64, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L1/TEX Cache Throughput,%,3.15,,,,,
0,45653,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(64, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L2 Cache Throughput,%,2.76,,,,,
0,45653,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(64, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Active Cycles,cycle,"1,160",,,,,
0,45653,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(64, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Compute (SM) Throughput,%,1.39,,,,,
0,45653,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(64, 1, 1)",0,7.5,SpeedOfLight,,,,SOLBottleneck,OPT,"This kernel grid is too small to fill the available resources on this device, resulting in only 0.3 full waves across all SMs. Look at Launch Statistics for more details.",,
0,45653,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(64, 1, 1)",0,7.5,SpeedOfLight_RooflineChart,,,,SOLFPRoofline,INF,The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved  close to 0% of this device's fp32 peak performance and 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.,,
0,45653,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(64, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Active,inst/cycle,0.05,,,,,
0,45653,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(64, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Elapsed,inst/cycle,0.02,,,,,
0,45653,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(64, 1, 1)",0,7.5,Compute Workload Analysis,Issue Slots Busy,%,1.67,,,,,
0,45653,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(64, 1, 1)",0,7.5,Compute Workload Analysis,Issued Ipc Active,inst/cycle,0.07,,,,,
0,45653,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(64, 1, 1)",0,7.5,Compute Workload Analysis,SM Busy,%,1.67,,,,,
0,45653,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(64, 1, 1)",0,7.5,ComputeWorkloadAnalysis,,,,HighPipeUtilization,OPT,All compute pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.,local,99.01
0,45653,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(64, 1, 1)",0,7.5,Memory Workload Analysis,Memory Throughput,byte/second,"4,142,857,142.86",,,,,
0,45653,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(64, 1, 1)",0,7.5,Memory Workload Analysis,Mem Busy,%,2.76,,,,,
0,45653,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(64, 1, 1)",0,7.5,Memory Workload Analysis,Max Bandwidth,%,2.32,,,,,
0,45653,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(64, 1, 1)",0,7.5,Memory Workload Analysis,L1/TEX Hit Rate,%,8.85,,,,,
0,45653,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(64, 1, 1)",0,7.5,Memory Workload Analysis,L2 Hit Rate,%,55.66,,,,,
0,45653,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(64, 1, 1)",0,7.5,Memory Workload Analysis,Mem Pipes Busy,%,1.39,,,,,
0,45653,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(64, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Chart,,,,MemoryL2Compression,WRN,The optional metric lts__average_gcomp_input_sector_success_rate.pct could not be found. Collecting it as an additional metric could enable the rule to provide more guidance.,,
0,45653,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(64, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for loads from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 2.5 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced loads and try to minimize how many cache lines need to be accessed per memory request.",global,0.5344
0,45653,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(64, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for stores from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 2.3 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced stores and try to minimize how many cache lines need to be accessed per memory request.",global,0.2917
0,45653,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(64, 1, 1)",0,7.5,Scheduler Statistics,One or More Eligible,%,1.79,,,,,
0,45653,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(64, 1, 1)",0,7.5,Scheduler Statistics,Issued Warp Per Scheduler,,0.02,,,,,
0,45653,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(64, 1, 1)",0,7.5,Scheduler Statistics,No Eligible,%,98.21,,,,,
0,45653,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(64, 1, 1)",0,7.5,Scheduler Statistics,Active Warps Per Scheduler,warp,1.15,,,,,
0,45653,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(64, 1, 1)",0,7.5,Scheduler Statistics,Eligible Warps Per Scheduler,warp,0.02,,,,,
0,45653,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(64, 1, 1)",0,7.5,SchedulerStats,,,,IssueSlotUtilization,OPT,"Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 55.9 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of 1.15 active warps per scheduler, but only an average of 0.02 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections.",local,97.24
0,45653,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(64, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Issued Instruction,cycle,64.04,,,,,
0,45653,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(64, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Executed Instruction,cycle,83.74,,,,,
0,45653,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(64, 1, 1)",0,7.5,Warp State Statistics,Avg. Active Threads Per Warp,,16,,,,,
0,45653,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(64, 1, 1)",0,7.5,Warp State Statistics,Avg. Not Predicated Off Threads Per Warp,,16,,,,,
0,45653,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(64, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,OPT,"On average, each warp of this kernel spends 33.4 cycles being stalled waiting for an immediate constant cache (IMC) miss. A read from constant memory costs one memory read from device memory only on a cache miss; otherwise, it just costs one read from the constant cache. Immediate constants are encoded into the SASS instruction as 'c[bank][offset]'. Accesses to different addresses by threads within a warp are serialized, thus the cost scales linearly with the number of unique addresses read by all threads within a warp. As such, the constant cache is best when threads in the same warp access only a few distinct locations. If all threads of a warp access the same location, then constant memory can be as fast as a register access. This stall type represents about 52.2% of the total average of 64.0 cycles between issuing two instructions.",global,52.21
0,45653,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(64, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,OPT,"On average, each warp of this kernel spends 24.3 cycles being stalled waiting for a scoreboard dependency on a L1TEX (local, global, surface, texture) operation. Find the instruction producing the data being waited upon to identify the culprit. To reduce the number of cycles waiting on L1TEX data accesses verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit rates by increasing data locality (coalescing), or by changing the cache configuration. Consider moving frequently used data to shared memory. This stall type represents about 38.0% of the total average of 64.0 cycles between issuing two instructions.",global,37.96
0,45653,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(64, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,INF,Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.,,
0,45653,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(64, 1, 1)",0,7.5,WarpStateStats,,,,ThreadDivergence,OPT,"Instructions are executed in warps, which are groups of 32 threads. Optimal instruction throughput is achieved if all 32 threads of a warp execute the same instruction. The chosen launch configuration, early thread completion, and divergent flow control can significantly lower the number of active threads in a warp per cycle. This kernel achieves an average of 16.0 threads being active per cycle.",global,0.6968
0,45653,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(64, 1, 1)",0,7.5,Instruction Statistics,Avg. Executed Instructions Per Scheduler,inst,14.86,,,,,
0,45653,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(64, 1, 1)",0,7.5,Instruction Statistics,Executed Instructions,inst,832,,,,,
0,45653,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(64, 1, 1)",0,7.5,Instruction Statistics,Avg. Issued Instructions Per Scheduler,inst,19.43,,,,,
0,45653,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(64, 1, 1)",0,7.5,Instruction Statistics,Issued Instructions,inst,"1,088",,,,,
0,45653,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(64, 1, 1)",0,7.5,InstructionStats,,,,FPInstructions,OPT,"This kernel executes 0 fused and 64 non-fused FP32 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP32 performance could be increased by up to 50% (relative to its current performance). Check the Source page to identify where this kernel executes FP32 instructions.",global,0.4926
0,45653,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(64, 1, 1)",0,7.5,Launch Statistics,Block Size,,16,,,,,
0,45653,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(64, 1, 1)",0,7.5,Launch Statistics,Function Cache Configuration,,CachePreferNone,,,,,
0,45653,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(64, 1, 1)",0,7.5,Launch Statistics,Grid Size,,64,,,,,
0,45653,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(64, 1, 1)",0,7.5,Launch Statistics,Registers Per Thread,register/thread,16,,,,,
0,45653,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(64, 1, 1)",0,7.5,Launch Statistics,Shared Memory Configuration Size,byte,"32,768",,,,,
0,45653,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(64, 1, 1)",0,7.5,Launch Statistics,Driver Shared Memory Per Block,byte/block,0,,,,,
0,45653,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(64, 1, 1)",0,7.5,Launch Statistics,Dynamic Shared Memory Per Block,byte/block,0,,,,,
0,45653,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(64, 1, 1)",0,7.5,Launch Statistics,Static Shared Memory Per Block,byte/block,0,,,,,
0,45653,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(64, 1, 1)",0,7.5,Launch Statistics,Threads,thread,"1,024",,,,,
0,45653,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(64, 1, 1)",0,7.5,Launch Statistics,Waves Per SM,,0.29,,,,,
0,45653,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(64, 1, 1)",0,7.5,LaunchStats,,,,LaunchConfiguration,OPT,"Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 16 threads per block. Consequently, some threads in a warp are masked off and those hardware resources are unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256 threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to kernels that frequently call __syncthreads(). See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations.",global,50.0
0,45653,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(64, 1, 1)",0,7.5,Occupancy,Block Limit SM,block,16,,,,,
0,45653,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(64, 1, 1)",0,7.5,Occupancy,Block Limit Registers,block,128,,,,,
0,45653,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(64, 1, 1)",0,7.5,Occupancy,Block Limit Shared Mem,block,16,,,,,
0,45653,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(64, 1, 1)",0,7.5,Occupancy,Block Limit Warps,block,32,,,,,
0,45653,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(64, 1, 1)",0,7.5,Occupancy,Theoretical Active Warps per SM,warp,16,,,,,
0,45653,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(64, 1, 1)",0,7.5,Occupancy,Theoretical Occupancy,%,50,,,,,
0,45653,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(64, 1, 1)",0,7.5,Occupancy,Achieved Occupancy,%,13.90,,,,,
0,45653,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(64, 1, 1)",0,7.5,Occupancy,Achieved Active Warps Per SM,warp,4.45,,,,,
0,45653,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(64, 1, 1)",0,7.5,Occupancy,,,,AchievedOccupancy,OPT,The difference between calculated theoretical (50.0%) and measured achieved occupancy (13.9%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy.,global,72.2
0,45653,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(64, 1, 1)",0,7.5,Occupancy,,,,TheoreticalOccupancy,OPT,The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared memory.,global,50.0
0,45653,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(64, 1, 1)",0,7.5,Source Counters,Branch Instructions Ratio,%,0.08,,,,,
0,45653,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(64, 1, 1)",0,7.5,Source Counters,Branch Instructions,inst,64,,,,,
0,45653,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(64, 1, 1)",0,7.5,Source Counters,Branch Efficiency,%,0,,,,,
0,45653,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(64, 1, 1)",0,7.5,Source Counters,Avg. Divergent Branches,,0,,,,,
0,45738,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(32, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Frequency,cycle/second,"6,032,786,885.25",,,,,
0,45738,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(32, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Frequency,cycle/second,"1,396,772,540.98",,,,,
0,45738,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(32, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Elapsed Cycles,cycle,"2,731",,,,,
0,45738,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(32, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Memory Throughput,%,2.63,,,,,
0,45738,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(32, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Throughput,%,2.22,,,,,
0,45738,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(32, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Duration,nsecond,"1,952",,,,,
0,45738,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(32, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L1/TEX Cache Throughput,%,1.58,,,,,
0,45738,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(32, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L2 Cache Throughput,%,2.63,,,,,
0,45738,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(32, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Active Cycles,cycle,"1,155.71",,,,,
0,45738,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(32, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Compute (SM) Throughput,%,0.67,,,,,
0,45738,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(32, 1, 1)",0,7.5,SpeedOfLight,,,,SOLBottleneck,OPT,"This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full waves across all SMs. Look at Launch Statistics for more details.",,
0,45738,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(32, 1, 1)",0,7.5,SpeedOfLight_RooflineChart,,,,SOLFPRoofline,INF,The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved  close to 0% of this device's fp32 peak performance and 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.,,
0,45738,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(32, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Active,inst/cycle,0.03,,,,,
0,45738,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(32, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Elapsed,inst/cycle,0.01,,,,,
0,45738,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(32, 1, 1)",0,7.5,Compute Workload Analysis,Issue Slots Busy,%,0.84,,,,,
0,45738,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(32, 1, 1)",0,7.5,Compute Workload Analysis,Issued Ipc Active,inst/cycle,0.03,,,,,
0,45738,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(32, 1, 1)",0,7.5,Compute Workload Analysis,SM Busy,%,0.84,,,,,
0,45738,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(32, 1, 1)",0,7.5,ComputeWorkloadAnalysis,,,,HighPipeUtilization,OPT,All compute pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.,local,99.51
0,45738,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(32, 1, 1)",0,7.5,Memory Workload Analysis,Memory Throughput,byte/second,"4,278,688,524.59",,,,,
0,45738,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(32, 1, 1)",0,7.5,Memory Workload Analysis,Mem Busy,%,2.63,,,,,
0,45738,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(32, 1, 1)",0,7.5,Memory Workload Analysis,Max Bandwidth,%,2.22,,,,,
0,45738,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(32, 1, 1)",0,7.5,Memory Workload Analysis,L1/TEX Hit Rate,%,0,,,,,
0,45738,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(32, 1, 1)",0,7.5,Memory Workload Analysis,L2 Hit Rate,%,52.99,,,,,
0,45738,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(32, 1, 1)",0,7.5,Memory Workload Analysis,Mem Pipes Busy,%,0.67,,,,,
0,45738,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(32, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Chart,,,,MemoryL2Compression,WRN,The optional metric lts__average_gcomp_input_sector_success_rate.pct could not be found. Collecting it as an additional metric could enable the rule to provide more guidance.,,
0,45738,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(32, 1, 1)",0,7.5,Scheduler Statistics,One or More Eligible,%,1.53,,,,,
0,45738,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(32, 1, 1)",0,7.5,Scheduler Statistics,Issued Warp Per Scheduler,,0.02,,,,,
0,45738,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(32, 1, 1)",0,7.5,Scheduler Statistics,No Eligible,%,98.47,,,,,
0,45738,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(32, 1, 1)",0,7.5,Scheduler Statistics,Active Warps Per Scheduler,warp,0.99,,,,,
0,45738,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(32, 1, 1)",0,7.5,Scheduler Statistics,Eligible Warps Per Scheduler,warp,0.02,,,,,
0,45738,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(32, 1, 1)",0,7.5,SchedulerStats,,,,IssueSlotUtilization,OPT,"Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 65.3 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of 0.99 active warps per scheduler, which already limits the scheduler to less than a warp per instruction.",local,97.37
0,45738,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(32, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Issued Instruction,cycle,64.76,,,,,
0,45738,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(32, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Executed Instruction,cycle,84.68,,,,,
0,45738,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(32, 1, 1)",0,7.5,Warp State Statistics,Avg. Active Threads Per Warp,,32,,,,,
0,45738,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(32, 1, 1)",0,7.5,Warp State Statistics,Avg. Not Predicated Off Threads Per Warp,,32,,,,,
0,45738,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(32, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,OPT,"On average, each warp of this kernel spends 33.6 cycles being stalled waiting for an immediate constant cache (IMC) miss. A read from constant memory costs one memory read from device memory only on a cache miss; otherwise, it just costs one read from the constant cache. Immediate constants are encoded into the SASS instruction as 'c[bank][offset]'. Accesses to different addresses by threads within a warp are serialized, thus the cost scales linearly with the number of unique addresses read by all threads within a warp. As such, the constant cache is best when threads in the same warp access only a few distinct locations. If all threads of a warp access the same location, then constant memory can be as fast as a register access. This stall type represents about 51.9% of the total average of 64.8 cycles between issuing two instructions.",global,51.91
0,45738,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(32, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,OPT,"On average, each warp of this kernel spends 26.7 cycles being stalled waiting for a scoreboard dependency on a L1TEX (local, global, surface, texture) operation. Find the instruction producing the data being waited upon to identify the culprit. To reduce the number of cycles waiting on L1TEX data accesses verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit rates by increasing data locality (coalescing), or by changing the cache configuration. Consider moving frequently used data to shared memory. This stall type represents about 41.2% of the total average of 64.8 cycles between issuing two instructions.",global,41.25
0,45738,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(32, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,INF,Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.,,
0,45738,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(32, 1, 1)",0,7.5,Instruction Statistics,Avg. Executed Instructions Per Scheduler,inst,7.43,,,,,
0,45738,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(32, 1, 1)",0,7.5,Instruction Statistics,Executed Instructions,inst,416,,,,,
0,45738,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(32, 1, 1)",0,7.5,Instruction Statistics,Avg. Issued Instructions Per Scheduler,inst,9.71,,,,,
0,45738,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(32, 1, 1)",0,7.5,Instruction Statistics,Issued Instructions,inst,544,,,,,
0,45738,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(32, 1, 1)",0,7.5,InstructionStats,,,,FPInstructions,OPT,"This kernel executes 0 fused and 32 non-fused FP32 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP32 performance could be increased by up to 50% (relative to its current performance). Check the Source page to identify where this kernel executes FP32 instructions.",global,0.2472
0,45738,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(32, 1, 1)",0,7.5,Launch Statistics,Block Size,,32,,,,,
0,45738,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(32, 1, 1)",0,7.5,Launch Statistics,Function Cache Configuration,,CachePreferNone,,,,,
0,45738,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(32, 1, 1)",0,7.5,Launch Statistics,Grid Size,,32,,,,,
0,45738,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(32, 1, 1)",0,7.5,Launch Statistics,Registers Per Thread,register/thread,16,,,,,
0,45738,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(32, 1, 1)",0,7.5,Launch Statistics,Shared Memory Configuration Size,byte,"32,768",,,,,
0,45738,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(32, 1, 1)",0,7.5,Launch Statistics,Driver Shared Memory Per Block,byte/block,0,,,,,
0,45738,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(32, 1, 1)",0,7.5,Launch Statistics,Dynamic Shared Memory Per Block,byte/block,0,,,,,
0,45738,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(32, 1, 1)",0,7.5,Launch Statistics,Static Shared Memory Per Block,byte/block,0,,,,,
0,45738,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(32, 1, 1)",0,7.5,Launch Statistics,Threads,thread,"1,024",,,,,
0,45738,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(32, 1, 1)",0,7.5,Launch Statistics,Waves Per SM,,0.14,,,,,
0,45738,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(32, 1, 1)",0,7.5,Occupancy,Block Limit SM,block,16,,,,,
0,45738,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(32, 1, 1)",0,7.5,Occupancy,Block Limit Registers,block,128,,,,,
0,45738,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(32, 1, 1)",0,7.5,Occupancy,Block Limit Shared Mem,block,16,,,,,
0,45738,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(32, 1, 1)",0,7.5,Occupancy,Block Limit Warps,block,32,,,,,
0,45738,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(32, 1, 1)",0,7.5,Occupancy,Theoretical Active Warps per SM,warp,16,,,,,
0,45738,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(32, 1, 1)",0,7.5,Occupancy,Theoretical Occupancy,%,50,,,,,
0,45738,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(32, 1, 1)",0,7.5,Occupancy,Achieved Occupancy,%,7.05,,,,,
0,45738,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(32, 1, 1)",0,7.5,Occupancy,Achieved Active Warps Per SM,warp,2.25,,,,,
0,45738,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(32, 1, 1)",0,7.5,Occupancy,,,,AchievedOccupancy,OPT,The difference between calculated theoretical (50.0%) and measured achieved occupancy (7.0%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy.,global,85.91
0,45738,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(32, 1, 1)",0,7.5,Occupancy,,,,TheoreticalOccupancy,OPT,The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared memory.,global,50.0
0,45738,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(32, 1, 1)",0,7.5,Source Counters,Branch Instructions Ratio,%,0.08,,,,,
0,45738,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(32, 1, 1)",0,7.5,Source Counters,Branch Instructions,inst,32,,,,,
0,45738,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(32, 1, 1)",0,7.5,Source Counters,Branch Efficiency,%,0,,,,,
0,45738,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(32, 1, 1)",0,7.5,Source Counters,Avg. Divergent Branches,,0,,,,,
0,45833,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(16, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Frequency,cycle/second,"5,466,666,666.67",,,,,
0,45833,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(16, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Frequency,cycle/second,"1,295,052,083.33",,,,,
0,45833,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(16, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Elapsed Cycles,cycle,"2,495",,,,,
0,45833,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(16, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Memory Throughput,%,2.80,,,,,
0,45833,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(16, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Throughput,%,2.49,,,,,
0,45833,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(16, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Duration,nsecond,"1,920",,,,,
0,45833,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(16, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L1/TEX Cache Throughput,%,1.58,,,,,
0,45833,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(16, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L2 Cache Throughput,%,2.80,,,,,
0,45833,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(16, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Active Cycles,cycle,"1,157.57",,,,,
0,45833,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(16, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Compute (SM) Throughput,%,0.74,,,,,
0,45833,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(16, 1, 1)",0,7.5,SpeedOfLight,,,,SOLBottleneck,OPT,"This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full waves across all SMs. Look at Launch Statistics for more details.",,
0,45833,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(16, 1, 1)",0,7.5,SpeedOfLight_RooflineChart,,,,SOLFPRoofline,INF,The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved  close to 0% of this device's fp32 peak performance and 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.,,
0,45833,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(16, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Active,inst/cycle,0.03,,,,,
0,45833,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(16, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Elapsed,inst/cycle,0.01,,,,,
0,45833,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(16, 1, 1)",0,7.5,Compute Workload Analysis,Issue Slots Busy,%,0.84,,,,,
0,45833,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(16, 1, 1)",0,7.5,Compute Workload Analysis,Issued Ipc Active,inst/cycle,0.03,,,,,
0,45833,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(16, 1, 1)",0,7.5,Compute Workload Analysis,SM Busy,%,0.84,,,,,
0,45833,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(16, 1, 1)",0,7.5,ComputeWorkloadAnalysis,,,,HighPipeUtilization,OPT,All compute pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.,local,99.51
0,45833,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(16, 1, 1)",0,7.5,Memory Workload Analysis,Memory Throughput,byte/second,"4,350,000,000",,,,,
0,45833,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(16, 1, 1)",0,7.5,Memory Workload Analysis,Mem Busy,%,2.80,,,,,
0,45833,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(16, 1, 1)",0,7.5,Memory Workload Analysis,Max Bandwidth,%,2.49,,,,,
0,45833,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(16, 1, 1)",0,7.5,Memory Workload Analysis,L1/TEX Hit Rate,%,0,,,,,
0,45833,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(16, 1, 1)",0,7.5,Memory Workload Analysis,L2 Hit Rate,%,51.21,,,,,
0,45833,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(16, 1, 1)",0,7.5,Memory Workload Analysis,Mem Pipes Busy,%,0.74,,,,,
0,45833,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(16, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Chart,,,,MemoryL2Compression,WRN,The optional metric lts__average_gcomp_input_sector_success_rate.pct could not be found. Collecting it as an additional metric could enable the rule to provide more guidance.,,
0,45833,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(16, 1, 1)",0,7.5,Scheduler Statistics,One or More Eligible,%,1.52,,,,,
0,45833,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(16, 1, 1)",0,7.5,Scheduler Statistics,Issued Warp Per Scheduler,,0.02,,,,,
0,45833,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(16, 1, 1)",0,7.5,Scheduler Statistics,No Eligible,%,98.48,,,,,
0,45833,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(16, 1, 1)",0,7.5,Scheduler Statistics,Active Warps Per Scheduler,warp,0.99,,,,,
0,45833,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(16, 1, 1)",0,7.5,Scheduler Statistics,Eligible Warps Per Scheduler,warp,0.02,,,,,
0,45833,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(16, 1, 1)",0,7.5,SchedulerStats,,,,IssueSlotUtilization,OPT,"Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 65.8 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of 0.99 active warps per scheduler, which already limits the scheduler to less than a warp per instruction.",local,97.2
0,45833,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(16, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Issued Instruction,cycle,65.08,,,,,
0,45833,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(16, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Executed Instruction,cycle,85.11,,,,,
0,45833,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(16, 1, 1)",0,7.5,Warp State Statistics,Avg. Active Threads Per Warp,,32,,,,,
0,45833,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(16, 1, 1)",0,7.5,Warp State Statistics,Avg. Not Predicated Off Threads Per Warp,,32,,,,,
0,45833,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(16, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,OPT,"On average, each warp of this kernel spends 34.2 cycles being stalled waiting for an immediate constant cache (IMC) miss. A read from constant memory costs one memory read from device memory only on a cache miss; otherwise, it just costs one read from the constant cache. Immediate constants are encoded into the SASS instruction as 'c[bank][offset]'. Accesses to different addresses by threads within a warp are serialized, thus the cost scales linearly with the number of unique addresses read by all threads within a warp. As such, the constant cache is best when threads in the same warp access only a few distinct locations. If all threads of a warp access the same location, then constant memory can be as fast as a register access. This stall type represents about 52.5% of the total average of 65.1 cycles between issuing two instructions.",global,52.54
0,45833,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(16, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,OPT,"On average, each warp of this kernel spends 24.8 cycles being stalled waiting for a scoreboard dependency on a L1TEX (local, global, surface, texture) operation. Find the instruction producing the data being waited upon to identify the culprit. To reduce the number of cycles waiting on L1TEX data accesses verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit rates by increasing data locality (coalescing), or by changing the cache configuration. Consider moving frequently used data to shared memory. This stall type represents about 38.2% of the total average of 65.1 cycles between issuing two instructions.",global,38.16
0,45833,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(16, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,INF,Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.,,
0,45833,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(16, 1, 1)",0,7.5,Instruction Statistics,Avg. Executed Instructions Per Scheduler,inst,7.43,,,,,
0,45833,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(16, 1, 1)",0,7.5,Instruction Statistics,Executed Instructions,inst,416,,,,,
0,45833,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(16, 1, 1)",0,7.5,Instruction Statistics,Avg. Issued Instructions Per Scheduler,inst,9.71,,,,,
0,45833,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(16, 1, 1)",0,7.5,Instruction Statistics,Issued Instructions,inst,544,,,,,
0,45833,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(16, 1, 1)",0,7.5,InstructionStats,,,,FPInstructions,OPT,"This kernel executes 0 fused and 32 non-fused FP32 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP32 performance could be increased by up to 50% (relative to its current performance). Check the Source page to identify where this kernel executes FP32 instructions.",global,0.2468
0,45833,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(16, 1, 1)",0,7.5,Launch Statistics,Block Size,,64,,,,,
0,45833,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(16, 1, 1)",0,7.5,Launch Statistics,Function Cache Configuration,,CachePreferNone,,,,,
0,45833,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(16, 1, 1)",0,7.5,Launch Statistics,Grid Size,,16,,,,,
0,45833,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(16, 1, 1)",0,7.5,Launch Statistics,Registers Per Thread,register/thread,16,,,,,
0,45833,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(16, 1, 1)",0,7.5,Launch Statistics,Shared Memory Configuration Size,byte,"32,768",,,,,
0,45833,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(16, 1, 1)",0,7.5,Launch Statistics,Driver Shared Memory Per Block,byte/block,0,,,,,
0,45833,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(16, 1, 1)",0,7.5,Launch Statistics,Dynamic Shared Memory Per Block,byte/block,0,,,,,
0,45833,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(16, 1, 1)",0,7.5,Launch Statistics,Static Shared Memory Per Block,byte/block,0,,,,,
0,45833,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(16, 1, 1)",0,7.5,Launch Statistics,Threads,thread,"1,024",,,,,
0,45833,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(16, 1, 1)",0,7.5,Launch Statistics,Waves Per SM,,0.07,,,,,
0,45833,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(16, 1, 1)",0,7.5,LaunchStats,,,,LaunchConfiguration,OPT,"If you execute __syncthreads() to synchronize the threads of a block, it is recommended to have more than the achieved 1 blocks per multiprocessor. This way, blocks that aren't waiting for __syncthreads() can keep the hardware busy.",,
0,45833,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(16, 1, 1)",0,7.5,Occupancy,Block Limit SM,block,16,,,,,
0,45833,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(16, 1, 1)",0,7.5,Occupancy,Block Limit Registers,block,64,,,,,
0,45833,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(16, 1, 1)",0,7.5,Occupancy,Block Limit Shared Mem,block,16,,,,,
0,45833,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(16, 1, 1)",0,7.5,Occupancy,Block Limit Warps,block,16,,,,,
0,45833,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(16, 1, 1)",0,7.5,Occupancy,Theoretical Active Warps per SM,warp,32,,,,,
0,45833,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(16, 1, 1)",0,7.5,Occupancy,Theoretical Occupancy,%,100,,,,,
0,45833,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(16, 1, 1)",0,7.5,Occupancy,Achieved Occupancy,%,7.12,,,,,
0,45833,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(16, 1, 1)",0,7.5,Occupancy,Achieved Active Warps Per SM,warp,2.28,,,,,
0,45833,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(16, 1, 1)",0,7.5,Occupancy,,,,AchievedOccupancy,OPT,The difference between calculated theoretical (100.0%) and measured achieved occupancy (7.1%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy.,global,92.88
0,45833,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(16, 1, 1)",0,7.5,Source Counters,Branch Instructions Ratio,%,0.08,,,,,
0,45833,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(16, 1, 1)",0,7.5,Source Counters,Branch Instructions,inst,32,,,,,
0,45833,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(16, 1, 1)",0,7.5,Source Counters,Branch Efficiency,%,0,,,,,
0,45833,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(16, 1, 1)",0,7.5,Source Counters,Avg. Divergent Branches,,0,,,,,
0,45918,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(8, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Frequency,cycle/second,"5,600,000,000",,,,,
0,45918,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(8, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Frequency,cycle/second,"1,271,093,750",,,,,
0,45918,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(8, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Elapsed Cycles,cycle,"2,443",,,,,
0,45918,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(8, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Memory Throughput,%,2.93,,,,,
0,45918,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(8, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Throughput,%,2.43,,,,,
0,45918,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(8, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Duration,nsecond,"1,920",,,,,
0,45918,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(8, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L1/TEX Cache Throughput,%,2.72,,,,,
0,45918,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(8, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L2 Cache Throughput,%,2.93,,,,,
0,45918,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(8, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Active Cycles,cycle,671.07,,,,,
0,45918,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(8, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Compute (SM) Throughput,%,0.75,,,,,
0,45918,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(8, 1, 1)",0,7.5,SpeedOfLight,,,,SOLBottleneck,OPT,"This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full waves across all SMs. Look at Launch Statistics for more details.",,
0,45918,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(8, 1, 1)",0,7.5,SpeedOfLight_RooflineChart,,,,SOLFPRoofline,INF,The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved  close to 0% of this device's fp32 peak performance and 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.,,
0,45918,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(8, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Active,inst/cycle,0.04,,,,,
0,45918,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(8, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Elapsed,inst/cycle,0.01,,,,,
0,45918,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(8, 1, 1)",0,7.5,Compute Workload Analysis,Issue Slots Busy,%,1.45,,,,,
0,45918,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(8, 1, 1)",0,7.5,Compute Workload Analysis,Issued Ipc Active,inst/cycle,0.06,,,,,
0,45918,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(8, 1, 1)",0,7.5,Compute Workload Analysis,SM Busy,%,1.45,,,,,
0,45918,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(8, 1, 1)",0,7.5,ComputeWorkloadAnalysis,,,,HighPipeUtilization,OPT,All compute pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.,local,99.15
0,45918,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(8, 1, 1)",0,7.5,Memory Workload Analysis,Memory Throughput,byte/second,"4,350,000,000",,,,,
0,45918,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(8, 1, 1)",0,7.5,Memory Workload Analysis,Mem Busy,%,2.93,,,,,
0,45918,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(8, 1, 1)",0,7.5,Memory Workload Analysis,Max Bandwidth,%,2.43,,,,,
0,45918,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(8, 1, 1)",0,7.5,Memory Workload Analysis,L1/TEX Hit Rate,%,0,,,,,
0,45918,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(8, 1, 1)",0,7.5,Memory Workload Analysis,L2 Hit Rate,%,52.48,,,,,
0,45918,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(8, 1, 1)",0,7.5,Memory Workload Analysis,Mem Pipes Busy,%,0.75,,,,,
0,45918,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(8, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Chart,,,,MemoryL2Compression,WRN,The optional metric lts__average_gcomp_input_sector_success_rate.pct could not be found. Collecting it as an additional metric could enable the rule to provide more guidance.,,
0,45918,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(8, 1, 1)",0,7.5,Scheduler Statistics,One or More Eligible,%,1.50,,,,,
0,45918,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(8, 1, 1)",0,7.5,Scheduler Statistics,Issued Warp Per Scheduler,,0.01,,,,,
0,45918,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(8, 1, 1)",0,7.5,Scheduler Statistics,No Eligible,%,98.50,,,,,
0,45918,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(8, 1, 1)",0,7.5,Scheduler Statistics,Active Warps Per Scheduler,warp,0.99,,,,,
0,45918,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(8, 1, 1)",0,7.5,Scheduler Statistics,Eligible Warps Per Scheduler,warp,0.01,,,,,
0,45918,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(8, 1, 1)",0,7.5,SchedulerStats,,,,IssueSlotUtilization,OPT,"Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 66.7 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of 0.99 active warps per scheduler, which already limits the scheduler to less than a warp per instruction.",local,97.07
0,45918,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(8, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Issued Instruction,cycle,66.15,,,,,
0,45918,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(8, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Executed Instruction,cycle,86.50,,,,,
0,45918,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(8, 1, 1)",0,7.5,Warp State Statistics,Avg. Active Threads Per Warp,,32,,,,,
0,45918,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(8, 1, 1)",0,7.5,Warp State Statistics,Avg. Not Predicated Off Threads Per Warp,,32,,,,,
0,45918,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(8, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,OPT,"On average, each warp of this kernel spends 34.4 cycles being stalled waiting for an immediate constant cache (IMC) miss. A read from constant memory costs one memory read from device memory only on a cache miss; otherwise, it just costs one read from the constant cache. Immediate constants are encoded into the SASS instruction as 'c[bank][offset]'. Accesses to different addresses by threads within a warp are serialized, thus the cost scales linearly with the number of unique addresses read by all threads within a warp. As such, the constant cache is best when threads in the same warp access only a few distinct locations. If all threads of a warp access the same location, then constant memory can be as fast as a register access. This stall type represents about 52.0% of the total average of 66.1 cycles between issuing two instructions.",global,51.96
0,45918,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(8, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,OPT,"On average, each warp of this kernel spends 25.1 cycles being stalled waiting for a scoreboard dependency on a L1TEX (local, global, surface, texture) operation. Find the instruction producing the data being waited upon to identify the culprit. To reduce the number of cycles waiting on L1TEX data accesses verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit rates by increasing data locality (coalescing), or by changing the cache configuration. Consider moving frequently used data to shared memory. This stall type represents about 38.0% of the total average of 66.1 cycles between issuing two instructions.",global,37.97
0,45918,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(8, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,INF,Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.,,
0,45918,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(8, 1, 1)",0,7.5,Instruction Statistics,Avg. Executed Instructions Per Scheduler,inst,7.43,,,,,
0,45918,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(8, 1, 1)",0,7.5,Instruction Statistics,Executed Instructions,inst,416,,,,,
0,45918,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(8, 1, 1)",0,7.5,Instruction Statistics,Avg. Issued Instructions Per Scheduler,inst,9.71,,,,,
0,45918,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(8, 1, 1)",0,7.5,Instruction Statistics,Issued Instructions,inst,544,,,,,
0,45918,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(8, 1, 1)",0,7.5,InstructionStats,,,,FPInstructions,OPT,"This kernel executes 0 fused and 32 non-fused FP32 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP32 performance could be increased by up to 50% (relative to its current performance). Check the Source page to identify where this kernel executes FP32 instructions.",global,0.4258
0,45918,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(8, 1, 1)",0,7.5,Launch Statistics,Block Size,,128,,,,,
0,45918,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(8, 1, 1)",0,7.5,Launch Statistics,Function Cache Configuration,,CachePreferNone,,,,,
0,45918,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(8, 1, 1)",0,7.5,Launch Statistics,Grid Size,,8,,,,,
0,45918,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(8, 1, 1)",0,7.5,Launch Statistics,Registers Per Thread,register/thread,16,,,,,
0,45918,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(8, 1, 1)",0,7.5,Launch Statistics,Shared Memory Configuration Size,byte,"32,768",,,,,
0,45918,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(8, 1, 1)",0,7.5,Launch Statistics,Driver Shared Memory Per Block,byte/block,0,,,,,
0,45918,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(8, 1, 1)",0,7.5,Launch Statistics,Dynamic Shared Memory Per Block,byte/block,0,,,,,
0,45918,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(8, 1, 1)",0,7.5,Launch Statistics,Static Shared Memory Per Block,byte/block,0,,,,,
0,45918,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(8, 1, 1)",0,7.5,Launch Statistics,Threads,thread,"1,024",,,,,
0,45918,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(8, 1, 1)",0,7.5,Launch Statistics,Waves Per SM,,0.07,,,,,
0,45918,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(8, 1, 1)",0,7.5,LaunchStats,,,,LaunchConfiguration,OPT,"The grid for this launch is configured to execute only 8 blocks, which is less than the GPU's 14 multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel concurrently with other workloads, consider reducing the block size to have at least one block per multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations.",global,42.86
0,45918,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(8, 1, 1)",0,7.5,Occupancy,Block Limit SM,block,16,,,,,
0,45918,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(8, 1, 1)",0,7.5,Occupancy,Block Limit Registers,block,32,,,,,
0,45918,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(8, 1, 1)",0,7.5,Occupancy,Block Limit Shared Mem,block,16,,,,,
0,45918,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(8, 1, 1)",0,7.5,Occupancy,Block Limit Warps,block,8,,,,,
0,45918,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(8, 1, 1)",0,7.5,Occupancy,Theoretical Active Warps per SM,warp,32,,,,,
0,45918,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(8, 1, 1)",0,7.5,Occupancy,Theoretical Occupancy,%,100,,,,,
0,45918,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(8, 1, 1)",0,7.5,Occupancy,Achieved Occupancy,%,12.44,,,,,
0,45918,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(8, 1, 1)",0,7.5,Occupancy,Achieved Active Warps Per SM,warp,3.98,,,,,
0,45918,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(8, 1, 1)",0,7.5,Occupancy,,,,AchievedOccupancy,OPT,The difference between calculated theoretical (100.0%) and measured achieved occupancy (12.4%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy.,global,87.56
0,45918,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(8, 1, 1)",0,7.5,Source Counters,Branch Instructions Ratio,%,0.08,,,,,
0,45918,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(8, 1, 1)",0,7.5,Source Counters,Branch Instructions,inst,32,,,,,
0,45918,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(8, 1, 1)",0,7.5,Source Counters,Branch Efficiency,%,0,,,,,
0,45918,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(8, 1, 1)",0,7.5,Source Counters,Avg. Divergent Branches,,0,,,,,
0,46012,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(4, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Frequency,cycle/second,"5,694,915,254.24",,,,,
0,46012,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(4, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Frequency,cycle/second,"1,292,637,711.86",,,,,
0,46012,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(4, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Elapsed Cycles,cycle,"2,454",,,,,
0,46012,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(4, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Memory Throughput,%,2.93,,,,,
0,46012,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(4, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Throughput,%,2.43,,,,,
0,46012,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(4, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Duration,nsecond,"1,888",,,,,
0,46012,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(4, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L1/TEX Cache Throughput,%,5.39,,,,,
0,46012,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(4, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L2 Cache Throughput,%,2.93,,,,,
0,46012,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(4, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Active Cycles,cycle,339.43,,,,,
0,46012,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(4, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Compute (SM) Throughput,%,0.75,,,,,
0,46012,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(4, 1, 1)",0,7.5,SpeedOfLight,,,,SOLBottleneck,OPT,"This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full waves across all SMs. Look at Launch Statistics for more details.",,
0,46012,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(4, 1, 1)",0,7.5,SpeedOfLight_RooflineChart,,,,SOLFPRoofline,INF,The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved  close to 0% of this device's fp32 peak performance and 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.,,
0,46012,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(4, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Active,inst/cycle,0.09,,,,,
0,46012,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(4, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Elapsed,inst/cycle,0.01,,,,,
0,46012,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(4, 1, 1)",0,7.5,Compute Workload Analysis,Issue Slots Busy,%,2.86,,,,,
0,46012,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(4, 1, 1)",0,7.5,Compute Workload Analysis,Issued Ipc Active,inst/cycle,0.11,,,,,
0,46012,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(4, 1, 1)",0,7.5,Compute Workload Analysis,SM Busy,%,2.86,,,,,
0,46012,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(4, 1, 1)",0,7.5,ComputeWorkloadAnalysis,,,,HighPipeUtilization,OPT,All compute pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.,local,98.32
0,46012,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(4, 1, 1)",0,7.5,Memory Workload Analysis,Memory Throughput,byte/second,"4,423,728,813.56",,,,,
0,46012,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(4, 1, 1)",0,7.5,Memory Workload Analysis,Mem Busy,%,2.93,,,,,
0,46012,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(4, 1, 1)",0,7.5,Memory Workload Analysis,Max Bandwidth,%,2.43,,,,,
0,46012,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(4, 1, 1)",0,7.5,Memory Workload Analysis,L1/TEX Hit Rate,%,0,,,,,
0,46012,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(4, 1, 1)",0,7.5,Memory Workload Analysis,L2 Hit Rate,%,48.63,,,,,
0,46012,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(4, 1, 1)",0,7.5,Memory Workload Analysis,Mem Pipes Busy,%,0.75,,,,,
0,46012,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(4, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Chart,,,,MemoryL2Compression,WRN,The optional metric lts__average_gcomp_input_sector_success_rate.pct could not be found. Collecting it as an additional metric could enable the rule to provide more guidance.,,
0,46012,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(4, 1, 1)",0,7.5,Scheduler Statistics,One or More Eligible,%,2.98,,,,,
0,46012,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(4, 1, 1)",0,7.5,Scheduler Statistics,Issued Warp Per Scheduler,,0.03,,,,,
0,46012,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(4, 1, 1)",0,7.5,Scheduler Statistics,No Eligible,%,97.02,,,,,
0,46012,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(4, 1, 1)",0,7.5,Scheduler Statistics,Active Warps Per Scheduler,warp,2.01,,,,,
0,46012,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(4, 1, 1)",0,7.5,Scheduler Statistics,Eligible Warps Per Scheduler,warp,0.03,,,,,
0,46012,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(4, 1, 1)",0,7.5,SchedulerStats,,,,IssueSlotUtilization,OPT,"Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 33.5 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of 2.01 active warps per scheduler, but only an average of 0.03 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections.",local,97.02
0,46012,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(4, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Issued Instruction,cycle,67.44,,,,,
0,46012,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(4, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Executed Instruction,cycle,88.19,,,,,
0,46012,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(4, 1, 1)",0,7.5,Warp State Statistics,Avg. Active Threads Per Warp,,32,,,,,
0,46012,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(4, 1, 1)",0,7.5,Warp State Statistics,Avg. Not Predicated Off Threads Per Warp,,32,,,,,
0,46012,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(4, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,OPT,"On average, each warp of this kernel spends 33.5 cycles being stalled waiting for an immediate constant cache (IMC) miss. A read from constant memory costs one memory read from device memory only on a cache miss; otherwise, it just costs one read from the constant cache. Immediate constants are encoded into the SASS instruction as 'c[bank][offset]'. Accesses to different addresses by threads within a warp are serialized, thus the cost scales linearly with the number of unique addresses read by all threads within a warp. As such, the constant cache is best when threads in the same warp access only a few distinct locations. If all threads of a warp access the same location, then constant memory can be as fast as a register access. This stall type represents about 49.7% of the total average of 67.4 cycles between issuing two instructions.",global,49.7
0,46012,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(4, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,OPT,"On average, each warp of this kernel spends 26.4 cycles being stalled waiting for a scoreboard dependency on a L1TEX (local, global, surface, texture) operation. Find the instruction producing the data being waited upon to identify the culprit. To reduce the number of cycles waiting on L1TEX data accesses verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit rates by increasing data locality (coalescing), or by changing the cache configuration. Consider moving frequently used data to shared memory. This stall type represents about 39.2% of the total average of 67.4 cycles between issuing two instructions.",global,39.15
0,46012,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(4, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,INF,Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.,,
0,46012,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(4, 1, 1)",0,7.5,Instruction Statistics,Avg. Executed Instructions Per Scheduler,inst,7.43,,,,,
0,46012,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(4, 1, 1)",0,7.5,Instruction Statistics,Executed Instructions,inst,416,,,,,
0,46012,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(4, 1, 1)",0,7.5,Instruction Statistics,Avg. Issued Instructions Per Scheduler,inst,9.71,,,,,
0,46012,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(4, 1, 1)",0,7.5,Instruction Statistics,Issued Instructions,inst,544,,,,,
0,46012,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(4, 1, 1)",0,7.5,InstructionStats,,,,FPInstructions,OPT,"This kernel executes 0 fused and 32 non-fused FP32 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP32 performance could be increased by up to 50% (relative to its current performance). Check the Source page to identify where this kernel executes FP32 instructions.",global,0.8418
0,46012,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(4, 1, 1)",0,7.5,Launch Statistics,Block Size,,256,,,,,
0,46012,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(4, 1, 1)",0,7.5,Launch Statistics,Function Cache Configuration,,CachePreferNone,,,,,
0,46012,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(4, 1, 1)",0,7.5,Launch Statistics,Grid Size,,4,,,,,
0,46012,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(4, 1, 1)",0,7.5,Launch Statistics,Registers Per Thread,register/thread,16,,,,,
0,46012,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(4, 1, 1)",0,7.5,Launch Statistics,Shared Memory Configuration Size,byte,"32,768",,,,,
0,46012,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(4, 1, 1)",0,7.5,Launch Statistics,Driver Shared Memory Per Block,byte/block,0,,,,,
0,46012,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(4, 1, 1)",0,7.5,Launch Statistics,Dynamic Shared Memory Per Block,byte/block,0,,,,,
0,46012,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(4, 1, 1)",0,7.5,Launch Statistics,Static Shared Memory Per Block,byte/block,0,,,,,
0,46012,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(4, 1, 1)",0,7.5,Launch Statistics,Threads,thread,"1,024",,,,,
0,46012,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(4, 1, 1)",0,7.5,Launch Statistics,Waves Per SM,,0.07,,,,,
0,46012,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(4, 1, 1)",0,7.5,LaunchStats,,,,LaunchConfiguration,OPT,"The grid for this launch is configured to execute only 4 blocks, which is less than the GPU's 14 multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel concurrently with other workloads, consider reducing the block size to have at least one block per multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations.",global,71.43
0,46012,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(4, 1, 1)",0,7.5,Occupancy,Block Limit SM,block,16,,,,,
0,46012,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(4, 1, 1)",0,7.5,Occupancy,Block Limit Registers,block,16,,,,,
0,46012,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(4, 1, 1)",0,7.5,Occupancy,Block Limit Shared Mem,block,16,,,,,
0,46012,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(4, 1, 1)",0,7.5,Occupancy,Block Limit Warps,block,4,,,,,
0,46012,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(4, 1, 1)",0,7.5,Occupancy,Theoretical Active Warps per SM,warp,32,,,,,
0,46012,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(4, 1, 1)",0,7.5,Occupancy,Theoretical Occupancy,%,100,,,,,
0,46012,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(4, 1, 1)",0,7.5,Occupancy,Achieved Occupancy,%,24.66,,,,,
0,46012,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(4, 1, 1)",0,7.5,Occupancy,Achieved Active Warps Per SM,warp,7.89,,,,,
0,46012,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(4, 1, 1)",0,7.5,Occupancy,,,,AchievedOccupancy,OPT,The difference between calculated theoretical (100.0%) and measured achieved occupancy (24.7%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy.,global,75.34
0,46012,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(4, 1, 1)",0,7.5,Source Counters,Branch Instructions Ratio,%,0.08,,,,,
0,46012,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(4, 1, 1)",0,7.5,Source Counters,Branch Instructions,inst,32,,,,,
0,46012,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(4, 1, 1)",0,7.5,Source Counters,Branch Efficiency,%,0,,,,,
0,46012,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(4, 1, 1)",0,7.5,Source Counters,Avg. Divergent Branches,,0,,,,,
0,46089,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(2, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Frequency,cycle/second,"5,375,000,000",,,,,
0,46089,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(2, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Frequency,cycle/second,"1,223,876,953.12",,,,,
0,46089,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(2, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Elapsed Cycles,cycle,"2,512",,,,,
0,46089,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(2, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Memory Throughput,%,2.69,,,,,
0,46089,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(2, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Throughput,%,2.37,,,,,
0,46089,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(2, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Duration,nsecond,"2,048",,,,,
0,46089,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(2, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L1/TEX Cache Throughput,%,10.24,,,,,
0,46089,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(2, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L2 Cache Throughput,%,2.69,,,,,
0,46089,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(2, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Active Cycles,cycle,178.50,,,,,
0,46089,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(2, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Compute (SM) Throughput,%,0.73,,,,,
0,46089,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(2, 1, 1)",0,7.5,SpeedOfLight,,,,SOLBottleneck,OPT,"This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full waves across all SMs. Look at Launch Statistics for more details.",,
0,46089,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(2, 1, 1)",0,7.5,SpeedOfLight_RooflineChart,,,,SOLFPRoofline,INF,The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved  close to 0% of this device's fp32 peak performance and 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.,,
0,46089,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(2, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Active,inst/cycle,0.17,,,,,
0,46089,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(2, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Elapsed,inst/cycle,0.01,,,,,
0,46089,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(2, 1, 1)",0,7.5,Compute Workload Analysis,Issue Slots Busy,%,5.44,,,,,
0,46089,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(2, 1, 1)",0,7.5,Compute Workload Analysis,Issued Ipc Active,inst/cycle,0.22,,,,,
0,46089,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(2, 1, 1)",0,7.5,Compute Workload Analysis,SM Busy,%,5.44,,,,,
0,46089,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(2, 1, 1)",0,7.5,ComputeWorkloadAnalysis,,,,HighPipeUtilization,OPT,All compute pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.,local,96.8
0,46089,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(2, 1, 1)",0,7.5,Memory Workload Analysis,Memory Throughput,byte/second,"4,078,125,000",,,,,
0,46089,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(2, 1, 1)",0,7.5,Memory Workload Analysis,Mem Busy,%,2.69,,,,,
0,46089,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(2, 1, 1)",0,7.5,Memory Workload Analysis,Max Bandwidth,%,2.37,,,,,
0,46089,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(2, 1, 1)",0,7.5,Memory Workload Analysis,L1/TEX Hit Rate,%,0,,,,,
0,46089,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(2, 1, 1)",0,7.5,Memory Workload Analysis,L2 Hit Rate,%,50.19,,,,,
0,46089,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(2, 1, 1)",0,7.5,Memory Workload Analysis,Mem Pipes Busy,%,0.73,,,,,
0,46089,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(2, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Chart,,,,MemoryL2Compression,WRN,The optional metric lts__average_gcomp_input_sector_success_rate.pct could not be found. Collecting it as an additional metric could enable the rule to provide more guidance.,,
0,46089,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(2, 1, 1)",0,7.5,Scheduler Statistics,One or More Eligible,%,5.59,,,,,
0,46089,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(2, 1, 1)",0,7.5,Scheduler Statistics,Issued Warp Per Scheduler,,0.06,,,,,
0,46089,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(2, 1, 1)",0,7.5,Scheduler Statistics,No Eligible,%,94.41,,,,,
0,46089,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(2, 1, 1)",0,7.5,Scheduler Statistics,Active Warps Per Scheduler,warp,3.79,,,,,
0,46089,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(2, 1, 1)",0,7.5,Scheduler Statistics,Eligible Warps Per Scheduler,warp,0.07,,,,,
0,46089,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(2, 1, 1)",0,7.5,SchedulerStats,,,,IssueSlotUtilization,OPT,"Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 17.9 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of 3.79 active warps per scheduler, but only an average of 0.07 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections.",local,94.41
0,46089,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(2, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Issued Instruction,cycle,67.76,,,,,
0,46089,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(2, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Executed Instruction,cycle,88.61,,,,,
0,46089,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(2, 1, 1)",0,7.5,Warp State Statistics,Avg. Active Threads Per Warp,,32,,,,,
0,46089,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(2, 1, 1)",0,7.5,Warp State Statistics,Avg. Not Predicated Off Threads Per Warp,,32,,,,,
0,46089,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(2, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,OPT,"On average, each warp of this kernel spends 32.5 cycles being stalled waiting for an immediate constant cache (IMC) miss. A read from constant memory costs one memory read from device memory only on a cache miss; otherwise, it just costs one read from the constant cache. Immediate constants are encoded into the SASS instruction as 'c[bank][offset]'. Accesses to different addresses by threads within a warp are serialized, thus the cost scales linearly with the number of unique addresses read by all threads within a warp. As such, the constant cache is best when threads in the same warp access only a few distinct locations. If all threads of a warp access the same location, then constant memory can be as fast as a register access. This stall type represents about 47.9% of the total average of 67.8 cycles between issuing two instructions.",global,47.93
0,46089,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(2, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,OPT,"On average, each warp of this kernel spends 27.8 cycles being stalled waiting for a scoreboard dependency on a L1TEX (local, global, surface, texture) operation. Find the instruction producing the data being waited upon to identify the culprit. To reduce the number of cycles waiting on L1TEX data accesses verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit rates by increasing data locality (coalescing), or by changing the cache configuration. Consider moving frequently used data to shared memory. This stall type represents about 41.0% of the total average of 67.8 cycles between issuing two instructions.",global,40.99
0,46089,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(2, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,INF,Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.,,
0,46089,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(2, 1, 1)",0,7.5,Instruction Statistics,Avg. Executed Instructions Per Scheduler,inst,7.43,,,,,
0,46089,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(2, 1, 1)",0,7.5,Instruction Statistics,Executed Instructions,inst,416,,,,,
0,46089,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(2, 1, 1)",0,7.5,Instruction Statistics,Avg. Issued Instructions Per Scheduler,inst,9.71,,,,,
0,46089,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(2, 1, 1)",0,7.5,Instruction Statistics,Issued Instructions,inst,544,,,,,
0,46089,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(2, 1, 1)",0,7.5,InstructionStats,,,,FPInstructions,OPT,"This kernel executes 0 fused and 32 non-fused FP32 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP32 performance could be increased by up to 50% (relative to its current performance). Check the Source page to identify where this kernel executes FP32 instructions.",global,1.601
0,46089,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(2, 1, 1)",0,7.5,Launch Statistics,Block Size,,512,,,,,
0,46089,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(2, 1, 1)",0,7.5,Launch Statistics,Function Cache Configuration,,CachePreferNone,,,,,
0,46089,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(2, 1, 1)",0,7.5,Launch Statistics,Grid Size,,2,,,,,
0,46089,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(2, 1, 1)",0,7.5,Launch Statistics,Registers Per Thread,register/thread,16,,,,,
0,46089,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(2, 1, 1)",0,7.5,Launch Statistics,Shared Memory Configuration Size,byte,"32,768",,,,,
0,46089,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(2, 1, 1)",0,7.5,Launch Statistics,Driver Shared Memory Per Block,byte/block,0,,,,,
0,46089,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(2, 1, 1)",0,7.5,Launch Statistics,Dynamic Shared Memory Per Block,byte/block,0,,,,,
0,46089,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(2, 1, 1)",0,7.5,Launch Statistics,Static Shared Memory Per Block,byte/block,0,,,,,
0,46089,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(2, 1, 1)",0,7.5,Launch Statistics,Threads,thread,"1,024",,,,,
0,46089,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(2, 1, 1)",0,7.5,Launch Statistics,Waves Per SM,,0.07,,,,,
0,46089,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(2, 1, 1)",0,7.5,LaunchStats,,,,LaunchConfiguration,OPT,"The grid for this launch is configured to execute only 2 blocks, which is less than the GPU's 14 multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel concurrently with other workloads, consider reducing the block size to have at least one block per multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations.",global,85.71
0,46089,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(2, 1, 1)",0,7.5,Occupancy,Block Limit SM,block,16,,,,,
0,46089,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(2, 1, 1)",0,7.5,Occupancy,Block Limit Registers,block,8,,,,,
0,46089,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(2, 1, 1)",0,7.5,Occupancy,Block Limit Shared Mem,block,16,,,,,
0,46089,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(2, 1, 1)",0,7.5,Occupancy,Block Limit Warps,block,2,,,,,
0,46089,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(2, 1, 1)",0,7.5,Occupancy,Theoretical Active Warps per SM,warp,32,,,,,
0,46089,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(2, 1, 1)",0,7.5,Occupancy,Theoretical Occupancy,%,100,,,,,
0,46089,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(2, 1, 1)",0,7.5,Occupancy,Achieved Occupancy,%,48.32,,,,,
0,46089,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(2, 1, 1)",0,7.5,Occupancy,Achieved Active Warps Per SM,warp,15.46,,,,,
0,46089,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(2, 1, 1)",0,7.5,Occupancy,,,,AchievedOccupancy,OPT,The difference between calculated theoretical (100.0%) and measured achieved occupancy (48.3%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy.,global,51.68
0,46089,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(2, 1, 1)",0,7.5,Source Counters,Branch Instructions Ratio,%,0.08,,,,,
0,46089,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(2, 1, 1)",0,7.5,Source Counters,Branch Instructions,inst,32,,,,,
0,46089,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(2, 1, 1)",0,7.5,Source Counters,Branch Efficiency,%,0,,,,,
0,46089,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(2, 1, 1)",0,7.5,Source Counters,Avg. Divergent Branches,,0,,,,,
0,46174,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(1, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Frequency,cycle/second,"5,500,000,000",,,,,
0,46174,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(1, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Frequency,cycle/second,"1,270,019,531.25",,,,,
0,46174,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(1, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Elapsed Cycles,cycle,"2,614",,,,,
0,46174,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(1, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Memory Throughput,%,2.46,,,,,
0,46174,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(1, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Throughput,%,2.32,,,,,
0,46174,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(1, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Duration,nsecond,"2,048",,,,,
0,46174,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(1, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L1/TEX Cache Throughput,%,18.44,,,,,
0,46174,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(1, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L2 Cache Throughput,%,2.46,,,,,
0,46174,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(1, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Active Cycles,cycle,99.14,,,,,
0,46174,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(1, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Compute (SM) Throughput,%,0.70,,,,,
0,46174,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(1, 1, 1)",0,7.5,SpeedOfLight,,,,SOLBottleneck,OPT,"This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full waves across all SMs. Look at Launch Statistics for more details.",,
0,46174,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(1, 1, 1)",0,7.5,SpeedOfLight_RooflineChart,,,,SOLFPRoofline,INF,The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved  close to 0% of this device's fp32 peak performance and 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.,,
0,46174,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(1, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Active,inst/cycle,0.30,,,,,
0,46174,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(1, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Elapsed,inst/cycle,0.01,,,,,
0,46174,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(1, 1, 1)",0,7.5,Compute Workload Analysis,Issue Slots Busy,%,9.80,,,,,
0,46174,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(1, 1, 1)",0,7.5,Compute Workload Analysis,Issued Ipc Active,inst/cycle,0.39,,,,,
0,46174,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(1, 1, 1)",0,7.5,Compute Workload Analysis,SM Busy,%,9.80,,,,,
0,46174,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(1, 1, 1)",0,7.5,ComputeWorkloadAnalysis,,,,HighPipeUtilization,OPT,All compute pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.,local,94.24
0,46174,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(1, 1, 1)",0,7.5,Memory Workload Analysis,Memory Throughput,byte/second,"4,078,125,000",,,,,
0,46174,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(1, 1, 1)",0,7.5,Memory Workload Analysis,Mem Busy,%,2.46,,,,,
0,46174,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(1, 1, 1)",0,7.5,Memory Workload Analysis,Max Bandwidth,%,2.32,,,,,
0,46174,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(1, 1, 1)",0,7.5,Memory Workload Analysis,L1/TEX Hit Rate,%,0,,,,,
0,46174,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(1, 1, 1)",0,7.5,Memory Workload Analysis,L2 Hit Rate,%,47.26,,,,,
0,46174,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(1, 1, 1)",0,7.5,Memory Workload Analysis,Mem Pipes Busy,%,0.70,,,,,
0,46174,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(1, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Chart,,,,MemoryL2Compression,WRN,The optional metric lts__average_gcomp_input_sector_success_rate.pct could not be found. Collecting it as an additional metric could enable the rule to provide more guidance.,,
0,46174,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(1, 1, 1)",0,7.5,Scheduler Statistics,One or More Eligible,%,9.93,,,,,
0,46174,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(1, 1, 1)",0,7.5,Scheduler Statistics,Issued Warp Per Scheduler,,0.10,,,,,
0,46174,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(1, 1, 1)",0,7.5,Scheduler Statistics,No Eligible,%,90.07,,,,,
0,46174,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(1, 1, 1)",0,7.5,Scheduler Statistics,Active Warps Per Scheduler,warp,7.38,,,,,
0,46174,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(1, 1, 1)",0,7.5,Scheduler Statistics,Eligible Warps Per Scheduler,warp,0.20,,,,,
0,46174,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(1, 1, 1)",0,7.5,SchedulerStats,,,,IssueSlotUtilization,OPT,"Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 10.1 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of 7.38 active warps per scheduler, but only an average of 0.20 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, avoid possible load imbalances due to highly different execution durations per warp. Reducing stalls indicated on the Warp State Statistics and Source Counters sections can help, too.",local,90.07
0,46174,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(1, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Issued Instruction,cycle,74.27,,,,,
0,46174,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(1, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Executed Instruction,cycle,97.12,,,,,
0,46174,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(1, 1, 1)",0,7.5,Warp State Statistics,Avg. Active Threads Per Warp,,32,,,,,
0,46174,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(1, 1, 1)",0,7.5,Warp State Statistics,Avg. Not Predicated Off Threads Per Warp,,32,,,,,
0,46174,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(1, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,OPT,"On average, each warp of this kernel spends 30.6 cycles being stalled waiting for an immediate constant cache (IMC) miss. A read from constant memory costs one memory read from device memory only on a cache miss; otherwise, it just costs one read from the constant cache. Immediate constants are encoded into the SASS instruction as 'c[bank][offset]'. Accesses to different addresses by threads within a warp are serialized, thus the cost scales linearly with the number of unique addresses read by all threads within a warp. As such, the constant cache is best when threads in the same warp access only a few distinct locations. If all threads of a warp access the same location, then constant memory can be as fast as a register access. This stall type represents about 41.2% of the total average of 74.3 cycles between issuing two instructions.",global,41.24
0,46174,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(1, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,OPT,"On average, each warp of this kernel spends 30.0 cycles being stalled waiting for a scoreboard dependency on a L1TEX (local, global, surface, texture) operation. Find the instruction producing the data being waited upon to identify the culprit. To reduce the number of cycles waiting on L1TEX data accesses verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit rates by increasing data locality (coalescing), or by changing the cache configuration. Consider moving frequently used data to shared memory. This stall type represents about 40.3% of the total average of 74.3 cycles between issuing two instructions.",global,40.33
0,46174,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(1, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,INF,Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.,,
0,46174,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(1, 1, 1)",0,7.5,Instruction Statistics,Avg. Executed Instructions Per Scheduler,inst,7.43,,,,,
0,46174,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(1, 1, 1)",0,7.5,Instruction Statistics,Executed Instructions,inst,416,,,,,
0,46174,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(1, 1, 1)",0,7.5,Instruction Statistics,Avg. Issued Instructions Per Scheduler,inst,9.71,,,,,
0,46174,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(1, 1, 1)",0,7.5,Instruction Statistics,Issued Instructions,inst,544,,,,,
0,46174,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(1, 1, 1)",0,7.5,InstructionStats,,,,FPInstructions,OPT,"This kernel executes 0 fused and 32 non-fused FP32 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP32 performance could be increased by up to 50% (relative to its current performance). Check the Source page to identify where this kernel executes FP32 instructions.",global,2.882
0,46174,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(1, 1, 1)",0,7.5,Launch Statistics,Block Size,,"1,024",,,,,
0,46174,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(1, 1, 1)",0,7.5,Launch Statistics,Function Cache Configuration,,CachePreferNone,,,,,
0,46174,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(1, 1, 1)",0,7.5,Launch Statistics,Grid Size,,1,,,,,
0,46174,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(1, 1, 1)",0,7.5,Launch Statistics,Registers Per Thread,register/thread,16,,,,,
0,46174,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(1, 1, 1)",0,7.5,Launch Statistics,Shared Memory Configuration Size,byte,"32,768",,,,,
0,46174,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(1, 1, 1)",0,7.5,Launch Statistics,Driver Shared Memory Per Block,byte/block,0,,,,,
0,46174,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(1, 1, 1)",0,7.5,Launch Statistics,Dynamic Shared Memory Per Block,byte/block,0,,,,,
0,46174,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(1, 1, 1)",0,7.5,Launch Statistics,Static Shared Memory Per Block,byte/block,0,,,,,
0,46174,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(1, 1, 1)",0,7.5,Launch Statistics,Threads,thread,"1,024",,,,,
0,46174,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(1, 1, 1)",0,7.5,Launch Statistics,Waves Per SM,,0.07,,,,,
0,46174,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(1, 1, 1)",0,7.5,LaunchStats,,,,LaunchConfiguration,OPT,"The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 14 multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel concurrently with other workloads, consider reducing the block size to have at least one block per multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations.",global,92.86
0,46174,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(1, 1, 1)",0,7.5,Occupancy,Block Limit SM,block,16,,,,,
0,46174,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(1, 1, 1)",0,7.5,Occupancy,Block Limit Registers,block,4,,,,,
0,46174,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(1, 1, 1)",0,7.5,Occupancy,Block Limit Shared Mem,block,16,,,,,
0,46174,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(1, 1, 1)",0,7.5,Occupancy,Block Limit Warps,block,1,,,,,
0,46174,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(1, 1, 1)",0,7.5,Occupancy,Theoretical Active Warps per SM,warp,32,,,,,
0,46174,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(1, 1, 1)",0,7.5,Occupancy,Theoretical Occupancy,%,100,,,,,
0,46174,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(1, 1, 1)",0,7.5,Occupancy,Achieved Occupancy,%,92.16,,,,,
0,46174,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(1, 1, 1)",0,7.5,Occupancy,Achieved Active Warps Per SM,warp,29.49,,,,,
0,46174,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(1, 1, 1)",0,7.5,Source Counters,Branch Instructions Ratio,%,0.08,,,,,
0,46174,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(1, 1, 1)",0,7.5,Source Counters,Branch Instructions,inst,32,,,,,
0,46174,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(1, 1, 1)",0,7.5,Source Counters,Branch Efficiency,%,0,,,,,
0,46174,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(1, 1, 1)",0,7.5,Source Counters,Avg. Divergent Branches,,0,,,,,
0,46251,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(2048, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Frequency,cycle/second,"5,863,013,698.63",,,,,
0,46251,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(2048, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Frequency,cycle/second,"1,354,719,606.16",,,,,
0,46251,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(2048, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Elapsed Cycles,cycle,"12,718",,,,,
0,46251,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(2048, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Memory Throughput,%,9.24,,,,,
0,46251,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(2048, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Throughput,%,0.94,,,,,
0,46251,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(2048, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Duration,nsecond,"9,344",,,,,
0,46251,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(2048, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L1/TEX Cache Throughput,%,13.86,,,,,
0,46251,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(2048, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L2 Cache Throughput,%,6.78,,,,,
0,46251,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(2048, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Active Cycles,cycle,"8,445.50",,,,,
0,46251,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(2048, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Compute (SM) Throughput,%,9.24,,,,,
0,46251,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(2048, 1, 1)",0,7.5,SpeedOfLight,,,,SOLBottleneck,OPT,This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.,,
0,46251,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(2048, 1, 1)",0,7.5,SpeedOfLight_RooflineChart,,,,SOLFPRoofline,INF,The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved  close to 0% of this device's fp32 peak performance and 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.,,
0,46251,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(2048, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Active,inst/cycle,0.23,,,,,
0,46251,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(2048, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Elapsed,inst/cycle,0.15,,,,,
0,46251,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(2048, 1, 1)",0,7.5,Compute Workload Analysis,Issue Slots Busy,%,5.79,,,,,
0,46251,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(2048, 1, 1)",0,7.5,Compute Workload Analysis,Issued Ipc Active,inst/cycle,0.23,,,,,
0,46251,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(2048, 1, 1)",0,7.5,Compute Workload Analysis,SM Busy,%,5.79,,,,,
0,46251,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(2048, 1, 1)",0,7.5,ComputeWorkloadAnalysis,,,,HighPipeUtilization,OPT,All compute pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.,local,95.67
0,46251,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(2048, 1, 1)",0,7.5,Memory Workload Analysis,Memory Throughput,byte/second,"1,770,547,945.21",,,,,
0,46251,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(2048, 1, 1)",0,7.5,Memory Workload Analysis,Mem Busy,%,5.81,,,,,
0,46251,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(2048, 1, 1)",0,7.5,Memory Workload Analysis,Max Bandwidth,%,9.24,,,,,
0,46251,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(2048, 1, 1)",0,7.5,Memory Workload Analysis,L1/TEX Hit Rate,%,27.18,,,,,
0,46251,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(2048, 1, 1)",0,7.5,Memory Workload Analysis,L2 Hit Rate,%,95.67,,,,,
0,46251,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(2048, 1, 1)",0,7.5,Memory Workload Analysis,Mem Pipes Busy,%,9.24,,,,,
0,46251,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(2048, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Chart,,,,MemoryL2Compression,WRN,The optional metric lts__average_gcomp_input_sector_success_rate.pct could not be found. Collecting it as an additional metric could enable the rule to provide more guidance.,,
0,46251,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(2048, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for loads from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced loads and try to minimize how many cache lines need to be accessed per memory request.",global,2.807
0,46251,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(2048, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for stores from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.4 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced stores and try to minimize how many cache lines need to be accessed per memory request.",global,1.215
0,46251,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(2048, 1, 1)",0,7.5,Scheduler Statistics,One or More Eligible,%,6.94,,,,,
0,46251,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(2048, 1, 1)",0,7.5,Scheduler Statistics,Issued Warp Per Scheduler,,0.07,,,,,
0,46251,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(2048, 1, 1)",0,7.5,Scheduler Statistics,No Eligible,%,93.06,,,,,
0,46251,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(2048, 1, 1)",0,7.5,Scheduler Statistics,Active Warps Per Scheduler,warp,3.01,,,,,
0,46251,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(2048, 1, 1)",0,7.5,Scheduler Statistics,Eligible Warps Per Scheduler,warp,0.07,,,,,
0,46251,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(2048, 1, 1)",0,7.5,SchedulerStats,,,,IssueSlotUtilization,OPT,"Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 14.4 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of 3.01 active warps per scheduler, but only an average of 0.07 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections.",local,90.76
0,46251,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(2048, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Issued Instruction,cycle,43.30,,,,,
0,46251,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(2048, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Executed Instruction,cycle,44.54,,,,,
0,46251,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(2048, 1, 1)",0,7.5,Warp State Statistics,Avg. Active Threads Per Warp,,1,,,,,
0,46251,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(2048, 1, 1)",0,7.5,Warp State Statistics,Avg. Not Predicated Off Threads Per Warp,,1,,,,,
0,46251,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(2048, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,OPT,"On average, each warp of this kernel spends 30.6 cycles being stalled waiting for a scoreboard dependency on a L1TEX (local, global, surface, texture) operation. Find the instruction producing the data being waited upon to identify the culprit. To reduce the number of cycles waiting on L1TEX data accesses verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit rates by increasing data locality (coalescing), or by changing the cache configuration. Consider moving frequently used data to shared memory. This stall type represents about 70.8% of the total average of 43.3 cycles between issuing two instructions.",global,70.76
0,46251,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(2048, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,INF,Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.,,
0,46251,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(2048, 1, 1)",0,7.5,WarpStateStats,,,,ThreadDivergence,OPT,"Instructions are executed in warps, which are groups of 32 threads. Optimal instruction throughput is achieved if all 32 threads of a warp execute the same instruction. The chosen launch configuration, early thread completion, and divergent flow control can significantly lower the number of active threads in a warp per cycle. This kernel achieves an average of 1.0 threads being active per cycle.",global,8.95
0,46251,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(2048, 1, 1)",0,7.5,Instruction Statistics,Avg. Executed Instructions Per Scheduler,inst,475.43,,,,,
0,46251,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(2048, 1, 1)",0,7.5,Instruction Statistics,Executed Instructions,inst,"26,624",,,,,
0,46251,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(2048, 1, 1)",0,7.5,Instruction Statistics,Avg. Issued Instructions Per Scheduler,inst,489.07,,,,,
0,46251,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(2048, 1, 1)",0,7.5,Instruction Statistics,Issued Instructions,inst,"27,388",,,,,
0,46251,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(2048, 1, 1)",0,7.5,InstructionStats,,,,FPInstructions,OPT,"This kernel executes 0 fused and 2048 non-fused FP32 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP32 performance could be increased by up to 50% (relative to its current performance). Check the Source page to identify where this kernel executes FP32 instructions.",global,2.165
0,46251,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(2048, 1, 1)",0,7.5,Launch Statistics,Block Size,,1,,,,,
0,46251,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(2048, 1, 1)",0,7.5,Launch Statistics,Function Cache Configuration,,CachePreferNone,,,,,
0,46251,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(2048, 1, 1)",0,7.5,Launch Statistics,Grid Size,,"2,048",,,,,
0,46251,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(2048, 1, 1)",0,7.5,Launch Statistics,Registers Per Thread,register/thread,16,,,,,
0,46251,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(2048, 1, 1)",0,7.5,Launch Statistics,Shared Memory Configuration Size,byte,"32,768",,,,,
0,46251,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(2048, 1, 1)",0,7.5,Launch Statistics,Driver Shared Memory Per Block,byte/block,0,,,,,
0,46251,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(2048, 1, 1)",0,7.5,Launch Statistics,Dynamic Shared Memory Per Block,byte/block,0,,,,,
0,46251,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(2048, 1, 1)",0,7.5,Launch Statistics,Static Shared Memory Per Block,byte/block,0,,,,,
0,46251,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(2048, 1, 1)",0,7.5,Launch Statistics,Threads,thread,"2,048",,,,,
0,46251,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(2048, 1, 1)",0,7.5,Launch Statistics,Waves Per SM,,9.14,,,,,
0,46251,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(2048, 1, 1)",0,7.5,LaunchStats,,,,LaunchConfiguration,OPT,"Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 1 threads per block. Consequently, some threads in a warp are masked off and those hardware resources are unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256 threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to kernels that frequently call __syncthreads(). See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations.",global,96.88
0,46251,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(2048, 1, 1)",0,7.5,Occupancy,Block Limit SM,block,16,,,,,
0,46251,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(2048, 1, 1)",0,7.5,Occupancy,Block Limit Registers,block,128,,,,,
0,46251,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(2048, 1, 1)",0,7.5,Occupancy,Block Limit Shared Mem,block,16,,,,,
0,46251,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(2048, 1, 1)",0,7.5,Occupancy,Block Limit Warps,block,32,,,,,
0,46251,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(2048, 1, 1)",0,7.5,Occupancy,Theoretical Active Warps per SM,warp,16,,,,,
0,46251,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(2048, 1, 1)",0,7.5,Occupancy,Theoretical Occupancy,%,50,,,,,
0,46251,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(2048, 1, 1)",0,7.5,Occupancy,Achieved Occupancy,%,31.96,,,,,
0,46251,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(2048, 1, 1)",0,7.5,Occupancy,Achieved Active Warps Per SM,warp,10.23,,,,,
0,46251,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(2048, 1, 1)",0,7.5,Occupancy,,,,AchievedOccupancy,OPT,The difference between calculated theoretical (50.0%) and measured achieved occupancy (32.0%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy.,global,36.09
0,46251,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(2048, 1, 1)",0,7.5,Occupancy,,,,TheoreticalOccupancy,OPT,The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared memory.,global,50.0
0,46251,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(2048, 1, 1)",0,7.5,Source Counters,Branch Instructions Ratio,%,0.08,,,,,
0,46251,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(2048, 1, 1)",0,7.5,Source Counters,Branch Instructions,inst,"2,048",,,,,
0,46251,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(2048, 1, 1)",0,7.5,Source Counters,Branch Efficiency,%,0,,,,,
0,46251,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(2048, 1, 1)",0,7.5,Source Counters,Avg. Divergent Branches,,0,,,,,
0,46343,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(1024, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Frequency,cycle/second,"6,095,238,095.24",,,,,
0,46343,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(1024, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Frequency,cycle/second,"1,411,272,321.43",,,,,
0,46343,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(1024, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Elapsed Cycles,cycle,"7,624",,,,,
0,46343,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(1024, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Memory Throughput,%,7.71,,,,,
0,46343,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(1024, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Throughput,%,1.58,,,,,
0,46343,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(1024, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Duration,nsecond,"5,376",,,,,
0,46343,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(1024, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L1/TEX Cache Throughput,%,14.48,,,,,
0,46343,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(1024, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L2 Cache Throughput,%,6.10,,,,,
0,46343,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(1024, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Active Cycles,cycle,"4,039.86",,,,,
0,46343,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(1024, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Compute (SM) Throughput,%,7.71,,,,,
0,46343,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(1024, 1, 1)",0,7.5,SpeedOfLight,,,,SOLBottleneck,OPT,This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.,,
0,46343,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(1024, 1, 1)",0,7.5,SpeedOfLight_RooflineChart,,,,SOLFPRoofline,INF,The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved  close to 0% of this device's fp32 peak performance and 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.,,
0,46343,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(1024, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Active,inst/cycle,0.24,,,,,
0,46343,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(1024, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Elapsed,inst/cycle,0.13,,,,,
0,46343,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(1024, 1, 1)",0,7.5,Compute Workload Analysis,Issue Slots Busy,%,6.22,,,,,
0,46343,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(1024, 1, 1)",0,7.5,Compute Workload Analysis,Issued Ipc Active,inst/cycle,0.25,,,,,
0,46343,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(1024, 1, 1)",0,7.5,Compute Workload Analysis,SM Busy,%,6.22,,,,,
0,46343,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(1024, 1, 1)",0,7.5,ComputeWorkloadAnalysis,,,,HighPipeUtilization,OPT,All compute pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.,local,95.47
0,46343,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(1024, 1, 1)",0,7.5,Memory Workload Analysis,Memory Throughput,byte/second,"3,077,380,952.38",,,,,
0,46343,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(1024, 1, 1)",0,7.5,Memory Workload Analysis,Mem Busy,%,5.01,,,,,
0,46343,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(1024, 1, 1)",0,7.5,Memory Workload Analysis,Max Bandwidth,%,7.71,,,,,
0,46343,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(1024, 1, 1)",0,7.5,Memory Workload Analysis,L1/TEX Hit Rate,%,17.73,,,,,
0,46343,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(1024, 1, 1)",0,7.5,Memory Workload Analysis,L2 Hit Rate,%,90.98,,,,,
0,46343,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(1024, 1, 1)",0,7.5,Memory Workload Analysis,Mem Pipes Busy,%,7.71,,,,,
0,46343,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(1024, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Chart,,,,MemoryL2Compression,WRN,The optional metric lts__average_gcomp_input_sector_success_rate.pct could not be found. Collecting it as an additional metric could enable the rule to provide more guidance.,,
0,46343,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(1024, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for loads from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced loads and try to minimize how many cache lines need to be accessed per memory request.",global,2.378
0,46343,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(1024, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for stores from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.2 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced stores and try to minimize how many cache lines need to be accessed per memory request.",global,1.121
0,46343,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(1024, 1, 1)",0,7.5,Scheduler Statistics,One or More Eligible,%,6.76,,,,,
0,46343,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(1024, 1, 1)",0,7.5,Scheduler Statistics,Issued Warp Per Scheduler,,0.07,,,,,
0,46343,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(1024, 1, 1)",0,7.5,Scheduler Statistics,No Eligible,%,93.24,,,,,
0,46343,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(1024, 1, 1)",0,7.5,Scheduler Statistics,Active Warps Per Scheduler,warp,2.94,,,,,
0,46343,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(1024, 1, 1)",0,7.5,Scheduler Statistics,Eligible Warps Per Scheduler,warp,0.07,,,,,
0,46343,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(1024, 1, 1)",0,7.5,SchedulerStats,,,,IssueSlotUtilization,OPT,"Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 14.8 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of 2.94 active warps per scheduler, but only an average of 0.07 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections.",local,92.29
0,46343,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(1024, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Issued Instruction,cycle,43.42,,,,,
0,46343,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(1024, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Executed Instruction,cycle,45.90,,,,,
0,46343,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(1024, 1, 1)",0,7.5,Warp State Statistics,Avg. Active Threads Per Warp,,2,,,,,
0,46343,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(1024, 1, 1)",0,7.5,Warp State Statistics,Avg. Not Predicated Off Threads Per Warp,,2,,,,,
0,46343,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(1024, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,OPT,"On average, each warp of this kernel spends 27.5 cycles being stalled waiting for a scoreboard dependency on a L1TEX (local, global, surface, texture) operation. Find the instruction producing the data being waited upon to identify the culprit. To reduce the number of cycles waiting on L1TEX data accesses verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit rates by increasing data locality (coalescing), or by changing the cache configuration. Consider moving frequently used data to shared memory. This stall type represents about 63.4% of the total average of 43.4 cycles between issuing two instructions.",global,63.41
0,46343,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(1024, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,INF,Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.,,
0,46343,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(1024, 1, 1)",0,7.5,WarpStateStats,,,,ThreadDivergence,OPT,"Instructions are executed in warps, which are groups of 32 threads. Optimal instruction throughput is achieved if all 32 threads of a warp execute the same instruction. The chosen launch configuration, early thread completion, and divergent flow control can significantly lower the number of active threads in a warp per cycle. This kernel achieves an average of 2.0 threads being active per cycle.",global,7.225
0,46343,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(1024, 1, 1)",0,7.5,Instruction Statistics,Avg. Executed Instructions Per Scheduler,inst,237.71,,,,,
0,46343,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(1024, 1, 1)",0,7.5,Instruction Statistics,Executed Instructions,inst,"13,312",,,,,
0,46343,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(1024, 1, 1)",0,7.5,Instruction Statistics,Avg. Issued Instructions Per Scheduler,inst,251.30,,,,,
0,46343,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(1024, 1, 1)",0,7.5,Instruction Statistics,Issued Instructions,inst,"14,073",,,,,
0,46343,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(1024, 1, 1)",0,7.5,InstructionStats,,,,FPInstructions,OPT,"This kernel executes 0 fused and 1024 non-fused FP32 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP32 performance could be increased by up to 50% (relative to its current performance). Check the Source page to identify where this kernel executes FP32 instructions.",global,2.263
0,46343,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(1024, 1, 1)",0,7.5,Launch Statistics,Block Size,,2,,,,,
0,46343,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(1024, 1, 1)",0,7.5,Launch Statistics,Function Cache Configuration,,CachePreferNone,,,,,
0,46343,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(1024, 1, 1)",0,7.5,Launch Statistics,Grid Size,,"1,024",,,,,
0,46343,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(1024, 1, 1)",0,7.5,Launch Statistics,Registers Per Thread,register/thread,16,,,,,
0,46343,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(1024, 1, 1)",0,7.5,Launch Statistics,Shared Memory Configuration Size,byte,"32,768",,,,,
0,46343,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(1024, 1, 1)",0,7.5,Launch Statistics,Driver Shared Memory Per Block,byte/block,0,,,,,
0,46343,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(1024, 1, 1)",0,7.5,Launch Statistics,Dynamic Shared Memory Per Block,byte/block,0,,,,,
0,46343,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(1024, 1, 1)",0,7.5,Launch Statistics,Static Shared Memory Per Block,byte/block,0,,,,,
0,46343,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(1024, 1, 1)",0,7.5,Launch Statistics,Threads,thread,"2,048",,,,,
0,46343,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(1024, 1, 1)",0,7.5,Launch Statistics,Waves Per SM,,4.57,,,,,
0,46343,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(1024, 1, 1)",0,7.5,LaunchStats,,,,LaunchConfiguration,OPT,"Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 2 threads per block. Consequently, some threads in a warp are masked off and those hardware resources are unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256 threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to kernels that frequently call __syncthreads(). See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations.",global,93.75
0,46343,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(1024, 1, 1)",0,7.5,LaunchStats,,,,LaunchConfiguration,OPT,"A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical occupancy of the kernel. This kernel launch results in 4 full waves and a partial wave of 127 thread blocks. Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for up to 20.0% of the total kernel runtime with a lower occupancy of 29.4%. Try launching a grid with no partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for a grid. See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations.",global,20.0
0,46343,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(1024, 1, 1)",0,7.5,Occupancy,Block Limit SM,block,16,,,,,
0,46343,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(1024, 1, 1)",0,7.5,Occupancy,Block Limit Registers,block,128,,,,,
0,46343,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(1024, 1, 1)",0,7.5,Occupancy,Block Limit Shared Mem,block,16,,,,,
0,46343,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(1024, 1, 1)",0,7.5,Occupancy,Block Limit Warps,block,32,,,,,
0,46343,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(1024, 1, 1)",0,7.5,Occupancy,Theoretical Active Warps per SM,warp,16,,,,,
0,46343,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(1024, 1, 1)",0,7.5,Occupancy,Theoretical Occupancy,%,50,,,,,
0,46343,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(1024, 1, 1)",0,7.5,Occupancy,Achieved Occupancy,%,35.29,,,,,
0,46343,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(1024, 1, 1)",0,7.5,Occupancy,Achieved Active Warps Per SM,warp,11.29,,,,,
0,46343,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(1024, 1, 1)",0,7.5,Occupancy,,,,AchievedOccupancy,OPT,The difference between calculated theoretical (50.0%) and measured achieved occupancy (35.3%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy.,global,29.42
0,46343,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(1024, 1, 1)",0,7.5,Occupancy,,,,TheoreticalOccupancy,OPT,The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared memory.,global,50.0
0,46343,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(1024, 1, 1)",0,7.5,Source Counters,Branch Instructions Ratio,%,0.08,,,,,
0,46343,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(1024, 1, 1)",0,7.5,Source Counters,Branch Instructions,inst,"1,024",,,,,
0,46343,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(1024, 1, 1)",0,7.5,Source Counters,Branch Efficiency,%,0,,,,,
0,46343,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(1024, 1, 1)",0,7.5,Source Counters,Avg. Divergent Branches,,0,,,,,
0,46428,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(512, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Frequency,cycle/second,"5,793,103,448.28",,,,,
0,46428,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(512, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Frequency,cycle/second,"1,349,003,232.76",,,,,
0,46428,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(512, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Elapsed Cycles,cycle,"5,026",,,,,
0,46428,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(512, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Memory Throughput,%,5.84,,,,,
0,46428,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(512, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Throughput,%,2.40,,,,,
0,46428,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(512, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Duration,nsecond,"3,712",,,,,
0,46428,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(512, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L1/TEX Cache Throughput,%,12.05,,,,,
0,46428,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(512, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L2 Cache Throughput,%,4.19,,,,,
0,46428,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(512, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Active Cycles,cycle,"2,427.79",,,,,
0,46428,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(512, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Compute (SM) Throughput,%,5.84,,,,,
0,46428,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(512, 1, 1)",0,7.5,SpeedOfLight,,,,SOLBottleneck,OPT,This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.,,
0,46428,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(512, 1, 1)",0,7.5,SpeedOfLight_RooflineChart,,,,SOLFPRoofline,INF,The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved  close to 0% of this device's fp32 peak performance and 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.,,
0,46428,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(512, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Active,inst/cycle,0.20,,,,,
0,46428,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(512, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Elapsed,inst/cycle,0.09,,,,,
0,46428,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(512, 1, 1)",0,7.5,Compute Workload Analysis,Issue Slots Busy,%,5.46,,,,,
0,46428,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(512, 1, 1)",0,7.5,Compute Workload Analysis,Issued Ipc Active,inst/cycle,0.22,,,,,
0,46428,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(512, 1, 1)",0,7.5,Compute Workload Analysis,SM Busy,%,5.46,,,,,
0,46428,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(512, 1, 1)",0,7.5,ComputeWorkloadAnalysis,,,,HighPipeUtilization,OPT,All compute pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.,local,96.23
0,46428,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(512, 1, 1)",0,7.5,Memory Workload Analysis,Memory Throughput,byte/second,"4,456,896,551.72",,,,,
0,46428,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(512, 1, 1)",0,7.5,Memory Workload Analysis,Mem Busy,%,3.58,,,,,
0,46428,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(512, 1, 1)",0,7.5,Memory Workload Analysis,Max Bandwidth,%,5.84,,,,,
0,46428,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(512, 1, 1)",0,7.5,Memory Workload Analysis,L1/TEX Hit Rate,%,23.05,,,,,
0,46428,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(512, 1, 1)",0,7.5,Memory Workload Analysis,L2 Hit Rate,%,81.85,,,,,
0,46428,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(512, 1, 1)",0,7.5,Memory Workload Analysis,Mem Pipes Busy,%,5.84,,,,,
0,46428,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(512, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Chart,,,,MemoryL2Compression,WRN,The optional metric lts__average_gcomp_input_sector_success_rate.pct could not be found. Collecting it as an additional metric could enable the rule to provide more guidance.,,
0,46428,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(512, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for loads from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced loads and try to minimize how many cache lines need to be accessed per memory request.",global,1.611
0,46428,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(512, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for stores from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced stores and try to minimize how many cache lines need to be accessed per memory request.",global,0.8164
0,46428,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(512, 1, 1)",0,7.5,Scheduler Statistics,One or More Eligible,%,5.84,,,,,
0,46428,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(512, 1, 1)",0,7.5,Scheduler Statistics,Issued Warp Per Scheduler,,0.06,,,,,
0,46428,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(512, 1, 1)",0,7.5,Scheduler Statistics,No Eligible,%,94.16,,,,,
0,46428,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(512, 1, 1)",0,7.5,Scheduler Statistics,Active Warps Per Scheduler,warp,2.91,,,,,
0,46428,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(512, 1, 1)",0,7.5,Scheduler Statistics,Eligible Warps Per Scheduler,warp,0.07,,,,,
0,46428,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(512, 1, 1)",0,7.5,SchedulerStats,,,,IssueSlotUtilization,OPT,"Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 17.1 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of 2.91 active warps per scheduler, but only an average of 0.07 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections.",local,94.16
0,46428,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(512, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Issued Instruction,cycle,49.84,,,,,
0,46428,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(512, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Executed Instruction,cycle,55.56,,,,,
0,46428,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(512, 1, 1)",0,7.5,Warp State Statistics,Avg. Active Threads Per Warp,,4,,,,,
0,46428,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(512, 1, 1)",0,7.5,Warp State Statistics,Avg. Not Predicated Off Threads Per Warp,,4,,,,,
0,46428,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(512, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,OPT,"On average, each warp of this kernel spends 26.5 cycles being stalled waiting for a scoreboard dependency on a L1TEX (local, global, surface, texture) operation. Find the instruction producing the data being waited upon to identify the culprit. To reduce the number of cycles waiting on L1TEX data accesses verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit rates by increasing data locality (coalescing), or by changing the cache configuration. Consider moving frequently used data to shared memory. This stall type represents about 53.2% of the total average of 49.8 cycles between issuing two instructions.",global,53.16
0,46428,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(512, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,INF,Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.,,
0,46428,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(512, 1, 1)",0,7.5,WarpStateStats,,,,ThreadDivergence,OPT,"Instructions are executed in warps, which are groups of 32 threads. Optimal instruction throughput is achieved if all 32 threads of a warp execute the same instruction. The chosen launch configuration, early thread completion, and divergent flow control can significantly lower the number of active threads in a warp per cycle. This kernel achieves an average of 4.0 threads being active per cycle.",global,5.11
0,46428,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(512, 1, 1)",0,7.5,Instruction Statistics,Avg. Executed Instructions Per Scheduler,inst,118.86,,,,,
0,46428,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(512, 1, 1)",0,7.5,Instruction Statistics,Executed Instructions,inst,"6,656",,,,,
0,46428,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(512, 1, 1)",0,7.5,Instruction Statistics,Avg. Issued Instructions Per Scheduler,inst,132.50,,,,,
0,46428,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(512, 1, 1)",0,7.5,Instruction Statistics,Issued Instructions,inst,"7,420",,,,,
0,46428,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(512, 1, 1)",0,7.5,InstructionStats,,,,FPInstructions,OPT,"This kernel executes 0 fused and 512 non-fused FP32 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP32 performance could be increased by up to 50% (relative to its current performance). Check the Source page to identify where this kernel executes FP32 instructions.",global,1.883
0,46428,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(512, 1, 1)",0,7.5,Launch Statistics,Block Size,,4,,,,,
0,46428,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(512, 1, 1)",0,7.5,Launch Statistics,Function Cache Configuration,,CachePreferNone,,,,,
0,46428,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(512, 1, 1)",0,7.5,Launch Statistics,Grid Size,,512,,,,,
0,46428,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(512, 1, 1)",0,7.5,Launch Statistics,Registers Per Thread,register/thread,16,,,,,
0,46428,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(512, 1, 1)",0,7.5,Launch Statistics,Shared Memory Configuration Size,byte,"32,768",,,,,
0,46428,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(512, 1, 1)",0,7.5,Launch Statistics,Driver Shared Memory Per Block,byte/block,0,,,,,
0,46428,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(512, 1, 1)",0,7.5,Launch Statistics,Dynamic Shared Memory Per Block,byte/block,0,,,,,
0,46428,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(512, 1, 1)",0,7.5,Launch Statistics,Static Shared Memory Per Block,byte/block,0,,,,,
0,46428,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(512, 1, 1)",0,7.5,Launch Statistics,Threads,thread,"2,048",,,,,
0,46428,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(512, 1, 1)",0,7.5,Launch Statistics,Waves Per SM,,2.29,,,,,
0,46428,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(512, 1, 1)",0,7.5,LaunchStats,,,,LaunchConfiguration,OPT,"Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 4 threads per block. Consequently, some threads in a warp are masked off and those hardware resources are unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256 threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to kernels that frequently call __syncthreads(). See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations.",global,87.5
0,46428,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(512, 1, 1)",0,7.5,LaunchStats,,,,LaunchConfiguration,OPT,"A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical occupancy of the kernel. This kernel launch results in 2 full waves and a partial wave of 63 thread blocks. Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for up to 33.3% of the total kernel runtime with a lower occupancy of 31.3%. Try launching a grid with no partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for a grid. See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations.",global,33.33
0,46428,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(512, 1, 1)",0,7.5,Occupancy,Block Limit SM,block,16,,,,,
0,46428,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(512, 1, 1)",0,7.5,Occupancy,Block Limit Registers,block,128,,,,,
0,46428,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(512, 1, 1)",0,7.5,Occupancy,Block Limit Shared Mem,block,16,,,,,
0,46428,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(512, 1, 1)",0,7.5,Occupancy,Block Limit Warps,block,32,,,,,
0,46428,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(512, 1, 1)",0,7.5,Occupancy,Theoretical Active Warps per SM,warp,16,,,,,
0,46428,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(512, 1, 1)",0,7.5,Occupancy,Theoretical Occupancy,%,50,,,,,
0,46428,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(512, 1, 1)",0,7.5,Occupancy,Achieved Occupancy,%,34.37,,,,,
0,46428,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(512, 1, 1)",0,7.5,Occupancy,Achieved Active Warps Per SM,warp,11.00,,,,,
0,46428,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(512, 1, 1)",0,7.5,Occupancy,,,,AchievedOccupancy,OPT,The difference between calculated theoretical (50.0%) and measured achieved occupancy (34.4%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy.,global,31.25
0,46428,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(512, 1, 1)",0,7.5,Occupancy,,,,TheoreticalOccupancy,OPT,The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared memory.,global,50.0
0,46428,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(512, 1, 1)",0,7.5,Source Counters,Branch Instructions Ratio,%,0.08,,,,,
0,46428,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(512, 1, 1)",0,7.5,Source Counters,Branch Instructions,inst,512,,,,,
0,46428,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(512, 1, 1)",0,7.5,Source Counters,Branch Efficiency,%,0,,,,,
0,46428,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(512, 1, 1)",0,7.5,Source Counters,Avg. Divergent Branches,,0,,,,,
0,46505,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(256, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Frequency,cycle/second,"5,860,465,116.28",,,,,
0,46505,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(256, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Frequency,cycle/second,"1,341,024,709.30",,,,,
0,46505,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(256, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Elapsed Cycles,cycle,"3,702",,,,,
0,46505,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(256, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Memory Throughput,%,3.96,,,,,
0,46505,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(256, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Throughput,%,3.21,,,,,
0,46505,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(256, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Duration,nsecond,"2,752",,,,,
0,46505,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(256, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L1/TEX Cache Throughput,%,8.46,,,,,
0,46505,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(256, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L2 Cache Throughput,%,3.32,,,,,
0,46505,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(256, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Active Cycles,cycle,"1,728.64",,,,,
0,46505,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(256, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Compute (SM) Throughput,%,3.96,,,,,
0,46505,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(256, 1, 1)",0,7.5,SpeedOfLight,,,,SOLBottleneck,OPT,This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.,,
0,46505,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(256, 1, 1)",0,7.5,SpeedOfLight_RooflineChart,,,,SOLFPRoofline,INF,The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved  close to 0% of this device's fp32 peak performance and 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.,,
0,46505,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(256, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Active,inst/cycle,0.14,,,,,
0,46505,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(256, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Elapsed,inst/cycle,0.06,,,,,
0,46505,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(256, 1, 1)",0,7.5,Compute Workload Analysis,Issue Slots Busy,%,4.23,,,,,
0,46505,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(256, 1, 1)",0,7.5,Compute Workload Analysis,Issued Ipc Active,inst/cycle,0.17,,,,,
0,46505,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(256, 1, 1)",0,7.5,Compute Workload Analysis,SM Busy,%,4.23,,,,,
0,46505,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(256, 1, 1)",0,7.5,ComputeWorkloadAnalysis,,,,HighPipeUtilization,OPT,All compute pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.,local,97.36
0,46505,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(256, 1, 1)",0,7.5,Memory Workload Analysis,Memory Throughput,byte/second,"6,011,627,906.98",,,,,
0,46505,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(256, 1, 1)",0,7.5,Memory Workload Analysis,Mem Busy,%,3.32,,,,,
0,46505,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(256, 1, 1)",0,7.5,Memory Workload Analysis,Max Bandwidth,%,3.96,,,,,
0,46505,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(256, 1, 1)",0,7.5,Memory Workload Analysis,L1/TEX Hit Rate,%,14.60,,,,,
0,46505,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(256, 1, 1)",0,7.5,Memory Workload Analysis,L2 Hit Rate,%,53.99,,,,,
0,46505,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(256, 1, 1)",0,7.5,Memory Workload Analysis,Mem Pipes Busy,%,3.96,,,,,
0,46505,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(256, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Chart,,,,MemoryL2Compression,WRN,The optional metric lts__average_gcomp_input_sector_success_rate.pct could not be found. Collecting it as an additional metric could enable the rule to provide more guidance.,,
0,46505,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(256, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for loads from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.5 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced loads and try to minimize how many cache lines need to be accessed per memory request.",global,1.195
0,46505,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(256, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for stores from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.7 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced stores and try to minimize how many cache lines need to be accessed per memory request.",global,0.5524
0,46505,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(256, 1, 1)",0,7.5,Scheduler Statistics,One or More Eligible,%,4.98,,,,,
0,46505,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(256, 1, 1)",0,7.5,Scheduler Statistics,Issued Warp Per Scheduler,,0.05,,,,,
0,46505,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(256, 1, 1)",0,7.5,Scheduler Statistics,No Eligible,%,95.02,,,,,
0,46505,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(256, 1, 1)",0,7.5,Scheduler Statistics,Active Warps Per Scheduler,warp,3.28,,,,,
0,46505,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(256, 1, 1)",0,7.5,Scheduler Statistics,Eligible Warps Per Scheduler,warp,0.06,,,,,
0,46505,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(256, 1, 1)",0,7.5,SchedulerStats,,,,IssueSlotUtilization,OPT,"Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 20.1 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of 3.28 active warps per scheduler, but only an average of 0.06 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, avoid possible load imbalances due to highly different execution durations per warp. Reducing stalls indicated on the Warp State Statistics and Source Counters sections can help, too.",local,95.02
0,46505,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(256, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Issued Instruction,cycle,65.92,,,,,
0,46505,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(256, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Executed Instruction,cycle,81.06,,,,,
0,46505,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(256, 1, 1)",0,7.5,Warp State Statistics,Avg. Active Threads Per Warp,,8,,,,,
0,46505,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(256, 1, 1)",0,7.5,Warp State Statistics,Avg. Not Predicated Off Threads Per Warp,,8,,,,,
0,46505,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(256, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,OPT,"On average, each warp of this kernel spends 27.2 cycles being stalled waiting for a scoreboard dependency on a L1TEX (local, global, surface, texture) operation. Find the instruction producing the data being waited upon to identify the culprit. To reduce the number of cycles waiting on L1TEX data accesses verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit rates by increasing data locality (coalescing), or by changing the cache configuration. Consider moving frequently used data to shared memory. This stall type represents about 41.3% of the total average of 65.9 cycles between issuing two instructions.",global,41.3
0,46505,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(256, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,OPT,"On average, each warp of this kernel spends 25.7 cycles being stalled waiting for an immediate constant cache (IMC) miss. A read from constant memory costs one memory read from device memory only on a cache miss; otherwise, it just costs one read from the constant cache. Immediate constants are encoded into the SASS instruction as 'c[bank][offset]'. Accesses to different addresses by threads within a warp are serialized, thus the cost scales linearly with the number of unique addresses read by all threads within a warp. As such, the constant cache is best when threads in the same warp access only a few distinct locations. If all threads of a warp access the same location, then constant memory can be as fast as a register access. This stall type represents about 39.0% of the total average of 65.9 cycles between issuing two instructions.",global,39.05
0,46505,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(256, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,INF,Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.,,
0,46505,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(256, 1, 1)",0,7.5,WarpStateStats,,,,ThreadDivergence,OPT,"Instructions are executed in warps, which are groups of 32 threads. Optimal instruction throughput is achieved if all 32 threads of a warp execute the same instruction. The chosen launch configuration, early thread completion, and divergent flow control can significantly lower the number of active threads in a warp per cycle. This kernel achieves an average of 8.0 threads being active per cycle.",global,2.972
0,46505,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(256, 1, 1)",0,7.5,Instruction Statistics,Avg. Executed Instructions Per Scheduler,inst,59.43,,,,,
0,46505,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(256, 1, 1)",0,7.5,Instruction Statistics,Executed Instructions,inst,"3,328",,,,,
0,46505,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(256, 1, 1)",0,7.5,Instruction Statistics,Avg. Issued Instructions Per Scheduler,inst,73.07,,,,,
0,46505,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(256, 1, 1)",0,7.5,Instruction Statistics,Issued Instructions,inst,"4,092",,,,,
0,46505,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(256, 1, 1)",0,7.5,InstructionStats,,,,FPInstructions,OPT,"This kernel executes 0 fused and 256 non-fused FP32 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP32 performance could be increased by up to 50% (relative to its current performance). Check the Source page to identify where this kernel executes FP32 instructions.",global,1.322
0,46505,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(256, 1, 1)",0,7.5,Launch Statistics,Block Size,,8,,,,,
0,46505,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(256, 1, 1)",0,7.5,Launch Statistics,Function Cache Configuration,,CachePreferNone,,,,,
0,46505,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(256, 1, 1)",0,7.5,Launch Statistics,Grid Size,,256,,,,,
0,46505,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(256, 1, 1)",0,7.5,Launch Statistics,Registers Per Thread,register/thread,16,,,,,
0,46505,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(256, 1, 1)",0,7.5,Launch Statistics,Shared Memory Configuration Size,byte,"32,768",,,,,
0,46505,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(256, 1, 1)",0,7.5,Launch Statistics,Driver Shared Memory Per Block,byte/block,0,,,,,
0,46505,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(256, 1, 1)",0,7.5,Launch Statistics,Dynamic Shared Memory Per Block,byte/block,0,,,,,
0,46505,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(256, 1, 1)",0,7.5,Launch Statistics,Static Shared Memory Per Block,byte/block,0,,,,,
0,46505,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(256, 1, 1)",0,7.5,Launch Statistics,Threads,thread,"2,048",,,,,
0,46505,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(256, 1, 1)",0,7.5,Launch Statistics,Waves Per SM,,1.14,,,,,
0,46505,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(256, 1, 1)",0,7.5,LaunchStats,,,,LaunchConfiguration,OPT,"Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 8 threads per block. Consequently, some threads in a warp are masked off and those hardware resources are unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256 threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to kernels that frequently call __syncthreads(). See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations.",global,75.0
0,46505,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(256, 1, 1)",0,7.5,LaunchStats,,,,LaunchConfiguration,OPT,"A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical occupancy of the kernel. This kernel launch results in 1 full waves and a partial wave of 31 thread blocks. Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for up to 50.0% of the total kernel runtime with a lower occupancy of 32.7%. Try launching a grid with no partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for a grid. See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations.",global,50.0
0,46505,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(256, 1, 1)",0,7.5,Occupancy,Block Limit SM,block,16,,,,,
0,46505,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(256, 1, 1)",0,7.5,Occupancy,Block Limit Registers,block,128,,,,,
0,46505,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(256, 1, 1)",0,7.5,Occupancy,Block Limit Shared Mem,block,16,,,,,
0,46505,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(256, 1, 1)",0,7.5,Occupancy,Block Limit Warps,block,32,,,,,
0,46505,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(256, 1, 1)",0,7.5,Occupancy,Theoretical Active Warps per SM,warp,16,,,,,
0,46505,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(256, 1, 1)",0,7.5,Occupancy,Theoretical Occupancy,%,50,,,,,
0,46505,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(256, 1, 1)",0,7.5,Occupancy,Achieved Occupancy,%,33.63,,,,,
0,46505,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(256, 1, 1)",0,7.5,Occupancy,Achieved Active Warps Per SM,warp,10.76,,,,,
0,46505,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(256, 1, 1)",0,7.5,Occupancy,,,,AchievedOccupancy,OPT,The difference between calculated theoretical (50.0%) and measured achieved occupancy (33.6%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy.,global,32.75
0,46505,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(256, 1, 1)",0,7.5,Occupancy,,,,TheoreticalOccupancy,OPT,The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared memory.,global,50.0
0,46505,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(256, 1, 1)",0,7.5,Source Counters,Branch Instructions Ratio,%,0.08,,,,,
0,46505,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(256, 1, 1)",0,7.5,Source Counters,Branch Instructions,inst,256,,,,,
0,46505,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(256, 1, 1)",0,7.5,Source Counters,Branch Efficiency,%,0,,,,,
0,46505,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(256, 1, 1)",0,7.5,Source Counters,Avg. Divergent Branches,,0,,,,,
0,46589,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(128, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Frequency,cycle/second,"5,565,217,391.30",,,,,
0,46589,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(128, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Frequency,cycle/second,"1,301,403,985.51",,,,,
0,46589,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(128, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Elapsed Cycles,cycle,"2,874",,,,,
0,46589,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(128, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Memory Throughput,%,4.27,,,,,
0,46589,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(128, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Throughput,%,4.27,,,,,
0,46589,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(128, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Duration,nsecond,"2,208",,,,,
0,46589,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(128, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L1/TEX Cache Throughput,%,5.66,,,,,
0,46589,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(128, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L2 Cache Throughput,%,4.27,,,,,
0,46589,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(128, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Active Cycles,cycle,"1,292.36",,,,,
0,46589,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(128, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Compute (SM) Throughput,%,2.55,,,,,
0,46589,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(128, 1, 1)",0,7.5,SpeedOfLight,,,,SOLBottleneck,OPT,"This kernel grid is too small to fill the available resources on this device, resulting in only 0.6 full waves across all SMs. Look at Launch Statistics for more details.",,
0,46589,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(128, 1, 1)",0,7.5,SpeedOfLight_RooflineChart,,,,SOLFPRoofline,INF,The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved  close to 0% of this device's fp32 peak performance and 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.,,
0,46589,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(128, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Active,inst/cycle,0.09,,,,,
0,46589,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(128, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Elapsed,inst/cycle,0.04,,,,,
0,46589,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(128, 1, 1)",0,7.5,Compute Workload Analysis,Issue Slots Busy,%,3.01,,,,,
0,46589,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(128, 1, 1)",0,7.5,Compute Workload Analysis,Issued Ipc Active,inst/cycle,0.12,,,,,
0,46589,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(128, 1, 1)",0,7.5,Compute Workload Analysis,SM Busy,%,3.01,,,,,
0,46589,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(128, 1, 1)",0,7.5,ComputeWorkloadAnalysis,,,,HighPipeUtilization,OPT,All compute pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.,local,98.23
0,46589,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(128, 1, 1)",0,7.5,Memory Workload Analysis,Memory Throughput,byte/second,"7,608,695,652.17",,,,,
0,46589,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(128, 1, 1)",0,7.5,Memory Workload Analysis,Mem Busy,%,4.27,,,,,
0,46589,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(128, 1, 1)",0,7.5,Memory Workload Analysis,Max Bandwidth,%,4.27,,,,,
0,46589,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(128, 1, 1)",0,7.5,Memory Workload Analysis,L1/TEX Hit Rate,%,12.76,,,,,
0,46589,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(128, 1, 1)",0,7.5,Memory Workload Analysis,L2 Hit Rate,%,45.48,,,,,
0,46589,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(128, 1, 1)",0,7.5,Memory Workload Analysis,Mem Pipes Busy,%,2.55,,,,,
0,46589,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(128, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Chart,,,,MemoryL2Compression,WRN,The optional metric lts__average_gcomp_input_sector_success_rate.pct could not be found. Collecting it as an additional metric could enable the rule to provide more guidance.,,
0,46589,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(128, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for loads from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 3.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced loads and try to minimize how many cache lines need to be accessed per memory request.",global,0.6094
0,46589,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(128, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for stores from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 2.8 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced stores and try to minimize how many cache lines need to be accessed per memory request.",global,0.3523
0,46589,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(128, 1, 1)",0,7.5,Scheduler Statistics,One or More Eligible,%,3.30,,,,,
0,46589,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(128, 1, 1)",0,7.5,Scheduler Statistics,Issued Warp Per Scheduler,,0.03,,,,,
0,46589,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(128, 1, 1)",0,7.5,Scheduler Statistics,No Eligible,%,96.70,,,,,
0,46589,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(128, 1, 1)",0,7.5,Scheduler Statistics,Active Warps Per Scheduler,warp,2.28,,,,,
0,46589,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(128, 1, 1)",0,7.5,Scheduler Statistics,Eligible Warps Per Scheduler,warp,0.04,,,,,
0,46589,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(128, 1, 1)",0,7.5,SchedulerStats,,,,IssueSlotUtilization,OPT,"Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 30.3 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of 2.28 active warps per scheduler, but only an average of 0.04 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections.",local,95.73
0,46589,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(128, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Issued Instruction,cycle,69.20,,,,,
0,46589,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(128, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Executed Instruction,cycle,90.50,,,,,
0,46589,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(128, 1, 1)",0,7.5,Warp State Statistics,Avg. Active Threads Per Warp,,16,,,,,
0,46589,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(128, 1, 1)",0,7.5,Warp State Statistics,Avg. Not Predicated Off Threads Per Warp,,16,,,,,
0,46589,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(128, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,OPT,"On average, each warp of this kernel spends 30.8 cycles being stalled waiting for an immediate constant cache (IMC) miss. A read from constant memory costs one memory read from device memory only on a cache miss; otherwise, it just costs one read from the constant cache. Immediate constants are encoded into the SASS instruction as 'c[bank][offset]'. Accesses to different addresses by threads within a warp are serialized, thus the cost scales linearly with the number of unique addresses read by all threads within a warp. As such, the constant cache is best when threads in the same warp access only a few distinct locations. If all threads of a warp access the same location, then constant memory can be as fast as a register access. This stall type represents about 44.5% of the total average of 69.2 cycles between issuing two instructions.",global,44.51
0,46589,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(128, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,OPT,"On average, each warp of this kernel spends 28.5 cycles being stalled waiting for a scoreboard dependency on a L1TEX (local, global, surface, texture) operation. Find the instruction producing the data being waited upon to identify the culprit. To reduce the number of cycles waiting on L1TEX data accesses verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit rates by increasing data locality (coalescing), or by changing the cache configuration. Consider moving frequently used data to shared memory. This stall type represents about 41.2% of the total average of 69.2 cycles between issuing two instructions.",global,41.24
0,46589,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(128, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,INF,Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.,,
0,46589,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(128, 1, 1)",0,7.5,WarpStateStats,,,,ThreadDivergence,OPT,"Instructions are executed in warps, which are groups of 32 threads. Optimal instruction throughput is achieved if all 32 threads of a warp execute the same instruction. The chosen launch configuration, early thread completion, and divergent flow control can significantly lower the number of active threads in a warp per cycle. This kernel achieves an average of 16.0 threads being active per cycle.",global,1.273
0,46589,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(128, 1, 1)",0,7.5,Instruction Statistics,Avg. Executed Instructions Per Scheduler,inst,29.71,,,,,
0,46589,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(128, 1, 1)",0,7.5,Instruction Statistics,Executed Instructions,inst,"1,664",,,,,
0,46589,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(128, 1, 1)",0,7.5,Instruction Statistics,Avg. Issued Instructions Per Scheduler,inst,38.86,,,,,
0,46589,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(128, 1, 1)",0,7.5,Instruction Statistics,Issued Instructions,inst,"2,176",,,,,
0,46589,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(128, 1, 1)",0,7.5,InstructionStats,,,,FPInstructions,OPT,"This kernel executes 0 fused and 128 non-fused FP32 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP32 performance could be increased by up to 50% (relative to its current performance). Check the Source page to identify where this kernel executes FP32 instructions.",global,0.8843
0,46589,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(128, 1, 1)",0,7.5,Launch Statistics,Block Size,,16,,,,,
0,46589,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(128, 1, 1)",0,7.5,Launch Statistics,Function Cache Configuration,,CachePreferNone,,,,,
0,46589,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(128, 1, 1)",0,7.5,Launch Statistics,Grid Size,,128,,,,,
0,46589,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(128, 1, 1)",0,7.5,Launch Statistics,Registers Per Thread,register/thread,16,,,,,
0,46589,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(128, 1, 1)",0,7.5,Launch Statistics,Shared Memory Configuration Size,byte,"32,768",,,,,
0,46589,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(128, 1, 1)",0,7.5,Launch Statistics,Driver Shared Memory Per Block,byte/block,0,,,,,
0,46589,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(128, 1, 1)",0,7.5,Launch Statistics,Dynamic Shared Memory Per Block,byte/block,0,,,,,
0,46589,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(128, 1, 1)",0,7.5,Launch Statistics,Static Shared Memory Per Block,byte/block,0,,,,,
0,46589,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(128, 1, 1)",0,7.5,Launch Statistics,Threads,thread,"2,048",,,,,
0,46589,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(128, 1, 1)",0,7.5,Launch Statistics,Waves Per SM,,0.57,,,,,
0,46589,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(128, 1, 1)",0,7.5,LaunchStats,,,,LaunchConfiguration,OPT,"Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 16 threads per block. Consequently, some threads in a warp are masked off and those hardware resources are unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256 threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to kernels that frequently call __syncthreads(). See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations.",global,50.0
0,46589,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(128, 1, 1)",0,7.5,Occupancy,Block Limit SM,block,16,,,,,
0,46589,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(128, 1, 1)",0,7.5,Occupancy,Block Limit Registers,block,128,,,,,
0,46589,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(128, 1, 1)",0,7.5,Occupancy,Block Limit Shared Mem,block,16,,,,,
0,46589,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(128, 1, 1)",0,7.5,Occupancy,Block Limit Warps,block,32,,,,,
0,46589,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(128, 1, 1)",0,7.5,Occupancy,Theoretical Active Warps per SM,warp,16,,,,,
0,46589,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(128, 1, 1)",0,7.5,Occupancy,Theoretical Occupancy,%,50,,,,,
0,46589,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(128, 1, 1)",0,7.5,Occupancy,Achieved Occupancy,%,26.03,,,,,
0,46589,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(128, 1, 1)",0,7.5,Occupancy,Achieved Active Warps Per SM,warp,8.33,,,,,
0,46589,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(128, 1, 1)",0,7.5,Occupancy,,,,AchievedOccupancy,OPT,The difference between calculated theoretical (50.0%) and measured achieved occupancy (26.0%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy.,global,47.93
0,46589,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(128, 1, 1)",0,7.5,Occupancy,,,,TheoreticalOccupancy,OPT,The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared memory.,global,50.0
0,46589,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(128, 1, 1)",0,7.5,Source Counters,Branch Instructions Ratio,%,0.08,,,,,
0,46589,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(128, 1, 1)",0,7.5,Source Counters,Branch Instructions,inst,128,,,,,
0,46589,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(128, 1, 1)",0,7.5,Source Counters,Branch Efficiency,%,0,,,,,
0,46589,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(128, 1, 1)",0,7.5,Source Counters,Avg. Divergent Branches,,0,,,,,
0,46675,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(64, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Frequency,cycle/second,"5,587,301,587.30",,,,,
0,46675,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(64, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Frequency,cycle/second,"1,312,003,968.25",,,,,
0,46675,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(64, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Elapsed Cycles,cycle,"2,648",,,,,
0,46675,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(64, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Memory Throughput,%,4.63,,,,,
0,46675,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(64, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Throughput,%,4.59,,,,,
0,46675,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(64, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Duration,nsecond,"2,016",,,,,
0,46675,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(64, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L1/TEX Cache Throughput,%,3.00,,,,,
0,46675,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(64, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L2 Cache Throughput,%,4.63,,,,,
0,46675,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(64, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Active Cycles,cycle,"1,219",,,,,
0,46675,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(64, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Compute (SM) Throughput,%,1.38,,,,,
0,46675,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(64, 1, 1)",0,7.5,SpeedOfLight,,,,SOLBottleneck,OPT,"This kernel grid is too small to fill the available resources on this device, resulting in only 0.3 full waves across all SMs. Look at Launch Statistics for more details.",,
0,46675,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(64, 1, 1)",0,7.5,SpeedOfLight_RooflineChart,,,,SOLFPRoofline,INF,The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved  close to 0% of this device's fp32 peak performance and 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.,,
0,46675,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(64, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Active,inst/cycle,0.05,,,,,
0,46675,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(64, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Elapsed,inst/cycle,0.02,,,,,
0,46675,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(64, 1, 1)",0,7.5,Compute Workload Analysis,Issue Slots Busy,%,1.59,,,,,
0,46675,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(64, 1, 1)",0,7.5,Compute Workload Analysis,Issued Ipc Active,inst/cycle,0.06,,,,,
0,46675,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(64, 1, 1)",0,7.5,Compute Workload Analysis,SM Busy,%,1.59,,,,,
0,46675,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(64, 1, 1)",0,7.5,ComputeWorkloadAnalysis,,,,HighPipeUtilization,OPT,All compute pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.,local,99.06
0,46675,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(64, 1, 1)",0,7.5,Memory Workload Analysis,Memory Throughput,byte/second,"8,206,349,206.35",,,,,
0,46675,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(64, 1, 1)",0,7.5,Memory Workload Analysis,Mem Busy,%,4.63,,,,,
0,46675,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(64, 1, 1)",0,7.5,Memory Workload Analysis,Max Bandwidth,%,4.59,,,,,
0,46675,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(64, 1, 1)",0,7.5,Memory Workload Analysis,L1/TEX Hit Rate,%,0,,,,,
0,46675,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(64, 1, 1)",0,7.5,Memory Workload Analysis,L2 Hit Rate,%,45.48,,,,,
0,46675,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(64, 1, 1)",0,7.5,Memory Workload Analysis,Mem Pipes Busy,%,1.38,,,,,
0,46675,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(64, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Chart,,,,MemoryL2Compression,WRN,The optional metric lts__average_gcomp_input_sector_success_rate.pct could not be found. Collecting it as an additional metric could enable the rule to provide more guidance.,,
0,46675,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(64, 1, 1)",0,7.5,Scheduler Statistics,One or More Eligible,%,1.71,,,,,
0,46675,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(64, 1, 1)",0,7.5,Scheduler Statistics,Issued Warp Per Scheduler,,0.02,,,,,
0,46675,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(64, 1, 1)",0,7.5,Scheduler Statistics,No Eligible,%,98.29,,,,,
0,46675,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(64, 1, 1)",0,7.5,Scheduler Statistics,Active Warps Per Scheduler,warp,1.14,,,,,
0,46675,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(64, 1, 1)",0,7.5,Scheduler Statistics,Eligible Warps Per Scheduler,warp,0.02,,,,,
0,46675,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(64, 1, 1)",0,7.5,SchedulerStats,,,,IssueSlotUtilization,OPT,"Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 58.6 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of 1.14 active warps per scheduler, but only an average of 0.02 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections.",local,95.37
0,46675,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(64, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Issued Instruction,cycle,66.60,,,,,
0,46675,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(64, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Executed Instruction,cycle,87.09,,,,,
0,46675,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(64, 1, 1)",0,7.5,Warp State Statistics,Avg. Active Threads Per Warp,,32,,,,,
0,46675,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(64, 1, 1)",0,7.5,Warp State Statistics,Avg. Not Predicated Off Threads Per Warp,,32,,,,,
0,46675,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(64, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,OPT,"On average, each warp of this kernel spends 33.4 cycles being stalled waiting for an immediate constant cache (IMC) miss. A read from constant memory costs one memory read from device memory only on a cache miss; otherwise, it just costs one read from the constant cache. Immediate constants are encoded into the SASS instruction as 'c[bank][offset]'. Accesses to different addresses by threads within a warp are serialized, thus the cost scales linearly with the number of unique addresses read by all threads within a warp. As such, the constant cache is best when threads in the same warp access only a few distinct locations. If all threads of a warp access the same location, then constant memory can be as fast as a register access. This stall type represents about 50.1% of the total average of 66.6 cycles between issuing two instructions.",global,50.12
0,46675,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(64, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,OPT,"On average, each warp of this kernel spends 26.9 cycles being stalled waiting for a scoreboard dependency on a L1TEX (local, global, surface, texture) operation. Find the instruction producing the data being waited upon to identify the culprit. To reduce the number of cycles waiting on L1TEX data accesses verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit rates by increasing data locality (coalescing), or by changing the cache configuration. Consider moving frequently used data to shared memory. This stall type represents about 40.4% of the total average of 66.6 cycles between issuing two instructions.",global,40.42
0,46675,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(64, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,INF,Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.,,
0,46675,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(64, 1, 1)",0,7.5,Instruction Statistics,Avg. Executed Instructions Per Scheduler,inst,14.86,,,,,
0,46675,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(64, 1, 1)",0,7.5,Instruction Statistics,Executed Instructions,inst,832,,,,,
0,46675,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(64, 1, 1)",0,7.5,Instruction Statistics,Avg. Issued Instructions Per Scheduler,inst,19.43,,,,,
0,46675,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(64, 1, 1)",0,7.5,Instruction Statistics,Issued Instructions,inst,"1,088",,,,,
0,46675,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(64, 1, 1)",0,7.5,InstructionStats,,,,FPInstructions,OPT,"This kernel executes 0 fused and 64 non-fused FP32 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP32 performance could be increased by up to 50% (relative to its current performance). Check the Source page to identify where this kernel executes FP32 instructions.",global,0.4688
0,46675,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(64, 1, 1)",0,7.5,Launch Statistics,Block Size,,32,,,,,
0,46675,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(64, 1, 1)",0,7.5,Launch Statistics,Function Cache Configuration,,CachePreferNone,,,,,
0,46675,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(64, 1, 1)",0,7.5,Launch Statistics,Grid Size,,64,,,,,
0,46675,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(64, 1, 1)",0,7.5,Launch Statistics,Registers Per Thread,register/thread,16,,,,,
0,46675,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(64, 1, 1)",0,7.5,Launch Statistics,Shared Memory Configuration Size,byte,"32,768",,,,,
0,46675,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(64, 1, 1)",0,7.5,Launch Statistics,Driver Shared Memory Per Block,byte/block,0,,,,,
0,46675,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(64, 1, 1)",0,7.5,Launch Statistics,Dynamic Shared Memory Per Block,byte/block,0,,,,,
0,46675,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(64, 1, 1)",0,7.5,Launch Statistics,Static Shared Memory Per Block,byte/block,0,,,,,
0,46675,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(64, 1, 1)",0,7.5,Launch Statistics,Threads,thread,"2,048",,,,,
0,46675,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(64, 1, 1)",0,7.5,Launch Statistics,Waves Per SM,,0.29,,,,,
0,46675,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(64, 1, 1)",0,7.5,Occupancy,Block Limit SM,block,16,,,,,
0,46675,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(64, 1, 1)",0,7.5,Occupancy,Block Limit Registers,block,128,,,,,
0,46675,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(64, 1, 1)",0,7.5,Occupancy,Block Limit Shared Mem,block,16,,,,,
0,46675,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(64, 1, 1)",0,7.5,Occupancy,Block Limit Warps,block,32,,,,,
0,46675,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(64, 1, 1)",0,7.5,Occupancy,Theoretical Active Warps per SM,warp,16,,,,,
0,46675,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(64, 1, 1)",0,7.5,Occupancy,Theoretical Occupancy,%,50,,,,,
0,46675,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(64, 1, 1)",0,7.5,Occupancy,Achieved Occupancy,%,13.79,,,,,
0,46675,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(64, 1, 1)",0,7.5,Occupancy,Achieved Active Warps Per SM,warp,4.41,,,,,
0,46675,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(64, 1, 1)",0,7.5,Occupancy,,,,AchievedOccupancy,OPT,The difference between calculated theoretical (50.0%) and measured achieved occupancy (13.8%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy.,global,72.43
0,46675,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(64, 1, 1)",0,7.5,Occupancy,,,,TheoreticalOccupancy,OPT,The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared memory.,global,50.0
0,46675,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(64, 1, 1)",0,7.5,Source Counters,Branch Instructions Ratio,%,0.08,,,,,
0,46675,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(64, 1, 1)",0,7.5,Source Counters,Branch Instructions,inst,64,,,,,
0,46675,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(64, 1, 1)",0,7.5,Source Counters,Branch Efficiency,%,0,,,,,
0,46675,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(64, 1, 1)",0,7.5,Source Counters,Avg. Divergent Branches,,0,,,,,
0,46767,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(32, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Frequency,cycle/second,"5,548,387,096.77",,,,,
0,46767,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(32, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Frequency,cycle/second,"1,292,338,709.68",,,,,
0,46767,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(32, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Elapsed Cycles,cycle,"2,568",,,,,
0,46767,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(32, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Memory Throughput,%,4.76,,,,,
0,46767,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(32, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Throughput,%,4.70,,,,,
0,46767,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(32, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Duration,nsecond,"1,984",,,,,
0,46767,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(32, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L1/TEX Cache Throughput,%,3.01,,,,,
0,46767,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(32, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L2 Cache Throughput,%,4.76,,,,,
0,46767,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(32, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Active Cycles,cycle,"1,215.79",,,,,
0,46767,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(32, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Compute (SM) Throughput,%,1.43,,,,,
0,46767,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(32, 1, 1)",0,7.5,SpeedOfLight,,,,SOLBottleneck,OPT,"This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full waves across all SMs. Look at Launch Statistics for more details.",,
0,46767,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(32, 1, 1)",0,7.5,SpeedOfLight_RooflineChart,,,,SOLFPRoofline,INF,The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved  close to 0% of this device's fp32 peak performance and 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.,,
0,46767,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(32, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Active,inst/cycle,0.05,,,,,
0,46767,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(32, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Elapsed,inst/cycle,0.02,,,,,
0,46767,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(32, 1, 1)",0,7.5,Compute Workload Analysis,Issue Slots Busy,%,1.60,,,,,
0,46767,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(32, 1, 1)",0,7.5,Compute Workload Analysis,Issued Ipc Active,inst/cycle,0.06,,,,,
0,46767,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(32, 1, 1)",0,7.5,Compute Workload Analysis,SM Busy,%,1.60,,,,,
0,46767,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(32, 1, 1)",0,7.5,ComputeWorkloadAnalysis,,,,HighPipeUtilization,OPT,All compute pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.,local,99.06
0,46767,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(32, 1, 1)",0,7.5,Memory Workload Analysis,Memory Throughput,byte/second,"8,338,709,677.42",,,,,
0,46767,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(32, 1, 1)",0,7.5,Memory Workload Analysis,Mem Busy,%,4.76,,,,,
0,46767,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(32, 1, 1)",0,7.5,Memory Workload Analysis,Max Bandwidth,%,4.70,,,,,
0,46767,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(32, 1, 1)",0,7.5,Memory Workload Analysis,L1/TEX Hit Rate,%,0,,,,,
0,46767,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(32, 1, 1)",0,7.5,Memory Workload Analysis,L2 Hit Rate,%,45.04,,,,,
0,46767,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(32, 1, 1)",0,7.5,Memory Workload Analysis,Mem Pipes Busy,%,1.43,,,,,
0,46767,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(32, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Chart,,,,MemoryL2Compression,WRN,The optional metric lts__average_gcomp_input_sector_success_rate.pct could not be found. Collecting it as an additional metric could enable the rule to provide more guidance.,,
0,46767,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(32, 1, 1)",0,7.5,Scheduler Statistics,One or More Eligible,%,1.82,,,,,
0,46767,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(32, 1, 1)",0,7.5,Scheduler Statistics,Issued Warp Per Scheduler,,0.02,,,,,
0,46767,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(32, 1, 1)",0,7.5,Scheduler Statistics,No Eligible,%,98.18,,,,,
0,46767,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(32, 1, 1)",0,7.5,Scheduler Statistics,Active Warps Per Scheduler,warp,1.24,,,,,
0,46767,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(32, 1, 1)",0,7.5,Scheduler Statistics,Eligible Warps Per Scheduler,warp,0.02,,,,,
0,46767,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(32, 1, 1)",0,7.5,SchedulerStats,,,,IssueSlotUtilization,OPT,"Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 55.0 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of 1.24 active warps per scheduler, but only an average of 0.02 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections.",local,95.24
0,46767,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(32, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Issued Instruction,cycle,68.03,,,,,
0,46767,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(32, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Executed Instruction,cycle,88.96,,,,,
0,46767,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(32, 1, 1)",0,7.5,Warp State Statistics,Avg. Active Threads Per Warp,,32,,,,,
0,46767,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(32, 1, 1)",0,7.5,Warp State Statistics,Avg. Not Predicated Off Threads Per Warp,,32,,,,,
0,46767,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(32, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,OPT,"On average, each warp of this kernel spends 34.0 cycles being stalled waiting for an immediate constant cache (IMC) miss. A read from constant memory costs one memory read from device memory only on a cache miss; otherwise, it just costs one read from the constant cache. Immediate constants are encoded into the SASS instruction as 'c[bank][offset]'. Accesses to different addresses by threads within a warp are serialized, thus the cost scales linearly with the number of unique addresses read by all threads within a warp. As such, the constant cache is best when threads in the same warp access only a few distinct locations. If all threads of a warp access the same location, then constant memory can be as fast as a register access. This stall type represents about 50.0% of the total average of 68.0 cycles between issuing two instructions.",global,50.0
0,46767,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(32, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,OPT,"On average, each warp of this kernel spends 26.9 cycles being stalled waiting for a scoreboard dependency on a L1TEX (local, global, surface, texture) operation. Find the instruction producing the data being waited upon to identify the culprit. To reduce the number of cycles waiting on L1TEX data accesses verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit rates by increasing data locality (coalescing), or by changing the cache configuration. Consider moving frequently used data to shared memory. This stall type represents about 39.6% of the total average of 68.0 cycles between issuing two instructions.",global,39.61
0,46767,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(32, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,INF,Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.,,
0,46767,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(32, 1, 1)",0,7.5,Instruction Statistics,Avg. Executed Instructions Per Scheduler,inst,14.86,,,,,
0,46767,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(32, 1, 1)",0,7.5,Instruction Statistics,Executed Instructions,inst,832,,,,,
0,46767,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(32, 1, 1)",0,7.5,Instruction Statistics,Avg. Issued Instructions Per Scheduler,inst,19.43,,,,,
0,46767,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(32, 1, 1)",0,7.5,Instruction Statistics,Issued Instructions,inst,"1,088",,,,,
0,46767,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(32, 1, 1)",0,7.5,InstructionStats,,,,FPInstructions,OPT,"This kernel executes 0 fused and 64 non-fused FP32 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP32 performance could be increased by up to 50% (relative to its current performance). Check the Source page to identify where this kernel executes FP32 instructions.",global,0.47
0,46767,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(32, 1, 1)",0,7.5,Launch Statistics,Block Size,,64,,,,,
0,46767,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(32, 1, 1)",0,7.5,Launch Statistics,Function Cache Configuration,,CachePreferNone,,,,,
0,46767,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(32, 1, 1)",0,7.5,Launch Statistics,Grid Size,,32,,,,,
0,46767,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(32, 1, 1)",0,7.5,Launch Statistics,Registers Per Thread,register/thread,16,,,,,
0,46767,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(32, 1, 1)",0,7.5,Launch Statistics,Shared Memory Configuration Size,byte,"32,768",,,,,
0,46767,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(32, 1, 1)",0,7.5,Launch Statistics,Driver Shared Memory Per Block,byte/block,0,,,,,
0,46767,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(32, 1, 1)",0,7.5,Launch Statistics,Dynamic Shared Memory Per Block,byte/block,0,,,,,
0,46767,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(32, 1, 1)",0,7.5,Launch Statistics,Static Shared Memory Per Block,byte/block,0,,,,,
0,46767,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(32, 1, 1)",0,7.5,Launch Statistics,Threads,thread,"2,048",,,,,
0,46767,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(32, 1, 1)",0,7.5,Launch Statistics,Waves Per SM,,0.14,,,,,
0,46767,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(32, 1, 1)",0,7.5,Occupancy,Block Limit SM,block,16,,,,,
0,46767,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(32, 1, 1)",0,7.5,Occupancy,Block Limit Registers,block,64,,,,,
0,46767,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(32, 1, 1)",0,7.5,Occupancy,Block Limit Shared Mem,block,16,,,,,
0,46767,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(32, 1, 1)",0,7.5,Occupancy,Block Limit Warps,block,16,,,,,
0,46767,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(32, 1, 1)",0,7.5,Occupancy,Theoretical Active Warps per SM,warp,32,,,,,
0,46767,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(32, 1, 1)",0,7.5,Occupancy,Theoretical Occupancy,%,100,,,,,
0,46767,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(32, 1, 1)",0,7.5,Occupancy,Achieved Occupancy,%,14.01,,,,,
0,46767,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(32, 1, 1)",0,7.5,Occupancy,Achieved Active Warps Per SM,warp,4.48,,,,,
0,46767,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(32, 1, 1)",0,7.5,Occupancy,,,,AchievedOccupancy,OPT,The difference between calculated theoretical (100.0%) and measured achieved occupancy (14.0%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy.,global,85.99
0,46767,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(32, 1, 1)",0,7.5,Source Counters,Branch Instructions Ratio,%,0.08,,,,,
0,46767,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(32, 1, 1)",0,7.5,Source Counters,Branch Instructions,inst,64,,,,,
0,46767,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(32, 1, 1)",0,7.5,Source Counters,Branch Efficiency,%,0,,,,,
0,46767,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(32, 1, 1)",0,7.5,Source Counters,Avg. Divergent Branches,,0,,,,,
0,46844,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(16, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Frequency,cycle/second,"5,090,909,090.91",,,,,
0,46844,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(16, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Frequency,cycle/second,"1,184,895,833.33",,,,,
0,46844,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(16, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Elapsed Cycles,cycle,"2,503",,,,,
0,46844,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(16, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Memory Throughput,%,4.87,,,,,
0,46844,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(16, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Throughput,%,4.81,,,,,
0,46844,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(16, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Duration,nsecond,"2,112",,,,,
0,46844,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(16, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L1/TEX Cache Throughput,%,3.05,,,,,
0,46844,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(16, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L2 Cache Throughput,%,4.87,,,,,
0,46844,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(16, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Active Cycles,cycle,"1,197.14",,,,,
0,46844,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(16, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Compute (SM) Throughput,%,1.46,,,,,
0,46844,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(16, 1, 1)",0,7.5,SpeedOfLight,,,,SOLBottleneck,OPT,"This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full waves across all SMs. Look at Launch Statistics for more details.",,
0,46844,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(16, 1, 1)",0,7.5,SpeedOfLight_RooflineChart,,,,SOLFPRoofline,INF,The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved  close to 0% of this device's fp32 peak performance and 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.,,
0,46844,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(16, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Active,inst/cycle,0.05,,,,,
0,46844,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(16, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Elapsed,inst/cycle,0.02,,,,,
0,46844,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(16, 1, 1)",0,7.5,Compute Workload Analysis,Issue Slots Busy,%,1.62,,,,,
0,46844,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(16, 1, 1)",0,7.5,Compute Workload Analysis,Issued Ipc Active,inst/cycle,0.06,,,,,
0,46844,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(16, 1, 1)",0,7.5,Compute Workload Analysis,SM Busy,%,1.62,,,,,
0,46844,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(16, 1, 1)",0,7.5,ComputeWorkloadAnalysis,,,,HighPipeUtilization,OPT,All compute pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.,local,99.05
0,46844,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(16, 1, 1)",0,7.5,Memory Workload Analysis,Memory Throughput,byte/second,"7,833,333,333.33",,,,,
0,46844,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(16, 1, 1)",0,7.5,Memory Workload Analysis,Mem Busy,%,4.87,,,,,
0,46844,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(16, 1, 1)",0,7.5,Memory Workload Analysis,Max Bandwidth,%,4.81,,,,,
0,46844,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(16, 1, 1)",0,7.5,Memory Workload Analysis,L1/TEX Hit Rate,%,0,,,,,
0,46844,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(16, 1, 1)",0,7.5,Memory Workload Analysis,L2 Hit Rate,%,52.72,,,,,
0,46844,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(16, 1, 1)",0,7.5,Memory Workload Analysis,Mem Pipes Busy,%,1.46,,,,,
0,46844,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(16, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Chart,,,,MemoryL2Compression,WRN,The optional metric lts__average_gcomp_input_sector_success_rate.pct could not be found. Collecting it as an additional metric could enable the rule to provide more guidance.,,
0,46844,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(16, 1, 1)",0,7.5,Scheduler Statistics,One or More Eligible,%,1.68,,,,,
0,46844,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(16, 1, 1)",0,7.5,Scheduler Statistics,Issued Warp Per Scheduler,,0.02,,,,,
0,46844,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(16, 1, 1)",0,7.5,Scheduler Statistics,No Eligible,%,98.32,,,,,
0,46844,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(16, 1, 1)",0,7.5,Scheduler Statistics,Active Warps Per Scheduler,warp,1.24,,,,,
0,46844,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(16, 1, 1)",0,7.5,Scheduler Statistics,Eligible Warps Per Scheduler,warp,0.02,,,,,
0,46844,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(16, 1, 1)",0,7.5,SchedulerStats,,,,IssueSlotUtilization,OPT,"Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 59.5 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of 1.24 active warps per scheduler, but only an average of 0.02 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections.",local,95.13
0,46844,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(16, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Issued Instruction,cycle,73.55,,,,,
0,46844,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(16, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Executed Instruction,cycle,96.19,,,,,
0,46844,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(16, 1, 1)",0,7.5,Warp State Statistics,Avg. Active Threads Per Warp,,32,,,,,
0,46844,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(16, 1, 1)",0,7.5,Warp State Statistics,Avg. Not Predicated Off Threads Per Warp,,32,,,,,
0,46844,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(16, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,OPT,"On average, each warp of this kernel spends 35.3 cycles being stalled waiting for an immediate constant cache (IMC) miss. A read from constant memory costs one memory read from device memory only on a cache miss; otherwise, it just costs one read from the constant cache. Immediate constants are encoded into the SASS instruction as 'c[bank][offset]'. Accesses to different addresses by threads within a warp are serialized, thus the cost scales linearly with the number of unique addresses read by all threads within a warp. As such, the constant cache is best when threads in the same warp access only a few distinct locations. If all threads of a warp access the same location, then constant memory can be as fast as a register access. This stall type represents about 48.0% of the total average of 73.6 cycles between issuing two instructions.",global,47.98
0,46844,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(16, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,OPT,"On average, each warp of this kernel spends 27.3 cycles being stalled waiting for a scoreboard dependency on a L1TEX (local, global, surface, texture) operation. Find the instruction producing the data being waited upon to identify the culprit. To reduce the number of cycles waiting on L1TEX data accesses verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit rates by increasing data locality (coalescing), or by changing the cache configuration. Consider moving frequently used data to shared memory. This stall type represents about 37.1% of the total average of 73.6 cycles between issuing two instructions.",global,37.09
0,46844,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(16, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,INF,Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.,,
0,46844,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(16, 1, 1)",0,7.5,Instruction Statistics,Avg. Executed Instructions Per Scheduler,inst,14.86,,,,,
0,46844,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(16, 1, 1)",0,7.5,Instruction Statistics,Executed Instructions,inst,832,,,,,
0,46844,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(16, 1, 1)",0,7.5,Instruction Statistics,Avg. Issued Instructions Per Scheduler,inst,19.43,,,,,
0,46844,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(16, 1, 1)",0,7.5,Instruction Statistics,Issued Instructions,inst,"1,088",,,,,
0,46844,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(16, 1, 1)",0,7.5,InstructionStats,,,,FPInstructions,OPT,"This kernel executes 0 fused and 64 non-fused FP32 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP32 performance could be increased by up to 50% (relative to its current performance). Check the Source page to identify where this kernel executes FP32 instructions.",global,0.4773
0,46844,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(16, 1, 1)",0,7.5,Launch Statistics,Block Size,,128,,,,,
0,46844,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(16, 1, 1)",0,7.5,Launch Statistics,Function Cache Configuration,,CachePreferNone,,,,,
0,46844,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(16, 1, 1)",0,7.5,Launch Statistics,Grid Size,,16,,,,,
0,46844,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(16, 1, 1)",0,7.5,Launch Statistics,Registers Per Thread,register/thread,16,,,,,
0,46844,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(16, 1, 1)",0,7.5,Launch Statistics,Shared Memory Configuration Size,byte,"32,768",,,,,
0,46844,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(16, 1, 1)",0,7.5,Launch Statistics,Driver Shared Memory Per Block,byte/block,0,,,,,
0,46844,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(16, 1, 1)",0,7.5,Launch Statistics,Dynamic Shared Memory Per Block,byte/block,0,,,,,
0,46844,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(16, 1, 1)",0,7.5,Launch Statistics,Static Shared Memory Per Block,byte/block,0,,,,,
0,46844,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(16, 1, 1)",0,7.5,Launch Statistics,Threads,thread,"2,048",,,,,
0,46844,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(16, 1, 1)",0,7.5,Launch Statistics,Waves Per SM,,0.14,,,,,
0,46844,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(16, 1, 1)",0,7.5,LaunchStats,,,,LaunchConfiguration,OPT,"If you execute __syncthreads() to synchronize the threads of a block, it is recommended to have more than the achieved 1 blocks per multiprocessor. This way, blocks that aren't waiting for __syncthreads() can keep the hardware busy.",,
0,46844,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(16, 1, 1)",0,7.5,Occupancy,Block Limit SM,block,16,,,,,
0,46844,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(16, 1, 1)",0,7.5,Occupancy,Block Limit Registers,block,32,,,,,
0,46844,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(16, 1, 1)",0,7.5,Occupancy,Block Limit Shared Mem,block,16,,,,,
0,46844,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(16, 1, 1)",0,7.5,Occupancy,Block Limit Warps,block,8,,,,,
0,46844,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(16, 1, 1)",0,7.5,Occupancy,Theoretical Active Warps per SM,warp,32,,,,,
0,46844,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(16, 1, 1)",0,7.5,Occupancy,Theoretical Occupancy,%,100,,,,,
0,46844,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(16, 1, 1)",0,7.5,Occupancy,Achieved Occupancy,%,14.13,,,,,
0,46844,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(16, 1, 1)",0,7.5,Occupancy,Achieved Active Warps Per SM,warp,4.52,,,,,
0,46844,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(16, 1, 1)",0,7.5,Occupancy,,,,AchievedOccupancy,OPT,The difference between calculated theoretical (100.0%) and measured achieved occupancy (14.1%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy.,global,85.87
0,46844,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(16, 1, 1)",0,7.5,Source Counters,Branch Instructions Ratio,%,0.08,,,,,
0,46844,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(16, 1, 1)",0,7.5,Source Counters,Branch Instructions,inst,64,,,,,
0,46844,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(16, 1, 1)",0,7.5,Source Counters,Branch Efficiency,%,0,,,,,
0,46844,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(16, 1, 1)",0,7.5,Source Counters,Avg. Divergent Branches,,0,,,,,
0,46939,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(8, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Frequency,cycle/second,"5,333,333,333.33",,,,,
0,46939,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(8, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Frequency,cycle/second,"1,239,087,301.59",,,,,
0,46939,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(8, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Elapsed Cycles,cycle,"2,503",,,,,
0,46939,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(8, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Memory Throughput,%,4.81,,,,,
0,46939,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(8, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Throughput,%,4.81,,,,,
0,46939,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(8, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Duration,nsecond,"2,016",,,,,
0,46939,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(8, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L1/TEX Cache Throughput,%,5.25,,,,,
0,46939,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(8, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L2 Cache Throughput,%,4.77,,,,,
0,46939,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(8, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Active Cycles,cycle,696.93,,,,,
0,46939,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(8, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Compute (SM) Throughput,%,1.46,,,,,
0,46939,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(8, 1, 1)",0,7.5,SpeedOfLight,,,,SOLBottleneck,OPT,"This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full waves across all SMs. Look at Launch Statistics for more details.",,
0,46939,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(8, 1, 1)",0,7.5,SpeedOfLight_RooflineChart,,,,SOLFPRoofline,INF,The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved  close to 0% of this device's fp32 peak performance and 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.,,
0,46939,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(8, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Active,inst/cycle,0.09,,,,,
0,46939,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(8, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Elapsed,inst/cycle,0.02,,,,,
0,46939,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(8, 1, 1)",0,7.5,Compute Workload Analysis,Issue Slots Busy,%,2.79,,,,,
0,46939,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(8, 1, 1)",0,7.5,Compute Workload Analysis,Issued Ipc Active,inst/cycle,0.11,,,,,
0,46939,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(8, 1, 1)",0,7.5,Compute Workload Analysis,SM Busy,%,2.79,,,,,
0,46939,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(8, 1, 1)",0,7.5,ComputeWorkloadAnalysis,,,,HighPipeUtilization,OPT,All compute pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.,local,98.36
0,46939,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(8, 1, 1)",0,7.5,Memory Workload Analysis,Memory Throughput,byte/second,"8,206,349,206.35",,,,,
0,46939,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(8, 1, 1)",0,7.5,Memory Workload Analysis,Mem Busy,%,4.77,,,,,
0,46939,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(8, 1, 1)",0,7.5,Memory Workload Analysis,Max Bandwidth,%,4.81,,,,,
0,46939,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(8, 1, 1)",0,7.5,Memory Workload Analysis,L1/TEX Hit Rate,%,0,,,,,
0,46939,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(8, 1, 1)",0,7.5,Memory Workload Analysis,L2 Hit Rate,%,43.70,,,,,
0,46939,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(8, 1, 1)",0,7.5,Memory Workload Analysis,Mem Pipes Busy,%,1.46,,,,,
0,46939,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(8, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Chart,,,,MemoryL2Compression,WRN,The optional metric lts__average_gcomp_input_sector_success_rate.pct could not be found. Collecting it as an additional metric could enable the rule to provide more guidance.,,
0,46939,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(8, 1, 1)",0,7.5,Scheduler Statistics,One or More Eligible,%,2.86,,,,,
0,46939,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(8, 1, 1)",0,7.5,Scheduler Statistics,Issued Warp Per Scheduler,,0.03,,,,,
0,46939,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(8, 1, 1)",0,7.5,Scheduler Statistics,No Eligible,%,97.14,,,,,
0,46939,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(8, 1, 1)",0,7.5,Scheduler Statistics,Active Warps Per Scheduler,warp,2.07,,,,,
0,46939,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(8, 1, 1)",0,7.5,Scheduler Statistics,Eligible Warps Per Scheduler,warp,0.03,,,,,
0,46939,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(8, 1, 1)",0,7.5,SchedulerStats,,,,IssueSlotUtilization,OPT,"Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 34.9 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of 2.07 active warps per scheduler, but only an average of 0.03 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections.",local,95.19
0,46939,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(8, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Issued Instruction,cycle,72.24,,,,,
0,46939,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(8, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Executed Instruction,cycle,94.47,,,,,
0,46939,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(8, 1, 1)",0,7.5,Warp State Statistics,Avg. Active Threads Per Warp,,32,,,,,
0,46939,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(8, 1, 1)",0,7.5,Warp State Statistics,Avg. Not Predicated Off Threads Per Warp,,32,,,,,
0,46939,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(8, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,OPT,"On average, each warp of this kernel spends 34.0 cycles being stalled waiting for an immediate constant cache (IMC) miss. A read from constant memory costs one memory read from device memory only on a cache miss; otherwise, it just costs one read from the constant cache. Immediate constants are encoded into the SASS instruction as 'c[bank][offset]'. Accesses to different addresses by threads within a warp are serialized, thus the cost scales linearly with the number of unique addresses read by all threads within a warp. As such, the constant cache is best when threads in the same warp access only a few distinct locations. If all threads of a warp access the same location, then constant memory can be as fast as a register access. This stall type represents about 47.0% of the total average of 72.2 cycles between issuing two instructions.",global,47.03
0,46939,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(8, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,OPT,"On average, each warp of this kernel spends 27.6 cycles being stalled waiting for a scoreboard dependency on a L1TEX (local, global, surface, texture) operation. Find the instruction producing the data being waited upon to identify the culprit. To reduce the number of cycles waiting on L1TEX data accesses verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit rates by increasing data locality (coalescing), or by changing the cache configuration. Consider moving frequently used data to shared memory. This stall type represents about 38.2% of the total average of 72.2 cycles between issuing two instructions.",global,38.23
0,46939,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(8, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,INF,Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.,,
0,46939,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(8, 1, 1)",0,7.5,Instruction Statistics,Avg. Executed Instructions Per Scheduler,inst,14.86,,,,,
0,46939,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(8, 1, 1)",0,7.5,Instruction Statistics,Executed Instructions,inst,832,,,,,
0,46939,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(8, 1, 1)",0,7.5,Instruction Statistics,Avg. Issued Instructions Per Scheduler,inst,19.43,,,,,
0,46939,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(8, 1, 1)",0,7.5,Instruction Statistics,Issued Instructions,inst,"1,088",,,,,
0,46939,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(8, 1, 1)",0,7.5,InstructionStats,,,,FPInstructions,OPT,"This kernel executes 0 fused and 64 non-fused FP32 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP32 performance could be increased by up to 50% (relative to its current performance). Check the Source page to identify where this kernel executes FP32 instructions.",global,0.8199
0,46939,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(8, 1, 1)",0,7.5,Launch Statistics,Block Size,,256,,,,,
0,46939,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(8, 1, 1)",0,7.5,Launch Statistics,Function Cache Configuration,,CachePreferNone,,,,,
0,46939,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(8, 1, 1)",0,7.5,Launch Statistics,Grid Size,,8,,,,,
0,46939,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(8, 1, 1)",0,7.5,Launch Statistics,Registers Per Thread,register/thread,16,,,,,
0,46939,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(8, 1, 1)",0,7.5,Launch Statistics,Shared Memory Configuration Size,byte,"32,768",,,,,
0,46939,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(8, 1, 1)",0,7.5,Launch Statistics,Driver Shared Memory Per Block,byte/block,0,,,,,
0,46939,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(8, 1, 1)",0,7.5,Launch Statistics,Dynamic Shared Memory Per Block,byte/block,0,,,,,
0,46939,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(8, 1, 1)",0,7.5,Launch Statistics,Static Shared Memory Per Block,byte/block,0,,,,,
0,46939,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(8, 1, 1)",0,7.5,Launch Statistics,Threads,thread,"2,048",,,,,
0,46939,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(8, 1, 1)",0,7.5,Launch Statistics,Waves Per SM,,0.14,,,,,
0,46939,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(8, 1, 1)",0,7.5,LaunchStats,,,,LaunchConfiguration,OPT,"The grid for this launch is configured to execute only 8 blocks, which is less than the GPU's 14 multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel concurrently with other workloads, consider reducing the block size to have at least one block per multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations.",global,42.86
0,46939,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(8, 1, 1)",0,7.5,Occupancy,Block Limit SM,block,16,,,,,
0,46939,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(8, 1, 1)",0,7.5,Occupancy,Block Limit Registers,block,16,,,,,
0,46939,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(8, 1, 1)",0,7.5,Occupancy,Block Limit Shared Mem,block,16,,,,,
0,46939,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(8, 1, 1)",0,7.5,Occupancy,Block Limit Warps,block,4,,,,,
0,46939,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(8, 1, 1)",0,7.5,Occupancy,Theoretical Active Warps per SM,warp,32,,,,,
0,46939,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(8, 1, 1)",0,7.5,Occupancy,Theoretical Occupancy,%,100,,,,,
0,46939,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(8, 1, 1)",0,7.5,Occupancy,Achieved Occupancy,%,24.60,,,,,
0,46939,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(8, 1, 1)",0,7.5,Occupancy,Achieved Active Warps Per SM,warp,7.87,,,,,
0,46939,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(8, 1, 1)",0,7.5,Occupancy,,,,AchievedOccupancy,OPT,The difference between calculated theoretical (100.0%) and measured achieved occupancy (24.6%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy.,global,75.4
0,46939,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(8, 1, 1)",0,7.5,Source Counters,Branch Instructions Ratio,%,0.08,,,,,
0,46939,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(8, 1, 1)",0,7.5,Source Counters,Branch Instructions,inst,64,,,,,
0,46939,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(8, 1, 1)",0,7.5,Source Counters,Branch Efficiency,%,0,,,,,
0,46939,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(8, 1, 1)",0,7.5,Source Counters,Avg. Divergent Branches,,0,,,,,
0,47025,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(4, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Frequency,cycle/second,"5,600,000,000",,,,,
0,47025,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(4, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Frequency,cycle/second,"1,301,302,083.33",,,,,
0,47025,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(4, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Elapsed Cycles,cycle,"2,506",,,,,
0,47025,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(4, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Memory Throughput,%,4.81,,,,,
0,47025,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(4, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Throughput,%,4.81,,,,,
0,47025,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(4, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Duration,nsecond,"1,920",,,,,
0,47025,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(4, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L1/TEX Cache Throughput,%,10.11,,,,,
0,47025,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(4, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L2 Cache Throughput,%,4.69,,,,,
0,47025,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(4, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Active Cycles,cycle,361.71,,,,,
0,47025,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(4, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Compute (SM) Throughput,%,1.46,,,,,
0,47025,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(4, 1, 1)",0,7.5,SpeedOfLight,,,,SOLBottleneck,OPT,"This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full waves across all SMs. Look at Launch Statistics for more details.",,
0,47025,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(4, 1, 1)",0,7.5,SpeedOfLight_RooflineChart,,,,SOLFPRoofline,INF,The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved  close to 0% of this device's fp32 peak performance and 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.,,
0,47025,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(4, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Active,inst/cycle,0.16,,,,,
0,47025,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(4, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Elapsed,inst/cycle,0.02,,,,,
0,47025,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(4, 1, 1)",0,7.5,Compute Workload Analysis,Issue Slots Busy,%,5.37,,,,,
0,47025,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(4, 1, 1)",0,7.5,Compute Workload Analysis,Issued Ipc Active,inst/cycle,0.21,,,,,
0,47025,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(4, 1, 1)",0,7.5,Compute Workload Analysis,SM Busy,%,5.37,,,,,
0,47025,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(4, 1, 1)",0,7.5,ComputeWorkloadAnalysis,,,,HighPipeUtilization,OPT,All compute pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.,local,96.84
0,47025,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(4, 1, 1)",0,7.5,Memory Workload Analysis,Memory Throughput,byte/second,"8,616,666,666.67",,,,,
0,47025,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(4, 1, 1)",0,7.5,Memory Workload Analysis,Mem Busy,%,4.69,,,,,
0,47025,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(4, 1, 1)",0,7.5,Memory Workload Analysis,Max Bandwidth,%,4.81,,,,,
0,47025,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(4, 1, 1)",0,7.5,Memory Workload Analysis,L1/TEX Hit Rate,%,0,,,,,
0,47025,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(4, 1, 1)",0,7.5,Memory Workload Analysis,L2 Hit Rate,%,42.84,,,,,
0,47025,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(4, 1, 1)",0,7.5,Memory Workload Analysis,Mem Pipes Busy,%,1.46,,,,,
0,47025,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(4, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Chart,,,,MemoryL2Compression,WRN,The optional metric lts__average_gcomp_input_sector_success_rate.pct could not be found. Collecting it as an additional metric could enable the rule to provide more guidance.,,
0,47025,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(4, 1, 1)",0,7.5,Scheduler Statistics,One or More Eligible,%,5.62,,,,,
0,47025,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(4, 1, 1)",0,7.5,Scheduler Statistics,Issued Warp Per Scheduler,,0.06,,,,,
0,47025,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(4, 1, 1)",0,7.5,Scheduler Statistics,No Eligible,%,94.38,,,,,
0,47025,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(4, 1, 1)",0,7.5,Scheduler Statistics,Active Warps Per Scheduler,warp,3.88,,,,,
0,47025,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(4, 1, 1)",0,7.5,Scheduler Statistics,Eligible Warps Per Scheduler,warp,0.07,,,,,
0,47025,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(4, 1, 1)",0,7.5,SchedulerStats,,,,IssueSlotUtilization,OPT,"Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 17.8 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of 3.88 active warps per scheduler, but only an average of 0.07 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections.",local,94.38
0,47025,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(4, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Issued Instruction,cycle,69.17,,,,,
0,47025,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(4, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Executed Instruction,cycle,90.46,,,,,
0,47025,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(4, 1, 1)",0,7.5,Warp State Statistics,Avg. Active Threads Per Warp,,32,,,,,
0,47025,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(4, 1, 1)",0,7.5,Warp State Statistics,Avg. Not Predicated Off Threads Per Warp,,32,,,,,
0,47025,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(4, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,OPT,"On average, each warp of this kernel spends 32.8 cycles being stalled waiting for an immediate constant cache (IMC) miss. A read from constant memory costs one memory read from device memory only on a cache miss; otherwise, it just costs one read from the constant cache. Immediate constants are encoded into the SASS instruction as 'c[bank][offset]'. Accesses to different addresses by threads within a warp are serialized, thus the cost scales linearly with the number of unique addresses read by all threads within a warp. As such, the constant cache is best when threads in the same warp access only a few distinct locations. If all threads of a warp access the same location, then constant memory can be as fast as a register access. This stall type represents about 47.4% of the total average of 69.2 cycles between issuing two instructions.",global,47.42
0,47025,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(4, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,OPT,"On average, each warp of this kernel spends 28.2 cycles being stalled waiting for a scoreboard dependency on a L1TEX (local, global, surface, texture) operation. Find the instruction producing the data being waited upon to identify the culprit. To reduce the number of cycles waiting on L1TEX data accesses verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit rates by increasing data locality (coalescing), or by changing the cache configuration. Consider moving frequently used data to shared memory. This stall type represents about 40.7% of the total average of 69.2 cycles between issuing two instructions.",global,40.75
0,47025,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(4, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,INF,Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.,,
0,47025,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(4, 1, 1)",0,7.5,Instruction Statistics,Avg. Executed Instructions Per Scheduler,inst,14.86,,,,,
0,47025,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(4, 1, 1)",0,7.5,Instruction Statistics,Executed Instructions,inst,832,,,,,
0,47025,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(4, 1, 1)",0,7.5,Instruction Statistics,Avg. Issued Instructions Per Scheduler,inst,19.43,,,,,
0,47025,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(4, 1, 1)",0,7.5,Instruction Statistics,Issued Instructions,inst,"1,088",,,,,
0,47025,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(4, 1, 1)",0,7.5,InstructionStats,,,,FPInstructions,OPT,"This kernel executes 0 fused and 64 non-fused FP32 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP32 performance could be increased by up to 50% (relative to its current performance). Check the Source page to identify where this kernel executes FP32 instructions.",global,1.58
0,47025,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(4, 1, 1)",0,7.5,Launch Statistics,Block Size,,512,,,,,
0,47025,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(4, 1, 1)",0,7.5,Launch Statistics,Function Cache Configuration,,CachePreferNone,,,,,
0,47025,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(4, 1, 1)",0,7.5,Launch Statistics,Grid Size,,4,,,,,
0,47025,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(4, 1, 1)",0,7.5,Launch Statistics,Registers Per Thread,register/thread,16,,,,,
0,47025,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(4, 1, 1)",0,7.5,Launch Statistics,Shared Memory Configuration Size,byte,"32,768",,,,,
0,47025,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(4, 1, 1)",0,7.5,Launch Statistics,Driver Shared Memory Per Block,byte/block,0,,,,,
0,47025,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(4, 1, 1)",0,7.5,Launch Statistics,Dynamic Shared Memory Per Block,byte/block,0,,,,,
0,47025,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(4, 1, 1)",0,7.5,Launch Statistics,Static Shared Memory Per Block,byte/block,0,,,,,
0,47025,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(4, 1, 1)",0,7.5,Launch Statistics,Threads,thread,"2,048",,,,,
0,47025,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(4, 1, 1)",0,7.5,Launch Statistics,Waves Per SM,,0.14,,,,,
0,47025,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(4, 1, 1)",0,7.5,LaunchStats,,,,LaunchConfiguration,OPT,"The grid for this launch is configured to execute only 4 blocks, which is less than the GPU's 14 multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel concurrently with other workloads, consider reducing the block size to have at least one block per multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations.",global,71.43
0,47025,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(4, 1, 1)",0,7.5,Occupancy,Block Limit SM,block,16,,,,,
0,47025,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(4, 1, 1)",0,7.5,Occupancy,Block Limit Registers,block,8,,,,,
0,47025,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(4, 1, 1)",0,7.5,Occupancy,Block Limit Shared Mem,block,16,,,,,
0,47025,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(4, 1, 1)",0,7.5,Occupancy,Block Limit Warps,block,2,,,,,
0,47025,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(4, 1, 1)",0,7.5,Occupancy,Theoretical Active Warps per SM,warp,32,,,,,
0,47025,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(4, 1, 1)",0,7.5,Occupancy,Theoretical Occupancy,%,100,,,,,
0,47025,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(4, 1, 1)",0,7.5,Occupancy,Achieved Occupancy,%,48.06,,,,,
0,47025,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(4, 1, 1)",0,7.5,Occupancy,Achieved Active Warps Per SM,warp,15.38,,,,,
0,47025,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(4, 1, 1)",0,7.5,Occupancy,,,,AchievedOccupancy,OPT,The difference between calculated theoretical (100.0%) and measured achieved occupancy (48.1%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy.,global,51.94
0,47025,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(4, 1, 1)",0,7.5,Source Counters,Branch Instructions Ratio,%,0.08,,,,,
0,47025,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(4, 1, 1)",0,7.5,Source Counters,Branch Instructions,inst,64,,,,,
0,47025,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(4, 1, 1)",0,7.5,Source Counters,Branch Efficiency,%,0,,,,,
0,47025,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(4, 1, 1)",0,7.5,Source Counters,Avg. Divergent Branches,,0,,,,,
0,47102,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(2, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Frequency,cycle/second,"5,333,333,333.33",,,,,
0,47102,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(2, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Frequency,cycle/second,"1,210,144,927.54",,,,,
0,47102,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(2, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Elapsed Cycles,cycle,"2,681",,,,,
0,47102,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(2, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Memory Throughput,%,4.39,,,,,
0,47102,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(2, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Throughput,%,4.39,,,,,
0,47102,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(2, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Duration,nsecond,"2,208",,,,,
0,47102,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(2, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L1/TEX Cache Throughput,%,18.40,,,,,
0,47102,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(2, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L2 Cache Throughput,%,4.38,,,,,
0,47102,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(2, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Active Cycles,cycle,198.71,,,,,
0,47102,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(2, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Compute (SM) Throughput,%,1.37,,,,,
0,47102,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(2, 1, 1)",0,7.5,SpeedOfLight,,,,SOLBottleneck,OPT,"This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full waves across all SMs. Look at Launch Statistics for more details.",,
0,47102,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(2, 1, 1)",0,7.5,SpeedOfLight_RooflineChart,,,,SOLFPRoofline,INF,The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved  close to 0% of this device's fp32 peak performance and 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.,,
0,47102,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(2, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Active,inst/cycle,0.30,,,,,
0,47102,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(2, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Elapsed,inst/cycle,0.02,,,,,
0,47102,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(2, 1, 1)",0,7.5,Compute Workload Analysis,Issue Slots Busy,%,9.78,,,,,
0,47102,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(2, 1, 1)",0,7.5,Compute Workload Analysis,Issued Ipc Active,inst/cycle,0.39,,,,,
0,47102,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(2, 1, 1)",0,7.5,Compute Workload Analysis,SM Busy,%,9.78,,,,,
0,47102,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(2, 1, 1)",0,7.5,ComputeWorkloadAnalysis,,,,HighPipeUtilization,OPT,All compute pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.,local,94.25
0,47102,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(2, 1, 1)",0,7.5,Memory Workload Analysis,Memory Throughput,byte/second,"7,492,753,623.19",,,,,
0,47102,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(2, 1, 1)",0,7.5,Memory Workload Analysis,Mem Busy,%,4.38,,,,,
0,47102,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(2, 1, 1)",0,7.5,Memory Workload Analysis,Max Bandwidth,%,4.39,,,,,
0,47102,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(2, 1, 1)",0,7.5,Memory Workload Analysis,L1/TEX Hit Rate,%,0,,,,,
0,47102,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(2, 1, 1)",0,7.5,Memory Workload Analysis,L2 Hit Rate,%,42.95,,,,,
0,47102,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(2, 1, 1)",0,7.5,Memory Workload Analysis,Mem Pipes Busy,%,1.37,,,,,
0,47102,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(2, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Chart,,,,MemoryL2Compression,WRN,The optional metric lts__average_gcomp_input_sector_success_rate.pct could not be found. Collecting it as an additional metric could enable the rule to provide more guidance.,,
0,47102,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(2, 1, 1)",0,7.5,Scheduler Statistics,One or More Eligible,%,10.15,,,,,
0,47102,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(2, 1, 1)",0,7.5,Scheduler Statistics,Issued Warp Per Scheduler,,0.10,,,,,
0,47102,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(2, 1, 1)",0,7.5,Scheduler Statistics,No Eligible,%,89.85,,,,,
0,47102,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(2, 1, 1)",0,7.5,Scheduler Statistics,Active Warps Per Scheduler,warp,7.43,,,,,
0,47102,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(2, 1, 1)",0,7.5,Scheduler Statistics,Eligible Warps Per Scheduler,warp,0.20,,,,,
0,47102,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(2, 1, 1)",0,7.5,SchedulerStats,,,,IssueSlotUtilization,OPT,"Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 9.9 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of 7.43 active warps per scheduler, but only an average of 0.20 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, avoid possible load imbalances due to highly different execution durations per warp. Reducing stalls indicated on the Warp State Statistics and Source Counters sections can help, too.",local,89.85
0,47102,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(2, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Issued Instruction,cycle,73.16,,,,,
0,47102,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(2, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Executed Instruction,cycle,95.67,,,,,
0,47102,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(2, 1, 1)",0,7.5,Warp State Statistics,Avg. Active Threads Per Warp,,32,,,,,
0,47102,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(2, 1, 1)",0,7.5,Warp State Statistics,Avg. Not Predicated Off Threads Per Warp,,32,,,,,
0,47102,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(2, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,OPT,"On average, each warp of this kernel spends 30.8 cycles being stalled waiting for an immediate constant cache (IMC) miss. A read from constant memory costs one memory read from device memory only on a cache miss; otherwise, it just costs one read from the constant cache. Immediate constants are encoded into the SASS instruction as 'c[bank][offset]'. Accesses to different addresses by threads within a warp are serialized, thus the cost scales linearly with the number of unique addresses read by all threads within a warp. As such, the constant cache is best when threads in the same warp access only a few distinct locations. If all threads of a warp access the same location, then constant memory can be as fast as a register access. This stall type represents about 42.1% of the total average of 73.2 cycles between issuing two instructions.",global,42.06
0,47102,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(2, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,OPT,"On average, each warp of this kernel spends 29.9 cycles being stalled waiting for a scoreboard dependency on a L1TEX (local, global, surface, texture) operation. Find the instruction producing the data being waited upon to identify the culprit. To reduce the number of cycles waiting on L1TEX data accesses verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit rates by increasing data locality (coalescing), or by changing the cache configuration. Consider moving frequently used data to shared memory. This stall type represents about 40.9% of the total average of 73.2 cycles between issuing two instructions.",global,40.86
0,47102,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(2, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,INF,Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.,,
0,47102,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(2, 1, 1)",0,7.5,Instruction Statistics,Avg. Executed Instructions Per Scheduler,inst,14.86,,,,,
0,47102,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(2, 1, 1)",0,7.5,Instruction Statistics,Executed Instructions,inst,832,,,,,
0,47102,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(2, 1, 1)",0,7.5,Instruction Statistics,Avg. Issued Instructions Per Scheduler,inst,19.43,,,,,
0,47102,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(2, 1, 1)",0,7.5,Instruction Statistics,Issued Instructions,inst,"1,088",,,,,
0,47102,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(2, 1, 1)",0,7.5,InstructionStats,,,,FPInstructions,OPT,"This kernel executes 0 fused and 64 non-fused FP32 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP32 performance could be increased by up to 50% (relative to its current performance). Check the Source page to identify where this kernel executes FP32 instructions.",global,2.876
0,47102,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(2, 1, 1)",0,7.5,Launch Statistics,Block Size,,"1,024",,,,,
0,47102,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(2, 1, 1)",0,7.5,Launch Statistics,Function Cache Configuration,,CachePreferNone,,,,,
0,47102,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(2, 1, 1)",0,7.5,Launch Statistics,Grid Size,,2,,,,,
0,47102,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(2, 1, 1)",0,7.5,Launch Statistics,Registers Per Thread,register/thread,16,,,,,
0,47102,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(2, 1, 1)",0,7.5,Launch Statistics,Shared Memory Configuration Size,byte,"32,768",,,,,
0,47102,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(2, 1, 1)",0,7.5,Launch Statistics,Driver Shared Memory Per Block,byte/block,0,,,,,
0,47102,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(2, 1, 1)",0,7.5,Launch Statistics,Dynamic Shared Memory Per Block,byte/block,0,,,,,
0,47102,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(2, 1, 1)",0,7.5,Launch Statistics,Static Shared Memory Per Block,byte/block,0,,,,,
0,47102,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(2, 1, 1)",0,7.5,Launch Statistics,Threads,thread,"2,048",,,,,
0,47102,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(2, 1, 1)",0,7.5,Launch Statistics,Waves Per SM,,0.14,,,,,
0,47102,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(2, 1, 1)",0,7.5,LaunchStats,,,,LaunchConfiguration,OPT,"The grid for this launch is configured to execute only 2 blocks, which is less than the GPU's 14 multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel concurrently with other workloads, consider reducing the block size to have at least one block per multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations.",global,85.71
0,47102,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(2, 1, 1)",0,7.5,Occupancy,Block Limit SM,block,16,,,,,
0,47102,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(2, 1, 1)",0,7.5,Occupancy,Block Limit Registers,block,4,,,,,
0,47102,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(2, 1, 1)",0,7.5,Occupancy,Block Limit Shared Mem,block,16,,,,,
0,47102,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(2, 1, 1)",0,7.5,Occupancy,Block Limit Warps,block,1,,,,,
0,47102,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(2, 1, 1)",0,7.5,Occupancy,Theoretical Active Warps per SM,warp,32,,,,,
0,47102,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(2, 1, 1)",0,7.5,Occupancy,Theoretical Occupancy,%,100,,,,,
0,47102,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(2, 1, 1)",0,7.5,Occupancy,Achieved Occupancy,%,91.97,,,,,
0,47102,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(2, 1, 1)",0,7.5,Occupancy,Achieved Active Warps Per SM,warp,29.43,,,,,
0,47102,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(2, 1, 1)",0,7.5,Source Counters,Branch Instructions Ratio,%,0.08,,,,,
0,47102,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(2, 1, 1)",0,7.5,Source Counters,Branch Instructions,inst,64,,,,,
0,47102,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(2, 1, 1)",0,7.5,Source Counters,Branch Efficiency,%,0,,,,,
0,47102,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(2, 1, 1)",0,7.5,Source Counters,Avg. Divergent Branches,,0,,,,,
0,47196,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(4096, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Frequency,cycle/second,"6,090,225,563.91",,,,,
0,47196,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(4096, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Frequency,cycle/second,"1,410,038,768.80",,,,,
0,47196,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(4096, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Elapsed Cycles,cycle,"24,049",,,,,
0,47196,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(4096, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Memory Throughput,%,9.75,,,,,
0,47196,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(4096, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Throughput,%,0.99,,,,,
0,47196,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(4096, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Duration,nsecond,"17,024",,,,,
0,47196,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(4096, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L1/TEX Cache Throughput,%,15.74,,,,,
0,47196,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(4096, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L2 Cache Throughput,%,7.24,,,,,
0,47196,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(4096, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Active Cycles,cycle,"14,869.43",,,,,
0,47196,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(4096, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Compute (SM) Throughput,%,9.75,,,,,
0,47196,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(4096, 1, 1)",0,7.5,SpeedOfLight,,,,SOLBottleneck,OPT,This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.,,
0,47196,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(4096, 1, 1)",0,7.5,SpeedOfLight_RooflineChart,,,,SOLFPRoofline,INF,The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved  close to 0% of this device's fp32 peak performance and 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.,,
0,47196,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(4096, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Active,inst/cycle,0.26,,,,,
0,47196,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(4096, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Elapsed,inst/cycle,0.16,,,,,
0,47196,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(4096, 1, 1)",0,7.5,Compute Workload Analysis,Issue Slots Busy,%,6.49,,,,,
0,47196,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(4096, 1, 1)",0,7.5,Compute Workload Analysis,Issued Ipc Active,inst/cycle,0.26,,,,,
0,47196,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(4096, 1, 1)",0,7.5,Compute Workload Analysis,SM Busy,%,6.56,,,,,
0,47196,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(4096, 1, 1)",0,7.5,ComputeWorkloadAnalysis,,,,HighPipeUtilization,OPT,All compute pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.,local,95.08
0,47196,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(4096, 1, 1)",0,7.5,Memory Workload Analysis,Memory Throughput,byte/second,"1,934,210,526.32",,,,,
0,47196,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(4096, 1, 1)",0,7.5,Memory Workload Analysis,Mem Busy,%,6.14,,,,,
0,47196,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(4096, 1, 1)",0,7.5,Memory Workload Analysis,Max Bandwidth,%,9.75,,,,,
0,47196,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(4096, 1, 1)",0,7.5,Memory Workload Analysis,L1/TEX Hit Rate,%,26.07,,,,,
0,47196,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(4096, 1, 1)",0,7.5,Memory Workload Analysis,L2 Hit Rate,%,97.63,,,,,
0,47196,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(4096, 1, 1)",0,7.5,Memory Workload Analysis,Mem Pipes Busy,%,9.75,,,,,
0,47196,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(4096, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Chart,,,,MemoryL2Compression,WRN,The optional metric lts__average_gcomp_input_sector_success_rate.pct could not be found. Collecting it as an additional metric could enable the rule to provide more guidance.,,
0,47196,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(4096, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for loads from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced loads and try to minimize how many cache lines need to be accessed per memory request.",global,2.996
0,47196,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(4096, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for stores from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.4 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced stores and try to minimize how many cache lines need to be accessed per memory request.",global,1.302
0,47196,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(4096, 1, 1)",0,7.5,Scheduler Statistics,One or More Eligible,%,7.36,,,,,
0,47196,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(4096, 1, 1)",0,7.5,Scheduler Statistics,Issued Warp Per Scheduler,,0.07,,,,,
0,47196,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(4096, 1, 1)",0,7.5,Scheduler Statistics,No Eligible,%,92.64,,,,,
0,47196,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(4096, 1, 1)",0,7.5,Scheduler Statistics,Active Warps Per Scheduler,warp,2.87,,,,,
0,47196,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(4096, 1, 1)",0,7.5,Scheduler Statistics,Eligible Warps Per Scheduler,warp,0.08,,,,,
0,47196,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(4096, 1, 1)",0,7.5,SchedulerStats,,,,IssueSlotUtilization,OPT,"Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 13.6 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of 2.87 active warps per scheduler, but only an average of 0.08 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections.",local,90.25
0,47196,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(4096, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Issued Instruction,cycle,38.97,,,,,
0,47196,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(4096, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Executed Instruction,cycle,39.53,,,,,
0,47196,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(4096, 1, 1)",0,7.5,Warp State Statistics,Avg. Active Threads Per Warp,,1,,,,,
0,47196,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(4096, 1, 1)",0,7.5,Warp State Statistics,Avg. Not Predicated Off Threads Per Warp,,1,,,,,
0,47196,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(4096, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,OPT,"On average, each warp of this kernel spends 28.2 cycles being stalled waiting for a scoreboard dependency on a L1TEX (local, global, surface, texture) operation. Find the instruction producing the data being waited upon to identify the culprit. To reduce the number of cycles waiting on L1TEX data accesses verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit rates by increasing data locality (coalescing), or by changing the cache configuration. Consider moving frequently used data to shared memory. This stall type represents about 72.4% of the total average of 39.0 cycles between issuing two instructions.",global,72.45
0,47196,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(4096, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,INF,Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.,,
0,47196,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(4096, 1, 1)",0,7.5,WarpStateStats,,,,ThreadDivergence,OPT,"Instructions are executed in warps, which are groups of 32 threads. Optimal instruction throughput is achieved if all 32 threads of a warp execute the same instruction. The chosen launch configuration, early thread completion, and divergent flow control can significantly lower the number of active threads in a warp per cycle. This kernel achieves an average of 1.0 threads being active per cycle.",global,9.443
0,47196,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(4096, 1, 1)",0,7.5,Instruction Statistics,Avg. Executed Instructions Per Scheduler,inst,950.86,,,,,
0,47196,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(4096, 1, 1)",0,7.5,Instruction Statistics,Executed Instructions,inst,"53,248",,,,,
0,47196,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(4096, 1, 1)",0,7.5,Instruction Statistics,Avg. Issued Instructions Per Scheduler,inst,964.50,,,,,
0,47196,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(4096, 1, 1)",0,7.5,Instruction Statistics,Issued Instructions,inst,"54,012",,,,,
0,47196,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(4096, 1, 1)",0,7.5,InstructionStats,,,,FPInstructions,OPT,"This kernel executes 0 fused and 4096 non-fused FP32 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP32 performance could be increased by up to 50% (relative to its current performance). Check the Source page to identify where this kernel executes FP32 instructions.",global,2.46
0,47196,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(4096, 1, 1)",0,7.5,Launch Statistics,Block Size,,1,,,,,
0,47196,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(4096, 1, 1)",0,7.5,Launch Statistics,Function Cache Configuration,,CachePreferNone,,,,,
0,47196,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(4096, 1, 1)",0,7.5,Launch Statistics,Grid Size,,"4,096",,,,,
0,47196,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(4096, 1, 1)",0,7.5,Launch Statistics,Registers Per Thread,register/thread,16,,,,,
0,47196,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(4096, 1, 1)",0,7.5,Launch Statistics,Shared Memory Configuration Size,byte,"32,768",,,,,
0,47196,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(4096, 1, 1)",0,7.5,Launch Statistics,Driver Shared Memory Per Block,byte/block,0,,,,,
0,47196,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(4096, 1, 1)",0,7.5,Launch Statistics,Dynamic Shared Memory Per Block,byte/block,0,,,,,
0,47196,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(4096, 1, 1)",0,7.5,Launch Statistics,Static Shared Memory Per Block,byte/block,0,,,,,
0,47196,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(4096, 1, 1)",0,7.5,Launch Statistics,Threads,thread,"4,096",,,,,
0,47196,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(4096, 1, 1)",0,7.5,Launch Statistics,Waves Per SM,,18.29,,,,,
0,47196,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(4096, 1, 1)",0,7.5,LaunchStats,,,,LaunchConfiguration,OPT,"Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 1 threads per block. Consequently, some threads in a warp are masked off and those hardware resources are unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256 threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to kernels that frequently call __syncthreads(). See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations.",global,96.88
0,47196,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(4096, 1, 1)",0,7.5,Occupancy,Block Limit SM,block,16,,,,,
0,47196,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(4096, 1, 1)",0,7.5,Occupancy,Block Limit Registers,block,128,,,,,
0,47196,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(4096, 1, 1)",0,7.5,Occupancy,Block Limit Shared Mem,block,16,,,,,
0,47196,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(4096, 1, 1)",0,7.5,Occupancy,Block Limit Warps,block,32,,,,,
0,47196,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(4096, 1, 1)",0,7.5,Occupancy,Theoretical Active Warps per SM,warp,16,,,,,
0,47196,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(4096, 1, 1)",0,7.5,Occupancy,Theoretical Occupancy,%,50,,,,,
0,47196,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(4096, 1, 1)",0,7.5,Occupancy,Achieved Occupancy,%,33.74,,,,,
0,47196,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(4096, 1, 1)",0,7.5,Occupancy,Achieved Active Warps Per SM,warp,10.80,,,,,
0,47196,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(4096, 1, 1)",0,7.5,Occupancy,,,,AchievedOccupancy,OPT,The difference between calculated theoretical (50.0%) and measured achieved occupancy (33.7%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy.,global,32.52
0,47196,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(4096, 1, 1)",0,7.5,Occupancy,,,,TheoreticalOccupancy,OPT,The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared memory.,global,50.0
0,47196,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(4096, 1, 1)",0,7.5,Source Counters,Branch Instructions Ratio,%,0.08,,,,,
0,47196,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(4096, 1, 1)",0,7.5,Source Counters,Branch Instructions,inst,"4,096",,,,,
0,47196,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(4096, 1, 1)",0,7.5,Source Counters,Branch Efficiency,%,0,,,,,
0,47196,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(4096, 1, 1)",0,7.5,Source Counters,Avg. Divergent Branches,,0,,,,,
0,47283,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(2048, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Frequency,cycle/second,"6,034,602,076.12",,,,,
0,47283,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(2048, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Frequency,cycle/second,"1,399,167,387.54",,,,,
0,47283,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(2048, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Elapsed Cycles,cycle,"12,972",,,,,
0,47283,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(2048, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Memory Throughput,%,9.04,,,,,
0,47283,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(2048, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Throughput,%,1.84,,,,,
0,47283,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(2048, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Duration,nsecond,"9,248",,,,,
0,47283,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(2048, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L1/TEX Cache Throughput,%,15.70,,,,,
0,47283,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(2048, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L2 Cache Throughput,%,7.25,,,,,
0,47283,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(2048, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Active Cycles,cycle,"7,452.93",,,,,
0,47283,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(2048, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Compute (SM) Throughput,%,9.04,,,,,
0,47283,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(2048, 1, 1)",0,7.5,SpeedOfLight,,,,SOLBottleneck,OPT,This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.,,
0,47283,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(2048, 1, 1)",0,7.5,SpeedOfLight_RooflineChart,,,,SOLFPRoofline,INF,The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved  close to 0% of this device's fp32 peak performance and 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.,,
0,47283,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(2048, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Active,inst/cycle,0.26,,,,,
0,47283,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(2048, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Elapsed,inst/cycle,0.15,,,,,
0,47283,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(2048, 1, 1)",0,7.5,Compute Workload Analysis,Issue Slots Busy,%,6.56,,,,,
0,47283,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(2048, 1, 1)",0,7.5,Compute Workload Analysis,Issued Ipc Active,inst/cycle,0.26,,,,,
0,47283,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(2048, 1, 1)",0,7.5,Compute Workload Analysis,SM Busy,%,6.56,,,,,
0,47283,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(2048, 1, 1)",0,7.5,ComputeWorkloadAnalysis,,,,HighPipeUtilization,OPT,All compute pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.,local,95.09
0,47283,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(2048, 1, 1)",0,7.5,Memory Workload Analysis,Memory Throughput,byte/second,"3,560,553,633.22",,,,,
0,47283,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(2048, 1, 1)",0,7.5,Memory Workload Analysis,Mem Busy,%,5.99,,,,,
0,47283,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(2048, 1, 1)",0,7.5,Memory Workload Analysis,Max Bandwidth,%,9.04,,,,,
0,47283,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(2048, 1, 1)",0,7.5,Memory Workload Analysis,L1/TEX Hit Rate,%,14.27,,,,,
0,47283,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(2048, 1, 1)",0,7.5,Memory Workload Analysis,L2 Hit Rate,%,91.07,,,,,
0,47283,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(2048, 1, 1)",0,7.5,Memory Workload Analysis,Mem Pipes Busy,%,9.04,,,,,
0,47283,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(2048, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Chart,,,,MemoryL2Compression,WRN,The optional metric lts__average_gcomp_input_sector_success_rate.pct could not be found. Collecting it as an additional metric could enable the rule to provide more guidance.,,
0,47283,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(2048, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for loads from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced loads and try to minimize how many cache lines need to be accessed per memory request.",global,2.883
0,47283,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(2048, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for stores from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.2 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced stores and try to minimize how many cache lines need to be accessed per memory request.",global,1.358
0,47283,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(2048, 1, 1)",0,7.5,Scheduler Statistics,One or More Eligible,%,7.29,,,,,
0,47283,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(2048, 1, 1)",0,7.5,Scheduler Statistics,Issued Warp Per Scheduler,,0.07,,,,,
0,47283,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(2048, 1, 1)",0,7.5,Scheduler Statistics,No Eligible,%,92.71,,,,,
0,47283,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(2048, 1, 1)",0,7.5,Scheduler Statistics,Active Warps Per Scheduler,warp,2.93,,,,,
0,47283,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(2048, 1, 1)",0,7.5,Scheduler Statistics,Eligible Warps Per Scheduler,warp,0.08,,,,,
0,47283,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(2048, 1, 1)",0,7.5,SchedulerStats,,,,IssueSlotUtilization,OPT,"Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 13.7 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of 2.93 active warps per scheduler, but only an average of 0.08 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections.",local,90.96
0,47283,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(2048, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Issued Instruction,cycle,40.15,,,,,
0,47283,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(2048, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Executed Instruction,cycle,41.31,,,,,
0,47283,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(2048, 1, 1)",0,7.5,Warp State Statistics,Avg. Active Threads Per Warp,,2,,,,,
0,47283,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(2048, 1, 1)",0,7.5,Warp State Statistics,Avg. Not Predicated Off Threads Per Warp,,2,,,,,
0,47283,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(2048, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,OPT,"On average, each warp of this kernel spends 26.9 cycles being stalled waiting for a scoreboard dependency on a L1TEX (local, global, surface, texture) operation. Find the instruction producing the data being waited upon to identify the culprit. To reduce the number of cycles waiting on L1TEX data accesses verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit rates by increasing data locality (coalescing), or by changing the cache configuration. Consider moving frequently used data to shared memory. This stall type represents about 66.9% of the total average of 40.2 cycles between issuing two instructions.",global,66.89
0,47283,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(2048, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,INF,Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.,,
0,47283,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(2048, 1, 1)",0,7.5,WarpStateStats,,,,ThreadDivergence,OPT,"Instructions are executed in warps, which are groups of 32 threads. Optimal instruction throughput is achieved if all 32 threads of a warp execute the same instruction. The chosen launch configuration, early thread completion, and divergent flow control can significantly lower the number of active threads in a warp per cycle. This kernel achieves an average of 2.0 threads being active per cycle.",global,8.476
0,47283,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(2048, 1, 1)",0,7.5,Instruction Statistics,Avg. Executed Instructions Per Scheduler,inst,475.43,,,,,
0,47283,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(2048, 1, 1)",0,7.5,Instruction Statistics,Executed Instructions,inst,"26,624",,,,,
0,47283,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(2048, 1, 1)",0,7.5,Instruction Statistics,Avg. Issued Instructions Per Scheduler,inst,489.12,,,,,
0,47283,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(2048, 1, 1)",0,7.5,Instruction Statistics,Issued Instructions,inst,"27,391",,,,,
0,47283,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(2048, 1, 1)",0,7.5,InstructionStats,,,,FPInstructions,OPT,"This kernel executes 0 fused and 2048 non-fused FP32 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP32 performance could be increased by up to 50% (relative to its current performance). Check the Source page to identify where this kernel executes FP32 instructions.",global,2.453
0,47283,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(2048, 1, 1)",0,7.5,Launch Statistics,Block Size,,2,,,,,
0,47283,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(2048, 1, 1)",0,7.5,Launch Statistics,Function Cache Configuration,,CachePreferNone,,,,,
0,47283,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(2048, 1, 1)",0,7.5,Launch Statistics,Grid Size,,"2,048",,,,,
0,47283,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(2048, 1, 1)",0,7.5,Launch Statistics,Registers Per Thread,register/thread,16,,,,,
0,47283,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(2048, 1, 1)",0,7.5,Launch Statistics,Shared Memory Configuration Size,byte,"32,768",,,,,
0,47283,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(2048, 1, 1)",0,7.5,Launch Statistics,Driver Shared Memory Per Block,byte/block,0,,,,,
0,47283,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(2048, 1, 1)",0,7.5,Launch Statistics,Dynamic Shared Memory Per Block,byte/block,0,,,,,
0,47283,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(2048, 1, 1)",0,7.5,Launch Statistics,Static Shared Memory Per Block,byte/block,0,,,,,
0,47283,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(2048, 1, 1)",0,7.5,Launch Statistics,Threads,thread,"4,096",,,,,
0,47283,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(2048, 1, 1)",0,7.5,Launch Statistics,Waves Per SM,,9.14,,,,,
0,47283,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(2048, 1, 1)",0,7.5,LaunchStats,,,,LaunchConfiguration,OPT,"Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 2 threads per block. Consequently, some threads in a warp are masked off and those hardware resources are unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256 threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to kernels that frequently call __syncthreads(). See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations.",global,93.75
0,47283,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(2048, 1, 1)",0,7.5,Occupancy,Block Limit SM,block,16,,,,,
0,47283,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(2048, 1, 1)",0,7.5,Occupancy,Block Limit Registers,block,128,,,,,
0,47283,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(2048, 1, 1)",0,7.5,Occupancy,Block Limit Shared Mem,block,16,,,,,
0,47283,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(2048, 1, 1)",0,7.5,Occupancy,Block Limit Warps,block,32,,,,,
0,47283,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(2048, 1, 1)",0,7.5,Occupancy,Theoretical Active Warps per SM,warp,16,,,,,
0,47283,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(2048, 1, 1)",0,7.5,Occupancy,Theoretical Occupancy,%,50,,,,,
0,47283,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(2048, 1, 1)",0,7.5,Occupancy,Achieved Occupancy,%,34.23,,,,,
0,47283,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(2048, 1, 1)",0,7.5,Occupancy,Achieved Active Warps Per SM,warp,10.95,,,,,
0,47283,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(2048, 1, 1)",0,7.5,Occupancy,,,,AchievedOccupancy,OPT,The difference between calculated theoretical (50.0%) and measured achieved occupancy (34.2%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy.,global,31.54
0,47283,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(2048, 1, 1)",0,7.5,Occupancy,,,,TheoreticalOccupancy,OPT,The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared memory.,global,50.0
0,47283,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(2048, 1, 1)",0,7.5,Source Counters,Branch Instructions Ratio,%,0.08,,,,,
0,47283,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(2048, 1, 1)",0,7.5,Source Counters,Branch Instructions,inst,"2,048",,,,,
0,47283,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(2048, 1, 1)",0,7.5,Source Counters,Branch Efficiency,%,0,,,,,
0,47283,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(2048, 1, 1)",0,7.5,Source Counters,Avg. Divergent Branches,,0,,,,,
0,47378,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(1024, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Frequency,cycle/second,"5,942,857,142.86",,,,,
0,47378,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(1024, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Frequency,cycle/second,"1,375,267,857.14",,,,,
0,47378,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(1024, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Elapsed Cycles,cycle,"7,726",,,,,
0,47378,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(1024, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Memory Throughput,%,7.59,,,,,
0,47378,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(1024, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Throughput,%,3.09,,,,,
0,47378,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(1024, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Duration,nsecond,"5,600",,,,,
0,47378,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(1024, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L1/TEX Cache Throughput,%,14.95,,,,,
0,47378,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(1024, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L2 Cache Throughput,%,5.98,,,,,
0,47378,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(1024, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Active Cycles,cycle,"3,914.21",,,,,
0,47378,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(1024, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Compute (SM) Throughput,%,7.59,,,,,
0,47378,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(1024, 1, 1)",0,7.5,SpeedOfLight,,,,SOLBottleneck,OPT,This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.,,
0,47378,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(1024, 1, 1)",0,7.5,SpeedOfLight_RooflineChart,,,,SOLFPRoofline,INF,The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved  close to 0% of this device's fp32 peak performance and 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.,,
0,47378,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(1024, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Active,inst/cycle,0.24,,,,,
0,47378,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(1024, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Elapsed,inst/cycle,0.12,,,,,
0,47378,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(1024, 1, 1)",0,7.5,Compute Workload Analysis,Issue Slots Busy,%,6.42,,,,,
0,47378,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(1024, 1, 1)",0,7.5,Compute Workload Analysis,Issued Ipc Active,inst/cycle,0.26,,,,,
0,47378,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(1024, 1, 1)",0,7.5,Compute Workload Analysis,SM Busy,%,6.42,,,,,
0,47378,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(1024, 1, 1)",0,7.5,ComputeWorkloadAnalysis,,,,HighPipeUtilization,OPT,All compute pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.,local,95.33
0,47378,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(1024, 1, 1)",0,7.5,Memory Workload Analysis,Memory Throughput,byte/second,"5,880,000,000",,,,,
0,47378,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(1024, 1, 1)",0,7.5,Memory Workload Analysis,Mem Busy,%,4.92,,,,,
0,47378,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(1024, 1, 1)",0,7.5,Memory Workload Analysis,Max Bandwidth,%,7.59,,,,,
0,47378,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(1024, 1, 1)",0,7.5,Memory Workload Analysis,L1/TEX Hit Rate,%,13.32,,,,,
0,47378,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(1024, 1, 1)",0,7.5,Memory Workload Analysis,L2 Hit Rate,%,82.41,,,,,
0,47378,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(1024, 1, 1)",0,7.5,Memory Workload Analysis,Mem Pipes Busy,%,7.59,,,,,
0,47378,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(1024, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Chart,,,,MemoryL2Compression,WRN,The optional metric lts__average_gcomp_input_sector_success_rate.pct could not be found. Collecting it as an additional metric could enable the rule to provide more guidance.,,
0,47378,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(1024, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for loads from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced loads and try to minimize how many cache lines need to be accessed per memory request.",global,2.333
0,47378,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(1024, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for stores from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.1 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced stores and try to minimize how many cache lines need to be accessed per memory request.",global,1.149
0,47378,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(1024, 1, 1)",0,7.5,Scheduler Statistics,One or More Eligible,%,6.88,,,,,
0,47378,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(1024, 1, 1)",0,7.5,Scheduler Statistics,Issued Warp Per Scheduler,,0.07,,,,,
0,47378,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(1024, 1, 1)",0,7.5,Scheduler Statistics,No Eligible,%,93.12,,,,,
0,47378,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(1024, 1, 1)",0,7.5,Scheduler Statistics,Active Warps Per Scheduler,warp,2.94,,,,,
0,47378,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(1024, 1, 1)",0,7.5,Scheduler Statistics,Eligible Warps Per Scheduler,warp,0.07,,,,,
0,47378,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(1024, 1, 1)",0,7.5,SchedulerStats,,,,IssueSlotUtilization,OPT,"Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 14.5 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of 2.94 active warps per scheduler, but only an average of 0.07 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections.",local,92.41
0,47378,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(1024, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Issued Instruction,cycle,42.70,,,,,
0,47378,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(1024, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Executed Instruction,cycle,45.15,,,,,
0,47378,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(1024, 1, 1)",0,7.5,Warp State Statistics,Avg. Active Threads Per Warp,,4,,,,,
0,47378,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(1024, 1, 1)",0,7.5,Warp State Statistics,Avg. Not Predicated Off Threads Per Warp,,4,,,,,
0,47378,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(1024, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,OPT,"On average, each warp of this kernel spends 28.1 cycles being stalled waiting for a scoreboard dependency on a L1TEX (local, global, surface, texture) operation. Find the instruction producing the data being waited upon to identify the culprit. To reduce the number of cycles waiting on L1TEX data accesses verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit rates by increasing data locality (coalescing), or by changing the cache configuration. Consider moving frequently used data to shared memory. This stall type represents about 65.8% of the total average of 42.7 cycles between issuing two instructions.",global,65.82
0,47378,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(1024, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,INF,Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.,,
0,47378,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(1024, 1, 1)",0,7.5,WarpStateStats,,,,ThreadDivergence,OPT,"Instructions are executed in warps, which are groups of 32 threads. Optimal instruction throughput is achieved if all 32 threads of a warp execute the same instruction. The chosen launch configuration, early thread completion, and divergent flow control can significantly lower the number of active threads in a warp per cycle. This kernel achieves an average of 4.0 threads being active per cycle.",global,6.645
0,47378,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(1024, 1, 1)",0,7.5,Instruction Statistics,Avg. Executed Instructions Per Scheduler,inst,237.71,,,,,
0,47378,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(1024, 1, 1)",0,7.5,Instruction Statistics,Executed Instructions,inst,"13,312",,,,,
0,47378,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(1024, 1, 1)",0,7.5,Instruction Statistics,Avg. Issued Instructions Per Scheduler,inst,251.36,,,,,
0,47378,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(1024, 1, 1)",0,7.5,Instruction Statistics,Issued Instructions,inst,"14,076",,,,,
0,47378,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(1024, 1, 1)",0,7.5,InstructionStats,,,,FPInstructions,OPT,"This kernel executes 0 fused and 1024 non-fused FP32 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP32 performance could be increased by up to 50% (relative to its current performance). Check the Source page to identify where this kernel executes FP32 instructions.",global,2.336
0,47378,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(1024, 1, 1)",0,7.5,Launch Statistics,Block Size,,4,,,,,
0,47378,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(1024, 1, 1)",0,7.5,Launch Statistics,Function Cache Configuration,,CachePreferNone,,,,,
0,47378,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(1024, 1, 1)",0,7.5,Launch Statistics,Grid Size,,"1,024",,,,,
0,47378,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(1024, 1, 1)",0,7.5,Launch Statistics,Registers Per Thread,register/thread,16,,,,,
0,47378,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(1024, 1, 1)",0,7.5,Launch Statistics,Shared Memory Configuration Size,byte,"32,768",,,,,
0,47378,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(1024, 1, 1)",0,7.5,Launch Statistics,Driver Shared Memory Per Block,byte/block,0,,,,,
0,47378,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(1024, 1, 1)",0,7.5,Launch Statistics,Dynamic Shared Memory Per Block,byte/block,0,,,,,
0,47378,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(1024, 1, 1)",0,7.5,Launch Statistics,Static Shared Memory Per Block,byte/block,0,,,,,
0,47378,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(1024, 1, 1)",0,7.5,Launch Statistics,Threads,thread,"4,096",,,,,
0,47378,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(1024, 1, 1)",0,7.5,Launch Statistics,Waves Per SM,,4.57,,,,,
0,47378,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(1024, 1, 1)",0,7.5,LaunchStats,,,,LaunchConfiguration,OPT,"Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 4 threads per block. Consequently, some threads in a warp are masked off and those hardware resources are unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256 threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to kernels that frequently call __syncthreads(). See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations.",global,87.5
0,47378,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(1024, 1, 1)",0,7.5,LaunchStats,,,,LaunchConfiguration,OPT,"A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical occupancy of the kernel. This kernel launch results in 4 full waves and a partial wave of 127 thread blocks. Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for up to 20.0% of the total kernel runtime with a lower occupancy of 29.7%. Try launching a grid with no partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for a grid. See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations.",global,20.0
0,47378,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(1024, 1, 1)",0,7.5,Occupancy,Block Limit SM,block,16,,,,,
0,47378,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(1024, 1, 1)",0,7.5,Occupancy,Block Limit Registers,block,128,,,,,
0,47378,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(1024, 1, 1)",0,7.5,Occupancy,Block Limit Shared Mem,block,16,,,,,
0,47378,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(1024, 1, 1)",0,7.5,Occupancy,Block Limit Warps,block,32,,,,,
0,47378,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(1024, 1, 1)",0,7.5,Occupancy,Theoretical Active Warps per SM,warp,16,,,,,
0,47378,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(1024, 1, 1)",0,7.5,Occupancy,Theoretical Occupancy,%,50,,,,,
0,47378,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(1024, 1, 1)",0,7.5,Occupancy,Achieved Occupancy,%,35.13,,,,,
0,47378,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(1024, 1, 1)",0,7.5,Occupancy,Achieved Active Warps Per SM,warp,11.24,,,,,
0,47378,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(1024, 1, 1)",0,7.5,Occupancy,,,,AchievedOccupancy,OPT,The difference between calculated theoretical (50.0%) and measured achieved occupancy (35.1%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy.,global,29.74
0,47378,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(1024, 1, 1)",0,7.5,Occupancy,,,,TheoreticalOccupancy,OPT,The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared memory.,global,50.0
0,47378,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(1024, 1, 1)",0,7.5,Source Counters,Branch Instructions Ratio,%,0.08,,,,,
0,47378,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(1024, 1, 1)",0,7.5,Source Counters,Branch Instructions,inst,"1,024",,,,,
0,47378,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(1024, 1, 1)",0,7.5,Source Counters,Branch Efficiency,%,0,,,,,
0,47378,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(1024, 1, 1)",0,7.5,Source Counters,Avg. Divergent Branches,,0,,,,,
0,47471,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(512, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Frequency,cycle/second,"5,743,589,743.59",,,,,
0,47471,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(512, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Frequency,cycle/second,"1,320,512,820.51",,,,,
0,47471,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(512, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Elapsed Cycles,cycle,"4,945",,,,,
0,47471,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(512, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Memory Throughput,%,5.92,,,,,
0,47471,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(512, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Throughput,%,4.79,,,,,
0,47471,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(512, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Duration,nsecond,"3,744",,,,,
0,47471,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(512, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L1/TEX Cache Throughput,%,11.55,,,,,
0,47471,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(512, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L2 Cache Throughput,%,4.52,,,,,
0,47471,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(512, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Active Cycles,cycle,"2,532.64",,,,,
0,47471,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(512, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Compute (SM) Throughput,%,5.92,,,,,
0,47471,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(512, 1, 1)",0,7.5,SpeedOfLight,,,,SOLBottleneck,OPT,This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.,,
0,47471,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(512, 1, 1)",0,7.5,SpeedOfLight_RooflineChart,,,,SOLFPRoofline,INF,The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved  close to 0% of this device's fp32 peak performance and 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.,,
0,47471,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(512, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Active,inst/cycle,0.19,,,,,
0,47471,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(512, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Elapsed,inst/cycle,0.10,,,,,
0,47471,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(512, 1, 1)",0,7.5,Compute Workload Analysis,Issue Slots Busy,%,5.23,,,,,
0,47471,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(512, 1, 1)",0,7.5,Compute Workload Analysis,Issued Ipc Active,inst/cycle,0.21,,,,,
0,47471,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(512, 1, 1)",0,7.5,Compute Workload Analysis,SM Busy,%,5.23,,,,,
0,47471,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(512, 1, 1)",0,7.5,ComputeWorkloadAnalysis,,,,HighPipeUtilization,OPT,All compute pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.,local,96.39
0,47471,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(512, 1, 1)",0,7.5,Memory Workload Analysis,Memory Throughput,byte/second,"8,794,871,794.87",,,,,
0,47471,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(512, 1, 1)",0,7.5,Memory Workload Analysis,Mem Busy,%,4.52,,,,,
0,47471,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(512, 1, 1)",0,7.5,Memory Workload Analysis,Max Bandwidth,%,5.92,,,,,
0,47471,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(512, 1, 1)",0,7.5,Memory Workload Analysis,L1/TEX Hit Rate,%,7.48,,,,,
0,47471,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(512, 1, 1)",0,7.5,Memory Workload Analysis,L2 Hit Rate,%,59.86,,,,,
0,47471,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(512, 1, 1)",0,7.5,Memory Workload Analysis,Mem Pipes Busy,%,5.92,,,,,
0,47471,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(512, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Chart,,,,MemoryL2Compression,WRN,The optional metric lts__average_gcomp_input_sector_success_rate.pct could not be found. Collecting it as an additional metric could enable the rule to provide more guidance.,,
0,47471,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(512, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for loads from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.2 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced loads and try to minimize how many cache lines need to be accessed per memory request.",global,1.947
0,47471,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(512, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for stores from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.2 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced stores and try to minimize how many cache lines need to be accessed per memory request.",global,0.9578
0,47471,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(512, 1, 1)",0,7.5,Scheduler Statistics,One or More Eligible,%,5.61,,,,,
0,47471,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(512, 1, 1)",0,7.5,Scheduler Statistics,Issued Warp Per Scheduler,,0.06,,,,,
0,47471,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(512, 1, 1)",0,7.5,Scheduler Statistics,No Eligible,%,94.39,,,,,
0,47471,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(512, 1, 1)",0,7.5,Scheduler Statistics,Active Warps Per Scheduler,warp,2.83,,,,,
0,47471,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(512, 1, 1)",0,7.5,Scheduler Statistics,Eligible Warps Per Scheduler,warp,0.06,,,,,
0,47471,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(512, 1, 1)",0,7.5,SchedulerStats,,,,IssueSlotUtilization,OPT,"Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 17.8 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of 2.83 active warps per scheduler, but only an average of 0.06 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections.",local,94.08
0,47471,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(512, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Issued Instruction,cycle,50.43,,,,,
0,47471,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(512, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Executed Instruction,cycle,56.22,,,,,
0,47471,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(512, 1, 1)",0,7.5,Warp State Statistics,Avg. Active Threads Per Warp,,8,,,,,
0,47471,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(512, 1, 1)",0,7.5,Warp State Statistics,Avg. Not Predicated Off Threads Per Warp,,8,,,,,
0,47471,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(512, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,OPT,"On average, each warp of this kernel spends 27.9 cycles being stalled waiting for a scoreboard dependency on a L1TEX (local, global, surface, texture) operation. Find the instruction producing the data being waited upon to identify the culprit. To reduce the number of cycles waiting on L1TEX data accesses verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit rates by increasing data locality (coalescing), or by changing the cache configuration. Consider moving frequently used data to shared memory. This stall type represents about 55.3% of the total average of 50.4 cycles between issuing two instructions.",global,55.34
0,47471,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(512, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,INF,Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.,,
0,47471,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(512, 1, 1)",0,7.5,WarpStateStats,,,,ThreadDivergence,OPT,"Instructions are executed in warps, which are groups of 32 threads. Optimal instruction throughput is achieved if all 32 threads of a warp execute the same instruction. The chosen launch configuration, early thread completion, and divergent flow control can significantly lower the number of active threads in a warp per cycle. This kernel achieves an average of 8.0 threads being active per cycle.",global,4.438
0,47471,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(512, 1, 1)",0,7.5,Instruction Statistics,Avg. Executed Instructions Per Scheduler,inst,118.86,,,,,
0,47471,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(512, 1, 1)",0,7.5,Instruction Statistics,Executed Instructions,inst,"6,656",,,,,
0,47471,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(512, 1, 1)",0,7.5,Instruction Statistics,Avg. Issued Instructions Per Scheduler,inst,132.50,,,,,
0,47471,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(512, 1, 1)",0,7.5,Instruction Statistics,Issued Instructions,inst,"7,420",,,,,
0,47471,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(512, 1, 1)",0,7.5,InstructionStats,,,,FPInstructions,OPT,"This kernel executes 0 fused and 512 non-fused FP32 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP32 performance could be increased by up to 50% (relative to its current performance). Check the Source page to identify where this kernel executes FP32 instructions.",global,1.805
0,47471,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(512, 1, 1)",0,7.5,Launch Statistics,Block Size,,8,,,,,
0,47471,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(512, 1, 1)",0,7.5,Launch Statistics,Function Cache Configuration,,CachePreferNone,,,,,
0,47471,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(512, 1, 1)",0,7.5,Launch Statistics,Grid Size,,512,,,,,
0,47471,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(512, 1, 1)",0,7.5,Launch Statistics,Registers Per Thread,register/thread,16,,,,,
0,47471,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(512, 1, 1)",0,7.5,Launch Statistics,Shared Memory Configuration Size,byte,"32,768",,,,,
0,47471,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(512, 1, 1)",0,7.5,Launch Statistics,Driver Shared Memory Per Block,byte/block,0,,,,,
0,47471,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(512, 1, 1)",0,7.5,Launch Statistics,Dynamic Shared Memory Per Block,byte/block,0,,,,,
0,47471,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(512, 1, 1)",0,7.5,Launch Statistics,Static Shared Memory Per Block,byte/block,0,,,,,
0,47471,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(512, 1, 1)",0,7.5,Launch Statistics,Threads,thread,"4,096",,,,,
0,47471,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(512, 1, 1)",0,7.5,Launch Statistics,Waves Per SM,,2.29,,,,,
0,47471,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(512, 1, 1)",0,7.5,LaunchStats,,,,LaunchConfiguration,OPT,"Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 8 threads per block. Consequently, some threads in a warp are masked off and those hardware resources are unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256 threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to kernels that frequently call __syncthreads(). See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations.",global,75.0
0,47471,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(512, 1, 1)",0,7.5,LaunchStats,,,,LaunchConfiguration,OPT,"A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical occupancy of the kernel. This kernel launch results in 2 full waves and a partial wave of 63 thread blocks. Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for up to 33.3% of the total kernel runtime with a lower occupancy of 31.4%. Try launching a grid with no partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for a grid. See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations.",global,33.33
0,47471,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(512, 1, 1)",0,7.5,Occupancy,Block Limit SM,block,16,,,,,
0,47471,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(512, 1, 1)",0,7.5,Occupancy,Block Limit Registers,block,128,,,,,
0,47471,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(512, 1, 1)",0,7.5,Occupancy,Block Limit Shared Mem,block,16,,,,,
0,47471,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(512, 1, 1)",0,7.5,Occupancy,Block Limit Warps,block,32,,,,,
0,47471,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(512, 1, 1)",0,7.5,Occupancy,Theoretical Active Warps per SM,warp,16,,,,,
0,47471,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(512, 1, 1)",0,7.5,Occupancy,Theoretical Occupancy,%,50,,,,,
0,47471,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(512, 1, 1)",0,7.5,Occupancy,Achieved Occupancy,%,34.29,,,,,
0,47471,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(512, 1, 1)",0,7.5,Occupancy,Achieved Active Warps Per SM,warp,10.97,,,,,
0,47471,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(512, 1, 1)",0,7.5,Occupancy,,,,AchievedOccupancy,OPT,The difference between calculated theoretical (50.0%) and measured achieved occupancy (34.3%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy.,global,31.42
0,47471,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(512, 1, 1)",0,7.5,Occupancy,,,,TheoreticalOccupancy,OPT,The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared memory.,global,50.0
0,47471,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(512, 1, 1)",0,7.5,Source Counters,Branch Instructions Ratio,%,0.08,,,,,
0,47471,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(512, 1, 1)",0,7.5,Source Counters,Branch Instructions,inst,512,,,,,
0,47471,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(512, 1, 1)",0,7.5,Source Counters,Branch Efficiency,%,0,,,,,
0,47471,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(512, 1, 1)",0,7.5,Source Counters,Avg. Divergent Branches,,0,,,,,
0,47555,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(256, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Frequency,cycle/second,"5,727,272,727.27",,,,,
0,47555,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(256, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Frequency,cycle/second,"1,314,630,681.82",,,,,
0,47555,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(256, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Elapsed Cycles,cycle,"3,705",,,,,
0,47555,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(256, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Memory Throughput,%,6.38,,,,,
0,47555,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(256, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Throughput,%,6.38,,,,,
0,47555,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(256, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Duration,nsecond,"2,816",,,,,
0,47555,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(256, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L1/TEX Cache Throughput,%,8.07,,,,,
0,47555,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(256, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L2 Cache Throughput,%,6.02,,,,,
0,47555,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(256, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Active Cycles,cycle,"1,812",,,,,
0,47555,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(256, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Compute (SM) Throughput,%,3.95,,,,,
0,47555,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(256, 1, 1)",0,7.5,SpeedOfLight,,,,SOLBottleneck,OPT,This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.,,
0,47555,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(256, 1, 1)",0,7.5,SpeedOfLight_RooflineChart,,,,SOLFPRoofline,INF,The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved  close to 0% of this device's fp32 peak performance and 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.,,
0,47555,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(256, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Active,inst/cycle,0.13,,,,,
0,47555,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(256, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Elapsed,inst/cycle,0.06,,,,,
0,47555,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(256, 1, 1)",0,7.5,Compute Workload Analysis,Issue Slots Busy,%,4.03,,,,,
0,47555,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(256, 1, 1)",0,7.5,Compute Workload Analysis,Issued Ipc Active,inst/cycle,0.16,,,,,
0,47555,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(256, 1, 1)",0,7.5,Compute Workload Analysis,SM Busy,%,4.03,,,,,
0,47555,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(256, 1, 1)",0,7.5,ComputeWorkloadAnalysis,,,,HighPipeUtilization,OPT,All compute pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.,local,97.48
0,47555,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(256, 1, 1)",0,7.5,Memory Workload Analysis,Memory Throughput,byte/second,"11,693,181,818.18",,,,,
0,47555,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(256, 1, 1)",0,7.5,Memory Workload Analysis,Mem Busy,%,6.02,,,,,
0,47555,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(256, 1, 1)",0,7.5,Memory Workload Analysis,Max Bandwidth,%,6.38,,,,,
0,47555,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(256, 1, 1)",0,7.5,Memory Workload Analysis,L1/TEX Hit Rate,%,14.58,,,,,
0,47555,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(256, 1, 1)",0,7.5,Memory Workload Analysis,L2 Hit Rate,%,39.96,,,,,
0,47555,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(256, 1, 1)",0,7.5,Memory Workload Analysis,Mem Pipes Busy,%,3.95,,,,,
0,47555,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(256, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Chart,,,,MemoryL2Compression,WRN,The optional metric lts__average_gcomp_input_sector_success_rate.pct could not be found. Collecting it as an additional metric could enable the rule to provide more guidance.,,
0,47555,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(256, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for loads from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 3.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced loads and try to minimize how many cache lines need to be accessed per memory request.",global,0.9021
0,47555,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(256, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for stores from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 3.2 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced stores and try to minimize how many cache lines need to be accessed per memory request.",global,0.3697
0,47555,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(256, 1, 1)",0,7.5,Scheduler Statistics,One or More Eligible,%,4.66,,,,,
0,47555,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(256, 1, 1)",0,7.5,Scheduler Statistics,Issued Warp Per Scheduler,,0.05,,,,,
0,47555,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(256, 1, 1)",0,7.5,Scheduler Statistics,No Eligible,%,95.34,,,,,
0,47555,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(256, 1, 1)",0,7.5,Scheduler Statistics,Active Warps Per Scheduler,warp,2.99,,,,,
0,47555,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(256, 1, 1)",0,7.5,Scheduler Statistics,Eligible Warps Per Scheduler,warp,0.06,,,,,
0,47555,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(256, 1, 1)",0,7.5,SchedulerStats,,,,IssueSlotUtilization,OPT,"Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 21.5 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of 2.99 active warps per scheduler, but only an average of 0.06 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections.",local,93.62
0,47555,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(256, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Issued Instruction,cycle,64.21,,,,,
0,47555,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(256, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Executed Instruction,cycle,78.96,,,,,
0,47555,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(256, 1, 1)",0,7.5,Warp State Statistics,Avg. Active Threads Per Warp,,16,,,,,
0,47555,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(256, 1, 1)",0,7.5,Warp State Statistics,Avg. Not Predicated Off Threads Per Warp,,16,,,,,
0,47555,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(256, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,OPT,"On average, each warp of this kernel spends 30.8 cycles being stalled waiting for a scoreboard dependency on a L1TEX (local, global, surface, texture) operation. Find the instruction producing the data being waited upon to identify the culprit. To reduce the number of cycles waiting on L1TEX data accesses verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit rates by increasing data locality (coalescing), or by changing the cache configuration. Consider moving frequently used data to shared memory. This stall type represents about 48.0% of the total average of 64.2 cycles between issuing two instructions.",global,47.97
0,47555,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(256, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,OPT,"On average, each warp of this kernel spends 25.9 cycles being stalled waiting for an immediate constant cache (IMC) miss. A read from constant memory costs one memory read from device memory only on a cache miss; otherwise, it just costs one read from the constant cache. Immediate constants are encoded into the SASS instruction as 'c[bank][offset]'. Accesses to different addresses by threads within a warp are serialized, thus the cost scales linearly with the number of unique addresses read by all threads within a warp. As such, the constant cache is best when threads in the same warp access only a few distinct locations. If all threads of a warp access the same location, then constant memory can be as fast as a register access. This stall type represents about 40.3% of the total average of 64.2 cycles between issuing two instructions.",global,40.34
0,47555,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(256, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,INF,Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.,,
0,47555,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(256, 1, 1)",0,7.5,WarpStateStats,,,,ThreadDivergence,OPT,"Instructions are executed in warps, which are groups of 32 threads. Optimal instruction throughput is achieved if all 32 threads of a warp execute the same instruction. The chosen launch configuration, early thread completion, and divergent flow control can significantly lower the number of active threads in a warp per cycle. This kernel achieves an average of 16.0 threads being active per cycle.",global,1.976
0,47555,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(256, 1, 1)",0,7.5,Instruction Statistics,Avg. Executed Instructions Per Scheduler,inst,59.43,,,,,
0,47555,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(256, 1, 1)",0,7.5,Instruction Statistics,Executed Instructions,inst,"3,328",,,,,
0,47555,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(256, 1, 1)",0,7.5,Instruction Statistics,Avg. Issued Instructions Per Scheduler,inst,73.07,,,,,
0,47555,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(256, 1, 1)",0,7.5,Instruction Statistics,Issued Instructions,inst,"4,092",,,,,
0,47555,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(256, 1, 1)",0,7.5,InstructionStats,,,,FPInstructions,OPT,"This kernel executes 0 fused and 256 non-fused FP32 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP32 performance could be increased by up to 50% (relative to its current performance). Check the Source page to identify where this kernel executes FP32 instructions.",global,1.261
0,47555,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(256, 1, 1)",0,7.5,Launch Statistics,Block Size,,16,,,,,
0,47555,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(256, 1, 1)",0,7.5,Launch Statistics,Function Cache Configuration,,CachePreferNone,,,,,
0,47555,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(256, 1, 1)",0,7.5,Launch Statistics,Grid Size,,256,,,,,
0,47555,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(256, 1, 1)",0,7.5,Launch Statistics,Registers Per Thread,register/thread,16,,,,,
0,47555,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(256, 1, 1)",0,7.5,Launch Statistics,Shared Memory Configuration Size,byte,"32,768",,,,,
0,47555,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(256, 1, 1)",0,7.5,Launch Statistics,Driver Shared Memory Per Block,byte/block,0,,,,,
0,47555,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(256, 1, 1)",0,7.5,Launch Statistics,Dynamic Shared Memory Per Block,byte/block,0,,,,,
0,47555,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(256, 1, 1)",0,7.5,Launch Statistics,Static Shared Memory Per Block,byte/block,0,,,,,
0,47555,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(256, 1, 1)",0,7.5,Launch Statistics,Threads,thread,"4,096",,,,,
0,47555,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(256, 1, 1)",0,7.5,Launch Statistics,Waves Per SM,,1.14,,,,,
0,47555,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(256, 1, 1)",0,7.5,LaunchStats,,,,LaunchConfiguration,OPT,"Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 16 threads per block. Consequently, some threads in a warp are masked off and those hardware resources are unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256 threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to kernels that frequently call __syncthreads(). See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations.",global,50.0
0,47555,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(256, 1, 1)",0,7.5,LaunchStats,,,,LaunchConfiguration,OPT,"A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical occupancy of the kernel. This kernel launch results in 1 full waves and a partial wave of 31 thread blocks. Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for up to 50.0% of the total kernel runtime with a lower occupancy of 31.9%. Try launching a grid with no partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for a grid. See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations.",global,50.0
0,47555,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(256, 1, 1)",0,7.5,Occupancy,Block Limit SM,block,16,,,,,
0,47555,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(256, 1, 1)",0,7.5,Occupancy,Block Limit Registers,block,128,,,,,
0,47555,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(256, 1, 1)",0,7.5,Occupancy,Block Limit Shared Mem,block,16,,,,,
0,47555,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(256, 1, 1)",0,7.5,Occupancy,Block Limit Warps,block,32,,,,,
0,47555,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(256, 1, 1)",0,7.5,Occupancy,Theoretical Active Warps per SM,warp,16,,,,,
0,47555,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(256, 1, 1)",0,7.5,Occupancy,Theoretical Occupancy,%,50,,,,,
0,47555,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(256, 1, 1)",0,7.5,Occupancy,Achieved Occupancy,%,34.04,,,,,
0,47555,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(256, 1, 1)",0,7.5,Occupancy,Achieved Active Warps Per SM,warp,10.89,,,,,
0,47555,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(256, 1, 1)",0,7.5,Occupancy,,,,AchievedOccupancy,OPT,The difference between calculated theoretical (50.0%) and measured achieved occupancy (34.0%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy.,global,31.91
0,47555,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(256, 1, 1)",0,7.5,Occupancy,,,,TheoreticalOccupancy,OPT,The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared memory.,global,50.0
0,47555,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(256, 1, 1)",0,7.5,Source Counters,Branch Instructions Ratio,%,0.08,,,,,
0,47555,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(256, 1, 1)",0,7.5,Source Counters,Branch Instructions,inst,256,,,,,
0,47555,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(256, 1, 1)",0,7.5,Source Counters,Branch Efficiency,%,0,,,,,
0,47555,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(256, 1, 1)",0,7.5,Source Counters,Avg. Divergent Branches,,0,,,,,
0,47648,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(128, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Frequency,cycle/second,"5,555,555,555.56",,,,,
0,47648,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(128, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Frequency,cycle/second,"1,303,819,444.44",,,,,
0,47648,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(128, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Elapsed Cycles,cycle,"3,012",,,,,
0,47648,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(128, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Memory Throughput,%,8.04,,,,,
0,47648,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(128, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Throughput,%,8.04,,,,,
0,47648,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(128, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Duration,nsecond,"2,304",,,,,
0,47648,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(128, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L1/TEX Cache Throughput,%,5.49,,,,,
0,47648,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(128, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L2 Cache Throughput,%,7.40,,,,,
0,47648,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(128, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Active Cycles,cycle,"1,331.79",,,,,
0,47648,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(128, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Compute (SM) Throughput,%,2.43,,,,,
0,47648,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(128, 1, 1)",0,7.5,SpeedOfLight,,,,SOLBottleneck,OPT,"This kernel grid is too small to fill the available resources on this device, resulting in only 0.6 full waves across all SMs. Look at Launch Statistics for more details.",,
0,47648,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(128, 1, 1)",0,7.5,SpeedOfLight_RooflineChart,,,,SOLFPRoofline,INF,The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved  close to 0% of this device's fp32 peak performance and 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.,,
0,47648,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(128, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Active,inst/cycle,0.09,,,,,
0,47648,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(128, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Elapsed,inst/cycle,0.04,,,,,
0,47648,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(128, 1, 1)",0,7.5,Compute Workload Analysis,Issue Slots Busy,%,2.92,,,,,
0,47648,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(128, 1, 1)",0,7.5,Compute Workload Analysis,Issued Ipc Active,inst/cycle,0.12,,,,,
0,47648,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(128, 1, 1)",0,7.5,Compute Workload Analysis,SM Busy,%,2.92,,,,,
0,47648,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(128, 1, 1)",0,7.5,ComputeWorkloadAnalysis,,,,HighPipeUtilization,OPT,All compute pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.,local,98.28
0,47648,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(128, 1, 1)",0,7.5,Memory Workload Analysis,Memory Throughput,byte/second,"14,291,666,666.67",,,,,
0,47648,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(128, 1, 1)",0,7.5,Memory Workload Analysis,Mem Busy,%,7.40,,,,,
0,47648,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(128, 1, 1)",0,7.5,Memory Workload Analysis,Max Bandwidth,%,8.04,,,,,
0,47648,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(128, 1, 1)",0,7.5,Memory Workload Analysis,L1/TEX Hit Rate,%,0,,,,,
0,47648,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(128, 1, 1)",0,7.5,Memory Workload Analysis,L2 Hit Rate,%,39.79,,,,,
0,47648,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(128, 1, 1)",0,7.5,Memory Workload Analysis,Mem Pipes Busy,%,2.43,,,,,
0,47648,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(128, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Chart,,,,MemoryL2Compression,WRN,The optional metric lts__average_gcomp_input_sector_success_rate.pct could not be found. Collecting it as an additional metric could enable the rule to provide more guidance.,,
0,47648,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(128, 1, 1)",0,7.5,Scheduler Statistics,One or More Eligible,%,3.05,,,,,
0,47648,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(128, 1, 1)",0,7.5,Scheduler Statistics,Issued Warp Per Scheduler,,0.03,,,,,
0,47648,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(128, 1, 1)",0,7.5,Scheduler Statistics,No Eligible,%,96.95,,,,,
0,47648,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(128, 1, 1)",0,7.5,Scheduler Statistics,Active Warps Per Scheduler,warp,2.19,,,,,
0,47648,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(128, 1, 1)",0,7.5,Scheduler Statistics,Eligible Warps Per Scheduler,warp,0.03,,,,,
0,47648,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(128, 1, 1)",0,7.5,SchedulerStats,,,,IssueSlotUtilization,OPT,"Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 32.8 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of 2.19 active warps per scheduler, but only an average of 0.03 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections.",local,91.96
0,47648,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(128, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Issued Instruction,cycle,71.94,,,,,
0,47648,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(128, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Executed Instruction,cycle,94.07,,,,,
0,47648,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(128, 1, 1)",0,7.5,Warp State Statistics,Avg. Active Threads Per Warp,,32,,,,,
0,47648,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(128, 1, 1)",0,7.5,Warp State Statistics,Avg. Not Predicated Off Threads Per Warp,,32,,,,,
0,47648,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(128, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,OPT,"On average, each warp of this kernel spends 33.5 cycles being stalled waiting for a scoreboard dependency on a L1TEX (local, global, surface, texture) operation. Find the instruction producing the data being waited upon to identify the culprit. To reduce the number of cycles waiting on L1TEX data accesses verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit rates by increasing data locality (coalescing), or by changing the cache configuration. Consider moving frequently used data to shared memory. This stall type represents about 46.6% of the total average of 71.9 cycles between issuing two instructions.",global,46.56
0,47648,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(128, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,OPT,"On average, each warp of this kernel spends 31.8 cycles being stalled waiting for an immediate constant cache (IMC) miss. A read from constant memory costs one memory read from device memory only on a cache miss; otherwise, it just costs one read from the constant cache. Immediate constants are encoded into the SASS instruction as 'c[bank][offset]'. Accesses to different addresses by threads within a warp are serialized, thus the cost scales linearly with the number of unique addresses read by all threads within a warp. As such, the constant cache is best when threads in the same warp access only a few distinct locations. If all threads of a warp access the same location, then constant memory can be as fast as a register access. This stall type represents about 44.3% of the total average of 71.9 cycles between issuing two instructions.",global,44.26
0,47648,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(128, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,INF,Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.,,
0,47648,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(128, 1, 1)",0,7.5,Instruction Statistics,Avg. Executed Instructions Per Scheduler,inst,29.71,,,,,
0,47648,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(128, 1, 1)",0,7.5,Instruction Statistics,Executed Instructions,inst,"1,664",,,,,
0,47648,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(128, 1, 1)",0,7.5,Instruction Statistics,Avg. Issued Instructions Per Scheduler,inst,38.86,,,,,
0,47648,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(128, 1, 1)",0,7.5,Instruction Statistics,Issued Instructions,inst,"2,176",,,,,
0,47648,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(128, 1, 1)",0,7.5,InstructionStats,,,,FPInstructions,OPT,"This kernel executes 0 fused and 128 non-fused FP32 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP32 performance could be increased by up to 50% (relative to its current performance). Check the Source page to identify where this kernel executes FP32 instructions.",global,0.8581
0,47648,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(128, 1, 1)",0,7.5,Launch Statistics,Block Size,,32,,,,,
0,47648,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(128, 1, 1)",0,7.5,Launch Statistics,Function Cache Configuration,,CachePreferNone,,,,,
0,47648,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(128, 1, 1)",0,7.5,Launch Statistics,Grid Size,,128,,,,,
0,47648,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(128, 1, 1)",0,7.5,Launch Statistics,Registers Per Thread,register/thread,16,,,,,
0,47648,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(128, 1, 1)",0,7.5,Launch Statistics,Shared Memory Configuration Size,byte,"32,768",,,,,
0,47648,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(128, 1, 1)",0,7.5,Launch Statistics,Driver Shared Memory Per Block,byte/block,0,,,,,
0,47648,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(128, 1, 1)",0,7.5,Launch Statistics,Dynamic Shared Memory Per Block,byte/block,0,,,,,
0,47648,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(128, 1, 1)",0,7.5,Launch Statistics,Static Shared Memory Per Block,byte/block,0,,,,,
0,47648,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(128, 1, 1)",0,7.5,Launch Statistics,Threads,thread,"4,096",,,,,
0,47648,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(128, 1, 1)",0,7.5,Launch Statistics,Waves Per SM,,0.57,,,,,
0,47648,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(128, 1, 1)",0,7.5,Occupancy,Block Limit SM,block,16,,,,,
0,47648,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(128, 1, 1)",0,7.5,Occupancy,Block Limit Registers,block,128,,,,,
0,47648,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(128, 1, 1)",0,7.5,Occupancy,Block Limit Shared Mem,block,16,,,,,
0,47648,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(128, 1, 1)",0,7.5,Occupancy,Block Limit Warps,block,32,,,,,
0,47648,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(128, 1, 1)",0,7.5,Occupancy,Theoretical Active Warps per SM,warp,16,,,,,
0,47648,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(128, 1, 1)",0,7.5,Occupancy,Theoretical Occupancy,%,50,,,,,
0,47648,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(128, 1, 1)",0,7.5,Occupancy,Achieved Occupancy,%,26.72,,,,,
0,47648,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(128, 1, 1)",0,7.5,Occupancy,Achieved Active Warps Per SM,warp,8.55,,,,,
0,47648,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(128, 1, 1)",0,7.5,Occupancy,,,,AchievedOccupancy,OPT,The difference between calculated theoretical (50.0%) and measured achieved occupancy (26.7%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy.,global,46.56
0,47648,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(128, 1, 1)",0,7.5,Occupancy,,,,TheoreticalOccupancy,OPT,The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared memory.,global,50.0
0,47648,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(128, 1, 1)",0,7.5,Source Counters,Branch Instructions Ratio,%,0.08,,,,,
0,47648,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(128, 1, 1)",0,7.5,Source Counters,Branch Instructions,inst,128,,,,,
0,47648,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(128, 1, 1)",0,7.5,Source Counters,Branch Efficiency,%,0,,,,,
0,47648,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(128, 1, 1)",0,7.5,Source Counters,Avg. Divergent Branches,,0,,,,,
0,47725,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(64, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Frequency,cycle/second,"4,947,368,421.05",,,,,
0,47725,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(64, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Frequency,cycle/second,"1,138,569,078.95",,,,,
0,47725,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(64, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Elapsed Cycles,cycle,"2,782",,,,,
0,47725,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(64, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Memory Throughput,%,8.55,,,,,
0,47725,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(64, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Throughput,%,8.55,,,,,
0,47725,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(64, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Duration,nsecond,"2,432",,,,,
0,47725,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(64, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L1/TEX Cache Throughput,%,5.55,,,,,
0,47725,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(64, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L2 Cache Throughput,%,8.00,,,,,
0,47725,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(64, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Active Cycles,cycle,"1,319",,,,,
0,47725,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(64, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Compute (SM) Throughput,%,2.64,,,,,
0,47725,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(64, 1, 1)",0,7.5,SpeedOfLight,,,,SOLBottleneck,OPT,"This kernel grid is too small to fill the available resources on this device, resulting in only 0.3 full waves across all SMs. Look at Launch Statistics for more details.",,
0,47725,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(64, 1, 1)",0,7.5,SpeedOfLight_RooflineChart,,,,SOLFPRoofline,INF,The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved  close to 0% of this device's fp32 peak performance and 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.,,
0,47725,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(64, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Active,inst/cycle,0.09,,,,,
0,47725,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(64, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Elapsed,inst/cycle,0.04,,,,,
0,47725,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(64, 1, 1)",0,7.5,Compute Workload Analysis,Issue Slots Busy,%,2.95,,,,,
0,47725,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(64, 1, 1)",0,7.5,Compute Workload Analysis,Issued Ipc Active,inst/cycle,0.12,,,,,
0,47725,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(64, 1, 1)",0,7.5,Compute Workload Analysis,SM Busy,%,2.95,,,,,
0,47725,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(64, 1, 1)",0,7.5,ComputeWorkloadAnalysis,,,,HighPipeUtilization,OPT,All compute pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.,local,98.27
0,47725,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(64, 1, 1)",0,7.5,Memory Workload Analysis,Memory Throughput,byte/second,"13,539,473,684.21",,,,,
0,47725,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(64, 1, 1)",0,7.5,Memory Workload Analysis,Mem Busy,%,8.00,,,,,
0,47725,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(64, 1, 1)",0,7.5,Memory Workload Analysis,Max Bandwidth,%,8.55,,,,,
0,47725,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(64, 1, 1)",0,7.5,Memory Workload Analysis,L1/TEX Hit Rate,%,0,,,,,
0,47725,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(64, 1, 1)",0,7.5,Memory Workload Analysis,L2 Hit Rate,%,40.07,,,,,
0,47725,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(64, 1, 1)",0,7.5,Memory Workload Analysis,Mem Pipes Busy,%,2.64,,,,,
0,47725,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(64, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Chart,,,,MemoryL2Compression,WRN,The optional metric lts__average_gcomp_input_sector_success_rate.pct could not be found. Collecting it as an additional metric could enable the rule to provide more guidance.,,
0,47725,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(64, 1, 1)",0,7.5,Scheduler Statistics,One or More Eligible,%,3.04,,,,,
0,47725,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(64, 1, 1)",0,7.5,Scheduler Statistics,Issued Warp Per Scheduler,,0.03,,,,,
0,47725,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(64, 1, 1)",0,7.5,Scheduler Statistics,No Eligible,%,96.96,,,,,
0,47725,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(64, 1, 1)",0,7.5,Scheduler Statistics,Active Warps Per Scheduler,warp,2.22,,,,,
0,47725,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(64, 1, 1)",0,7.5,Scheduler Statistics,Eligible Warps Per Scheduler,warp,0.03,,,,,
0,47725,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(64, 1, 1)",0,7.5,SchedulerStats,,,,IssueSlotUtilization,OPT,"Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 32.9 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of 2.22 active warps per scheduler, but only an average of 0.03 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections.",local,91.45
0,47725,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(64, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Issued Instruction,cycle,73.08,,,,,
0,47725,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(64, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Executed Instruction,cycle,95.56,,,,,
0,47725,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(64, 1, 1)",0,7.5,Warp State Statistics,Avg. Active Threads Per Warp,,32,,,,,
0,47725,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(64, 1, 1)",0,7.5,Warp State Statistics,Avg. Not Predicated Off Threads Per Warp,,32,,,,,
0,47725,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(64, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,OPT,"On average, each warp of this kernel spends 33.0 cycles being stalled waiting for an immediate constant cache (IMC) miss. A read from constant memory costs one memory read from device memory only on a cache miss; otherwise, it just costs one read from the constant cache. Immediate constants are encoded into the SASS instruction as 'c[bank][offset]'. Accesses to different addresses by threads within a warp are serialized, thus the cost scales linearly with the number of unique addresses read by all threads within a warp. As such, the constant cache is best when threads in the same warp access only a few distinct locations. If all threads of a warp access the same location, then constant memory can be as fast as a register access. This stall type represents about 45.2% of the total average of 73.1 cycles between issuing two instructions.",global,45.16
0,47725,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(64, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,OPT,"On average, each warp of this kernel spends 32.8 cycles being stalled waiting for a scoreboard dependency on a L1TEX (local, global, surface, texture) operation. Find the instruction producing the data being waited upon to identify the culprit. To reduce the number of cycles waiting on L1TEX data accesses verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit rates by increasing data locality (coalescing), or by changing the cache configuration. Consider moving frequently used data to shared memory. This stall type represents about 44.8% of the total average of 73.1 cycles between issuing two instructions.",global,44.82
0,47725,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(64, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,INF,Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.,,
0,47725,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(64, 1, 1)",0,7.5,Instruction Statistics,Avg. Executed Instructions Per Scheduler,inst,29.71,,,,,
0,47725,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(64, 1, 1)",0,7.5,Instruction Statistics,Executed Instructions,inst,"1,664",,,,,
0,47725,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(64, 1, 1)",0,7.5,Instruction Statistics,Avg. Issued Instructions Per Scheduler,inst,38.86,,,,,
0,47725,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(64, 1, 1)",0,7.5,Instruction Statistics,Issued Instructions,inst,"2,176",,,,,
0,47725,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(64, 1, 1)",0,7.5,InstructionStats,,,,FPInstructions,OPT,"This kernel executes 0 fused and 128 non-fused FP32 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP32 performance could be increased by up to 50% (relative to its current performance). Check the Source page to identify where this kernel executes FP32 instructions.",global,0.8665
0,47725,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(64, 1, 1)",0,7.5,Launch Statistics,Block Size,,64,,,,,
0,47725,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(64, 1, 1)",0,7.5,Launch Statistics,Function Cache Configuration,,CachePreferNone,,,,,
0,47725,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(64, 1, 1)",0,7.5,Launch Statistics,Grid Size,,64,,,,,
0,47725,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(64, 1, 1)",0,7.5,Launch Statistics,Registers Per Thread,register/thread,16,,,,,
0,47725,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(64, 1, 1)",0,7.5,Launch Statistics,Shared Memory Configuration Size,byte,"32,768",,,,,
0,47725,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(64, 1, 1)",0,7.5,Launch Statistics,Driver Shared Memory Per Block,byte/block,0,,,,,
0,47725,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(64, 1, 1)",0,7.5,Launch Statistics,Dynamic Shared Memory Per Block,byte/block,0,,,,,
0,47725,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(64, 1, 1)",0,7.5,Launch Statistics,Static Shared Memory Per Block,byte/block,0,,,,,
0,47725,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(64, 1, 1)",0,7.5,Launch Statistics,Threads,thread,"4,096",,,,,
0,47725,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(64, 1, 1)",0,7.5,Launch Statistics,Waves Per SM,,0.29,,,,,
0,47725,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(64, 1, 1)",0,7.5,Occupancy,Block Limit SM,block,16,,,,,
0,47725,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(64, 1, 1)",0,7.5,Occupancy,Block Limit Registers,block,64,,,,,
0,47725,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(64, 1, 1)",0,7.5,Occupancy,Block Limit Shared Mem,block,16,,,,,
0,47725,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(64, 1, 1)",0,7.5,Occupancy,Block Limit Warps,block,16,,,,,
0,47725,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(64, 1, 1)",0,7.5,Occupancy,Theoretical Active Warps per SM,warp,32,,,,,
0,47725,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(64, 1, 1)",0,7.5,Occupancy,Theoretical Occupancy,%,100,,,,,
0,47725,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(64, 1, 1)",0,7.5,Occupancy,Achieved Occupancy,%,27.42,,,,,
0,47725,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(64, 1, 1)",0,7.5,Occupancy,Achieved Active Warps Per SM,warp,8.77,,,,,
0,47725,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(64, 1, 1)",0,7.5,Occupancy,,,,AchievedOccupancy,OPT,The difference between calculated theoretical (100.0%) and measured achieved occupancy (27.4%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy.,global,72.58
0,47725,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(64, 1, 1)",0,7.5,Source Counters,Branch Instructions Ratio,%,0.08,,,,,
0,47725,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(64, 1, 1)",0,7.5,Source Counters,Branch Instructions,inst,128,,,,,
0,47725,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(64, 1, 1)",0,7.5,Source Counters,Branch Efficiency,%,0,,,,,
0,47725,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(64, 1, 1)",0,7.5,Source Counters,Avg. Divergent Branches,,0,,,,,
0,47809,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(32, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Frequency,cycle/second,"5,611,940,298.51",,,,,
0,47809,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(32, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Frequency,cycle/second,"1,279,384,328.36",,,,,
0,47809,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(32, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Elapsed Cycles,cycle,"2,746",,,,,
0,47809,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(32, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Memory Throughput,%,8.55,,,,,
0,47809,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(32, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Throughput,%,8.55,,,,,
0,47809,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(32, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Duration,nsecond,"2,144",,,,,
0,47809,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(32, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L1/TEX Cache Throughput,%,5.48,,,,,
0,47809,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(32, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L2 Cache Throughput,%,8.14,,,,,
0,47809,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(32, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Active Cycles,cycle,"1,334",,,,,
0,47809,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(32, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Compute (SM) Throughput,%,2.67,,,,,
0,47809,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(32, 1, 1)",0,7.5,SpeedOfLight,,,,SOLBottleneck,OPT,"This kernel grid is too small to fill the available resources on this device, resulting in only 0.3 full waves across all SMs. Look at Launch Statistics for more details.",,
0,47809,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(32, 1, 1)",0,7.5,SpeedOfLight_RooflineChart,,,,SOLFPRoofline,INF,The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved  close to 0% of this device's fp32 peak performance and 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.,,
0,47809,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(32, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Active,inst/cycle,0.09,,,,,
0,47809,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(32, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Elapsed,inst/cycle,0.04,,,,,
0,47809,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(32, 1, 1)",0,7.5,Compute Workload Analysis,Issue Slots Busy,%,2.91,,,,,
0,47809,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(32, 1, 1)",0,7.5,Compute Workload Analysis,Issued Ipc Active,inst/cycle,0.12,,,,,
0,47809,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(32, 1, 1)",0,7.5,Compute Workload Analysis,SM Busy,%,2.91,,,,,
0,47809,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(32, 1, 1)",0,7.5,ComputeWorkloadAnalysis,,,,HighPipeUtilization,OPT,All compute pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.,local,98.29
0,47809,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(32, 1, 1)",0,7.5,Memory Workload Analysis,Memory Throughput,byte/second,"15,358,208,955.22",,,,,
0,47809,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(32, 1, 1)",0,7.5,Memory Workload Analysis,Mem Busy,%,8.14,,,,,
0,47809,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(32, 1, 1)",0,7.5,Memory Workload Analysis,Max Bandwidth,%,8.55,,,,,
0,47809,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(32, 1, 1)",0,7.5,Memory Workload Analysis,L1/TEX Hit Rate,%,0,,,,,
0,47809,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(32, 1, 1)",0,7.5,Memory Workload Analysis,L2 Hit Rate,%,40.96,,,,,
0,47809,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(32, 1, 1)",0,7.5,Memory Workload Analysis,Mem Pipes Busy,%,2.67,,,,,
0,47809,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(32, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Chart,,,,MemoryL2Compression,WRN,The optional metric lts__average_gcomp_input_sector_success_rate.pct could not be found. Collecting it as an additional metric could enable the rule to provide more guidance.,,
0,47809,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(32, 1, 1)",0,7.5,Scheduler Statistics,One or More Eligible,%,3.06,,,,,
0,47809,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(32, 1, 1)",0,7.5,Scheduler Statistics,Issued Warp Per Scheduler,,0.03,,,,,
0,47809,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(32, 1, 1)",0,7.5,Scheduler Statistics,No Eligible,%,96.94,,,,,
0,47809,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(32, 1, 1)",0,7.5,Scheduler Statistics,Active Warps Per Scheduler,warp,2.20,,,,,
0,47809,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(32, 1, 1)",0,7.5,Scheduler Statistics,Eligible Warps Per Scheduler,warp,0.03,,,,,
0,47809,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(32, 1, 1)",0,7.5,SchedulerStats,,,,IssueSlotUtilization,OPT,"Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 32.7 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of 2.20 active warps per scheduler, but only an average of 0.03 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections.",local,91.45
0,47809,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(32, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Issued Instruction,cycle,71.81,,,,,
0,47809,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(32, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Executed Instruction,cycle,93.90,,,,,
0,47809,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(32, 1, 1)",0,7.5,Warp State Statistics,Avg. Active Threads Per Warp,,32,,,,,
0,47809,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(32, 1, 1)",0,7.5,Warp State Statistics,Avg. Not Predicated Off Threads Per Warp,,32,,,,,
0,47809,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(32, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,OPT,"On average, each warp of this kernel spends 33.6 cycles being stalled waiting for an immediate constant cache (IMC) miss. A read from constant memory costs one memory read from device memory only on a cache miss; otherwise, it just costs one read from the constant cache. Immediate constants are encoded into the SASS instruction as 'c[bank][offset]'. Accesses to different addresses by threads within a warp are serialized, thus the cost scales linearly with the number of unique addresses read by all threads within a warp. As such, the constant cache is best when threads in the same warp access only a few distinct locations. If all threads of a warp access the same location, then constant memory can be as fast as a register access. This stall type represents about 46.9% of the total average of 71.8 cycles between issuing two instructions.",global,46.86
0,47809,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(32, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,OPT,"On average, each warp of this kernel spends 31.5 cycles being stalled waiting for a scoreboard dependency on a L1TEX (local, global, surface, texture) operation. Find the instruction producing the data being waited upon to identify the culprit. To reduce the number of cycles waiting on L1TEX data accesses verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit rates by increasing data locality (coalescing), or by changing the cache configuration. Consider moving frequently used data to shared memory. This stall type represents about 43.8% of the total average of 71.8 cycles between issuing two instructions.",global,43.85
0,47809,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(32, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,INF,Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.,,
0,47809,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(32, 1, 1)",0,7.5,Instruction Statistics,Avg. Executed Instructions Per Scheduler,inst,29.71,,,,,
0,47809,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(32, 1, 1)",0,7.5,Instruction Statistics,Executed Instructions,inst,"1,664",,,,,
0,47809,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(32, 1, 1)",0,7.5,Instruction Statistics,Avg. Issued Instructions Per Scheduler,inst,38.86,,,,,
0,47809,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(32, 1, 1)",0,7.5,Instruction Statistics,Issued Instructions,inst,"2,176",,,,,
0,47809,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(32, 1, 1)",0,7.5,InstructionStats,,,,FPInstructions,OPT,"This kernel executes 0 fused and 128 non-fused FP32 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP32 performance could be increased by up to 50% (relative to its current performance). Check the Source page to identify where this kernel executes FP32 instructions.",global,0.8567
0,47809,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(32, 1, 1)",0,7.5,Launch Statistics,Block Size,,128,,,,,
0,47809,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(32, 1, 1)",0,7.5,Launch Statistics,Function Cache Configuration,,CachePreferNone,,,,,
0,47809,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(32, 1, 1)",0,7.5,Launch Statistics,Grid Size,,32,,,,,
0,47809,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(32, 1, 1)",0,7.5,Launch Statistics,Registers Per Thread,register/thread,16,,,,,
0,47809,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(32, 1, 1)",0,7.5,Launch Statistics,Shared Memory Configuration Size,byte,"32,768",,,,,
0,47809,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(32, 1, 1)",0,7.5,Launch Statistics,Driver Shared Memory Per Block,byte/block,0,,,,,
0,47809,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(32, 1, 1)",0,7.5,Launch Statistics,Dynamic Shared Memory Per Block,byte/block,0,,,,,
0,47809,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(32, 1, 1)",0,7.5,Launch Statistics,Static Shared Memory Per Block,byte/block,0,,,,,
0,47809,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(32, 1, 1)",0,7.5,Launch Statistics,Threads,thread,"4,096",,,,,
0,47809,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(32, 1, 1)",0,7.5,Launch Statistics,Waves Per SM,,0.29,,,,,
0,47809,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(32, 1, 1)",0,7.5,Occupancy,Block Limit SM,block,16,,,,,
0,47809,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(32, 1, 1)",0,7.5,Occupancy,Block Limit Registers,block,32,,,,,
0,47809,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(32, 1, 1)",0,7.5,Occupancy,Block Limit Shared Mem,block,16,,,,,
0,47809,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(32, 1, 1)",0,7.5,Occupancy,Block Limit Warps,block,8,,,,,
0,47809,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(32, 1, 1)",0,7.5,Occupancy,Theoretical Active Warps per SM,warp,32,,,,,
0,47809,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(32, 1, 1)",0,7.5,Occupancy,Theoretical Occupancy,%,100,,,,,
0,47809,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(32, 1, 1)",0,7.5,Occupancy,Achieved Occupancy,%,27.43,,,,,
0,47809,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(32, 1, 1)",0,7.5,Occupancy,Achieved Active Warps Per SM,warp,8.78,,,,,
0,47809,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(32, 1, 1)",0,7.5,Occupancy,,,,AchievedOccupancy,OPT,The difference between calculated theoretical (100.0%) and measured achieved occupancy (27.4%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy.,global,72.57
0,47809,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(32, 1, 1)",0,7.5,Source Counters,Branch Instructions Ratio,%,0.08,,,,,
0,47809,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(32, 1, 1)",0,7.5,Source Counters,Branch Instructions,inst,128,,,,,
0,47809,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(32, 1, 1)",0,7.5,Source Counters,Branch Efficiency,%,0,,,,,
0,47809,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(32, 1, 1)",0,7.5,Source Counters,Avg. Divergent Branches,,0,,,,,
0,47886,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(16, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Frequency,cycle/second,"5,373,134,328.36",,,,,
0,47886,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(16, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Frequency,cycle/second,"1,230,177,238.81",,,,,
0,47886,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(16, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Elapsed Cycles,cycle,"2,640",,,,,
0,47886,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(16, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Memory Throughput,%,8.93,,,,,
0,47886,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(16, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Throughput,%,8.93,,,,,
0,47886,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(16, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Duration,nsecond,"2,144",,,,,
0,47886,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(16, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L1/TEX Cache Throughput,%,5.70,,,,,
0,47886,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(16, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L2 Cache Throughput,%,8.39,,,,,
0,47886,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(16, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Active Cycles,cycle,"1,283.64",,,,,
0,47886,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(16, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Compute (SM) Throughput,%,2.77,,,,,
0,47886,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(16, 1, 1)",0,7.5,SpeedOfLight,,,,SOLBottleneck,OPT,"This kernel grid is too small to fill the available resources on this device, resulting in only 0.3 full waves across all SMs. Look at Launch Statistics for more details.",,
0,47886,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(16, 1, 1)",0,7.5,SpeedOfLight_RooflineChart,,,,SOLFPRoofline,INF,The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved  close to 0% of this device's fp32 peak performance and 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.,,
0,47886,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(16, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Active,inst/cycle,0.09,,,,,
0,47886,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(16, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Elapsed,inst/cycle,0.05,,,,,
0,47886,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(16, 1, 1)",0,7.5,Compute Workload Analysis,Issue Slots Busy,%,3.03,,,,,
0,47886,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(16, 1, 1)",0,7.5,Compute Workload Analysis,Issued Ipc Active,inst/cycle,0.12,,,,,
0,47886,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(16, 1, 1)",0,7.5,Compute Workload Analysis,SM Busy,%,3.03,,,,,
0,47886,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(16, 1, 1)",0,7.5,ComputeWorkloadAnalysis,,,,HighPipeUtilization,OPT,All compute pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.,local,98.22
0,47886,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(16, 1, 1)",0,7.5,Memory Workload Analysis,Memory Throughput,byte/second,"15,358,208,955.22",,,,,
0,47886,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(16, 1, 1)",0,7.5,Memory Workload Analysis,Mem Busy,%,8.39,,,,,
0,47886,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(16, 1, 1)",0,7.5,Memory Workload Analysis,Max Bandwidth,%,8.93,,,,,
0,47886,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(16, 1, 1)",0,7.5,Memory Workload Analysis,L1/TEX Hit Rate,%,0,,,,,
0,47886,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(16, 1, 1)",0,7.5,Memory Workload Analysis,L2 Hit Rate,%,40.31,,,,,
0,47886,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(16, 1, 1)",0,7.5,Memory Workload Analysis,Mem Pipes Busy,%,2.77,,,,,
0,47886,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(16, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Chart,,,,MemoryL2Compression,WRN,The optional metric lts__average_gcomp_input_sector_success_rate.pct could not be found. Collecting it as an additional metric could enable the rule to provide more guidance.,,
0,47886,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(16, 1, 1)",0,7.5,Scheduler Statistics,One or More Eligible,%,3.13,,,,,
0,47886,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(16, 1, 1)",0,7.5,Scheduler Statistics,Issued Warp Per Scheduler,,0.03,,,,,
0,47886,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(16, 1, 1)",0,7.5,Scheduler Statistics,No Eligible,%,96.87,,,,,
0,47886,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(16, 1, 1)",0,7.5,Scheduler Statistics,Active Warps Per Scheduler,warp,2.29,,,,,
0,47886,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(16, 1, 1)",0,7.5,Scheduler Statistics,Eligible Warps Per Scheduler,warp,0.03,,,,,
0,47886,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(16, 1, 1)",0,7.5,SchedulerStats,,,,IssueSlotUtilization,OPT,"Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 32.0 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of 2.29 active warps per scheduler, but only an average of 0.03 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections.",local,91.07
0,47886,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(16, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Issued Instruction,cycle,73.11,,,,,
0,47886,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(16, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Executed Instruction,cycle,95.61,,,,,
0,47886,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(16, 1, 1)",0,7.5,Warp State Statistics,Avg. Active Threads Per Warp,,32,,,,,
0,47886,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(16, 1, 1)",0,7.5,Warp State Statistics,Avg. Not Predicated Off Threads Per Warp,,32,,,,,
0,47886,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(16, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,OPT,"On average, each warp of this kernel spends 33.9 cycles being stalled waiting for an immediate constant cache (IMC) miss. A read from constant memory costs one memory read from device memory only on a cache miss; otherwise, it just costs one read from the constant cache. Immediate constants are encoded into the SASS instruction as 'c[bank][offset]'. Accesses to different addresses by threads within a warp are serialized, thus the cost scales linearly with the number of unique addresses read by all threads within a warp. As such, the constant cache is best when threads in the same warp access only a few distinct locations. If all threads of a warp access the same location, then constant memory can be as fast as a register access. This stall type represents about 46.4% of the total average of 73.1 cycles between issuing two instructions.",global,46.38
0,47886,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(16, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,OPT,"On average, each warp of this kernel spends 30.7 cycles being stalled waiting for a scoreboard dependency on a L1TEX (local, global, surface, texture) operation. Find the instruction producing the data being waited upon to identify the culprit. To reduce the number of cycles waiting on L1TEX data accesses verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit rates by increasing data locality (coalescing), or by changing the cache configuration. Consider moving frequently used data to shared memory. This stall type represents about 42.0% of the total average of 73.1 cycles between issuing two instructions.",global,41.99
0,47886,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(16, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,INF,Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.,,
0,47886,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(16, 1, 1)",0,7.5,Instruction Statistics,Avg. Executed Instructions Per Scheduler,inst,29.71,,,,,
0,47886,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(16, 1, 1)",0,7.5,Instruction Statistics,Executed Instructions,inst,"1,664",,,,,
0,47886,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(16, 1, 1)",0,7.5,Instruction Statistics,Avg. Issued Instructions Per Scheduler,inst,38.86,,,,,
0,47886,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(16, 1, 1)",0,7.5,Instruction Statistics,Issued Instructions,inst,"2,176",,,,,
0,47886,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(16, 1, 1)",0,7.5,InstructionStats,,,,FPInstructions,OPT,"This kernel executes 0 fused and 128 non-fused FP32 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP32 performance could be increased by up to 50% (relative to its current performance). Check the Source page to identify where this kernel executes FP32 instructions.",global,0.8903
0,47886,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(16, 1, 1)",0,7.5,Launch Statistics,Block Size,,256,,,,,
0,47886,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(16, 1, 1)",0,7.5,Launch Statistics,Function Cache Configuration,,CachePreferNone,,,,,
0,47886,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(16, 1, 1)",0,7.5,Launch Statistics,Grid Size,,16,,,,,
0,47886,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(16, 1, 1)",0,7.5,Launch Statistics,Registers Per Thread,register/thread,16,,,,,
0,47886,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(16, 1, 1)",0,7.5,Launch Statistics,Shared Memory Configuration Size,byte,"32,768",,,,,
0,47886,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(16, 1, 1)",0,7.5,Launch Statistics,Driver Shared Memory Per Block,byte/block,0,,,,,
0,47886,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(16, 1, 1)",0,7.5,Launch Statistics,Dynamic Shared Memory Per Block,byte/block,0,,,,,
0,47886,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(16, 1, 1)",0,7.5,Launch Statistics,Static Shared Memory Per Block,byte/block,0,,,,,
0,47886,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(16, 1, 1)",0,7.5,Launch Statistics,Threads,thread,"4,096",,,,,
0,47886,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(16, 1, 1)",0,7.5,Launch Statistics,Waves Per SM,,0.29,,,,,
0,47886,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(16, 1, 1)",0,7.5,LaunchStats,,,,LaunchConfiguration,OPT,"If you execute __syncthreads() to synchronize the threads of a block, it is recommended to have more than the achieved 1 blocks per multiprocessor. This way, blocks that aren't waiting for __syncthreads() can keep the hardware busy.",,
0,47886,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(16, 1, 1)",0,7.5,Occupancy,Block Limit SM,block,16,,,,,
0,47886,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(16, 1, 1)",0,7.5,Occupancy,Block Limit Registers,block,16,,,,,
0,47886,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(16, 1, 1)",0,7.5,Occupancy,Block Limit Shared Mem,block,16,,,,,
0,47886,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(16, 1, 1)",0,7.5,Occupancy,Block Limit Warps,block,4,,,,,
0,47886,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(16, 1, 1)",0,7.5,Occupancy,Theoretical Active Warps per SM,warp,32,,,,,
0,47886,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(16, 1, 1)",0,7.5,Occupancy,Theoretical Occupancy,%,100,,,,,
0,47886,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(16, 1, 1)",0,7.5,Occupancy,Achieved Occupancy,%,27.83,,,,,
0,47886,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(16, 1, 1)",0,7.5,Occupancy,Achieved Active Warps Per SM,warp,8.91,,,,,
0,47886,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(16, 1, 1)",0,7.5,Occupancy,,,,AchievedOccupancy,OPT,The difference between calculated theoretical (100.0%) and measured achieved occupancy (27.8%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy.,global,72.17
0,47886,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(16, 1, 1)",0,7.5,Source Counters,Branch Instructions Ratio,%,0.08,,,,,
0,47886,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(16, 1, 1)",0,7.5,Source Counters,Branch Instructions,inst,128,,,,,
0,47886,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(16, 1, 1)",0,7.5,Source Counters,Branch Efficiency,%,0,,,,,
0,47886,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(16, 1, 1)",0,7.5,Source Counters,Avg. Divergent Branches,,0,,,,,
0,47972,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(8, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Frequency,cycle/second,"3,485,148,514.85",,,,,
0,47972,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(8, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Frequency,cycle/second,"808,323,019.80",,,,,
0,47972,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(8, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Elapsed Cycles,cycle,"2,615",,,,,
0,47972,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(8, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Memory Throughput,%,9.14,,,,,
0,47972,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(8, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Throughput,%,9.14,,,,,
0,47972,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(8, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Duration,nsecond,"3,232",,,,,
0,47972,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(8, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L1/TEX Cache Throughput,%,9.41,,,,,
0,47972,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(8, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L2 Cache Throughput,%,8.53,,,,,
0,47972,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(8, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Active Cycles,cycle,776.93,,,,,
0,47972,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(8, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Compute (SM) Throughput,%,2.80,,,,,
0,47972,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(8, 1, 1)",0,7.5,SpeedOfLight,,,,SOLBottleneck,OPT,"This kernel grid is too small to fill the available resources on this device, resulting in only 0.3 full waves across all SMs. Look at Launch Statistics for more details.",,
0,47972,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(8, 1, 1)",0,7.5,SpeedOfLight_RooflineChart,,,,SOLFPRoofline,INF,The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved  close to 0% of this device's fp32 peak performance and 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.,,
0,47972,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(8, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Active,inst/cycle,0.15,,,,,
0,47972,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(8, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Elapsed,inst/cycle,0.05,,,,,
0,47972,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(8, 1, 1)",0,7.5,Compute Workload Analysis,Issue Slots Busy,%,5.00,,,,,
0,47972,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(8, 1, 1)",0,7.5,Compute Workload Analysis,Issued Ipc Active,inst/cycle,0.20,,,,,
0,47972,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(8, 1, 1)",0,7.5,Compute Workload Analysis,SM Busy,%,5.00,,,,,
0,47972,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(8, 1, 1)",0,7.5,ComputeWorkloadAnalysis,,,,HighPipeUtilization,OPT,All compute pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.,local,97.06
0,47972,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(8, 1, 1)",0,7.5,Memory Workload Analysis,Memory Throughput,byte/second,"10,188,118,811.88",,,,,
0,47972,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(8, 1, 1)",0,7.5,Memory Workload Analysis,Mem Busy,%,8.53,,,,,
0,47972,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(8, 1, 1)",0,7.5,Memory Workload Analysis,Max Bandwidth,%,9.14,,,,,
0,47972,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(8, 1, 1)",0,7.5,Memory Workload Analysis,L1/TEX Hit Rate,%,0,,,,,
0,47972,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(8, 1, 1)",0,7.5,Memory Workload Analysis,L2 Hit Rate,%,40.96,,,,,
0,47972,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(8, 1, 1)",0,7.5,Memory Workload Analysis,Mem Pipes Busy,%,2.80,,,,,
0,47972,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(8, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Chart,,,,MemoryL2Compression,WRN,The optional metric lts__average_gcomp_input_sector_success_rate.pct could not be found. Collecting it as an additional metric could enable the rule to provide more guidance.,,
0,47972,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(8, 1, 1)",0,7.5,Scheduler Statistics,One or More Eligible,%,5.18,,,,,
0,47972,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(8, 1, 1)",0,7.5,Scheduler Statistics,Issued Warp Per Scheduler,,0.05,,,,,
0,47972,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(8, 1, 1)",0,7.5,Scheduler Statistics,No Eligible,%,94.82,,,,,
0,47972,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(8, 1, 1)",0,7.5,Scheduler Statistics,Active Warps Per Scheduler,warp,3.73,,,,,
0,47972,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(8, 1, 1)",0,7.5,Scheduler Statistics,Eligible Warps Per Scheduler,warp,0.07,,,,,
0,47972,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(8, 1, 1)",0,7.5,SchedulerStats,,,,IssueSlotUtilization,OPT,"Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 19.3 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of 3.73 active warps per scheduler, but only an average of 0.07 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections.",local,90.86
0,47972,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(8, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Issued Instruction,cycle,72.05,,,,,
0,47972,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(8, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Executed Instruction,cycle,94.22,,,,,
0,47972,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(8, 1, 1)",0,7.5,Warp State Statistics,Avg. Active Threads Per Warp,,32,,,,,
0,47972,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(8, 1, 1)",0,7.5,Warp State Statistics,Avg. Not Predicated Off Threads Per Warp,,32,,,,,
0,47972,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(8, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,OPT,"On average, each warp of this kernel spends 33.3 cycles being stalled waiting for an immediate constant cache (IMC) miss. A read from constant memory costs one memory read from device memory only on a cache miss; otherwise, it just costs one read from the constant cache. Immediate constants are encoded into the SASS instruction as 'c[bank][offset]'. Accesses to different addresses by threads within a warp are serialized, thus the cost scales linearly with the number of unique addresses read by all threads within a warp. As such, the constant cache is best when threads in the same warp access only a few distinct locations. If all threads of a warp access the same location, then constant memory can be as fast as a register access. This stall type represents about 46.2% of the total average of 72.1 cycles between issuing two instructions.",global,46.15
0,47972,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(8, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,OPT,"On average, each warp of this kernel spends 31.2 cycles being stalled waiting for a scoreboard dependency on a L1TEX (local, global, surface, texture) operation. Find the instruction producing the data being waited upon to identify the culprit. To reduce the number of cycles waiting on L1TEX data accesses verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit rates by increasing data locality (coalescing), or by changing the cache configuration. Consider moving frequently used data to shared memory. This stall type represents about 43.3% of the total average of 72.1 cycles between issuing two instructions.",global,43.35
0,47972,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(8, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,INF,Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.,,
0,47972,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(8, 1, 1)",0,7.5,Instruction Statistics,Avg. Executed Instructions Per Scheduler,inst,29.71,,,,,
0,47972,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(8, 1, 1)",0,7.5,Instruction Statistics,Executed Instructions,inst,"1,664",,,,,
0,47972,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(8, 1, 1)",0,7.5,Instruction Statistics,Avg. Issued Instructions Per Scheduler,inst,38.86,,,,,
0,47972,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(8, 1, 1)",0,7.5,Instruction Statistics,Issued Instructions,inst,"2,176",,,,,
0,47972,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(8, 1, 1)",0,7.5,InstructionStats,,,,FPInstructions,OPT,"This kernel executes 0 fused and 128 non-fused FP32 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP32 performance could be increased by up to 50% (relative to its current performance). Check the Source page to identify where this kernel executes FP32 instructions.",global,1.471
0,47972,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(8, 1, 1)",0,7.5,Launch Statistics,Block Size,,512,,,,,
0,47972,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(8, 1, 1)",0,7.5,Launch Statistics,Function Cache Configuration,,CachePreferNone,,,,,
0,47972,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(8, 1, 1)",0,7.5,Launch Statistics,Grid Size,,8,,,,,
0,47972,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(8, 1, 1)",0,7.5,Launch Statistics,Registers Per Thread,register/thread,16,,,,,
0,47972,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(8, 1, 1)",0,7.5,Launch Statistics,Shared Memory Configuration Size,byte,"32,768",,,,,
0,47972,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(8, 1, 1)",0,7.5,Launch Statistics,Driver Shared Memory Per Block,byte/block,0,,,,,
0,47972,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(8, 1, 1)",0,7.5,Launch Statistics,Dynamic Shared Memory Per Block,byte/block,0,,,,,
0,47972,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(8, 1, 1)",0,7.5,Launch Statistics,Static Shared Memory Per Block,byte/block,0,,,,,
0,47972,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(8, 1, 1)",0,7.5,Launch Statistics,Threads,thread,"4,096",,,,,
0,47972,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(8, 1, 1)",0,7.5,Launch Statistics,Waves Per SM,,0.29,,,,,
0,47972,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(8, 1, 1)",0,7.5,LaunchStats,,,,LaunchConfiguration,OPT,"The grid for this launch is configured to execute only 8 blocks, which is less than the GPU's 14 multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel concurrently with other workloads, consider reducing the block size to have at least one block per multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations.",global,42.86
0,47972,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(8, 1, 1)",0,7.5,Occupancy,Block Limit SM,block,16,,,,,
0,47972,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(8, 1, 1)",0,7.5,Occupancy,Block Limit Registers,block,8,,,,,
0,47972,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(8, 1, 1)",0,7.5,Occupancy,Block Limit Shared Mem,block,16,,,,,
0,47972,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(8, 1, 1)",0,7.5,Occupancy,Block Limit Warps,block,2,,,,,
0,47972,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(8, 1, 1)",0,7.5,Occupancy,Theoretical Active Warps per SM,warp,32,,,,,
0,47972,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(8, 1, 1)",0,7.5,Occupancy,Theoretical Occupancy,%,100,,,,,
0,47972,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(8, 1, 1)",0,7.5,Occupancy,Achieved Occupancy,%,46.88,,,,,
0,47972,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(8, 1, 1)",0,7.5,Occupancy,Achieved Active Warps Per SM,warp,15.00,,,,,
0,47972,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(8, 1, 1)",0,7.5,Occupancy,,,,AchievedOccupancy,OPT,The difference between calculated theoretical (100.0%) and measured achieved occupancy (46.9%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy.,global,53.12
0,47972,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(8, 1, 1)",0,7.5,Source Counters,Branch Instructions Ratio,%,0.08,,,,,
0,47972,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(8, 1, 1)",0,7.5,Source Counters,Branch Instructions,inst,128,,,,,
0,47972,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(8, 1, 1)",0,7.5,Source Counters,Branch Efficiency,%,0,,,,,
0,47972,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(8, 1, 1)",0,7.5,Source Counters,Avg. Divergent Branches,,0,,,,,
0,48049,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(4, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Frequency,cycle/second,"5,333,333,333.33",,,,,
0,48049,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(4, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Frequency,cycle/second,"1,226,449,275.36",,,,,
0,48049,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(4, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Elapsed Cycles,cycle,"2,711",,,,,
0,48049,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(4, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Memory Throughput,%,8.74,,,,,
0,48049,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(4, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Throughput,%,8.74,,,,,
0,48049,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(4, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Duration,nsecond,"2,208",,,,,
0,48049,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(4, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L1/TEX Cache Throughput,%,18.17,,,,,
0,48049,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(4, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L2 Cache Throughput,%,8.13,,,,,
0,48049,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(4, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Active Cycles,cycle,402.64,,,,,
0,48049,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(4, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Compute (SM) Throughput,%,2.70,,,,,
0,48049,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(4, 1, 1)",0,7.5,SpeedOfLight,,,,SOLBottleneck,OPT,"This kernel grid is too small to fill the available resources on this device, resulting in only 0.3 full waves across all SMs. Look at Launch Statistics for more details.",,
0,48049,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(4, 1, 1)",0,7.5,SpeedOfLight_RooflineChart,,,,SOLFPRoofline,INF,The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved  close to 0% of this device's fp32 peak performance and 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.,,
0,48049,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(4, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Active,inst/cycle,0.30,,,,,
0,48049,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(4, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Elapsed,inst/cycle,0.04,,,,,
0,48049,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(4, 1, 1)",0,7.5,Compute Workload Analysis,Issue Slots Busy,%,9.65,,,,,
0,48049,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(4, 1, 1)",0,7.5,Compute Workload Analysis,Issued Ipc Active,inst/cycle,0.39,,,,,
0,48049,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(4, 1, 1)",0,7.5,Compute Workload Analysis,SM Busy,%,9.65,,,,,
0,48049,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(4, 1, 1)",0,7.5,ComputeWorkloadAnalysis,,,,HighPipeUtilization,OPT,All compute pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.,local,94.32
0,48049,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(4, 1, 1)",0,7.5,Memory Workload Analysis,Memory Throughput,byte/second,"14,913,043,478.26",,,,,
0,48049,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(4, 1, 1)",0,7.5,Memory Workload Analysis,Mem Busy,%,8.13,,,,,
0,48049,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(4, 1, 1)",0,7.5,Memory Workload Analysis,Max Bandwidth,%,8.74,,,,,
0,48049,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(4, 1, 1)",0,7.5,Memory Workload Analysis,L1/TEX Hit Rate,%,0,,,,,
0,48049,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(4, 1, 1)",0,7.5,Memory Workload Analysis,L2 Hit Rate,%,39.17,,,,,
0,48049,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(4, 1, 1)",0,7.5,Memory Workload Analysis,Mem Pipes Busy,%,2.70,,,,,
0,48049,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(4, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Chart,,,,MemoryL2Compression,WRN,The optional metric lts__average_gcomp_input_sector_success_rate.pct could not be found. Collecting it as an additional metric could enable the rule to provide more guidance.,,
0,48049,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(4, 1, 1)",0,7.5,Scheduler Statistics,One or More Eligible,%,10.04,,,,,
0,48049,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(4, 1, 1)",0,7.5,Scheduler Statistics,Issued Warp Per Scheduler,,0.10,,,,,
0,48049,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(4, 1, 1)",0,7.5,Scheduler Statistics,No Eligible,%,89.96,,,,,
0,48049,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(4, 1, 1)",0,7.5,Scheduler Statistics,Active Warps Per Scheduler,warp,7.40,,,,,
0,48049,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(4, 1, 1)",0,7.5,Scheduler Statistics,Eligible Warps Per Scheduler,warp,0.20,,,,,
0,48049,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(4, 1, 1)",0,7.5,SchedulerStats,,,,IssueSlotUtilization,OPT,"Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 10.0 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of 7.40 active warps per scheduler, but only an average of 0.20 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, avoid possible load imbalances due to highly different execution durations per warp. Reducing stalls indicated on the Warp State Statistics and Source Counters sections can help, too.",local,89.96
0,48049,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(4, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Issued Instruction,cycle,73.75,,,,,
0,48049,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(4, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Executed Instruction,cycle,96.44,,,,,
0,48049,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(4, 1, 1)",0,7.5,Warp State Statistics,Avg. Active Threads Per Warp,,32,,,,,
0,48049,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(4, 1, 1)",0,7.5,Warp State Statistics,Avg. Not Predicated Off Threads Per Warp,,32,,,,,
0,48049,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(4, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,OPT,"On average, each warp of this kernel spends 31.3 cycles being stalled waiting for an immediate constant cache (IMC) miss. A read from constant memory costs one memory read from device memory only on a cache miss; otherwise, it just costs one read from the constant cache. Immediate constants are encoded into the SASS instruction as 'c[bank][offset]'. Accesses to different addresses by threads within a warp are serialized, thus the cost scales linearly with the number of unique addresses read by all threads within a warp. As such, the constant cache is best when threads in the same warp access only a few distinct locations. If all threads of a warp access the same location, then constant memory can be as fast as a register access. This stall type represents about 42.4% of the total average of 73.7 cycles between issuing two instructions.",global,42.44
0,48049,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(4, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,OPT,"On average, each warp of this kernel spends 30.7 cycles being stalled waiting for a scoreboard dependency on a L1TEX (local, global, surface, texture) operation. Find the instruction producing the data being waited upon to identify the culprit. To reduce the number of cycles waiting on L1TEX data accesses verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit rates by increasing data locality (coalescing), or by changing the cache configuration. Consider moving frequently used data to shared memory. This stall type represents about 41.7% of the total average of 73.7 cycles between issuing two instructions.",global,41.68
0,48049,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(4, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,INF,Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.,,
0,48049,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(4, 1, 1)",0,7.5,Instruction Statistics,Avg. Executed Instructions Per Scheduler,inst,29.71,,,,,
0,48049,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(4, 1, 1)",0,7.5,Instruction Statistics,Executed Instructions,inst,"1,664",,,,,
0,48049,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(4, 1, 1)",0,7.5,Instruction Statistics,Avg. Issued Instructions Per Scheduler,inst,38.86,,,,,
0,48049,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(4, 1, 1)",0,7.5,Instruction Statistics,Issued Instructions,inst,"2,176",,,,,
0,48049,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(4, 1, 1)",0,7.5,InstructionStats,,,,FPInstructions,OPT,"This kernel executes 0 fused and 128 non-fused FP32 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP32 performance could be increased by up to 50% (relative to its current performance). Check the Source page to identify where this kernel executes FP32 instructions.",global,2.838
0,48049,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(4, 1, 1)",0,7.5,Launch Statistics,Block Size,,"1,024",,,,,
0,48049,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(4, 1, 1)",0,7.5,Launch Statistics,Function Cache Configuration,,CachePreferNone,,,,,
0,48049,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(4, 1, 1)",0,7.5,Launch Statistics,Grid Size,,4,,,,,
0,48049,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(4, 1, 1)",0,7.5,Launch Statistics,Registers Per Thread,register/thread,16,,,,,
0,48049,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(4, 1, 1)",0,7.5,Launch Statistics,Shared Memory Configuration Size,byte,"32,768",,,,,
0,48049,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(4, 1, 1)",0,7.5,Launch Statistics,Driver Shared Memory Per Block,byte/block,0,,,,,
0,48049,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(4, 1, 1)",0,7.5,Launch Statistics,Dynamic Shared Memory Per Block,byte/block,0,,,,,
0,48049,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(4, 1, 1)",0,7.5,Launch Statistics,Static Shared Memory Per Block,byte/block,0,,,,,
0,48049,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(4, 1, 1)",0,7.5,Launch Statistics,Threads,thread,"4,096",,,,,
0,48049,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(4, 1, 1)",0,7.5,Launch Statistics,Waves Per SM,,0.29,,,,,
0,48049,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(4, 1, 1)",0,7.5,LaunchStats,,,,LaunchConfiguration,OPT,"The grid for this launch is configured to execute only 4 blocks, which is less than the GPU's 14 multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel concurrently with other workloads, consider reducing the block size to have at least one block per multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations.",global,71.43
0,48049,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(4, 1, 1)",0,7.5,Occupancy,Block Limit SM,block,16,,,,,
0,48049,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(4, 1, 1)",0,7.5,Occupancy,Block Limit Registers,block,4,,,,,
0,48049,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(4, 1, 1)",0,7.5,Occupancy,Block Limit Shared Mem,block,16,,,,,
0,48049,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(4, 1, 1)",0,7.5,Occupancy,Block Limit Warps,block,1,,,,,
0,48049,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(4, 1, 1)",0,7.5,Occupancy,Theoretical Active Warps per SM,warp,32,,,,,
0,48049,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(4, 1, 1)",0,7.5,Occupancy,Theoretical Occupancy,%,100,,,,,
0,48049,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(4, 1, 1)",0,7.5,Occupancy,Achieved Occupancy,%,92.01,,,,,
0,48049,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(4, 1, 1)",0,7.5,Occupancy,Achieved Active Warps Per SM,warp,29.44,,,,,
0,48049,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(4, 1, 1)",0,7.5,Source Counters,Branch Instructions Ratio,%,0.08,,,,,
0,48049,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(4, 1, 1)",0,7.5,Source Counters,Branch Instructions,inst,128,,,,,
0,48049,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(4, 1, 1)",0,7.5,Source Counters,Branch Efficiency,%,0,,,,,
0,48049,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(4, 1, 1)",0,7.5,Source Counters,Avg. Divergent Branches,,0,,,,,
0,48143,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(8192, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Frequency,cycle/second,"6,080,947,680.16",,,,,
0,48143,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(8192, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Frequency,cycle/second,"1,399,802,566.63",,,,,
0,48143,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(8192, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Elapsed Cycles,cycle,"45,428",,,,,
0,48143,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(8192, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Memory Throughput,%,10.31,,,,,
0,48143,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(8192, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Throughput,%,1.04,,,,,
0,48143,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(8192, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Duration,nsecond,"32,416",,,,,
0,48143,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(8192, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L1/TEX Cache Throughput,%,15.10,,,,,
0,48143,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(8192, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L2 Cache Throughput,%,7.96,,,,,
0,48143,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(8192, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Active Cycles,cycle,"31,009.71",,,,,
0,48143,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(8192, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Compute (SM) Throughput,%,10.31,,,,,
0,48143,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(8192, 1, 1)",0,7.5,SpeedOfLight,,,,SOLBottleneck,OPT,This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.,,
0,48143,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(8192, 1, 1)",0,7.5,SpeedOfLight_RooflineChart,,,,SOLFPRoofline,INF,The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved  close to 0% of this device's fp32 peak performance and 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.,,
0,48143,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(8192, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Active,inst/cycle,0.25,,,,,
0,48143,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(8192, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Elapsed,inst/cycle,0.17,,,,,
0,48143,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(8192, 1, 1)",0,7.5,Compute Workload Analysis,Issue Slots Busy,%,6.18,,,,,
0,48143,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(8192, 1, 1)",0,7.5,Compute Workload Analysis,Issued Ipc Active,inst/cycle,0.25,,,,,
0,48143,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(8192, 1, 1)",0,7.5,Compute Workload Analysis,SM Busy,%,6.29,,,,,
0,48143,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(8192, 1, 1)",0,7.5,ComputeWorkloadAnalysis,,,,HighPipeUtilization,OPT,All compute pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.,local,95.28
0,48143,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(8192, 1, 1)",0,7.5,Memory Workload Analysis,Memory Throughput,byte/second,"2,026,653,504.44",,,,,
0,48143,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(8192, 1, 1)",0,7.5,Memory Workload Analysis,Mem Busy,%,6.65,,,,,
0,48143,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(8192, 1, 1)",0,7.5,Memory Workload Analysis,Max Bandwidth,%,10.31,,,,,
0,48143,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(8192, 1, 1)",0,7.5,Memory Workload Analysis,L1/TEX Hit Rate,%,23.43,,,,,
0,48143,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(8192, 1, 1)",0,7.5,Memory Workload Analysis,L2 Hit Rate,%,94.30,,,,,
0,48143,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(8192, 1, 1)",0,7.5,Memory Workload Analysis,Mem Pipes Busy,%,10.31,,,,,
0,48143,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(8192, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Chart,,,,MemoryL2Compression,WRN,The optional metric lts__average_gcomp_input_sector_success_rate.pct could not be found. Collecting it as an additional metric could enable the rule to provide more guidance.,,
0,48143,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(8192, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for loads from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced loads and try to minimize how many cache lines need to be accessed per memory request.",global,3.266
0,48143,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(8192, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for stores from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.5 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced stores and try to minimize how many cache lines need to be accessed per memory request.",global,1.372
0,48143,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(8192, 1, 1)",0,7.5,Scheduler Statistics,One or More Eligible,%,6.72,,,,,
0,48143,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(8192, 1, 1)",0,7.5,Scheduler Statistics,Issued Warp Per Scheduler,,0.07,,,,,
0,48143,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(8192, 1, 1)",0,7.5,Scheduler Statistics,No Eligible,%,93.28,,,,,
0,48143,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(8192, 1, 1)",0,7.5,Scheduler Statistics,Active Warps Per Scheduler,warp,2.73,,,,,
0,48143,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(8192, 1, 1)",0,7.5,Scheduler Statistics,Eligible Warps Per Scheduler,warp,0.07,,,,,
0,48143,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(8192, 1, 1)",0,7.5,SchedulerStats,,,,IssueSlotUtilization,OPT,"Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 14.9 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of 2.73 active warps per scheduler, but only an average of 0.07 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections.",local,89.69
0,48143,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(8192, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Issued Instruction,cycle,40.54,,,,,
0,48143,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(8192, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Executed Instruction,cycle,40.83,,,,,
0,48143,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(8192, 1, 1)",0,7.5,Warp State Statistics,Avg. Active Threads Per Warp,,1,,,,,
0,48143,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(8192, 1, 1)",0,7.5,Warp State Statistics,Avg. Not Predicated Off Threads Per Warp,,1,,,,,
0,48143,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(8192, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,OPT,"On average, each warp of this kernel spends 30.8 cycles being stalled waiting for a scoreboard dependency on a L1TEX (local, global, surface, texture) operation. Find the instruction producing the data being waited upon to identify the culprit. To reduce the number of cycles waiting on L1TEX data accesses verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit rates by increasing data locality (coalescing), or by changing the cache configuration. Consider moving frequently used data to shared memory. This stall type represents about 75.9% of the total average of 40.5 cycles between issuing two instructions.",global,75.86
0,48143,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(8192, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,INF,Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.,,
0,48143,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(8192, 1, 1)",0,7.5,WarpStateStats,,,,ThreadDivergence,OPT,"Instructions are executed in warps, which are groups of 32 threads. Optimal instruction throughput is achieved if all 32 threads of a warp execute the same instruction. The chosen launch configuration, early thread completion, and divergent flow control can significantly lower the number of active threads in a warp per cycle. This kernel achieves an average of 1.0 threads being active per cycle.",global,9.992
0,48143,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(8192, 1, 1)",0,7.5,Instruction Statistics,Avg. Executed Instructions Per Scheduler,inst,"1,901.71",,,,,
0,48143,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(8192, 1, 1)",0,7.5,Instruction Statistics,Executed Instructions,inst,"106,496",,,,,
0,48143,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(8192, 1, 1)",0,7.5,Instruction Statistics,Avg. Issued Instructions Per Scheduler,inst,"1,915.36",,,,,
0,48143,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(8192, 1, 1)",0,7.5,Instruction Statistics,Issued Instructions,inst,"107,260",,,,,
0,48143,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(8192, 1, 1)",0,7.5,InstructionStats,,,,FPInstructions,OPT,"This kernel executes 0 fused and 8192 non-fused FP32 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP32 performance could be increased by up to 50% (relative to its current performance). Check the Source page to identify where this kernel executes FP32 instructions.",global,2.359
0,48143,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(8192, 1, 1)",0,7.5,Launch Statistics,Block Size,,1,,,,,
0,48143,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(8192, 1, 1)",0,7.5,Launch Statistics,Function Cache Configuration,,CachePreferNone,,,,,
0,48143,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(8192, 1, 1)",0,7.5,Launch Statistics,Grid Size,,"8,192",,,,,
0,48143,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(8192, 1, 1)",0,7.5,Launch Statistics,Registers Per Thread,register/thread,16,,,,,
0,48143,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(8192, 1, 1)",0,7.5,Launch Statistics,Shared Memory Configuration Size,byte,"32,768",,,,,
0,48143,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(8192, 1, 1)",0,7.5,Launch Statistics,Driver Shared Memory Per Block,byte/block,0,,,,,
0,48143,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(8192, 1, 1)",0,7.5,Launch Statistics,Dynamic Shared Memory Per Block,byte/block,0,,,,,
0,48143,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(8192, 1, 1)",0,7.5,Launch Statistics,Static Shared Memory Per Block,byte/block,0,,,,,
0,48143,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(8192, 1, 1)",0,7.5,Launch Statistics,Threads,thread,"8,192",,,,,
0,48143,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(8192, 1, 1)",0,7.5,Launch Statistics,Waves Per SM,,36.57,,,,,
0,48143,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(8192, 1, 1)",0,7.5,LaunchStats,,,,LaunchConfiguration,OPT,"Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 1 threads per block. Consequently, some threads in a warp are masked off and those hardware resources are unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256 threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to kernels that frequently call __syncthreads(). See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations.",global,96.88
0,48143,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(8192, 1, 1)",0,7.5,Occupancy,Block Limit SM,block,16,,,,,
0,48143,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(8192, 1, 1)",0,7.5,Occupancy,Block Limit Registers,block,128,,,,,
0,48143,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(8192, 1, 1)",0,7.5,Occupancy,Block Limit Shared Mem,block,16,,,,,
0,48143,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(8192, 1, 1)",0,7.5,Occupancy,Block Limit Warps,block,32,,,,,
0,48143,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(8192, 1, 1)",0,7.5,Occupancy,Theoretical Active Warps per SM,warp,16,,,,,
0,48143,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(8192, 1, 1)",0,7.5,Occupancy,Theoretical Occupancy,%,50,,,,,
0,48143,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(8192, 1, 1)",0,7.5,Occupancy,Achieved Occupancy,%,31.69,,,,,
0,48143,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(8192, 1, 1)",0,7.5,Occupancy,Achieved Active Warps Per SM,warp,10.14,,,,,
0,48143,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(8192, 1, 1)",0,7.5,Occupancy,,,,AchievedOccupancy,OPT,The difference between calculated theoretical (50.0%) and measured achieved occupancy (31.7%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy.,global,36.62
0,48143,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(8192, 1, 1)",0,7.5,Occupancy,,,,TheoreticalOccupancy,OPT,The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared memory.,global,50.0
0,48143,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(8192, 1, 1)",0,7.5,Source Counters,Branch Instructions Ratio,%,0.08,,,,,
0,48143,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(8192, 1, 1)",0,7.5,Source Counters,Branch Instructions,inst,"8,192",,,,,
0,48143,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(8192, 1, 1)",0,7.5,Source Counters,Branch Efficiency,%,0,,,,,
0,48143,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(8192, 1, 1)",0,7.5,Source Counters,Avg. Divergent Branches,,0,,,,,
0,48228,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(4096, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Frequency,cycle/second,"5,984,962,406.02",,,,,
0,48228,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(4096, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Frequency,cycle/second,"1,374,177,631.58",,,,,
0,48228,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(4096, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Elapsed Cycles,cycle,"23,416",,,,,
0,48228,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(4096, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Memory Throughput,%,10.00,,,,,
0,48228,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(4096, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Throughput,%,2.01,,,,,
0,48228,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(4096, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Duration,nsecond,"17,024",,,,,
0,48228,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(4096, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L1/TEX Cache Throughput,%,15.85,,,,,
0,48228,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(4096, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L2 Cache Throughput,%,8.35,,,,,
0,48228,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(4096, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Active Cycles,cycle,"14,766.93",,,,,
0,48228,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(4096, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Compute (SM) Throughput,%,10.00,,,,,
0,48228,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(4096, 1, 1)",0,7.5,SpeedOfLight,,,,SOLBottleneck,OPT,This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.,,
0,48228,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(4096, 1, 1)",0,7.5,SpeedOfLight_RooflineChart,,,,SOLFPRoofline,INF,The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved  close to 0% of this device's fp32 peak performance and 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.,,
0,48228,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(4096, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Active,inst/cycle,0.26,,,,,
0,48228,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(4096, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Elapsed,inst/cycle,0.16,,,,,
0,48228,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(4096, 1, 1)",0,7.5,Compute Workload Analysis,Issue Slots Busy,%,6.53,,,,,
0,48228,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(4096, 1, 1)",0,7.5,Compute Workload Analysis,Issued Ipc Active,inst/cycle,0.26,,,,,
0,48228,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(4096, 1, 1)",0,7.5,Compute Workload Analysis,SM Busy,%,6.60,,,,,
0,48228,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(4096, 1, 1)",0,7.5,ComputeWorkloadAnalysis,,,,HighPipeUtilization,OPT,All compute pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.,local,95.05
0,48228,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(4096, 1, 1)",0,7.5,Memory Workload Analysis,Memory Throughput,byte/second,"3,859,022,556.39",,,,,
0,48228,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(4096, 1, 1)",0,7.5,Memory Workload Analysis,Mem Busy,%,6.76,,,,,
0,48228,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(4096, 1, 1)",0,7.5,Memory Workload Analysis,Max Bandwidth,%,10.00,,,,,
0,48228,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(4096, 1, 1)",0,7.5,Memory Workload Analysis,L1/TEX Hit Rate,%,11.61,,,,,
0,48228,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(4096, 1, 1)",0,7.5,Memory Workload Analysis,L2 Hit Rate,%,92.01,,,,,
0,48228,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(4096, 1, 1)",0,7.5,Memory Workload Analysis,Mem Pipes Busy,%,10.00,,,,,
0,48228,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(4096, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Chart,,,,MemoryL2Compression,WRN,The optional metric lts__average_gcomp_input_sector_success_rate.pct could not be found. Collecting it as an additional metric could enable the rule to provide more guidance.,,
0,48228,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(4096, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for loads from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced loads and try to minimize how many cache lines need to be accessed per memory request.",global,3.324
0,48228,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(4096, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for stores from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.3 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced stores and try to minimize how many cache lines need to be accessed per memory request.",global,1.522
0,48228,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(4096, 1, 1)",0,7.5,Scheduler Statistics,One or More Eligible,%,7.28,,,,,
0,48228,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(4096, 1, 1)",0,7.5,Scheduler Statistics,Issued Warp Per Scheduler,,0.07,,,,,
0,48228,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(4096, 1, 1)",0,7.5,Scheduler Statistics,No Eligible,%,92.72,,,,,
0,48228,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(4096, 1, 1)",0,7.5,Scheduler Statistics,Active Warps Per Scheduler,warp,2.80,,,,,
0,48228,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(4096, 1, 1)",0,7.5,Scheduler Statistics,Eligible Warps Per Scheduler,warp,0.07,,,,,
0,48228,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(4096, 1, 1)",0,7.5,SchedulerStats,,,,IssueSlotUtilization,OPT,"Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 13.7 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of 2.80 active warps per scheduler, but only an average of 0.07 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections.",local,90.0
0,48228,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(4096, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Issued Instruction,cycle,38.48,,,,,
0,48228,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(4096, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Executed Instruction,cycle,39.03,,,,,
0,48228,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(4096, 1, 1)",0,7.5,Warp State Statistics,Avg. Active Threads Per Warp,,2,,,,,
0,48228,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(4096, 1, 1)",0,7.5,Warp State Statistics,Avg. Not Predicated Off Threads Per Warp,,2,,,,,
0,48228,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(4096, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,OPT,"On average, each warp of this kernel spends 28.9 cycles being stalled waiting for a scoreboard dependency on a L1TEX (local, global, surface, texture) operation. Find the instruction producing the data being waited upon to identify the culprit. To reduce the number of cycles waiting on L1TEX data accesses verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit rates by increasing data locality (coalescing), or by changing the cache configuration. Consider moving frequently used data to shared memory. This stall type represents about 75.1% of the total average of 38.5 cycles between issuing two instructions.",global,75.06
0,48228,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(4096, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,INF,Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.,,
0,48228,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(4096, 1, 1)",0,7.5,WarpStateStats,,,,ThreadDivergence,OPT,"Instructions are executed in warps, which are groups of 32 threads. Optimal instruction throughput is achieved if all 32 threads of a warp execute the same instruction. The chosen launch configuration, early thread completion, and divergent flow control can significantly lower the number of active threads in a warp per cycle. This kernel achieves an average of 2.0 threads being active per cycle.",global,9.378
0,48228,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(4096, 1, 1)",0,7.5,Instruction Statistics,Avg. Executed Instructions Per Scheduler,inst,950.86,,,,,
0,48228,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(4096, 1, 1)",0,7.5,Instruction Statistics,Executed Instructions,inst,"53,248",,,,,
0,48228,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(4096, 1, 1)",0,7.5,Instruction Statistics,Avg. Issued Instructions Per Scheduler,inst,964.50,,,,,
0,48228,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(4096, 1, 1)",0,7.5,Instruction Statistics,Issued Instructions,inst,"54,012",,,,,
0,48228,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(4096, 1, 1)",0,7.5,InstructionStats,,,,FPInstructions,OPT,"This kernel executes 0 fused and 4096 non-fused FP32 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP32 performance could be increased by up to 50% (relative to its current performance). Check the Source page to identify where this kernel executes FP32 instructions.",global,2.477
0,48228,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(4096, 1, 1)",0,7.5,Launch Statistics,Block Size,,2,,,,,
0,48228,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(4096, 1, 1)",0,7.5,Launch Statistics,Function Cache Configuration,,CachePreferNone,,,,,
0,48228,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(4096, 1, 1)",0,7.5,Launch Statistics,Grid Size,,"4,096",,,,,
0,48228,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(4096, 1, 1)",0,7.5,Launch Statistics,Registers Per Thread,register/thread,16,,,,,
0,48228,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(4096, 1, 1)",0,7.5,Launch Statistics,Shared Memory Configuration Size,byte,"32,768",,,,,
0,48228,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(4096, 1, 1)",0,7.5,Launch Statistics,Driver Shared Memory Per Block,byte/block,0,,,,,
0,48228,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(4096, 1, 1)",0,7.5,Launch Statistics,Dynamic Shared Memory Per Block,byte/block,0,,,,,
0,48228,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(4096, 1, 1)",0,7.5,Launch Statistics,Static Shared Memory Per Block,byte/block,0,,,,,
0,48228,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(4096, 1, 1)",0,7.5,Launch Statistics,Threads,thread,"8,192",,,,,
0,48228,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(4096, 1, 1)",0,7.5,Launch Statistics,Waves Per SM,,18.29,,,,,
0,48228,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(4096, 1, 1)",0,7.5,LaunchStats,,,,LaunchConfiguration,OPT,"Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 2 threads per block. Consequently, some threads in a warp are masked off and those hardware resources are unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256 threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to kernels that frequently call __syncthreads(). See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations.",global,93.75
0,48228,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(4096, 1, 1)",0,7.5,Occupancy,Block Limit SM,block,16,,,,,
0,48228,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(4096, 1, 1)",0,7.5,Occupancy,Block Limit Registers,block,128,,,,,
0,48228,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(4096, 1, 1)",0,7.5,Occupancy,Block Limit Shared Mem,block,16,,,,,
0,48228,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(4096, 1, 1)",0,7.5,Occupancy,Block Limit Warps,block,32,,,,,
0,48228,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(4096, 1, 1)",0,7.5,Occupancy,Theoretical Active Warps per SM,warp,16,,,,,
0,48228,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(4096, 1, 1)",0,7.5,Occupancy,Theoretical Occupancy,%,50,,,,,
0,48228,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(4096, 1, 1)",0,7.5,Occupancy,Achieved Occupancy,%,33.08,,,,,
0,48228,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(4096, 1, 1)",0,7.5,Occupancy,Achieved Active Warps Per SM,warp,10.58,,,,,
0,48228,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(4096, 1, 1)",0,7.5,Occupancy,,,,AchievedOccupancy,OPT,The difference between calculated theoretical (50.0%) and measured achieved occupancy (33.1%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy.,global,33.85
0,48228,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(4096, 1, 1)",0,7.5,Occupancy,,,,TheoreticalOccupancy,OPT,The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared memory.,global,50.0
0,48228,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(4096, 1, 1)",0,7.5,Source Counters,Branch Instructions Ratio,%,0.08,,,,,
0,48228,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(4096, 1, 1)",0,7.5,Source Counters,Branch Instructions,inst,"4,096",,,,,
0,48228,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(4096, 1, 1)",0,7.5,Source Counters,Branch Efficiency,%,0,,,,,
0,48228,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(4096, 1, 1)",0,7.5,Source Counters,Avg. Divergent Branches,,0,,,,,
0,48314,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(2048, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Frequency,cycle/second,"6,243,902,439.02",,,,,
0,48314,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(2048, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Frequency,cycle/second,"1,434,723,432.06",,,,,
0,48314,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(2048, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Elapsed Cycles,cycle,"13,189",,,,,
0,48314,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(2048, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Memory Throughput,%,8.88,,,,,
0,48314,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(2048, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Throughput,%,3.58,,,,,
0,48314,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(2048, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Duration,nsecond,"9,184",,,,,
0,48314,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(2048, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L1/TEX Cache Throughput,%,15.08,,,,,
0,48314,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(2048, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L2 Cache Throughput,%,7.45,,,,,
0,48314,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(2048, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Active Cycles,cycle,"7,758.86",,,,,
0,48314,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(2048, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Compute (SM) Throughput,%,8.88,,,,,
0,48314,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(2048, 1, 1)",0,7.5,SpeedOfLight,,,,SOLBottleneck,OPT,This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.,,
0,48314,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(2048, 1, 1)",0,7.5,SpeedOfLight_RooflineChart,,,,SOLFPRoofline,INF,The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved  close to 0% of this device's fp32 peak performance and 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.,,
0,48314,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(2048, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Active,inst/cycle,0.25,,,,,
0,48314,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(2048, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Elapsed,inst/cycle,0.14,,,,,
0,48314,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(2048, 1, 1)",0,7.5,Compute Workload Analysis,Issue Slots Busy,%,6.30,,,,,
0,48314,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(2048, 1, 1)",0,7.5,Compute Workload Analysis,Issued Ipc Active,inst/cycle,0.25,,,,,
0,48314,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(2048, 1, 1)",0,7.5,Compute Workload Analysis,SM Busy,%,6.30,,,,,
0,48314,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(2048, 1, 1)",0,7.5,ComputeWorkloadAnalysis,,,,HighPipeUtilization,OPT,All compute pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.,local,95.29
0,48314,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(2048, 1, 1)",0,7.5,Memory Workload Analysis,Memory Throughput,byte/second,"7,153,310,104.53",,,,,
0,48314,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(2048, 1, 1)",0,7.5,Memory Workload Analysis,Mem Busy,%,6.02,,,,,
0,48314,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(2048, 1, 1)",0,7.5,Memory Workload Analysis,Max Bandwidth,%,8.88,,,,,
0,48314,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(2048, 1, 1)",0,7.5,Memory Workload Analysis,L1/TEX Hit Rate,%,7.26,,,,,
0,48314,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(2048, 1, 1)",0,7.5,Memory Workload Analysis,L2 Hit Rate,%,81.63,,,,,
0,48314,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(2048, 1, 1)",0,7.5,Memory Workload Analysis,Mem Pipes Busy,%,8.88,,,,,
0,48314,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(2048, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Chart,,,,MemoryL2Compression,WRN,The optional metric lts__average_gcomp_input_sector_success_rate.pct could not be found. Collecting it as an additional metric could enable the rule to provide more guidance.,,
0,48314,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(2048, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for loads from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced loads and try to minimize how many cache lines need to be accessed per memory request.",global,2.948
0,48314,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(2048, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for stores from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.1 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced stores and try to minimize how many cache lines need to be accessed per memory request.",global,1.39
0,48314,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(2048, 1, 1)",0,7.5,Scheduler Statistics,One or More Eligible,%,7.38,,,,,
0,48314,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(2048, 1, 1)",0,7.5,Scheduler Statistics,Issued Warp Per Scheduler,,0.07,,,,,
0,48314,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(2048, 1, 1)",0,7.5,Scheduler Statistics,No Eligible,%,92.62,,,,,
0,48314,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(2048, 1, 1)",0,7.5,Scheduler Statistics,Active Warps Per Scheduler,warp,2.92,,,,,
0,48314,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(2048, 1, 1)",0,7.5,Scheduler Statistics,Eligible Warps Per Scheduler,warp,0.08,,,,,
0,48314,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(2048, 1, 1)",0,7.5,SchedulerStats,,,,IssueSlotUtilization,OPT,"Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 13.6 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of 2.92 active warps per scheduler, but only an average of 0.08 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections.",local,91.12
0,48314,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(2048, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Issued Instruction,cycle,39.58,,,,,
0,48314,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(2048, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Executed Instruction,cycle,40.72,,,,,
0,48314,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(2048, 1, 1)",0,7.5,Warp State Statistics,Avg. Active Threads Per Warp,,4,,,,,
0,48314,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(2048, 1, 1)",0,7.5,Warp State Statistics,Avg. Not Predicated Off Threads Per Warp,,4,,,,,
0,48314,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(2048, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,OPT,"On average, each warp of this kernel spends 27.3 cycles being stalled waiting for a scoreboard dependency on a L1TEX (local, global, surface, texture) operation. Find the instruction producing the data being waited upon to identify the culprit. To reduce the number of cycles waiting on L1TEX data accesses verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit rates by increasing data locality (coalescing), or by changing the cache configuration. Consider moving frequently used data to shared memory. This stall type represents about 69.0% of the total average of 39.6 cycles between issuing two instructions.",global,68.96
0,48314,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(2048, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,INF,Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.,,
0,48314,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(2048, 1, 1)",0,7.5,WarpStateStats,,,,ThreadDivergence,OPT,"Instructions are executed in warps, which are groups of 32 threads. Optimal instruction throughput is achieved if all 32 threads of a warp execute the same instruction. The chosen launch configuration, early thread completion, and divergent flow control can significantly lower the number of active threads in a warp per cycle. This kernel achieves an average of 4.0 threads being active per cycle.",global,7.77
0,48314,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(2048, 1, 1)",0,7.5,Instruction Statistics,Avg. Executed Instructions Per Scheduler,inst,475.43,,,,,
0,48314,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(2048, 1, 1)",0,7.5,Instruction Statistics,Executed Instructions,inst,"26,624",,,,,
0,48314,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(2048, 1, 1)",0,7.5,Instruction Statistics,Avg. Issued Instructions Per Scheduler,inst,489.07,,,,,
0,48314,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(2048, 1, 1)",0,7.5,Instruction Statistics,Issued Instructions,inst,"27,388",,,,,
0,48314,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(2048, 1, 1)",0,7.5,InstructionStats,,,,FPInstructions,OPT,"This kernel executes 0 fused and 2048 non-fused FP32 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP32 performance could be increased by up to 50% (relative to its current performance). Check the Source page to identify where this kernel executes FP32 instructions.",global,2.357
0,48314,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(2048, 1, 1)",0,7.5,Launch Statistics,Block Size,,4,,,,,
0,48314,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(2048, 1, 1)",0,7.5,Launch Statistics,Function Cache Configuration,,CachePreferNone,,,,,
0,48314,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(2048, 1, 1)",0,7.5,Launch Statistics,Grid Size,,"2,048",,,,,
0,48314,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(2048, 1, 1)",0,7.5,Launch Statistics,Registers Per Thread,register/thread,16,,,,,
0,48314,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(2048, 1, 1)",0,7.5,Launch Statistics,Shared Memory Configuration Size,byte,"32,768",,,,,
0,48314,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(2048, 1, 1)",0,7.5,Launch Statistics,Driver Shared Memory Per Block,byte/block,0,,,,,
0,48314,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(2048, 1, 1)",0,7.5,Launch Statistics,Dynamic Shared Memory Per Block,byte/block,0,,,,,
0,48314,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(2048, 1, 1)",0,7.5,Launch Statistics,Static Shared Memory Per Block,byte/block,0,,,,,
0,48314,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(2048, 1, 1)",0,7.5,Launch Statistics,Threads,thread,"8,192",,,,,
0,48314,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(2048, 1, 1)",0,7.5,Launch Statistics,Waves Per SM,,9.14,,,,,
0,48314,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(2048, 1, 1)",0,7.5,LaunchStats,,,,LaunchConfiguration,OPT,"Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 4 threads per block. Consequently, some threads in a warp are masked off and those hardware resources are unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256 threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to kernels that frequently call __syncthreads(). See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations.",global,87.5
0,48314,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(2048, 1, 1)",0,7.5,Occupancy,Block Limit SM,block,16,,,,,
0,48314,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(2048, 1, 1)",0,7.5,Occupancy,Block Limit Registers,block,128,,,,,
0,48314,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(2048, 1, 1)",0,7.5,Occupancy,Block Limit Shared Mem,block,16,,,,,
0,48314,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(2048, 1, 1)",0,7.5,Occupancy,Block Limit Warps,block,32,,,,,
0,48314,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(2048, 1, 1)",0,7.5,Occupancy,Theoretical Active Warps per SM,warp,16,,,,,
0,48314,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(2048, 1, 1)",0,7.5,Occupancy,Theoretical Occupancy,%,50,,,,,
0,48314,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(2048, 1, 1)",0,7.5,Occupancy,Achieved Occupancy,%,32.95,,,,,
0,48314,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(2048, 1, 1)",0,7.5,Occupancy,Achieved Active Warps Per SM,warp,10.54,,,,,
0,48314,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(2048, 1, 1)",0,7.5,Occupancy,,,,AchievedOccupancy,OPT,The difference between calculated theoretical (50.0%) and measured achieved occupancy (33.0%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy.,global,34.1
0,48314,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(2048, 1, 1)",0,7.5,Occupancy,,,,TheoreticalOccupancy,OPT,The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared memory.,global,50.0
0,48314,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(2048, 1, 1)",0,7.5,Source Counters,Branch Instructions Ratio,%,0.08,,,,,
0,48314,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(2048, 1, 1)",0,7.5,Source Counters,Branch Instructions,inst,"2,048",,,,,
0,48314,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(2048, 1, 1)",0,7.5,Source Counters,Branch Efficiency,%,0,,,,,
0,48314,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(2048, 1, 1)",0,7.5,Source Counters,Avg. Divergent Branches,,0,,,,,
0,48391,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(1024, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Frequency,cycle/second,"5,885,057,471.26",,,,,
0,48391,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(1024, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Frequency,cycle/second,"1,349,407,327.59",,,,,
0,48391,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(1024, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Elapsed Cycles,cycle,"7,524",,,,,
0,48391,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(1024, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Memory Throughput,%,7.79,,,,,
0,48391,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(1024, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Throughput,%,6.27,,,,,
0,48391,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(1024, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Duration,nsecond,"5,568",,,,,
0,48391,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(1024, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L1/TEX Cache Throughput,%,14.22,,,,,
0,48391,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(1024, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L2 Cache Throughput,%,5.64,,,,,
0,48391,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(1024, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Active Cycles,cycle,"4,113.79",,,,,
0,48391,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(1024, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Compute (SM) Throughput,%,7.79,,,,,
0,48391,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(1024, 1, 1)",0,7.5,SpeedOfLight,,,,SOLBottleneck,OPT,This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.,,
0,48391,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(1024, 1, 1)",0,7.5,SpeedOfLight_RooflineChart,,,,SOLFPRoofline,INF,The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved  close to 0% of this device's fp32 peak performance and 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.,,
0,48391,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(1024, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Active,inst/cycle,0.23,,,,,
0,48391,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(1024, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Elapsed,inst/cycle,0.13,,,,,
0,48391,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(1024, 1, 1)",0,7.5,Compute Workload Analysis,Issue Slots Busy,%,6.11,,,,,
0,48391,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(1024, 1, 1)",0,7.5,Compute Workload Analysis,Issued Ipc Active,inst/cycle,0.24,,,,,
0,48391,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(1024, 1, 1)",0,7.5,Compute Workload Analysis,SM Busy,%,6.11,,,,,
0,48391,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(1024, 1, 1)",0,7.5,ComputeWorkloadAnalysis,,,,HighPipeUtilization,OPT,All compute pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.,local,95.56
0,48391,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(1024, 1, 1)",0,7.5,Memory Workload Analysis,Memory Throughput,byte/second,"11,798,850,574.71",,,,,
0,48391,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(1024, 1, 1)",0,7.5,Memory Workload Analysis,Mem Busy,%,5.64,,,,,
0,48391,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(1024, 1, 1)",0,7.5,Memory Workload Analysis,Max Bandwidth,%,7.79,,,,,
0,48391,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(1024, 1, 1)",0,7.5,Memory Workload Analysis,L1/TEX Hit Rate,%,4.09,,,,,
0,48391,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(1024, 1, 1)",0,7.5,Memory Workload Analysis,L2 Hit Rate,%,65.23,,,,,
0,48391,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(1024, 1, 1)",0,7.5,Memory Workload Analysis,Mem Pipes Busy,%,7.79,,,,,
0,48391,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(1024, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Chart,,,,MemoryL2Compression,WRN,The optional metric lts__average_gcomp_input_sector_success_rate.pct could not be found. Collecting it as an additional metric could enable the rule to provide more guidance.,,
0,48391,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(1024, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for loads from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.1 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced loads and try to minimize how many cache lines need to be accessed per memory request.",global,2.622
0,48391,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(1024, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for stores from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.1 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced stores and try to minimize how many cache lines need to be accessed per memory request.",global,1.302
0,48391,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(1024, 1, 1)",0,7.5,Scheduler Statistics,One or More Eligible,%,6.68,,,,,
0,48391,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(1024, 1, 1)",0,7.5,Scheduler Statistics,Issued Warp Per Scheduler,,0.07,,,,,
0,48391,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(1024, 1, 1)",0,7.5,Scheduler Statistics,No Eligible,%,93.32,,,,,
0,48391,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(1024, 1, 1)",0,7.5,Scheduler Statistics,Active Warps Per Scheduler,warp,2.95,,,,,
0,48391,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(1024, 1, 1)",0,7.5,Scheduler Statistics,Eligible Warps Per Scheduler,warp,0.07,,,,,
0,48391,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(1024, 1, 1)",0,7.5,SchedulerStats,,,,IssueSlotUtilization,OPT,"Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 15.0 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of 2.95 active warps per scheduler, but only an average of 0.07 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections.",local,92.21
0,48391,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(1024, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Issued Instruction,cycle,44.22,,,,,
0,48391,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(1024, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Executed Instruction,cycle,46.76,,,,,
0,48391,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(1024, 1, 1)",0,7.5,Warp State Statistics,Avg. Active Threads Per Warp,,8,,,,,
0,48391,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(1024, 1, 1)",0,7.5,Warp State Statistics,Avg. Not Predicated Off Threads Per Warp,,8,,,,,
0,48391,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(1024, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,OPT,"On average, each warp of this kernel spends 28.5 cycles being stalled waiting for a scoreboard dependency on a L1TEX (local, global, surface, texture) operation. Find the instruction producing the data being waited upon to identify the culprit. To reduce the number of cycles waiting on L1TEX data accesses verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit rates by increasing data locality (coalescing), or by changing the cache configuration. Consider moving frequently used data to shared memory. This stall type represents about 64.4% of the total average of 44.2 cycles between issuing two instructions.",global,64.4
0,48391,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(1024, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,INF,Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.,,
0,48391,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(1024, 1, 1)",0,7.5,WarpStateStats,,,,ThreadDivergence,OPT,"Instructions are executed in warps, which are groups of 32 threads. Optimal instruction throughput is achieved if all 32 threads of a warp execute the same instruction. The chosen launch configuration, early thread completion, and divergent flow control can significantly lower the number of active threads in a warp per cycle. This kernel achieves an average of 8.0 threads being active per cycle.",global,5.84
0,48391,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(1024, 1, 1)",0,7.5,Instruction Statistics,Avg. Executed Instructions Per Scheduler,inst,237.71,,,,,
0,48391,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(1024, 1, 1)",0,7.5,Instruction Statistics,Executed Instructions,inst,"13,312",,,,,
0,48391,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(1024, 1, 1)",0,7.5,Instruction Statistics,Avg. Issued Instructions Per Scheduler,inst,251.36,,,,,
0,48391,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(1024, 1, 1)",0,7.5,Instruction Statistics,Issued Instructions,inst,"14,076",,,,,
0,48391,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(1024, 1, 1)",0,7.5,InstructionStats,,,,FPInstructions,OPT,"This kernel executes 0 fused and 1024 non-fused FP32 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP32 performance could be increased by up to 50% (relative to its current performance). Check the Source page to identify where this kernel executes FP32 instructions.",global,2.222
0,48391,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(1024, 1, 1)",0,7.5,Launch Statistics,Block Size,,8,,,,,
0,48391,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(1024, 1, 1)",0,7.5,Launch Statistics,Function Cache Configuration,,CachePreferNone,,,,,
0,48391,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(1024, 1, 1)",0,7.5,Launch Statistics,Grid Size,,"1,024",,,,,
0,48391,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(1024, 1, 1)",0,7.5,Launch Statistics,Registers Per Thread,register/thread,16,,,,,
0,48391,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(1024, 1, 1)",0,7.5,Launch Statistics,Shared Memory Configuration Size,byte,"32,768",,,,,
0,48391,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(1024, 1, 1)",0,7.5,Launch Statistics,Driver Shared Memory Per Block,byte/block,0,,,,,
0,48391,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(1024, 1, 1)",0,7.5,Launch Statistics,Dynamic Shared Memory Per Block,byte/block,0,,,,,
0,48391,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(1024, 1, 1)",0,7.5,Launch Statistics,Static Shared Memory Per Block,byte/block,0,,,,,
0,48391,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(1024, 1, 1)",0,7.5,Launch Statistics,Threads,thread,"8,192",,,,,
0,48391,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(1024, 1, 1)",0,7.5,Launch Statistics,Waves Per SM,,4.57,,,,,
0,48391,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(1024, 1, 1)",0,7.5,LaunchStats,,,,LaunchConfiguration,OPT,"Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 8 threads per block. Consequently, some threads in a warp are masked off and those hardware resources are unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256 threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to kernels that frequently call __syncthreads(). See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations.",global,75.0
0,48391,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(1024, 1, 1)",0,7.5,LaunchStats,,,,LaunchConfiguration,OPT,"A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical occupancy of the kernel. This kernel launch results in 4 full waves and a partial wave of 127 thread blocks. Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for up to 20.0% of the total kernel runtime with a lower occupancy of 30.2%. Try launching a grid with no partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for a grid. See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations.",global,20.0
0,48391,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(1024, 1, 1)",0,7.5,Occupancy,Block Limit SM,block,16,,,,,
0,48391,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(1024, 1, 1)",0,7.5,Occupancy,Block Limit Registers,block,128,,,,,
0,48391,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(1024, 1, 1)",0,7.5,Occupancy,Block Limit Shared Mem,block,16,,,,,
0,48391,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(1024, 1, 1)",0,7.5,Occupancy,Block Limit Warps,block,32,,,,,
0,48391,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(1024, 1, 1)",0,7.5,Occupancy,Theoretical Active Warps per SM,warp,16,,,,,
0,48391,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(1024, 1, 1)",0,7.5,Occupancy,Theoretical Occupancy,%,50,,,,,
0,48391,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(1024, 1, 1)",0,7.5,Occupancy,Achieved Occupancy,%,34.89,,,,,
0,48391,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(1024, 1, 1)",0,7.5,Occupancy,Achieved Active Warps Per SM,warp,11.16,,,,,
0,48391,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(1024, 1, 1)",0,7.5,Occupancy,,,,AchievedOccupancy,OPT,The difference between calculated theoretical (50.0%) and measured achieved occupancy (34.9%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy.,global,30.23
0,48391,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(1024, 1, 1)",0,7.5,Occupancy,,,,TheoreticalOccupancy,OPT,The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared memory.,global,50.0
0,48391,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(1024, 1, 1)",0,7.5,Source Counters,Branch Instructions Ratio,%,0.08,,,,,
0,48391,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(1024, 1, 1)",0,7.5,Source Counters,Branch Instructions,inst,"1,024",,,,,
0,48391,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(1024, 1, 1)",0,7.5,Source Counters,Branch Efficiency,%,0,,,,,
0,48391,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(1024, 1, 1)",0,7.5,Source Counters,Avg. Divergent Branches,,0,,,,,
0,48479,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(512, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Frequency,cycle/second,"5,639,344,262.30",,,,,
0,48479,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(512, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Frequency,cycle/second,"1,293,160,860.66",,,,,
0,48479,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(512, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Elapsed Cycles,cycle,"5,051",,,,,
0,48479,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(512, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Memory Throughput,%,9.33,,,,,
0,48479,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(512, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Throughput,%,9.33,,,,,
0,48479,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(512, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Duration,nsecond,"3,904",,,,,
0,48479,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(512, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L1/TEX Cache Throughput,%,10.68,,,,,
0,48479,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(512, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L2 Cache Throughput,%,8.39,,,,,
0,48479,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(512, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Active Cycles,cycle,"2,738.86",,,,,
0,48479,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(512, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Compute (SM) Throughput,%,5.79,,,,,
0,48479,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(512, 1, 1)",0,7.5,SpeedOfLight,,,,SOLBottleneck,OPT,This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.,,
0,48479,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(512, 1, 1)",0,7.5,SpeedOfLight_RooflineChart,,,,SOLFPRoofline,INF,The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved  close to 0% of this device's fp32 peak performance and 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.,,
0,48479,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(512, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Active,inst/cycle,0.17,,,,,
0,48479,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(512, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Elapsed,inst/cycle,0.09,,,,,
0,48479,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(512, 1, 1)",0,7.5,Compute Workload Analysis,Issue Slots Busy,%,4.84,,,,,
0,48479,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(512, 1, 1)",0,7.5,Compute Workload Analysis,Issued Ipc Active,inst/cycle,0.19,,,,,
0,48479,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(512, 1, 1)",0,7.5,Compute Workload Analysis,SM Busy,%,4.84,,,,,
0,48479,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(512, 1, 1)",0,7.5,ComputeWorkloadAnalysis,,,,HighPipeUtilization,OPT,All compute pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.,local,96.66
0,48479,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(512, 1, 1)",0,7.5,Memory Workload Analysis,Memory Throughput,byte/second,"16,827,868,852.46",,,,,
0,48479,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(512, 1, 1)",0,7.5,Memory Workload Analysis,Mem Busy,%,8.39,,,,,
0,48479,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(512, 1, 1)",0,7.5,Memory Workload Analysis,Max Bandwidth,%,9.33,,,,,
0,48479,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(512, 1, 1)",0,7.5,Memory Workload Analysis,L1/TEX Hit Rate,%,7.29,,,,,
0,48479,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(512, 1, 1)",0,7.5,Memory Workload Analysis,L2 Hit Rate,%,36.86,,,,,
0,48479,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(512, 1, 1)",0,7.5,Memory Workload Analysis,Mem Pipes Busy,%,5.79,,,,,
0,48479,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(512, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Chart,,,,MemoryL2Compression,WRN,The optional metric lts__average_gcomp_input_sector_success_rate.pct could not be found. Collecting it as an additional metric could enable the rule to provide more guidance.,,
0,48479,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(512, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for loads from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 2.4 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced loads and try to minimize how many cache lines need to be accessed per memory request.",global,2.139
0,48479,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(512, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for stores from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 2.5 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced stores and try to minimize how many cache lines need to be accessed per memory request.",global,1.023
0,48479,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(512, 1, 1)",0,7.5,Scheduler Statistics,One or More Eligible,%,5.45,,,,,
0,48479,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(512, 1, 1)",0,7.5,Scheduler Statistics,Issued Warp Per Scheduler,,0.05,,,,,
0,48479,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(512, 1, 1)",0,7.5,Scheduler Statistics,No Eligible,%,94.55,,,,,
0,48479,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(512, 1, 1)",0,7.5,Scheduler Statistics,Active Warps Per Scheduler,warp,2.90,,,,,
0,48479,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(512, 1, 1)",0,7.5,Scheduler Statistics,Eligible Warps Per Scheduler,warp,0.06,,,,,
0,48479,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(512, 1, 1)",0,7.5,SchedulerStats,,,,IssueSlotUtilization,OPT,"Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 18.4 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of 2.90 active warps per scheduler, but only an average of 0.06 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections.",local,90.67
0,48479,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(512, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Issued Instruction,cycle,53.24,,,,,
0,48479,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(512, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Executed Instruction,cycle,59.35,,,,,
0,48479,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(512, 1, 1)",0,7.5,Warp State Statistics,Avg. Active Threads Per Warp,,16,,,,,
0,48479,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(512, 1, 1)",0,7.5,Warp State Statistics,Avg. Not Predicated Off Threads Per Warp,,16,,,,,
0,48479,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(512, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,OPT,"On average, each warp of this kernel spends 31.4 cycles being stalled waiting for a scoreboard dependency on a L1TEX (local, global, surface, texture) operation. Find the instruction producing the data being waited upon to identify the culprit. To reduce the number of cycles waiting on L1TEX data accesses verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit rates by increasing data locality (coalescing), or by changing the cache configuration. Consider moving frequently used data to shared memory. This stall type represents about 58.9% of the total average of 53.2 cycles between issuing two instructions.",global,58.9
0,48479,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(512, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,INF,Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.,,
0,48479,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(512, 1, 1)",0,7.5,WarpStateStats,,,,ThreadDivergence,OPT,"Instructions are executed in warps, which are groups of 32 threads. Optimal instruction throughput is achieved if all 32 threads of a warp execute the same instruction. The chosen launch configuration, early thread completion, and divergent flow control can significantly lower the number of active threads in a warp per cycle. This kernel achieves an average of 16.0 threads being active per cycle.",global,2.897
0,48479,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(512, 1, 1)",0,7.5,Instruction Statistics,Avg. Executed Instructions Per Scheduler,inst,118.86,,,,,
0,48479,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(512, 1, 1)",0,7.5,Instruction Statistics,Executed Instructions,inst,"6,656",,,,,
0,48479,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(512, 1, 1)",0,7.5,Instruction Statistics,Avg. Issued Instructions Per Scheduler,inst,132.50,,,,,
0,48479,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(512, 1, 1)",0,7.5,Instruction Statistics,Issued Instructions,inst,"7,420",,,,,
0,48479,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(512, 1, 1)",0,7.5,InstructionStats,,,,FPInstructions,OPT,"This kernel executes 0 fused and 512 non-fused FP32 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP32 performance could be increased by up to 50% (relative to its current performance). Check the Source page to identify where this kernel executes FP32 instructions.",global,1.669
0,48479,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(512, 1, 1)",0,7.5,Launch Statistics,Block Size,,16,,,,,
0,48479,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(512, 1, 1)",0,7.5,Launch Statistics,Function Cache Configuration,,CachePreferNone,,,,,
0,48479,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(512, 1, 1)",0,7.5,Launch Statistics,Grid Size,,512,,,,,
0,48479,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(512, 1, 1)",0,7.5,Launch Statistics,Registers Per Thread,register/thread,16,,,,,
0,48479,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(512, 1, 1)",0,7.5,Launch Statistics,Shared Memory Configuration Size,byte,"32,768",,,,,
0,48479,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(512, 1, 1)",0,7.5,Launch Statistics,Driver Shared Memory Per Block,byte/block,0,,,,,
0,48479,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(512, 1, 1)",0,7.5,Launch Statistics,Dynamic Shared Memory Per Block,byte/block,0,,,,,
0,48479,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(512, 1, 1)",0,7.5,Launch Statistics,Static Shared Memory Per Block,byte/block,0,,,,,
0,48479,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(512, 1, 1)",0,7.5,Launch Statistics,Threads,thread,"8,192",,,,,
0,48479,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(512, 1, 1)",0,7.5,Launch Statistics,Waves Per SM,,2.29,,,,,
0,48479,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(512, 1, 1)",0,7.5,LaunchStats,,,,LaunchConfiguration,OPT,"Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 16 threads per block. Consequently, some threads in a warp are masked off and those hardware resources are unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256 threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to kernels that frequently call __syncthreads(). See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations.",global,50.0
0,48479,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(512, 1, 1)",0,7.5,LaunchStats,,,,LaunchConfiguration,OPT,"A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical occupancy of the kernel. This kernel launch results in 2 full waves and a partial wave of 63 thread blocks. Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for up to 33.3% of the total kernel runtime with a lower occupancy of 32.9%. Try launching a grid with no partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for a grid. See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations.",global,33.33
0,48479,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(512, 1, 1)",0,7.5,Occupancy,Block Limit SM,block,16,,,,,
0,48479,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(512, 1, 1)",0,7.5,Occupancy,Block Limit Registers,block,128,,,,,
0,48479,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(512, 1, 1)",0,7.5,Occupancy,Block Limit Shared Mem,block,16,,,,,
0,48479,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(512, 1, 1)",0,7.5,Occupancy,Block Limit Warps,block,32,,,,,
0,48479,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(512, 1, 1)",0,7.5,Occupancy,Theoretical Active Warps per SM,warp,16,,,,,
0,48479,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(512, 1, 1)",0,7.5,Occupancy,Theoretical Occupancy,%,50,,,,,
0,48479,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(512, 1, 1)",0,7.5,Occupancy,Achieved Occupancy,%,33.53,,,,,
0,48479,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(512, 1, 1)",0,7.5,Occupancy,Achieved Active Warps Per SM,warp,10.73,,,,,
0,48479,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(512, 1, 1)",0,7.5,Occupancy,,,,AchievedOccupancy,OPT,The difference between calculated theoretical (50.0%) and measured achieved occupancy (33.5%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy.,global,32.94
0,48479,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(512, 1, 1)",0,7.5,Occupancy,,,,TheoreticalOccupancy,OPT,The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared memory.,global,50.0
0,48479,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(512, 1, 1)",0,7.5,Source Counters,Branch Instructions Ratio,%,0.08,,,,,
0,48479,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(512, 1, 1)",0,7.5,Source Counters,Branch Instructions,inst,512,,,,,
0,48479,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(512, 1, 1)",0,7.5,Source Counters,Branch Efficiency,%,0,,,,,
0,48479,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(512, 1, 1)",0,7.5,Source Counters,Avg. Divergent Branches,,0,,,,,
0,48556,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(256, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Frequency,cycle/second,"5,658,536,585.37",,,,,
0,48556,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(256, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Frequency,cycle/second,"1,281,440,548.78",,,,,
0,48556,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(256, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Elapsed Cycles,cycle,"3,366",,,,,
0,48556,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(256, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Memory Throughput,%,13.83,,,,,
0,48556,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(256, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Throughput,%,13.83,,,,,
0,48556,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(256, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Duration,nsecond,"2,624",,,,,
0,48556,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(256, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L1/TEX Cache Throughput,%,7.94,,,,,
0,48556,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(256, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L2 Cache Throughput,%,12.59,,,,,
0,48556,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(256, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Active Cycles,cycle,"1,842.43",,,,,
0,48556,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(256, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Compute (SM) Throughput,%,4.35,,,,,
0,48556,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(256, 1, 1)",0,7.5,SpeedOfLight,,,,SOLBottleneck,OPT,This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.,,
0,48556,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(256, 1, 1)",0,7.5,SpeedOfLight_RooflineChart,,,,SOLFPRoofline,INF,The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved  close to 0% of this device's fp32 peak performance and 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.,,
0,48556,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(256, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Active,inst/cycle,0.13,,,,,
0,48556,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(256, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Elapsed,inst/cycle,0.07,,,,,
0,48556,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(256, 1, 1)",0,7.5,Compute Workload Analysis,Issue Slots Busy,%,3.97,,,,,
0,48556,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(256, 1, 1)",0,7.5,Compute Workload Analysis,Issued Ipc Active,inst/cycle,0.16,,,,,
0,48556,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(256, 1, 1)",0,7.5,Compute Workload Analysis,SM Busy,%,3.97,,,,,
0,48556,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(256, 1, 1)",0,7.5,ComputeWorkloadAnalysis,,,,HighPipeUtilization,OPT,All compute pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.,local,97.52
0,48556,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(256, 1, 1)",0,7.5,Memory Workload Analysis,Memory Throughput,byte/second,"25,036,585,365.85",,,,,
0,48556,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(256, 1, 1)",0,7.5,Memory Workload Analysis,Mem Busy,%,12.59,,,,,
0,48556,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(256, 1, 1)",0,7.5,Memory Workload Analysis,Max Bandwidth,%,13.83,,,,,
0,48556,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(256, 1, 1)",0,7.5,Memory Workload Analysis,L1/TEX Hit Rate,%,0,,,,,
0,48556,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(256, 1, 1)",0,7.5,Memory Workload Analysis,L2 Hit Rate,%,36.86,,,,,
0,48556,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(256, 1, 1)",0,7.5,Memory Workload Analysis,Mem Pipes Busy,%,4.35,,,,,
0,48556,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(256, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Chart,,,,MemoryL2Compression,WRN,The optional metric lts__average_gcomp_input_sector_success_rate.pct could not be found. Collecting it as an additional metric could enable the rule to provide more guidance.,,
0,48556,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(256, 1, 1)",0,7.5,Scheduler Statistics,One or More Eligible,%,4.36,,,,,
0,48556,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(256, 1, 1)",0,7.5,Scheduler Statistics,Issued Warp Per Scheduler,,0.04,,,,,
0,48556,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(256, 1, 1)",0,7.5,Scheduler Statistics,No Eligible,%,95.64,,,,,
0,48556,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(256, 1, 1)",0,7.5,Scheduler Statistics,Active Warps Per Scheduler,warp,3.24,,,,,
0,48556,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(256, 1, 1)",0,7.5,Scheduler Statistics,Eligible Warps Per Scheduler,warp,0.05,,,,,
0,48556,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(256, 1, 1)",0,7.5,SchedulerStats,,,,IssueSlotUtilization,OPT,"Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 22.9 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of 3.24 active warps per scheduler, but only an average of 0.05 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, avoid possible load imbalances due to highly different execution durations per warp. Reducing stalls indicated on the Warp State Statistics and Source Counters sections can help, too.",local,86.17
0,48556,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(256, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Issued Instruction,cycle,74.43,,,,,
0,48556,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(256, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Executed Instruction,cycle,91.52,,,,,
0,48556,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(256, 1, 1)",0,7.5,Warp State Statistics,Avg. Active Threads Per Warp,,32,,,,,
0,48556,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(256, 1, 1)",0,7.5,Warp State Statistics,Avg. Not Predicated Off Threads Per Warp,,32,,,,,
0,48556,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(256, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,OPT,"On average, each warp of this kernel spends 40.7 cycles being stalled waiting for a scoreboard dependency on a L1TEX (local, global, surface, texture) operation. Find the instruction producing the data being waited upon to identify the culprit. To reduce the number of cycles waiting on L1TEX data accesses verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit rates by increasing data locality (coalescing), or by changing the cache configuration. Consider moving frequently used data to shared memory. This stall type represents about 54.6% of the total average of 74.4 cycles between issuing two instructions.",global,54.64
0,48556,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(256, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,OPT,"On average, each warp of this kernel spends 25.8 cycles being stalled waiting for an immediate constant cache (IMC) miss. A read from constant memory costs one memory read from device memory only on a cache miss; otherwise, it just costs one read from the constant cache. Immediate constants are encoded into the SASS instruction as 'c[bank][offset]'. Accesses to different addresses by threads within a warp are serialized, thus the cost scales linearly with the number of unique addresses read by all threads within a warp. As such, the constant cache is best when threads in the same warp access only a few distinct locations. If all threads of a warp access the same location, then constant memory can be as fast as a register access. This stall type represents about 34.7% of the total average of 74.4 cycles between issuing two instructions.",global,34.67
0,48556,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(256, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,INF,Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.,,
0,48556,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(256, 1, 1)",0,7.5,Instruction Statistics,Avg. Executed Instructions Per Scheduler,inst,59.43,,,,,
0,48556,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(256, 1, 1)",0,7.5,Instruction Statistics,Executed Instructions,inst,"3,328",,,,,
0,48556,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(256, 1, 1)",0,7.5,Instruction Statistics,Avg. Issued Instructions Per Scheduler,inst,73.07,,,,,
0,48556,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(256, 1, 1)",0,7.5,Instruction Statistics,Issued Instructions,inst,"4,092",,,,,
0,48556,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(256, 1, 1)",0,7.5,InstructionStats,,,,FPInstructions,OPT,"This kernel executes 0 fused and 256 non-fused FP32 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP32 performance could be increased by up to 50% (relative to its current performance). Check the Source page to identify where this kernel executes FP32 instructions.",global,1.241
0,48556,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(256, 1, 1)",0,7.5,Launch Statistics,Block Size,,32,,,,,
0,48556,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(256, 1, 1)",0,7.5,Launch Statistics,Function Cache Configuration,,CachePreferNone,,,,,
0,48556,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(256, 1, 1)",0,7.5,Launch Statistics,Grid Size,,256,,,,,
0,48556,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(256, 1, 1)",0,7.5,Launch Statistics,Registers Per Thread,register/thread,16,,,,,
0,48556,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(256, 1, 1)",0,7.5,Launch Statistics,Shared Memory Configuration Size,byte,"32,768",,,,,
0,48556,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(256, 1, 1)",0,7.5,Launch Statistics,Driver Shared Memory Per Block,byte/block,0,,,,,
0,48556,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(256, 1, 1)",0,7.5,Launch Statistics,Dynamic Shared Memory Per Block,byte/block,0,,,,,
0,48556,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(256, 1, 1)",0,7.5,Launch Statistics,Static Shared Memory Per Block,byte/block,0,,,,,
0,48556,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(256, 1, 1)",0,7.5,Launch Statistics,Threads,thread,"8,192",,,,,
0,48556,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(256, 1, 1)",0,7.5,Launch Statistics,Waves Per SM,,1.14,,,,,
0,48556,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(256, 1, 1)",0,7.5,LaunchStats,,,,LaunchConfiguration,OPT,"A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical occupancy of the kernel. This kernel launch results in 1 full waves and a partial wave of 31 thread blocks. Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for up to 50.0% of the total kernel runtime with a lower occupancy of 24.2%. Try launching a grid with no partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for a grid. See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations.",global,50.0
0,48556,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(256, 1, 1)",0,7.5,Occupancy,Block Limit SM,block,16,,,,,
0,48556,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(256, 1, 1)",0,7.5,Occupancy,Block Limit Registers,block,128,,,,,
0,48556,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(256, 1, 1)",0,7.5,Occupancy,Block Limit Shared Mem,block,16,,,,,
0,48556,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(256, 1, 1)",0,7.5,Occupancy,Block Limit Warps,block,32,,,,,
0,48556,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(256, 1, 1)",0,7.5,Occupancy,Theoretical Active Warps per SM,warp,16,,,,,
0,48556,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(256, 1, 1)",0,7.5,Occupancy,Theoretical Occupancy,%,50,,,,,
0,48556,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(256, 1, 1)",0,7.5,Occupancy,Achieved Occupancy,%,37.91,,,,,
0,48556,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(256, 1, 1)",0,7.5,Occupancy,Achieved Active Warps Per SM,warp,12.13,,,,,
0,48556,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(256, 1, 1)",0,7.5,Occupancy,,,,AchievedOccupancy,OPT,The difference between calculated theoretical (50.0%) and measured achieved occupancy (37.9%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy.,global,24.17
0,48556,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(256, 1, 1)",0,7.5,Occupancy,,,,TheoreticalOccupancy,OPT,The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared memory.,global,50.0
0,48556,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(256, 1, 1)",0,7.5,Source Counters,Branch Instructions Ratio,%,0.08,,,,,
0,48556,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(256, 1, 1)",0,7.5,Source Counters,Branch Instructions,inst,256,,,,,
0,48556,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(256, 1, 1)",0,7.5,Source Counters,Branch Efficiency,%,0,,,,,
0,48556,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(256, 1, 1)",0,7.5,Source Counters,Avg. Divergent Branches,,0,,,,,
0,48642,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(128, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Frequency,cycle/second,"5,684,210,526.32",,,,,
0,48642,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(128, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Frequency,cycle/second,"1,298,725,328.95",,,,,
0,48642,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(128, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Elapsed Cycles,cycle,"3,159",,,,,
0,48642,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(128, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Memory Throughput,%,14.85,,,,,
0,48642,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(128, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Throughput,%,14.85,,,,,
0,48642,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(128, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Duration,nsecond,"2,432",,,,,
0,48642,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(128, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L1/TEX Cache Throughput,%,9.37,,,,,
0,48642,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(128, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L2 Cache Throughput,%,13.40,,,,,
0,48642,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(128, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Active Cycles,cycle,"1,561.14",,,,,
0,48642,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(128, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Compute (SM) Throughput,%,4.63,,,,,
0,48642,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(128, 1, 1)",0,7.5,SpeedOfLight,,,,SOLBottleneck,OPT,"This kernel grid is too small to fill the available resources on this device, resulting in only 0.6 full waves across all SMs. Look at Launch Statistics for more details.",,
0,48642,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(128, 1, 1)",0,7.5,SpeedOfLight_RooflineChart,,,,SOLFPRoofline,INF,The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved  close to 0% of this device's fp32 peak performance and 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.,,
0,48642,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(128, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Active,inst/cycle,0.15,,,,,
0,48642,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(128, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Elapsed,inst/cycle,0.08,,,,,
0,48642,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(128, 1, 1)",0,7.5,Compute Workload Analysis,Issue Slots Busy,%,4.98,,,,,
0,48642,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(128, 1, 1)",0,7.5,Compute Workload Analysis,Issued Ipc Active,inst/cycle,0.20,,,,,
0,48642,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(128, 1, 1)",0,7.5,Compute Workload Analysis,SM Busy,%,4.98,,,,,
0,48642,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(128, 1, 1)",0,7.5,ComputeWorkloadAnalysis,,,,HighPipeUtilization,OPT,All compute pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.,local,97.07
0,48642,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(128, 1, 1)",0,7.5,Memory Workload Analysis,Memory Throughput,byte/second,"27,013,157,894.74",,,,,
0,48642,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(128, 1, 1)",0,7.5,Memory Workload Analysis,Mem Busy,%,13.40,,,,,
0,48642,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(128, 1, 1)",0,7.5,Memory Workload Analysis,Max Bandwidth,%,14.85,,,,,
0,48642,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(128, 1, 1)",0,7.5,Memory Workload Analysis,L1/TEX Hit Rate,%,0,,,,,
0,48642,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(128, 1, 1)",0,7.5,Memory Workload Analysis,L2 Hit Rate,%,36.86,,,,,
0,48642,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(128, 1, 1)",0,7.5,Memory Workload Analysis,Mem Pipes Busy,%,4.63,,,,,
0,48642,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(128, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Chart,,,,MemoryL2Compression,WRN,The optional metric lts__average_gcomp_input_sector_success_rate.pct could not be found. Collecting it as an additional metric could enable the rule to provide more guidance.,,
0,48642,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(128, 1, 1)",0,7.5,Scheduler Statistics,One or More Eligible,%,5.13,,,,,
0,48642,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(128, 1, 1)",0,7.5,Scheduler Statistics,Issued Warp Per Scheduler,,0.05,,,,,
0,48642,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(128, 1, 1)",0,7.5,Scheduler Statistics,No Eligible,%,94.87,,,,,
0,48642,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(128, 1, 1)",0,7.5,Scheduler Statistics,Active Warps Per Scheduler,warp,4.14,,,,,
0,48642,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(128, 1, 1)",0,7.5,Scheduler Statistics,Eligible Warps Per Scheduler,warp,0.07,,,,,
0,48642,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(128, 1, 1)",0,7.5,SchedulerStats,,,,IssueSlotUtilization,OPT,"Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 19.5 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of 4.14 active warps per scheduler, but only an average of 0.07 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections.",local,85.15
0,48642,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(128, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Issued Instruction,cycle,80.74,,,,,
0,48642,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(128, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Executed Instruction,cycle,105.58,,,,,
0,48642,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(128, 1, 1)",0,7.5,Warp State Statistics,Avg. Active Threads Per Warp,,32,,,,,
0,48642,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(128, 1, 1)",0,7.5,Warp State Statistics,Avg. Not Predicated Off Threads Per Warp,,32,,,,,
0,48642,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(128, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,OPT,"On average, each warp of this kernel spends 41.8 cycles being stalled waiting for a scoreboard dependency on a L1TEX (local, global, surface, texture) operation. Find the instruction producing the data being waited upon to identify the culprit. To reduce the number of cycles waiting on L1TEX data accesses verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit rates by increasing data locality (coalescing), or by changing the cache configuration. Consider moving frequently used data to shared memory. This stall type represents about 51.8% of the total average of 80.7 cycles between issuing two instructions.",global,51.78
0,48642,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(128, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,OPT,"On average, each warp of this kernel spends 30.0 cycles being stalled waiting for an immediate constant cache (IMC) miss. A read from constant memory costs one memory read from device memory only on a cache miss; otherwise, it just costs one read from the constant cache. Immediate constants are encoded into the SASS instruction as 'c[bank][offset]'. Accesses to different addresses by threads within a warp are serialized, thus the cost scales linearly with the number of unique addresses read by all threads within a warp. As such, the constant cache is best when threads in the same warp access only a few distinct locations. If all threads of a warp access the same location, then constant memory can be as fast as a register access. This stall type represents about 37.1% of the total average of 80.7 cycles between issuing two instructions.",global,37.14
0,48642,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(128, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,INF,Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.,,
0,48642,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(128, 1, 1)",0,7.5,Instruction Statistics,Avg. Executed Instructions Per Scheduler,inst,59.43,,,,,
0,48642,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(128, 1, 1)",0,7.5,Instruction Statistics,Executed Instructions,inst,"3,328",,,,,
0,48642,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(128, 1, 1)",0,7.5,Instruction Statistics,Avg. Issued Instructions Per Scheduler,inst,77.71,,,,,
0,48642,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(128, 1, 1)",0,7.5,Instruction Statistics,Issued Instructions,inst,"4,352",,,,,
0,48642,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(128, 1, 1)",0,7.5,InstructionStats,,,,FPInstructions,OPT,"This kernel executes 0 fused and 256 non-fused FP32 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP32 performance could be increased by up to 50% (relative to its current performance). Check the Source page to identify where this kernel executes FP32 instructions.",global,1.464
0,48642,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(128, 1, 1)",0,7.5,Launch Statistics,Block Size,,64,,,,,
0,48642,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(128, 1, 1)",0,7.5,Launch Statistics,Function Cache Configuration,,CachePreferNone,,,,,
0,48642,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(128, 1, 1)",0,7.5,Launch Statistics,Grid Size,,128,,,,,
0,48642,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(128, 1, 1)",0,7.5,Launch Statistics,Registers Per Thread,register/thread,16,,,,,
0,48642,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(128, 1, 1)",0,7.5,Launch Statistics,Shared Memory Configuration Size,byte,"32,768",,,,,
0,48642,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(128, 1, 1)",0,7.5,Launch Statistics,Driver Shared Memory Per Block,byte/block,0,,,,,
0,48642,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(128, 1, 1)",0,7.5,Launch Statistics,Dynamic Shared Memory Per Block,byte/block,0,,,,,
0,48642,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(128, 1, 1)",0,7.5,Launch Statistics,Static Shared Memory Per Block,byte/block,0,,,,,
0,48642,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(128, 1, 1)",0,7.5,Launch Statistics,Threads,thread,"8,192",,,,,
0,48642,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(128, 1, 1)",0,7.5,Launch Statistics,Waves Per SM,,0.57,,,,,
0,48642,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(128, 1, 1)",0,7.5,Occupancy,Block Limit SM,block,16,,,,,
0,48642,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(128, 1, 1)",0,7.5,Occupancy,Block Limit Registers,block,64,,,,,
0,48642,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(128, 1, 1)",0,7.5,Occupancy,Block Limit Shared Mem,block,16,,,,,
0,48642,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(128, 1, 1)",0,7.5,Occupancy,Block Limit Warps,block,16,,,,,
0,48642,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(128, 1, 1)",0,7.5,Occupancy,Theoretical Active Warps per SM,warp,32,,,,,
0,48642,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(128, 1, 1)",0,7.5,Occupancy,Theoretical Occupancy,%,100,,,,,
0,48642,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(128, 1, 1)",0,7.5,Occupancy,Achieved Occupancy,%,50.60,,,,,
0,48642,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(128, 1, 1)",0,7.5,Occupancy,Achieved Active Warps Per SM,warp,16.19,,,,,
0,48642,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(128, 1, 1)",0,7.5,Occupancy,,,,AchievedOccupancy,OPT,The difference between calculated theoretical (100.0%) and measured achieved occupancy (50.6%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy.,global,49.4
0,48642,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(128, 1, 1)",0,7.5,Source Counters,Branch Instructions Ratio,%,0.08,,,,,
0,48642,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(128, 1, 1)",0,7.5,Source Counters,Branch Instructions,inst,256,,,,,
0,48642,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(128, 1, 1)",0,7.5,Source Counters,Branch Efficiency,%,0,,,,,
0,48642,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(128, 1, 1)",0,7.5,Source Counters,Avg. Divergent Branches,,0,,,,,
0,48719,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(64, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Frequency,cycle/second,"5,479,452,054.79",,,,,
0,48719,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(64, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Frequency,cycle/second,"1,250,642,123.29",,,,,
0,48719,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(64, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Elapsed Cycles,cycle,"2,928",,,,,
0,48719,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(64, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Memory Throughput,%,16.04,,,,,
0,48719,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(64, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Throughput,%,16.04,,,,,
0,48719,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(64, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Duration,nsecond,"2,336",,,,,
0,48719,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(64, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L1/TEX Cache Throughput,%,9.41,,,,,
0,48719,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(64, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L2 Cache Throughput,%,14.51,,,,,
0,48719,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(64, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Active Cycles,cycle,"1,555.07",,,,,
0,48719,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(64, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Compute (SM) Throughput,%,5.01,,,,,
0,48719,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(64, 1, 1)",0,7.5,SpeedOfLight,,,,SOLBottleneck,OPT,"This kernel grid is too small to fill the available resources on this device, resulting in only 0.6 full waves across all SMs. Look at Launch Statistics for more details.",,
0,48719,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(64, 1, 1)",0,7.5,SpeedOfLight_RooflineChart,,,,SOLFPRoofline,INF,The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved  close to 0% of this device's fp32 peak performance and 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.,,
0,48719,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(64, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Active,inst/cycle,0.15,,,,,
0,48719,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(64, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Elapsed,inst/cycle,0.08,,,,,
0,48719,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(64, 1, 1)",0,7.5,Compute Workload Analysis,Issue Slots Busy,%,5.00,,,,,
0,48719,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(64, 1, 1)",0,7.5,Compute Workload Analysis,Issued Ipc Active,inst/cycle,0.20,,,,,
0,48719,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(64, 1, 1)",0,7.5,Compute Workload Analysis,SM Busy,%,5.00,,,,,
0,48719,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(64, 1, 1)",0,7.5,ComputeWorkloadAnalysis,,,,HighPipeUtilization,OPT,All compute pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.,local,97.06
0,48719,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(64, 1, 1)",0,7.5,Memory Workload Analysis,Memory Throughput,byte/second,"28,123,287,671.23",,,,,
0,48719,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(64, 1, 1)",0,7.5,Memory Workload Analysis,Mem Busy,%,14.51,,,,,
0,48719,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(64, 1, 1)",0,7.5,Memory Workload Analysis,Max Bandwidth,%,16.04,,,,,
0,48719,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(64, 1, 1)",0,7.5,Memory Workload Analysis,L1/TEX Hit Rate,%,0,,,,,
0,48719,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(64, 1, 1)",0,7.5,Memory Workload Analysis,L2 Hit Rate,%,36.92,,,,,
0,48719,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(64, 1, 1)",0,7.5,Memory Workload Analysis,Mem Pipes Busy,%,5.01,,,,,
0,48719,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(64, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Chart,,,,MemoryL2Compression,WRN,The optional metric lts__average_gcomp_input_sector_success_rate.pct could not be found. Collecting it as an additional metric could enable the rule to provide more guidance.,,
0,48719,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(64, 1, 1)",0,7.5,Scheduler Statistics,One or More Eligible,%,5.03,,,,,
0,48719,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(64, 1, 1)",0,7.5,Scheduler Statistics,Issued Warp Per Scheduler,,0.05,,,,,
0,48719,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(64, 1, 1)",0,7.5,Scheduler Statistics,No Eligible,%,94.97,,,,,
0,48719,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(64, 1, 1)",0,7.5,Scheduler Statistics,Active Warps Per Scheduler,warp,3.97,,,,,
0,48719,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(64, 1, 1)",0,7.5,Scheduler Statistics,Eligible Warps Per Scheduler,warp,0.07,,,,,
0,48719,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(64, 1, 1)",0,7.5,SchedulerStats,,,,IssueSlotUtilization,OPT,"Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 19.9 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of 3.97 active warps per scheduler, but only an average of 0.07 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections.",local,83.96
0,48719,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(64, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Issued Instruction,cycle,78.86,,,,,
0,48719,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(64, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Executed Instruction,cycle,103.12,,,,,
0,48719,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(64, 1, 1)",0,7.5,Warp State Statistics,Avg. Active Threads Per Warp,,32,,,,,
0,48719,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(64, 1, 1)",0,7.5,Warp State Statistics,Avg. Not Predicated Off Threads Per Warp,,32,,,,,
0,48719,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(64, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,OPT,"On average, each warp of this kernel spends 39.3 cycles being stalled waiting for a scoreboard dependency on a L1TEX (local, global, surface, texture) operation. Find the instruction producing the data being waited upon to identify the culprit. To reduce the number of cycles waiting on L1TEX data accesses verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit rates by increasing data locality (coalescing), or by changing the cache configuration. Consider moving frequently used data to shared memory. This stall type represents about 49.8% of the total average of 78.9 cycles between issuing two instructions.",global,49.79
0,48719,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(64, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,OPT,"On average, each warp of this kernel spends 31.3 cycles being stalled waiting for an immediate constant cache (IMC) miss. A read from constant memory costs one memory read from device memory only on a cache miss; otherwise, it just costs one read from the constant cache. Immediate constants are encoded into the SASS instruction as 'c[bank][offset]'. Accesses to different addresses by threads within a warp are serialized, thus the cost scales linearly with the number of unique addresses read by all threads within a warp. As such, the constant cache is best when threads in the same warp access only a few distinct locations. If all threads of a warp access the same location, then constant memory can be as fast as a register access. This stall type represents about 39.7% of the total average of 78.9 cycles between issuing two instructions.",global,39.73
0,48719,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(64, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,INF,Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.,,
0,48719,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(64, 1, 1)",0,7.5,Instruction Statistics,Avg. Executed Instructions Per Scheduler,inst,59.43,,,,,
0,48719,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(64, 1, 1)",0,7.5,Instruction Statistics,Executed Instructions,inst,"3,328",,,,,
0,48719,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(64, 1, 1)",0,7.5,Instruction Statistics,Avg. Issued Instructions Per Scheduler,inst,77.71,,,,,
0,48719,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(64, 1, 1)",0,7.5,Instruction Statistics,Issued Instructions,inst,"4,352",,,,,
0,48719,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(64, 1, 1)",0,7.5,InstructionStats,,,,FPInstructions,OPT,"This kernel executes 0 fused and 256 non-fused FP32 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP32 performance could be increased by up to 50% (relative to its current performance). Check the Source page to identify where this kernel executes FP32 instructions.",global,1.47
0,48719,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(64, 1, 1)",0,7.5,Launch Statistics,Block Size,,128,,,,,
0,48719,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(64, 1, 1)",0,7.5,Launch Statistics,Function Cache Configuration,,CachePreferNone,,,,,
0,48719,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(64, 1, 1)",0,7.5,Launch Statistics,Grid Size,,64,,,,,
0,48719,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(64, 1, 1)",0,7.5,Launch Statistics,Registers Per Thread,register/thread,16,,,,,
0,48719,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(64, 1, 1)",0,7.5,Launch Statistics,Shared Memory Configuration Size,byte,"32,768",,,,,
0,48719,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(64, 1, 1)",0,7.5,Launch Statistics,Driver Shared Memory Per Block,byte/block,0,,,,,
0,48719,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(64, 1, 1)",0,7.5,Launch Statistics,Dynamic Shared Memory Per Block,byte/block,0,,,,,
0,48719,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(64, 1, 1)",0,7.5,Launch Statistics,Static Shared Memory Per Block,byte/block,0,,,,,
0,48719,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(64, 1, 1)",0,7.5,Launch Statistics,Threads,thread,"8,192",,,,,
0,48719,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(64, 1, 1)",0,7.5,Launch Statistics,Waves Per SM,,0.57,,,,,
0,48719,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(64, 1, 1)",0,7.5,Occupancy,Block Limit SM,block,16,,,,,
0,48719,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(64, 1, 1)",0,7.5,Occupancy,Block Limit Registers,block,32,,,,,
0,48719,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(64, 1, 1)",0,7.5,Occupancy,Block Limit Shared Mem,block,16,,,,,
0,48719,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(64, 1, 1)",0,7.5,Occupancy,Block Limit Warps,block,8,,,,,
0,48719,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(64, 1, 1)",0,7.5,Occupancy,Theoretical Active Warps per SM,warp,32,,,,,
0,48719,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(64, 1, 1)",0,7.5,Occupancy,Theoretical Occupancy,%,100,,,,,
0,48719,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(64, 1, 1)",0,7.5,Occupancy,Achieved Occupancy,%,51.09,,,,,
0,48719,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(64, 1, 1)",0,7.5,Occupancy,Achieved Active Warps Per SM,warp,16.35,,,,,
0,48719,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(64, 1, 1)",0,7.5,Occupancy,,,,AchievedOccupancy,OPT,The difference between calculated theoretical (100.0%) and measured achieved occupancy (51.1%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy.,global,48.91
0,48719,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(64, 1, 1)",0,7.5,Source Counters,Branch Instructions Ratio,%,0.08,,,,,
0,48719,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(64, 1, 1)",0,7.5,Source Counters,Branch Instructions,inst,256,,,,,
0,48719,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(64, 1, 1)",0,7.5,Source Counters,Branch Efficiency,%,0,,,,,
0,48719,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(64, 1, 1)",0,7.5,Source Counters,Avg. Divergent Branches,,0,,,,,
0,48831,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(32, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Frequency,cycle/second,"5,521,126,760.56",,,,,
0,48831,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(32, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Frequency,cycle/second,"1,257,042,253.52",,,,,
0,48831,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(32, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Elapsed Cycles,cycle,"2,859",,,,,
0,48831,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(32, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Memory Throughput,%,16.37,,,,,
0,48831,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(32, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Throughput,%,16.37,,,,,
0,48831,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(32, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Duration,nsecond,"2,272",,,,,
0,48831,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(32, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L1/TEX Cache Throughput,%,9.38,,,,,
0,48831,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(32, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L2 Cache Throughput,%,14.86,,,,,
0,48831,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(32, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Active Cycles,cycle,"1,559.36",,,,,
0,48831,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(32, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Compute (SM) Throughput,%,5.12,,,,,
0,48831,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(32, 1, 1)",0,7.5,SpeedOfLight,,,,SOLBottleneck,OPT,"This kernel grid is too small to fill the available resources on this device, resulting in only 0.6 full waves across all SMs. Look at Launch Statistics for more details.",,
0,48831,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(32, 1, 1)",0,7.5,SpeedOfLight_RooflineChart,,,,SOLFPRoofline,INF,The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved  close to 0% of this device's fp32 peak performance and 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.,,
0,48831,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(32, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Active,inst/cycle,0.15,,,,,
0,48831,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(32, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Elapsed,inst/cycle,0.08,,,,,
0,48831,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(32, 1, 1)",0,7.5,Compute Workload Analysis,Issue Slots Busy,%,4.98,,,,,
0,48831,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(32, 1, 1)",0,7.5,Compute Workload Analysis,Issued Ipc Active,inst/cycle,0.20,,,,,
0,48831,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(32, 1, 1)",0,7.5,Compute Workload Analysis,SM Busy,%,4.98,,,,,
0,48831,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(32, 1, 1)",0,7.5,ComputeWorkloadAnalysis,,,,HighPipeUtilization,OPT,All compute pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.,local,97.07
0,48831,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(32, 1, 1)",0,7.5,Memory Workload Analysis,Memory Throughput,byte/second,"28,915,492,957.75",,,,,
0,48831,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(32, 1, 1)",0,7.5,Memory Workload Analysis,Mem Busy,%,14.86,,,,,
0,48831,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(32, 1, 1)",0,7.5,Memory Workload Analysis,Max Bandwidth,%,16.37,,,,,
0,48831,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(32, 1, 1)",0,7.5,Memory Workload Analysis,L1/TEX Hit Rate,%,0,,,,,
0,48831,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(32, 1, 1)",0,7.5,Memory Workload Analysis,L2 Hit Rate,%,36.82,,,,,
0,48831,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(32, 1, 1)",0,7.5,Memory Workload Analysis,Mem Pipes Busy,%,5.12,,,,,
0,48831,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(32, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Chart,,,,MemoryL2Compression,WRN,The optional metric lts__average_gcomp_input_sector_success_rate.pct could not be found. Collecting it as an additional metric could enable the rule to provide more guidance.,,
0,48831,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(32, 1, 1)",0,7.5,Scheduler Statistics,One or More Eligible,%,5.24,,,,,
0,48831,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(32, 1, 1)",0,7.5,Scheduler Statistics,Issued Warp Per Scheduler,,0.05,,,,,
0,48831,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(32, 1, 1)",0,7.5,Scheduler Statistics,No Eligible,%,94.76,,,,,
0,48831,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(32, 1, 1)",0,7.5,Scheduler Statistics,Active Warps Per Scheduler,warp,4.68,,,,,
0,48831,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(32, 1, 1)",0,7.5,Scheduler Statistics,Eligible Warps Per Scheduler,warp,0.07,,,,,
0,48831,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(32, 1, 1)",0,7.5,SchedulerStats,,,,IssueSlotUtilization,OPT,"Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 19.1 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of 4.68 active warps per scheduler, but only an average of 0.07 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections.",local,83.63
0,48831,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(32, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Issued Instruction,cycle,89.30,,,,,
0,48831,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(32, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Executed Instruction,cycle,116.78,,,,,
0,48831,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(32, 1, 1)",0,7.5,Warp State Statistics,Avg. Active Threads Per Warp,,32,,,,,
0,48831,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(32, 1, 1)",0,7.5,Warp State Statistics,Avg. Not Predicated Off Threads Per Warp,,32,,,,,
0,48831,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(32, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,OPT,"On average, each warp of this kernel spends 39.4 cycles being stalled waiting for a scoreboard dependency on a L1TEX (local, global, surface, texture) operation. Find the instruction producing the data being waited upon to identify the culprit. To reduce the number of cycles waiting on L1TEX data accesses verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit rates by increasing data locality (coalescing), or by changing the cache configuration. Consider moving frequently used data to shared memory. This stall type represents about 44.1% of the total average of 89.3 cycles between issuing two instructions.",global,44.09
0,48831,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(32, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,OPT,"On average, each warp of this kernel spends 32.6 cycles being stalled waiting for an immediate constant cache (IMC) miss. A read from constant memory costs one memory read from device memory only on a cache miss; otherwise, it just costs one read from the constant cache. Immediate constants are encoded into the SASS instruction as 'c[bank][offset]'. Accesses to different addresses by threads within a warp are serialized, thus the cost scales linearly with the number of unique addresses read by all threads within a warp. As such, the constant cache is best when threads in the same warp access only a few distinct locations. If all threads of a warp access the same location, then constant memory can be as fast as a register access. This stall type represents about 36.5% of the total average of 89.3 cycles between issuing two instructions.",global,36.53
0,48831,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(32, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,INF,Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.,,
0,48831,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(32, 1, 1)",0,7.5,Instruction Statistics,Avg. Executed Instructions Per Scheduler,inst,59.43,,,,,
0,48831,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(32, 1, 1)",0,7.5,Instruction Statistics,Executed Instructions,inst,"3,328",,,,,
0,48831,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(32, 1, 1)",0,7.5,Instruction Statistics,Avg. Issued Instructions Per Scheduler,inst,77.71,,,,,
0,48831,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(32, 1, 1)",0,7.5,Instruction Statistics,Issued Instructions,inst,"4,352",,,,,
0,48831,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(32, 1, 1)",0,7.5,InstructionStats,,,,FPInstructions,OPT,"This kernel executes 0 fused and 256 non-fused FP32 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP32 performance could be increased by up to 50% (relative to its current performance). Check the Source page to identify where this kernel executes FP32 instructions.",global,1.466
0,48831,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(32, 1, 1)",0,7.5,Launch Statistics,Block Size,,256,,,,,
0,48831,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(32, 1, 1)",0,7.5,Launch Statistics,Function Cache Configuration,,CachePreferNone,,,,,
0,48831,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(32, 1, 1)",0,7.5,Launch Statistics,Grid Size,,32,,,,,
0,48831,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(32, 1, 1)",0,7.5,Launch Statistics,Registers Per Thread,register/thread,16,,,,,
0,48831,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(32, 1, 1)",0,7.5,Launch Statistics,Shared Memory Configuration Size,byte,"32,768",,,,,
0,48831,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(32, 1, 1)",0,7.5,Launch Statistics,Driver Shared Memory Per Block,byte/block,0,,,,,
0,48831,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(32, 1, 1)",0,7.5,Launch Statistics,Dynamic Shared Memory Per Block,byte/block,0,,,,,
0,48831,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(32, 1, 1)",0,7.5,Launch Statistics,Static Shared Memory Per Block,byte/block,0,,,,,
0,48831,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(32, 1, 1)",0,7.5,Launch Statistics,Threads,thread,"8,192",,,,,
0,48831,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(32, 1, 1)",0,7.5,Launch Statistics,Waves Per SM,,0.57,,,,,
0,48831,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(32, 1, 1)",0,7.5,Occupancy,Block Limit SM,block,16,,,,,
0,48831,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(32, 1, 1)",0,7.5,Occupancy,Block Limit Registers,block,16,,,,,
0,48831,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(32, 1, 1)",0,7.5,Occupancy,Block Limit Shared Mem,block,16,,,,,
0,48831,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(32, 1, 1)",0,7.5,Occupancy,Block Limit Warps,block,4,,,,,
0,48831,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(32, 1, 1)",0,7.5,Occupancy,Theoretical Active Warps per SM,warp,32,,,,,
0,48831,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(32, 1, 1)",0,7.5,Occupancy,Theoretical Occupancy,%,100,,,,,
0,48831,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(32, 1, 1)",0,7.5,Occupancy,Achieved Occupancy,%,52.91,,,,,
0,48831,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(32, 1, 1)",0,7.5,Occupancy,Achieved Active Warps Per SM,warp,16.93,,,,,
0,48831,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(32, 1, 1)",0,7.5,Occupancy,,,,AchievedOccupancy,OPT,The difference between calculated theoretical (100.0%) and measured achieved occupancy (52.9%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy.,global,47.09
0,48831,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(32, 1, 1)",0,7.5,Source Counters,Branch Instructions Ratio,%,0.08,,,,,
0,48831,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(32, 1, 1)",0,7.5,Source Counters,Branch Instructions,inst,256,,,,,
0,48831,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(32, 1, 1)",0,7.5,Source Counters,Branch Efficiency,%,0,,,,,
0,48831,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(32, 1, 1)",0,7.5,Source Counters,Avg. Divergent Branches,,0,,,,,
0,48911,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(16, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Frequency,cycle/second,"5,828,571,428.57",,,,,
0,48911,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(16, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Frequency,cycle/second,"1,315,401,785.71",,,,,
0,48911,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(16, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Elapsed Cycles,cycle,"2,959",,,,,
0,48911,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(16, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Memory Throughput,%,15.72,,,,,
0,48911,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(16, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Throughput,%,15.72,,,,,
0,48911,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(16, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Duration,nsecond,"2,240",,,,,
0,48911,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(16, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L1/TEX Cache Throughput,%,9.70,,,,,
0,48911,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(16, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L2 Cache Throughput,%,14.40,,,,,
0,48911,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(16, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Active Cycles,cycle,"1,508.57",,,,,
0,48911,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(16, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Compute (SM) Throughput,%,4.96,,,,,
0,48911,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(16, 1, 1)",0,7.5,SpeedOfLight,,,,SOLBottleneck,OPT,"This kernel grid is too small to fill the available resources on this device, resulting in only 0.6 full waves across all SMs. Look at Launch Statistics for more details.",,
0,48911,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(16, 1, 1)",0,7.5,SpeedOfLight_RooflineChart,,,,SOLFPRoofline,INF,The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved  close to 0% of this device's fp32 peak performance and 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.,,
0,48911,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(16, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Active,inst/cycle,0.16,,,,,
0,48911,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(16, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Elapsed,inst/cycle,0.08,,,,,
0,48911,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(16, 1, 1)",0,7.5,Compute Workload Analysis,Issue Slots Busy,%,5.15,,,,,
0,48911,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(16, 1, 1)",0,7.5,Compute Workload Analysis,Issued Ipc Active,inst/cycle,0.21,,,,,
0,48911,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(16, 1, 1)",0,7.5,Compute Workload Analysis,SM Busy,%,5.15,,,,,
0,48911,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(16, 1, 1)",0,7.5,ComputeWorkloadAnalysis,,,,HighPipeUtilization,OPT,All compute pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.,local,96.97
0,48911,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(16, 1, 1)",0,7.5,Memory Workload Analysis,Memory Throughput,byte/second,"29,328,571,428.57",,,,,
0,48911,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(16, 1, 1)",0,7.5,Memory Workload Analysis,Mem Busy,%,14.40,,,,,
0,48911,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(16, 1, 1)",0,7.5,Memory Workload Analysis,Max Bandwidth,%,15.72,,,,,
0,48911,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(16, 1, 1)",0,7.5,Memory Workload Analysis,L1/TEX Hit Rate,%,0,,,,,
0,48911,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(16, 1, 1)",0,7.5,Memory Workload Analysis,L2 Hit Rate,%,36.95,,,,,
0,48911,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(16, 1, 1)",0,7.5,Memory Workload Analysis,Mem Pipes Busy,%,4.96,,,,,
0,48911,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(16, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Chart,,,,MemoryL2Compression,WRN,The optional metric lts__average_gcomp_input_sector_success_rate.pct could not be found. Collecting it as an additional metric could enable the rule to provide more guidance.,,
0,48911,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(16, 1, 1)",0,7.5,Scheduler Statistics,One or More Eligible,%,5.31,,,,,
0,48911,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(16, 1, 1)",0,7.5,Scheduler Statistics,Issued Warp Per Scheduler,,0.05,,,,,
0,48911,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(16, 1, 1)",0,7.5,Scheduler Statistics,No Eligible,%,94.69,,,,,
0,48911,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(16, 1, 1)",0,7.5,Scheduler Statistics,Active Warps Per Scheduler,warp,4.34,,,,,
0,48911,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(16, 1, 1)",0,7.5,Scheduler Statistics,Eligible Warps Per Scheduler,warp,0.08,,,,,
0,48911,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(16, 1, 1)",0,7.5,SchedulerStats,,,,IssueSlotUtilization,OPT,"Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 18.8 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of 4.34 active warps per scheduler, but only an average of 0.08 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections.",local,84.28
0,48911,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(16, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Issued Instruction,cycle,81.72,,,,,
0,48911,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(16, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Executed Instruction,cycle,106.86,,,,,
0,48911,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(16, 1, 1)",0,7.5,Warp State Statistics,Avg. Active Threads Per Warp,,32,,,,,
0,48911,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(16, 1, 1)",0,7.5,Warp State Statistics,Avg. Not Predicated Off Threads Per Warp,,32,,,,,
0,48911,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(16, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,OPT,"On average, each warp of this kernel spends 39.0 cycles being stalled waiting for a scoreboard dependency on a L1TEX (local, global, surface, texture) operation. Find the instruction producing the data being waited upon to identify the culprit. To reduce the number of cycles waiting on L1TEX data accesses verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit rates by increasing data locality (coalescing), or by changing the cache configuration. Consider moving frequently used data to shared memory. This stall type represents about 47.7% of the total average of 81.7 cycles between issuing two instructions.",global,47.7
0,48911,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(16, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,OPT,"On average, each warp of this kernel spends 33.0 cycles being stalled waiting for an immediate constant cache (IMC) miss. A read from constant memory costs one memory read from device memory only on a cache miss; otherwise, it just costs one read from the constant cache. Immediate constants are encoded into the SASS instruction as 'c[bank][offset]'. Accesses to different addresses by threads within a warp are serialized, thus the cost scales linearly with the number of unique addresses read by all threads within a warp. As such, the constant cache is best when threads in the same warp access only a few distinct locations. If all threads of a warp access the same location, then constant memory can be as fast as a register access. This stall type represents about 40.4% of the total average of 81.7 cycles between issuing two instructions.",global,40.37
0,48911,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(16, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,INF,Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.,,
0,48911,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(16, 1, 1)",0,7.5,Instruction Statistics,Avg. Executed Instructions Per Scheduler,inst,59.43,,,,,
0,48911,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(16, 1, 1)",0,7.5,Instruction Statistics,Executed Instructions,inst,"3,328",,,,,
0,48911,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(16, 1, 1)",0,7.5,Instruction Statistics,Avg. Issued Instructions Per Scheduler,inst,77.71,,,,,
0,48911,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(16, 1, 1)",0,7.5,Instruction Statistics,Issued Instructions,inst,"4,352",,,,,
0,48911,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(16, 1, 1)",0,7.5,InstructionStats,,,,FPInstructions,OPT,"This kernel executes 0 fused and 256 non-fused FP32 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP32 performance could be increased by up to 50% (relative to its current performance). Check the Source page to identify where this kernel executes FP32 instructions.",global,1.515
0,48911,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(16, 1, 1)",0,7.5,Launch Statistics,Block Size,,512,,,,,
0,48911,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(16, 1, 1)",0,7.5,Launch Statistics,Function Cache Configuration,,CachePreferNone,,,,,
0,48911,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(16, 1, 1)",0,7.5,Launch Statistics,Grid Size,,16,,,,,
0,48911,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(16, 1, 1)",0,7.5,Launch Statistics,Registers Per Thread,register/thread,16,,,,,
0,48911,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(16, 1, 1)",0,7.5,Launch Statistics,Shared Memory Configuration Size,byte,"32,768",,,,,
0,48911,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(16, 1, 1)",0,7.5,Launch Statistics,Driver Shared Memory Per Block,byte/block,0,,,,,
0,48911,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(16, 1, 1)",0,7.5,Launch Statistics,Dynamic Shared Memory Per Block,byte/block,0,,,,,
0,48911,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(16, 1, 1)",0,7.5,Launch Statistics,Static Shared Memory Per Block,byte/block,0,,,,,
0,48911,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(16, 1, 1)",0,7.5,Launch Statistics,Threads,thread,"8,192",,,,,
0,48911,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(16, 1, 1)",0,7.5,Launch Statistics,Waves Per SM,,0.57,,,,,
0,48911,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(16, 1, 1)",0,7.5,LaunchStats,,,,LaunchConfiguration,OPT,"If you execute __syncthreads() to synchronize the threads of a block, it is recommended to have more than the achieved 1 blocks per multiprocessor. This way, blocks that aren't waiting for __syncthreads() can keep the hardware busy.",,
0,48911,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(16, 1, 1)",0,7.5,Occupancy,Block Limit SM,block,16,,,,,
0,48911,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(16, 1, 1)",0,7.5,Occupancy,Block Limit Registers,block,8,,,,,
0,48911,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(16, 1, 1)",0,7.5,Occupancy,Block Limit Shared Mem,block,16,,,,,
0,48911,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(16, 1, 1)",0,7.5,Occupancy,Block Limit Warps,block,2,,,,,
0,48911,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(16, 1, 1)",0,7.5,Occupancy,Theoretical Active Warps per SM,warp,32,,,,,
0,48911,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(16, 1, 1)",0,7.5,Occupancy,Theoretical Occupancy,%,100,,,,,
0,48911,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(16, 1, 1)",0,7.5,Occupancy,Achieved Occupancy,%,54.00,,,,,
0,48911,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(16, 1, 1)",0,7.5,Occupancy,Achieved Active Warps Per SM,warp,17.28,,,,,
0,48911,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(16, 1, 1)",0,7.5,Occupancy,,,,AchievedOccupancy,OPT,The difference between calculated theoretical (100.0%) and measured achieved occupancy (54.0%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy.,global,46.0
0,48911,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(16, 1, 1)",0,7.5,Source Counters,Branch Instructions Ratio,%,0.08,,,,,
0,48911,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(16, 1, 1)",0,7.5,Source Counters,Branch Instructions,inst,256,,,,,
0,48911,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(16, 1, 1)",0,7.5,Source Counters,Branch Efficiency,%,0,,,,,
0,48911,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(16, 1, 1)",0,7.5,Source Counters,Avg. Divergent Branches,,0,,,,,
0,48997,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(8, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Frequency,cycle/second,"5,263,157,894.74",,,,,
0,48997,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(8, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Frequency,cycle/second,"1,189,761,513.16",,,,,
0,48997,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(8, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Elapsed Cycles,cycle,"2,897",,,,,
0,48997,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(8, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Memory Throughput,%,16.04,,,,,
0,48997,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(8, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Throughput,%,16.04,,,,,
0,48997,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(8, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Duration,nsecond,"2,432",,,,,
0,48997,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(8, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L1/TEX Cache Throughput,%,16.08,,,,,
0,48997,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(8, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L2 Cache Throughput,%,14.63,,,,,
0,48997,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(8, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Active Cycles,cycle,909.64,,,,,
0,48997,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(8, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Compute (SM) Throughput,%,5.05,,,,,
0,48997,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(8, 1, 1)",0,7.5,SpeedOfLight,,,,SOLBottleneck,OPT,"This kernel grid is too small to fill the available resources on this device, resulting in only 0.6 full waves across all SMs. Look at Launch Statistics for more details.",,
0,48997,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(8, 1, 1)",0,7.5,SpeedOfLight_RooflineChart,,,,SOLFPRoofline,INF,The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved  close to 0% of this device's fp32 peak performance and 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.,,
0,48997,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(8, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Active,inst/cycle,0.26,,,,,
0,48997,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(8, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Elapsed,inst/cycle,0.08,,,,,
0,48997,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(8, 1, 1)",0,7.5,Compute Workload Analysis,Issue Slots Busy,%,8.54,,,,,
0,48997,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(8, 1, 1)",0,7.5,Compute Workload Analysis,Issued Ipc Active,inst/cycle,0.34,,,,,
0,48997,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(8, 1, 1)",0,7.5,Compute Workload Analysis,SM Busy,%,8.54,,,,,
0,48997,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(8, 1, 1)",0,7.5,ComputeWorkloadAnalysis,,,,HighPipeUtilization,OPT,All compute pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.,local,94.97
0,48997,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(8, 1, 1)",0,7.5,Memory Workload Analysis,Memory Throughput,byte/second,"27,013,157,894.74",,,,,
0,48997,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(8, 1, 1)",0,7.5,Memory Workload Analysis,Mem Busy,%,14.63,,,,,
0,48997,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(8, 1, 1)",0,7.5,Memory Workload Analysis,Max Bandwidth,%,16.04,,,,,
0,48997,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(8, 1, 1)",0,7.5,Memory Workload Analysis,L1/TEX Hit Rate,%,0,,,,,
0,48997,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(8, 1, 1)",0,7.5,Memory Workload Analysis,L2 Hit Rate,%,36.86,,,,,
0,48997,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(8, 1, 1)",0,7.5,Memory Workload Analysis,Mem Pipes Busy,%,5.05,,,,,
0,48997,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(8, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Chart,,,,MemoryL2Compression,WRN,The optional metric lts__average_gcomp_input_sector_success_rate.pct could not be found. Collecting it as an additional metric could enable the rule to provide more guidance.,,
0,48997,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(8, 1, 1)",0,7.5,Scheduler Statistics,One or More Eligible,%,8.76,,,,,
0,48997,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(8, 1, 1)",0,7.5,Scheduler Statistics,Issued Warp Per Scheduler,,0.09,,,,,
0,48997,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(8, 1, 1)",0,7.5,Scheduler Statistics,No Eligible,%,91.24,,,,,
0,48997,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(8, 1, 1)",0,7.5,Scheduler Statistics,Active Warps Per Scheduler,warp,7.11,,,,,
0,48997,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(8, 1, 1)",0,7.5,Scheduler Statistics,Eligible Warps Per Scheduler,warp,0.17,,,,,
0,48997,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(8, 1, 1)",0,7.5,SchedulerStats,,,,IssueSlotUtilization,OPT,"Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 11.4 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of 7.11 active warps per scheduler, but only an average of 0.17 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, avoid possible load imbalances due to highly different execution durations per warp. Reducing stalls indicated on the Warp State Statistics and Source Counters sections can help, too.",local,83.96
0,48997,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(8, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Issued Instruction,cycle,81.14,,,,,
0,48997,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(8, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Executed Instruction,cycle,106.10,,,,,
0,48997,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(8, 1, 1)",0,7.5,Warp State Statistics,Avg. Active Threads Per Warp,,32,,,,,
0,48997,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(8, 1, 1)",0,7.5,Warp State Statistics,Avg. Not Predicated Off Threads Per Warp,,32,,,,,
0,48997,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(8, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,OPT,"On average, each warp of this kernel spends 38.5 cycles being stalled waiting for a scoreboard dependency on a L1TEX (local, global, surface, texture) operation. Find the instruction producing the data being waited upon to identify the culprit. To reduce the number of cycles waiting on L1TEX data accesses verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit rates by increasing data locality (coalescing), or by changing the cache configuration. Consider moving frequently used data to shared memory. This stall type represents about 47.4% of the total average of 81.1 cycles between issuing two instructions.",global,47.43
0,48997,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(8, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,OPT,"On average, each warp of this kernel spends 30.8 cycles being stalled waiting for an immediate constant cache (IMC) miss. A read from constant memory costs one memory read from device memory only on a cache miss; otherwise, it just costs one read from the constant cache. Immediate constants are encoded into the SASS instruction as 'c[bank][offset]'. Accesses to different addresses by threads within a warp are serialized, thus the cost scales linearly with the number of unique addresses read by all threads within a warp. As such, the constant cache is best when threads in the same warp access only a few distinct locations. If all threads of a warp access the same location, then constant memory can be as fast as a register access. This stall type represents about 38.0% of the total average of 81.1 cycles between issuing two instructions.",global,37.96
0,48997,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(8, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,INF,Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.,,
0,48997,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(8, 1, 1)",0,7.5,Instruction Statistics,Avg. Executed Instructions Per Scheduler,inst,59.43,,,,,
0,48997,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(8, 1, 1)",0,7.5,Instruction Statistics,Executed Instructions,inst,"3,328",,,,,
0,48997,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(8, 1, 1)",0,7.5,Instruction Statistics,Avg. Issued Instructions Per Scheduler,inst,77.71,,,,,
0,48997,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(8, 1, 1)",0,7.5,Instruction Statistics,Issued Instructions,inst,"4,352",,,,,
0,48997,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(8, 1, 1)",0,7.5,InstructionStats,,,,FPInstructions,OPT,"This kernel executes 0 fused and 256 non-fused FP32 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP32 performance could be increased by up to 50% (relative to its current performance). Check the Source page to identify where this kernel executes FP32 instructions.",global,2.513
0,48997,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(8, 1, 1)",0,7.5,Launch Statistics,Block Size,,"1,024",,,,,
0,48997,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(8, 1, 1)",0,7.5,Launch Statistics,Function Cache Configuration,,CachePreferNone,,,,,
0,48997,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(8, 1, 1)",0,7.5,Launch Statistics,Grid Size,,8,,,,,
0,48997,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(8, 1, 1)",0,7.5,Launch Statistics,Registers Per Thread,register/thread,16,,,,,
0,48997,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(8, 1, 1)",0,7.5,Launch Statistics,Shared Memory Configuration Size,byte,"32,768",,,,,
0,48997,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(8, 1, 1)",0,7.5,Launch Statistics,Driver Shared Memory Per Block,byte/block,0,,,,,
0,48997,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(8, 1, 1)",0,7.5,Launch Statistics,Dynamic Shared Memory Per Block,byte/block,0,,,,,
0,48997,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(8, 1, 1)",0,7.5,Launch Statistics,Static Shared Memory Per Block,byte/block,0,,,,,
0,48997,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(8, 1, 1)",0,7.5,Launch Statistics,Threads,thread,"8,192",,,,,
0,48997,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(8, 1, 1)",0,7.5,Launch Statistics,Waves Per SM,,0.57,,,,,
0,48997,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(8, 1, 1)",0,7.5,LaunchStats,,,,LaunchConfiguration,OPT,"The grid for this launch is configured to execute only 8 blocks, which is less than the GPU's 14 multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel concurrently with other workloads, consider reducing the block size to have at least one block per multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations.",global,42.86
0,48997,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(8, 1, 1)",0,7.5,Occupancy,Block Limit SM,block,16,,,,,
0,48997,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(8, 1, 1)",0,7.5,Occupancy,Block Limit Registers,block,4,,,,,
0,48997,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(8, 1, 1)",0,7.5,Occupancy,Block Limit Shared Mem,block,16,,,,,
0,48997,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(8, 1, 1)",0,7.5,Occupancy,Block Limit Warps,block,1,,,,,
0,48997,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(8, 1, 1)",0,7.5,Occupancy,Theoretical Active Warps per SM,warp,32,,,,,
0,48997,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(8, 1, 1)",0,7.5,Occupancy,Theoretical Occupancy,%,100,,,,,
0,48997,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(8, 1, 1)",0,7.5,Occupancy,Achieved Occupancy,%,89.38,,,,,
0,48997,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(8, 1, 1)",0,7.5,Occupancy,Achieved Active Warps Per SM,warp,28.60,,,,,
0,48997,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(8, 1, 1)",0,7.5,Occupancy,,,,AchievedOccupancy,OPT,The difference between calculated theoretical (100.0%) and measured achieved occupancy (89.4%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy.,global,10.62
0,48997,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(8, 1, 1)",0,7.5,Source Counters,Branch Instructions Ratio,%,0.08,,,,,
0,48997,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(8, 1, 1)",0,7.5,Source Counters,Branch Instructions,inst,256,,,,,
0,48997,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(8, 1, 1)",0,7.5,Source Counters,Branch Efficiency,%,0,,,,,
0,48997,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(8, 1, 1)",0,7.5,Source Counters,Avg. Divergent Branches,,0,,,,,
0,49083,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(16384, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Frequency,cycle/second,"5,957,614,588.47",,,,,
0,49083,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(16384, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Frequency,cycle/second,"1,368,954,842.29",,,,,
0,49083,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(16384, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Elapsed Cycles,cycle,"89,015",,,,,
0,49083,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(16384, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Memory Throughput,%,10.53,,,,,
0,49083,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(16384, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Throughput,%,1.06,,,,,
0,49083,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(16384, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Duration,nsecond,"64,928",,,,,
0,49083,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(16384, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L1/TEX Cache Throughput,%,15.14,,,,,
0,49083,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(16384, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L2 Cache Throughput,%,8.21,,,,,
0,49083,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(16384, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Active Cycles,cycle,"61,831.29",,,,,
0,49083,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(16384, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Compute (SM) Throughput,%,10.53,,,,,
0,49083,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(16384, 1, 1)",0,7.5,SpeedOfLight,,,,SOLBottleneck,OPT,This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.,,
0,49083,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(16384, 1, 1)",0,7.5,SpeedOfLight_RooflineChart,,,,SOLFPRoofline,INF,The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved  close to 0% of this device's fp32 peak performance and 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.,,
0,49083,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(16384, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Active,inst/cycle,0.25,,,,,
0,49083,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(16384, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Elapsed,inst/cycle,0.17,,,,,
0,49083,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(16384, 1, 1)",0,7.5,Compute Workload Analysis,Issue Slots Busy,%,6.17,,,,,
0,49083,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(16384, 1, 1)",0,7.5,Compute Workload Analysis,Issued Ipc Active,inst/cycle,0.25,,,,,
0,49083,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(16384, 1, 1)",0,7.5,Compute Workload Analysis,SM Busy,%,6.31,,,,,
0,49083,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(16384, 1, 1)",0,7.5,ComputeWorkloadAnalysis,,,,HighPipeUtilization,OPT,All compute pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.,local,95.27
0,49083,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(16384, 1, 1)",0,7.5,Memory Workload Analysis,Memory Throughput,byte/second,"2,021,192,705.77",,,,,
0,49083,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(16384, 1, 1)",0,7.5,Memory Workload Analysis,Mem Busy,%,6.79,,,,,
0,49083,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(16384, 1, 1)",0,7.5,Memory Workload Analysis,Max Bandwidth,%,10.53,,,,,
0,49083,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(16384, 1, 1)",0,7.5,Memory Workload Analysis,L1/TEX Hit Rate,%,23.16,,,,,
0,49083,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(16384, 1, 1)",0,7.5,Memory Workload Analysis,L2 Hit Rate,%,95.76,,,,,
0,49083,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(16384, 1, 1)",0,7.5,Memory Workload Analysis,Mem Pipes Busy,%,10.53,,,,,
0,49083,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(16384, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Chart,,,,MemoryL2Compression,WRN,The optional metric lts__average_gcomp_input_sector_success_rate.pct could not be found. Collecting it as an additional metric could enable the rule to provide more guidance.,,
0,49083,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(16384, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for loads from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced loads and try to minimize how many cache lines need to be accessed per memory request.",global,3.365
0,49083,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(16384, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for stores from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.5 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced stores and try to minimize how many cache lines need to be accessed per memory request.",global,1.423
0,49083,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(16384, 1, 1)",0,7.5,Scheduler Statistics,One or More Eligible,%,6.87,,,,,
0,49083,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(16384, 1, 1)",0,7.5,Scheduler Statistics,Issued Warp Per Scheduler,,0.07,,,,,
0,49083,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(16384, 1, 1)",0,7.5,Scheduler Statistics,No Eligible,%,93.13,,,,,
0,49083,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(16384, 1, 1)",0,7.5,Scheduler Statistics,Active Warps Per Scheduler,warp,2.79,,,,,
0,49083,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(16384, 1, 1)",0,7.5,Scheduler Statistics,Eligible Warps Per Scheduler,warp,0.07,,,,,
0,49083,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(16384, 1, 1)",0,7.5,SchedulerStats,,,,IssueSlotUtilization,OPT,"Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 14.6 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of 2.79 active warps per scheduler, but only an average of 0.07 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections.",local,89.47
0,49083,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(16384, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Issued Instruction,cycle,40.56,,,,,
0,49083,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(16384, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Executed Instruction,cycle,40.71,,,,,
0,49083,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(16384, 1, 1)",0,7.5,Warp State Statistics,Avg. Active Threads Per Warp,,1,,,,,
0,49083,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(16384, 1, 1)",0,7.5,Warp State Statistics,Avg. Not Predicated Off Threads Per Warp,,1,,,,,
0,49083,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(16384, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,OPT,"On average, each warp of this kernel spends 31.7 cycles being stalled waiting for a scoreboard dependency on a L1TEX (local, global, surface, texture) operation. Find the instruction producing the data being waited upon to identify the culprit. To reduce the number of cycles waiting on L1TEX data accesses verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit rates by increasing data locality (coalescing), or by changing the cache configuration. Consider moving frequently used data to shared memory. This stall type represents about 78.1% of the total average of 40.6 cycles between issuing two instructions.",global,78.08
0,49083,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(16384, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,INF,Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.,,
0,49083,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(16384, 1, 1)",0,7.5,WarpStateStats,,,,ThreadDivergence,OPT,"Instructions are executed in warps, which are groups of 32 threads. Optimal instruction throughput is achieved if all 32 threads of a warp execute the same instruction. The chosen launch configuration, early thread completion, and divergent flow control can significantly lower the number of active threads in a warp per cycle. This kernel achieves an average of 1.0 threads being active per cycle.",global,10.2
0,49083,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(16384, 1, 1)",0,7.5,Instruction Statistics,Avg. Executed Instructions Per Scheduler,inst,"3,803.43",,,,,
0,49083,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(16384, 1, 1)",0,7.5,Instruction Statistics,Executed Instructions,inst,"212,992",,,,,
0,49083,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(16384, 1, 1)",0,7.5,Instruction Statistics,Avg. Issued Instructions Per Scheduler,inst,"3,817.07",,,,,
0,49083,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(16384, 1, 1)",0,7.5,Instruction Statistics,Issued Instructions,inst,"213,756",,,,,
0,49083,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(16384, 1, 1)",0,7.5,InstructionStats,,,,FPInstructions,OPT,"This kernel executes 0 fused and 16384 non-fused FP32 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP32 performance could be increased by up to 50% (relative to its current performance). Check the Source page to identify where this kernel executes FP32 instructions.",global,2.366
0,49083,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(16384, 1, 1)",0,7.5,Launch Statistics,Block Size,,1,,,,,
0,49083,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(16384, 1, 1)",0,7.5,Launch Statistics,Function Cache Configuration,,CachePreferNone,,,,,
0,49083,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(16384, 1, 1)",0,7.5,Launch Statistics,Grid Size,,"16,384",,,,,
0,49083,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(16384, 1, 1)",0,7.5,Launch Statistics,Registers Per Thread,register/thread,16,,,,,
0,49083,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(16384, 1, 1)",0,7.5,Launch Statistics,Shared Memory Configuration Size,byte,"32,768",,,,,
0,49083,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(16384, 1, 1)",0,7.5,Launch Statistics,Driver Shared Memory Per Block,byte/block,0,,,,,
0,49083,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(16384, 1, 1)",0,7.5,Launch Statistics,Dynamic Shared Memory Per Block,byte/block,0,,,,,
0,49083,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(16384, 1, 1)",0,7.5,Launch Statistics,Static Shared Memory Per Block,byte/block,0,,,,,
0,49083,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(16384, 1, 1)",0,7.5,Launch Statistics,Threads,thread,"16,384",,,,,
0,49083,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(16384, 1, 1)",0,7.5,Launch Statistics,Waves Per SM,,73.14,,,,,
0,49083,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(16384, 1, 1)",0,7.5,LaunchStats,,,,LaunchConfiguration,OPT,"Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 1 threads per block. Consequently, some threads in a warp are masked off and those hardware resources are unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256 threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to kernels that frequently call __syncthreads(). See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations.",global,96.88
0,49083,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(16384, 1, 1)",0,7.5,Occupancy,Block Limit SM,block,16,,,,,
0,49083,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(16384, 1, 1)",0,7.5,Occupancy,Block Limit Registers,block,128,,,,,
0,49083,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(16384, 1, 1)",0,7.5,Occupancy,Block Limit Shared Mem,block,16,,,,,
0,49083,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(16384, 1, 1)",0,7.5,Occupancy,Block Limit Warps,block,32,,,,,
0,49083,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(16384, 1, 1)",0,7.5,Occupancy,Theoretical Active Warps per SM,warp,16,,,,,
0,49083,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(16384, 1, 1)",0,7.5,Occupancy,Theoretical Occupancy,%,50,,,,,
0,49083,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(16384, 1, 1)",0,7.5,Occupancy,Achieved Occupancy,%,31.70,,,,,
0,49083,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(16384, 1, 1)",0,7.5,Occupancy,Achieved Active Warps Per SM,warp,10.14,,,,,
0,49083,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(16384, 1, 1)",0,7.5,Occupancy,,,,AchievedOccupancy,OPT,The difference between calculated theoretical (50.0%) and measured achieved occupancy (31.7%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy.,global,36.59
0,49083,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(16384, 1, 1)",0,7.5,Occupancy,,,,TheoreticalOccupancy,OPT,The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared memory.,global,50.0
0,49083,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(16384, 1, 1)",0,7.5,Source Counters,Branch Instructions Ratio,%,0.08,,,,,
0,49083,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(16384, 1, 1)",0,7.5,Source Counters,Branch Instructions,inst,"16,384",,,,,
0,49083,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(16384, 1, 1)",0,7.5,Source Counters,Branch Efficiency,%,0,,,,,
0,49083,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(16384, 1, 1)",0,7.5,Source Counters,Avg. Divergent Branches,,0,,,,,
0,49160,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(8192, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Frequency,cycle/second,"6,178,217,821.78",,,,,
0,49160,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(8192, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Frequency,cycle/second,"1,418,997,524.75",,,,,
0,49160,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(8192, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Elapsed Cycles,cycle,"45,917",,,,,
0,49160,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(8192, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Memory Throughput,%,10.21,,,,,
0,49160,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(8192, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Throughput,%,2.05,,,,,
0,49160,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(8192, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Duration,nsecond,"32,320",,,,,
0,49160,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(8192, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L1/TEX Cache Throughput,%,16.74,,,,,
0,49160,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(8192, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L2 Cache Throughput,%,8.58,,,,,
0,49160,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(8192, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Active Cycles,cycle,"27,960",,,,,
0,49160,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(8192, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Compute (SM) Throughput,%,10.21,,,,,
0,49160,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(8192, 1, 1)",0,7.5,SpeedOfLight,,,,SOLBottleneck,OPT,This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.,,
0,49160,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(8192, 1, 1)",0,7.5,SpeedOfLight_RooflineChart,,,,SOLFPRoofline,INF,The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved  close to 0% of this device's fp32 peak performance and 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.,,
0,49160,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(8192, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Active,inst/cycle,0.27,,,,,
0,49160,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(8192, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Elapsed,inst/cycle,0.17,,,,,
0,49160,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(8192, 1, 1)",0,7.5,Compute Workload Analysis,Issue Slots Busy,%,6.85,,,,,
0,49160,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(8192, 1, 1)",0,7.5,Compute Workload Analysis,Issued Ipc Active,inst/cycle,0.27,,,,,
0,49160,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(8192, 1, 1)",0,7.5,Compute Workload Analysis,SM Busy,%,6.98,,,,,
0,49160,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(8192, 1, 1)",0,7.5,ComputeWorkloadAnalysis,,,,HighPipeUtilization,OPT,All compute pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.,local,94.77
0,49160,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(8192, 1, 1)",0,7.5,Memory Workload Analysis,Memory Throughput,byte/second,"4,060,396,039.60",,,,,
0,49160,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(8192, 1, 1)",0,7.5,Memory Workload Analysis,Mem Busy,%,6.92,,,,,
0,49160,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(8192, 1, 1)",0,7.5,Memory Workload Analysis,Max Bandwidth,%,10.21,,,,,
0,49160,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(8192, 1, 1)",0,7.5,Memory Workload Analysis,L1/TEX Hit Rate,%,9.92,,,,,
0,49160,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(8192, 1, 1)",0,7.5,Memory Workload Analysis,L2 Hit Rate,%,91.20,,,,,
0,49160,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(8192, 1, 1)",0,7.5,Memory Workload Analysis,Mem Pipes Busy,%,10.21,,,,,
0,49160,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(8192, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Chart,,,,MemoryL2Compression,WRN,The optional metric lts__average_gcomp_input_sector_success_rate.pct could not be found. Collecting it as an additional metric could enable the rule to provide more guidance.,,
0,49160,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(8192, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for loads from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced loads and try to minimize how many cache lines need to be accessed per memory request.",global,3.413
0,49160,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(8192, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for stores from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.3 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced stores and try to minimize how many cache lines need to be accessed per memory request.",global,1.578
0,49160,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(8192, 1, 1)",0,7.5,Scheduler Statistics,One or More Eligible,%,7.48,,,,,
0,49160,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(8192, 1, 1)",0,7.5,Scheduler Statistics,Issued Warp Per Scheduler,,0.07,,,,,
0,49160,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(8192, 1, 1)",0,7.5,Scheduler Statistics,No Eligible,%,92.52,,,,,
0,49160,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(8192, 1, 1)",0,7.5,Scheduler Statistics,Active Warps Per Scheduler,warp,2.86,,,,,
0,49160,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(8192, 1, 1)",0,7.5,Scheduler Statistics,Eligible Warps Per Scheduler,warp,0.08,,,,,
0,49160,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(8192, 1, 1)",0,7.5,SchedulerStats,,,,IssueSlotUtilization,OPT,"Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 13.4 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of 2.86 active warps per scheduler, but only an average of 0.08 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections.",local,89.79
0,49160,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(8192, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Issued Instruction,cycle,38.20,,,,,
0,49160,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(8192, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Executed Instruction,cycle,38.48,,,,,
0,49160,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(8192, 1, 1)",0,7.5,Warp State Statistics,Avg. Active Threads Per Warp,,2,,,,,
0,49160,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(8192, 1, 1)",0,7.5,Warp State Statistics,Avg. Not Predicated Off Threads Per Warp,,2,,,,,
0,49160,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(8192, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,OPT,"On average, each warp of this kernel spends 29.8 cycles being stalled waiting for a scoreboard dependency on a L1TEX (local, global, surface, texture) operation. Find the instruction producing the data being waited upon to identify the culprit. To reduce the number of cycles waiting on L1TEX data accesses verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit rates by increasing data locality (coalescing), or by changing the cache configuration. Consider moving frequently used data to shared memory. This stall type represents about 77.9% of the total average of 38.2 cycles between issuing two instructions.",global,77.87
0,49160,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(8192, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,INF,Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.,,
0,49160,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(8192, 1, 1)",0,7.5,WarpStateStats,,,,ThreadDivergence,OPT,"Instructions are executed in warps, which are groups of 32 threads. Optimal instruction throughput is achieved if all 32 threads of a warp execute the same instruction. The chosen launch configuration, early thread completion, and divergent flow control can significantly lower the number of active threads in a warp per cycle. This kernel achieves an average of 2.0 threads being active per cycle.",global,9.567
0,49160,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(8192, 1, 1)",0,7.5,Instruction Statistics,Avg. Executed Instructions Per Scheduler,inst,"1,901.71",,,,,
0,49160,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(8192, 1, 1)",0,7.5,Instruction Statistics,Executed Instructions,inst,"106,496",,,,,
0,49160,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(8192, 1, 1)",0,7.5,Instruction Statistics,Avg. Issued Instructions Per Scheduler,inst,"1,915.36",,,,,
0,49160,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(8192, 1, 1)",0,7.5,Instruction Statistics,Issued Instructions,inst,"107,260",,,,,
0,49160,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(8192, 1, 1)",0,7.5,InstructionStats,,,,FPInstructions,OPT,"This kernel executes 0 fused and 8192 non-fused FP32 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP32 performance could be increased by up to 50% (relative to its current performance). Check the Source page to identify where this kernel executes FP32 instructions.",global,2.616
0,49160,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(8192, 1, 1)",0,7.5,Launch Statistics,Block Size,,2,,,,,
0,49160,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(8192, 1, 1)",0,7.5,Launch Statistics,Function Cache Configuration,,CachePreferNone,,,,,
0,49160,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(8192, 1, 1)",0,7.5,Launch Statistics,Grid Size,,"8,192",,,,,
0,49160,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(8192, 1, 1)",0,7.5,Launch Statistics,Registers Per Thread,register/thread,16,,,,,
0,49160,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(8192, 1, 1)",0,7.5,Launch Statistics,Shared Memory Configuration Size,byte,"32,768",,,,,
0,49160,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(8192, 1, 1)",0,7.5,Launch Statistics,Driver Shared Memory Per Block,byte/block,0,,,,,
0,49160,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(8192, 1, 1)",0,7.5,Launch Statistics,Dynamic Shared Memory Per Block,byte/block,0,,,,,
0,49160,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(8192, 1, 1)",0,7.5,Launch Statistics,Static Shared Memory Per Block,byte/block,0,,,,,
0,49160,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(8192, 1, 1)",0,7.5,Launch Statistics,Threads,thread,"16,384",,,,,
0,49160,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(8192, 1, 1)",0,7.5,Launch Statistics,Waves Per SM,,36.57,,,,,
0,49160,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(8192, 1, 1)",0,7.5,LaunchStats,,,,LaunchConfiguration,OPT,"Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 2 threads per block. Consequently, some threads in a warp are masked off and those hardware resources are unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256 threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to kernels that frequently call __syncthreads(). See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations.",global,93.75
0,49160,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(8192, 1, 1)",0,7.5,Occupancy,Block Limit SM,block,16,,,,,
0,49160,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(8192, 1, 1)",0,7.5,Occupancy,Block Limit Registers,block,128,,,,,
0,49160,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(8192, 1, 1)",0,7.5,Occupancy,Block Limit Shared Mem,block,16,,,,,
0,49160,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(8192, 1, 1)",0,7.5,Occupancy,Block Limit Warps,block,32,,,,,
0,49160,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(8192, 1, 1)",0,7.5,Occupancy,Theoretical Active Warps per SM,warp,16,,,,,
0,49160,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(8192, 1, 1)",0,7.5,Occupancy,Theoretical Occupancy,%,50,,,,,
0,49160,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(8192, 1, 1)",0,7.5,Occupancy,Achieved Occupancy,%,33.92,,,,,
0,49160,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(8192, 1, 1)",0,7.5,Occupancy,Achieved Active Warps Per SM,warp,10.85,,,,,
0,49160,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(8192, 1, 1)",0,7.5,Occupancy,,,,AchievedOccupancy,OPT,The difference between calculated theoretical (50.0%) and measured achieved occupancy (33.9%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy.,global,32.16
0,49160,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(8192, 1, 1)",0,7.5,Occupancy,,,,TheoreticalOccupancy,OPT,The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared memory.,global,50.0
0,49160,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(8192, 1, 1)",0,7.5,Source Counters,Branch Instructions Ratio,%,0.08,,,,,
0,49160,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(8192, 1, 1)",0,7.5,Source Counters,Branch Instructions,inst,"8,192",,,,,
0,49160,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(8192, 1, 1)",0,7.5,Source Counters,Branch Efficiency,%,0,,,,,
0,49160,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(8192, 1, 1)",0,7.5,Source Counters,Avg. Divergent Branches,,0,,,,,
0,49244,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(4096, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Frequency,cycle/second,"6,081,784,386.62",,,,,
0,49244,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(4096, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Frequency,cycle/second,"1,396,665,892.19",,,,,
0,49244,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(4096, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Elapsed Cycles,cycle,"24,079",,,,,
0,49244,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(4096, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Memory Throughput,%,9.73,,,,,
0,49244,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(4096, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Throughput,%,3.92,,,,,
0,49244,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(4096, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Duration,nsecond,"17,216",,,,,
0,49244,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(4096, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L1/TEX Cache Throughput,%,16.47,,,,,
0,49244,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(4096, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L2 Cache Throughput,%,8.44,,,,,
0,49244,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(4096, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Active Cycles,cycle,"14,214.36",,,,,
0,49244,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(4096, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Compute (SM) Throughput,%,9.73,,,,,
0,49244,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(4096, 1, 1)",0,7.5,SpeedOfLight,,,,SOLBottleneck,OPT,This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.,,
0,49244,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(4096, 1, 1)",0,7.5,SpeedOfLight_RooflineChart,,,,SOLFPRoofline,INF,The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved  close to 0% of this device's fp32 peak performance and 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.,,
0,49244,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(4096, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Active,inst/cycle,0.27,,,,,
0,49244,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(4096, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Elapsed,inst/cycle,0.16,,,,,
0,49244,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(4096, 1, 1)",0,7.5,Compute Workload Analysis,Issue Slots Busy,%,6.79,,,,,
0,49244,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(4096, 1, 1)",0,7.5,Compute Workload Analysis,Issued Ipc Active,inst/cycle,0.27,,,,,
0,49244,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(4096, 1, 1)",0,7.5,Compute Workload Analysis,SM Busy,%,6.86,,,,,
0,49244,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(4096, 1, 1)",0,7.5,ComputeWorkloadAnalysis,,,,HighPipeUtilization,OPT,All compute pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.,local,94.85
0,49244,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(4096, 1, 1)",0,7.5,Memory Workload Analysis,Memory Throughput,byte/second,"7,622,676,579.93",,,,,
0,49244,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(4096, 1, 1)",0,7.5,Memory Workload Analysis,Mem Busy,%,6.60,,,,,
0,49244,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(4096, 1, 1)",0,7.5,Memory Workload Analysis,Max Bandwidth,%,9.73,,,,,
0,49244,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(4096, 1, 1)",0,7.5,Memory Workload Analysis,L1/TEX Hit Rate,%,4.83,,,,,
0,49244,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(4096, 1, 1)",0,7.5,Memory Workload Analysis,L2 Hit Rate,%,83.82,,,,,
0,49244,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(4096, 1, 1)",0,7.5,Memory Workload Analysis,Mem Pipes Busy,%,9.73,,,,,
0,49244,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(4096, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Chart,,,,MemoryL2Compression,WRN,The optional metric lts__average_gcomp_input_sector_success_rate.pct could not be found. Collecting it as an additional metric could enable the rule to provide more guidance.,,
0,49244,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(4096, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for loads from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced loads and try to minimize how many cache lines need to be accessed per memory request.",global,3.25
0,49244,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(4096, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for stores from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.1 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced stores and try to minimize how many cache lines need to be accessed per memory request.",global,1.589
0,49244,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(4096, 1, 1)",0,7.5,Scheduler Statistics,One or More Eligible,%,7.74,,,,,
0,49244,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(4096, 1, 1)",0,7.5,Scheduler Statistics,Issued Warp Per Scheduler,,0.08,,,,,
0,49244,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(4096, 1, 1)",0,7.5,Scheduler Statistics,No Eligible,%,92.26,,,,,
0,49244,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(4096, 1, 1)",0,7.5,Scheduler Statistics,Active Warps Per Scheduler,warp,2.92,,,,,
0,49244,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(4096, 1, 1)",0,7.5,Scheduler Statistics,Eligible Warps Per Scheduler,warp,0.08,,,,,
0,49244,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(4096, 1, 1)",0,7.5,SchedulerStats,,,,IssueSlotUtilization,OPT,"Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 12.9 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of 2.92 active warps per scheduler, but only an average of 0.08 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections.",local,90.27
0,49244,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(4096, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Issued Instruction,cycle,37.75,,,,,
0,49244,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(4096, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Executed Instruction,cycle,38.29,,,,,
0,49244,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(4096, 1, 1)",0,7.5,Warp State Statistics,Avg. Active Threads Per Warp,,4,,,,,
0,49244,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(4096, 1, 1)",0,7.5,Warp State Statistics,Avg. Not Predicated Off Threads Per Warp,,4,,,,,
0,49244,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(4096, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,OPT,"On average, each warp of this kernel spends 29.3 cycles being stalled waiting for a scoreboard dependency on a L1TEX (local, global, surface, texture) operation. Find the instruction producing the data being waited upon to identify the culprit. To reduce the number of cycles waiting on L1TEX data accesses verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit rates by increasing data locality (coalescing), or by changing the cache configuration. Consider moving frequently used data to shared memory. This stall type represents about 77.7% of the total average of 37.7 cycles between issuing two instructions.",global,77.68
0,49244,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(4096, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,INF,Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.,,
0,49244,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(4096, 1, 1)",0,7.5,WarpStateStats,,,,ThreadDivergence,OPT,"Instructions are executed in warps, which are groups of 32 threads. Optimal instruction throughput is achieved if all 32 threads of a warp execute the same instruction. The chosen launch configuration, early thread completion, and divergent flow control can significantly lower the number of active threads in a warp per cycle. This kernel achieves an average of 4.0 threads being active per cycle.",global,8.516
0,49244,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(4096, 1, 1)",0,7.5,Instruction Statistics,Avg. Executed Instructions Per Scheduler,inst,950.86,,,,,
0,49244,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(4096, 1, 1)",0,7.5,Instruction Statistics,Executed Instructions,inst,"53,248",,,,,
0,49244,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(4096, 1, 1)",0,7.5,Instruction Statistics,Avg. Issued Instructions Per Scheduler,inst,964.50,,,,,
0,49244,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(4096, 1, 1)",0,7.5,Instruction Statistics,Issued Instructions,inst,"54,012",,,,,
0,49244,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(4096, 1, 1)",0,7.5,InstructionStats,,,,FPInstructions,OPT,"This kernel executes 0 fused and 4096 non-fused FP32 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP32 performance could be increased by up to 50% (relative to its current performance). Check the Source page to identify where this kernel executes FP32 instructions.",global,2.573
0,49244,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(4096, 1, 1)",0,7.5,Launch Statistics,Block Size,,4,,,,,
0,49244,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(4096, 1, 1)",0,7.5,Launch Statistics,Function Cache Configuration,,CachePreferNone,,,,,
0,49244,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(4096, 1, 1)",0,7.5,Launch Statistics,Grid Size,,"4,096",,,,,
0,49244,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(4096, 1, 1)",0,7.5,Launch Statistics,Registers Per Thread,register/thread,16,,,,,
0,49244,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(4096, 1, 1)",0,7.5,Launch Statistics,Shared Memory Configuration Size,byte,"32,768",,,,,
0,49244,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(4096, 1, 1)",0,7.5,Launch Statistics,Driver Shared Memory Per Block,byte/block,0,,,,,
0,49244,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(4096, 1, 1)",0,7.5,Launch Statistics,Dynamic Shared Memory Per Block,byte/block,0,,,,,
0,49244,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(4096, 1, 1)",0,7.5,Launch Statistics,Static Shared Memory Per Block,byte/block,0,,,,,
0,49244,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(4096, 1, 1)",0,7.5,Launch Statistics,Threads,thread,"16,384",,,,,
0,49244,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(4096, 1, 1)",0,7.5,Launch Statistics,Waves Per SM,,18.29,,,,,
0,49244,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(4096, 1, 1)",0,7.5,LaunchStats,,,,LaunchConfiguration,OPT,"Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 4 threads per block. Consequently, some threads in a warp are masked off and those hardware resources are unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256 threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to kernels that frequently call __syncthreads(). See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations.",global,87.5
0,49244,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(4096, 1, 1)",0,7.5,Occupancy,Block Limit SM,block,16,,,,,
0,49244,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(4096, 1, 1)",0,7.5,Occupancy,Block Limit Registers,block,128,,,,,
0,49244,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(4096, 1, 1)",0,7.5,Occupancy,Block Limit Shared Mem,block,16,,,,,
0,49244,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(4096, 1, 1)",0,7.5,Occupancy,Block Limit Warps,block,32,,,,,
0,49244,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(4096, 1, 1)",0,7.5,Occupancy,Theoretical Active Warps per SM,warp,16,,,,,
0,49244,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(4096, 1, 1)",0,7.5,Occupancy,Theoretical Occupancy,%,50,,,,,
0,49244,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(4096, 1, 1)",0,7.5,Occupancy,Achieved Occupancy,%,33.83,,,,,
0,49244,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(4096, 1, 1)",0,7.5,Occupancy,Achieved Active Warps Per SM,warp,10.82,,,,,
0,49244,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(4096, 1, 1)",0,7.5,Occupancy,,,,AchievedOccupancy,OPT,The difference between calculated theoretical (50.0%) and measured achieved occupancy (33.8%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy.,global,32.35
0,49244,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(4096, 1, 1)",0,7.5,Occupancy,,,,TheoreticalOccupancy,OPT,The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared memory.,global,50.0
0,49244,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(4096, 1, 1)",0,7.5,Source Counters,Branch Instructions Ratio,%,0.08,,,,,
0,49244,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(4096, 1, 1)",0,7.5,Source Counters,Branch Instructions,inst,"4,096",,,,,
0,49244,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(4096, 1, 1)",0,7.5,Source Counters,Branch Efficiency,%,0,,,,,
0,49244,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(4096, 1, 1)",0,7.5,Source Counters,Avg. Divergent Branches,,0,,,,,
0,49321,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(2048, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Frequency,cycle/second,"6,112,676,056.34",,,,,
0,49321,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(2048, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Frequency,cycle/second,"1,403,224,031.69",,,,,
0,49321,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(2048, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Elapsed Cycles,cycle,"12,777",,,,,
0,49321,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(2048, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Memory Throughput,%,9.17,,,,,
0,49321,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(2048, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Throughput,%,7.38,,,,,
0,49321,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(2048, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Duration,nsecond,"9,088",,,,,
0,49321,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(2048, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L1/TEX Cache Throughput,%,14.82,,,,,
0,49321,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(2048, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L2 Cache Throughput,%,6.47,,,,,
0,49321,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(2048, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Active Cycles,cycle,"7,898.29",,,,,
0,49321,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(2048, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Compute (SM) Throughput,%,9.17,,,,,
0,49321,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(2048, 1, 1)",0,7.5,SpeedOfLight,,,,SOLBottleneck,OPT,This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.,,
0,49321,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(2048, 1, 1)",0,7.5,SpeedOfLight_RooflineChart,,,,SOLFPRoofline,INF,The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved  close to 0% of this device's fp32 peak performance and 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.,,
0,49321,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(2048, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Active,inst/cycle,0.24,,,,,
0,49321,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(2048, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Elapsed,inst/cycle,0.15,,,,,
0,49321,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(2048, 1, 1)",0,7.5,Compute Workload Analysis,Issue Slots Busy,%,6.19,,,,,
0,49321,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(2048, 1, 1)",0,7.5,Compute Workload Analysis,Issued Ipc Active,inst/cycle,0.25,,,,,
0,49321,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(2048, 1, 1)",0,7.5,Compute Workload Analysis,SM Busy,%,6.19,,,,,
0,49321,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(2048, 1, 1)",0,7.5,ComputeWorkloadAnalysis,,,,HighPipeUtilization,OPT,All compute pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.,local,95.37
0,49321,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(2048, 1, 1)",0,7.5,Memory Workload Analysis,Memory Throughput,byte/second,"14,440,140,845.07",,,,,
0,49321,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(2048, 1, 1)",0,7.5,Memory Workload Analysis,Mem Busy,%,6.47,,,,,
0,49321,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(2048, 1, 1)",0,7.5,Memory Workload Analysis,Max Bandwidth,%,9.17,,,,,
0,49321,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(2048, 1, 1)",0,7.5,Memory Workload Analysis,L1/TEX Hit Rate,%,2.13,,,,,
0,49321,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(2048, 1, 1)",0,7.5,Memory Workload Analysis,L2 Hit Rate,%,64.65,,,,,
0,49321,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(2048, 1, 1)",0,7.5,Memory Workload Analysis,Mem Pipes Busy,%,9.17,,,,,
0,49321,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(2048, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Chart,,,,MemoryL2Compression,WRN,The optional metric lts__average_gcomp_input_sector_success_rate.pct could not be found. Collecting it as an additional metric could enable the rule to provide more guidance.,,
0,49321,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(2048, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for loads from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced loads and try to minimize how many cache lines need to be accessed per memory request.",global,3.123
0,49321,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(2048, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for stores from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.1 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced stores and try to minimize how many cache lines need to be accessed per memory request.",global,1.542
0,49321,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(2048, 1, 1)",0,7.5,Scheduler Statistics,One or More Eligible,%,7.11,,,,,
0,49321,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(2048, 1, 1)",0,7.5,Scheduler Statistics,Issued Warp Per Scheduler,,0.07,,,,,
0,49321,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(2048, 1, 1)",0,7.5,Scheduler Statistics,No Eligible,%,92.89,,,,,
0,49321,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(2048, 1, 1)",0,7.5,Scheduler Statistics,Active Warps Per Scheduler,warp,3.02,,,,,
0,49321,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(2048, 1, 1)",0,7.5,Scheduler Statistics,Eligible Warps Per Scheduler,warp,0.07,,,,,
0,49321,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(2048, 1, 1)",0,7.5,SchedulerStats,,,,IssueSlotUtilization,OPT,"Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 14.1 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of 3.02 active warps per scheduler, but only an average of 0.07 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections.",local,90.83
0,49321,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(2048, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Issued Instruction,cycle,42.42,,,,,
0,49321,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(2048, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Executed Instruction,cycle,43.64,,,,,
0,49321,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(2048, 1, 1)",0,7.5,Warp State Statistics,Avg. Active Threads Per Warp,,8,,,,,
0,49321,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(2048, 1, 1)",0,7.5,Warp State Statistics,Avg. Not Predicated Off Threads Per Warp,,8,,,,,
0,49321,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(2048, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,OPT,"On average, each warp of this kernel spends 29.0 cycles being stalled waiting for a scoreboard dependency on a L1TEX (local, global, surface, texture) operation. Find the instruction producing the data being waited upon to identify the culprit. To reduce the number of cycles waiting on L1TEX data accesses verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit rates by increasing data locality (coalescing), or by changing the cache configuration. Consider moving frequently used data to shared memory. This stall type represents about 68.4% of the total average of 42.4 cycles between issuing two instructions.",global,68.37
0,49321,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(2048, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,INF,Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.,,
0,49321,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(2048, 1, 1)",0,7.5,WarpStateStats,,,,ThreadDivergence,OPT,"Instructions are executed in warps, which are groups of 32 threads. Optimal instruction throughput is achieved if all 32 threads of a warp execute the same instruction. The chosen launch configuration, early thread completion, and divergent flow control can significantly lower the number of active threads in a warp per cycle. This kernel achieves an average of 8.0 threads being active per cycle.",global,6.881
0,49321,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(2048, 1, 1)",0,7.5,Instruction Statistics,Avg. Executed Instructions Per Scheduler,inst,475.43,,,,,
0,49321,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(2048, 1, 1)",0,7.5,Instruction Statistics,Executed Instructions,inst,"26,624",,,,,
0,49321,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(2048, 1, 1)",0,7.5,Instruction Statistics,Avg. Issued Instructions Per Scheduler,inst,489.07,,,,,
0,49321,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(2048, 1, 1)",0,7.5,Instruction Statistics,Issued Instructions,inst,"27,388",,,,,
0,49321,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(2048, 1, 1)",0,7.5,InstructionStats,,,,FPInstructions,OPT,"This kernel executes 0 fused and 2048 non-fused FP32 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP32 performance could be increased by up to 50% (relative to its current performance). Check the Source page to identify where this kernel executes FP32 instructions.",global,2.315
0,49321,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(2048, 1, 1)",0,7.5,Launch Statistics,Block Size,,8,,,,,
0,49321,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(2048, 1, 1)",0,7.5,Launch Statistics,Function Cache Configuration,,CachePreferNone,,,,,
0,49321,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(2048, 1, 1)",0,7.5,Launch Statistics,Grid Size,,"2,048",,,,,
0,49321,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(2048, 1, 1)",0,7.5,Launch Statistics,Registers Per Thread,register/thread,16,,,,,
0,49321,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(2048, 1, 1)",0,7.5,Launch Statistics,Shared Memory Configuration Size,byte,"32,768",,,,,
0,49321,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(2048, 1, 1)",0,7.5,Launch Statistics,Driver Shared Memory Per Block,byte/block,0,,,,,
0,49321,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(2048, 1, 1)",0,7.5,Launch Statistics,Dynamic Shared Memory Per Block,byte/block,0,,,,,
0,49321,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(2048, 1, 1)",0,7.5,Launch Statistics,Static Shared Memory Per Block,byte/block,0,,,,,
0,49321,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(2048, 1, 1)",0,7.5,Launch Statistics,Threads,thread,"16,384",,,,,
0,49321,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(2048, 1, 1)",0,7.5,Launch Statistics,Waves Per SM,,9.14,,,,,
0,49321,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(2048, 1, 1)",0,7.5,LaunchStats,,,,LaunchConfiguration,OPT,"Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 8 threads per block. Consequently, some threads in a warp are masked off and those hardware resources are unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256 threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to kernels that frequently call __syncthreads(). See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations.",global,75.0
0,49321,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(2048, 1, 1)",0,7.5,Occupancy,Block Limit SM,block,16,,,,,
0,49321,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(2048, 1, 1)",0,7.5,Occupancy,Block Limit Registers,block,128,,,,,
0,49321,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(2048, 1, 1)",0,7.5,Occupancy,Block Limit Shared Mem,block,16,,,,,
0,49321,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(2048, 1, 1)",0,7.5,Occupancy,Block Limit Warps,block,32,,,,,
0,49321,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(2048, 1, 1)",0,7.5,Occupancy,Theoretical Active Warps per SM,warp,16,,,,,
0,49321,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(2048, 1, 1)",0,7.5,Occupancy,Theoretical Occupancy,%,50,,,,,
0,49321,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(2048, 1, 1)",0,7.5,Occupancy,Achieved Occupancy,%,33.12,,,,,
0,49321,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(2048, 1, 1)",0,7.5,Occupancy,Achieved Active Warps Per SM,warp,10.60,,,,,
0,49321,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(2048, 1, 1)",0,7.5,Occupancy,,,,AchievedOccupancy,OPT,The difference between calculated theoretical (50.0%) and measured achieved occupancy (33.1%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy.,global,33.77
0,49321,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(2048, 1, 1)",0,7.5,Occupancy,,,,TheoreticalOccupancy,OPT,The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared memory.,global,50.0
0,49321,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(2048, 1, 1)",0,7.5,Source Counters,Branch Instructions Ratio,%,0.08,,,,,
0,49321,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(2048, 1, 1)",0,7.5,Source Counters,Branch Instructions,inst,"2,048",,,,,
0,49321,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(2048, 1, 1)",0,7.5,Source Counters,Branch Efficiency,%,0,,,,,
0,49321,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(2048, 1, 1)",0,7.5,Source Counters,Avg. Divergent Branches,,0,,,,,
0,49406,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(1024, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Frequency,cycle/second,"5,617,021,276.60",,,,,
0,49406,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(1024, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Frequency,cycle/second,"1,285,488,696.81",,,,,
0,49406,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(1024, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Elapsed Cycles,cycle,"7,752",,,,,
0,49406,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(1024, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Memory Throughput,%,12.14,,,,,
0,49406,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(1024, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Throughput,%,12.14,,,,,
0,49406,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(1024, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Duration,nsecond,"6,016",,,,,
0,49406,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(1024, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L1/TEX Cache Throughput,%,13.72,,,,,
0,49406,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(1024, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L2 Cache Throughput,%,10.66,,,,,
0,49406,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(1024, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Active Cycles,cycle,"4,265.29",,,,,
0,49406,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(1024, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Compute (SM) Throughput,%,7.56,,,,,
0,49406,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(1024, 1, 1)",0,7.5,SpeedOfLight,,,,SOLBottleneck,OPT,This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.,,
0,49406,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(1024, 1, 1)",0,7.5,SpeedOfLight_RooflineChart,,,,SOLFPRoofline,INF,The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved  close to 0% of this device's fp32 peak performance and 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.,,
0,49406,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(1024, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Active,inst/cycle,0.22,,,,,
0,49406,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(1024, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Elapsed,inst/cycle,0.12,,,,,
0,49406,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(1024, 1, 1)",0,7.5,Compute Workload Analysis,Issue Slots Busy,%,5.89,,,,,
0,49406,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(1024, 1, 1)",0,7.5,Compute Workload Analysis,Issued Ipc Active,inst/cycle,0.24,,,,,
0,49406,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(1024, 1, 1)",0,7.5,Compute Workload Analysis,SM Busy,%,5.89,,,,,
0,49406,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(1024, 1, 1)",0,7.5,ComputeWorkloadAnalysis,,,,HighPipeUtilization,OPT,All compute pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.,local,95.71
0,49406,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(1024, 1, 1)",0,7.5,Memory Workload Analysis,Memory Throughput,byte/second,"21,813,829,787.23",,,,,
0,49406,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(1024, 1, 1)",0,7.5,Memory Workload Analysis,Mem Busy,%,10.66,,,,,
0,49406,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(1024, 1, 1)",0,7.5,Memory Workload Analysis,Max Bandwidth,%,12.14,,,,,
0,49406,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(1024, 1, 1)",0,7.5,Memory Workload Analysis,L1/TEX Hit Rate,%,3.71,,,,,
0,49406,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(1024, 1, 1)",0,7.5,Memory Workload Analysis,L2 Hit Rate,%,35.63,,,,,
0,49406,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(1024, 1, 1)",0,7.5,Memory Workload Analysis,Mem Pipes Busy,%,7.56,,,,,
0,49406,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(1024, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Chart,,,,MemoryL2Compression,WRN,The optional metric lts__average_gcomp_input_sector_success_rate.pct could not be found. Collecting it as an additional metric could enable the rule to provide more guidance.,,
0,49406,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(1024, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for loads from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 2.2 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced loads and try to minimize how many cache lines need to be accessed per memory request.",global,3.155
0,49406,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(1024, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for stores from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 2.2 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced stores and try to minimize how many cache lines need to be accessed per memory request.",global,1.552
0,49406,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(1024, 1, 1)",0,7.5,Scheduler Statistics,One or More Eligible,%,6.14,,,,,
0,49406,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(1024, 1, 1)",0,7.5,Scheduler Statistics,Issued Warp Per Scheduler,,0.06,,,,,
0,49406,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(1024, 1, 1)",0,7.5,Scheduler Statistics,No Eligible,%,93.86,,,,,
0,49406,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(1024, 1, 1)",0,7.5,Scheduler Statistics,Active Warps Per Scheduler,warp,2.85,,,,,
0,49406,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(1024, 1, 1)",0,7.5,Scheduler Statistics,Eligible Warps Per Scheduler,warp,0.07,,,,,
0,49406,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(1024, 1, 1)",0,7.5,SchedulerStats,,,,IssueSlotUtilization,OPT,"Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 16.3 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of 2.85 active warps per scheduler, but only an average of 0.07 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections.",local,87.86
0,49406,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(1024, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Issued Instruction,cycle,46.47,,,,,
0,49406,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(1024, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Executed Instruction,cycle,49.14,,,,,
0,49406,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(1024, 1, 1)",0,7.5,Warp State Statistics,Avg. Active Threads Per Warp,,16,,,,,
0,49406,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(1024, 1, 1)",0,7.5,Warp State Statistics,Avg. Not Predicated Off Threads Per Warp,,16,,,,,
0,49406,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(1024, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,OPT,"On average, each warp of this kernel spends 32.1 cycles being stalled waiting for a scoreboard dependency on a L1TEX (local, global, surface, texture) operation. Find the instruction producing the data being waited upon to identify the culprit. To reduce the number of cycles waiting on L1TEX data accesses verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit rates by increasing data locality (coalescing), or by changing the cache configuration. Consider moving frequently used data to shared memory. This stall type represents about 69.1% of the total average of 46.5 cycles between issuing two instructions.",global,69.08
0,49406,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(1024, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,INF,Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.,,
0,49406,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(1024, 1, 1)",0,7.5,WarpStateStats,,,,ThreadDivergence,OPT,"Instructions are executed in warps, which are groups of 32 threads. Optimal instruction throughput is achieved if all 32 threads of a warp execute the same instruction. The chosen launch configuration, early thread completion, and divergent flow control can significantly lower the number of active threads in a warp per cycle. This kernel achieves an average of 16.0 threads being active per cycle.",global,3.782
0,49406,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(1024, 1, 1)",0,7.5,Instruction Statistics,Avg. Executed Instructions Per Scheduler,inst,237.71,,,,,
0,49406,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(1024, 1, 1)",0,7.5,Instruction Statistics,Executed Instructions,inst,"13,312",,,,,
0,49406,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(1024, 1, 1)",0,7.5,Instruction Statistics,Avg. Issued Instructions Per Scheduler,inst,251.36,,,,,
0,49406,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(1024, 1, 1)",0,7.5,Instruction Statistics,Issued Instructions,inst,"14,076",,,,,
0,49406,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(1024, 1, 1)",0,7.5,InstructionStats,,,,FPInstructions,OPT,"This kernel executes 0 fused and 1024 non-fused FP32 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP32 performance could be increased by up to 50% (relative to its current performance). Check the Source page to identify where this kernel executes FP32 instructions.",global,2.144
0,49406,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(1024, 1, 1)",0,7.5,Launch Statistics,Block Size,,16,,,,,
0,49406,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(1024, 1, 1)",0,7.5,Launch Statistics,Function Cache Configuration,,CachePreferNone,,,,,
0,49406,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(1024, 1, 1)",0,7.5,Launch Statistics,Grid Size,,"1,024",,,,,
0,49406,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(1024, 1, 1)",0,7.5,Launch Statistics,Registers Per Thread,register/thread,16,,,,,
0,49406,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(1024, 1, 1)",0,7.5,Launch Statistics,Shared Memory Configuration Size,byte,"32,768",,,,,
0,49406,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(1024, 1, 1)",0,7.5,Launch Statistics,Driver Shared Memory Per Block,byte/block,0,,,,,
0,49406,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(1024, 1, 1)",0,7.5,Launch Statistics,Dynamic Shared Memory Per Block,byte/block,0,,,,,
0,49406,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(1024, 1, 1)",0,7.5,Launch Statistics,Static Shared Memory Per Block,byte/block,0,,,,,
0,49406,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(1024, 1, 1)",0,7.5,Launch Statistics,Threads,thread,"16,384",,,,,
0,49406,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(1024, 1, 1)",0,7.5,Launch Statistics,Waves Per SM,,4.57,,,,,
0,49406,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(1024, 1, 1)",0,7.5,LaunchStats,,,,LaunchConfiguration,OPT,"Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 16 threads per block. Consequently, some threads in a warp are masked off and those hardware resources are unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256 threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to kernels that frequently call __syncthreads(). See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations.",global,50.0
0,49406,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(1024, 1, 1)",0,7.5,LaunchStats,,,,LaunchConfiguration,OPT,"A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical occupancy of the kernel. This kernel launch results in 4 full waves and a partial wave of 127 thread blocks. Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for up to 20.0% of the total kernel runtime with a lower occupancy of 28.0%. Try launching a grid with no partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for a grid. See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations.",global,20.0
0,49406,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(1024, 1, 1)",0,7.5,Occupancy,Block Limit SM,block,16,,,,,
0,49406,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(1024, 1, 1)",0,7.5,Occupancy,Block Limit Registers,block,128,,,,,
0,49406,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(1024, 1, 1)",0,7.5,Occupancy,Block Limit Shared Mem,block,16,,,,,
0,49406,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(1024, 1, 1)",0,7.5,Occupancy,Block Limit Warps,block,32,,,,,
0,49406,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(1024, 1, 1)",0,7.5,Occupancy,Theoretical Active Warps per SM,warp,16,,,,,
0,49406,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(1024, 1, 1)",0,7.5,Occupancy,Theoretical Occupancy,%,50,,,,,
0,49406,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(1024, 1, 1)",0,7.5,Occupancy,Achieved Occupancy,%,35.98,,,,,
0,49406,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(1024, 1, 1)",0,7.5,Occupancy,Achieved Active Warps Per SM,warp,11.51,,,,,
0,49406,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(1024, 1, 1)",0,7.5,Occupancy,,,,AchievedOccupancy,OPT,The difference between calculated theoretical (50.0%) and measured achieved occupancy (36.0%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy.,global,28.03
0,49406,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(1024, 1, 1)",0,7.5,Occupancy,,,,TheoreticalOccupancy,OPT,The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared memory.,global,50.0
0,49406,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(1024, 1, 1)",0,7.5,Source Counters,Branch Instructions Ratio,%,0.08,,,,,
0,49406,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(1024, 1, 1)",0,7.5,Source Counters,Branch Instructions,inst,"1,024",,,,,
0,49406,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(1024, 1, 1)",0,7.5,Source Counters,Branch Efficiency,%,0,,,,,
0,49406,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(1024, 1, 1)",0,7.5,Source Counters,Avg. Divergent Branches,,0,,,,,
0,49483,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(512, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Frequency,cycle/second,"5,788,617,886.18",,,,,
0,49483,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(512, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Frequency,cycle/second,"1,337,017,276.42",,,,,
0,49483,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(512, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Elapsed Cycles,cycle,"5,272",,,,,
0,49483,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(512, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Memory Throughput,%,18.00,,,,,
0,49483,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(512, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Throughput,%,18.00,,,,,
0,49483,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(512, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Duration,nsecond,"3,936",,,,,
0,49483,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(512, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L1/TEX Cache Throughput,%,10.04,,,,,
0,49483,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(512, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L2 Cache Throughput,%,15.67,,,,,
0,49483,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(512, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Active Cycles,cycle,"2,914",,,,,
0,49483,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(512, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Compute (SM) Throughput,%,5.56,,,,,
0,49483,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(512, 1, 1)",0,7.5,SpeedOfLight,,,,SOLBottleneck,OPT,This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.,,
0,49483,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(512, 1, 1)",0,7.5,SpeedOfLight_RooflineChart,,,,SOLFPRoofline,INF,The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved  close to 0% of this device's fp32 peak performance and 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.,,
0,49483,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(512, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Active,inst/cycle,0.16,,,,,
0,49483,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(512, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Elapsed,inst/cycle,0.09,,,,,
0,49483,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(512, 1, 1)",0,7.5,Compute Workload Analysis,Issue Slots Busy,%,4.55,,,,,
0,49483,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(512, 1, 1)",0,7.5,Compute Workload Analysis,Issued Ipc Active,inst/cycle,0.18,,,,,
0,49483,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(512, 1, 1)",0,7.5,Compute Workload Analysis,SM Busy,%,4.55,,,,,
0,49483,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(512, 1, 1)",0,7.5,ComputeWorkloadAnalysis,,,,HighPipeUtilization,OPT,All compute pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.,local,96.86
0,49483,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(512, 1, 1)",0,7.5,Memory Workload Analysis,Memory Throughput,byte/second,"33,341,463,414.63",,,,,
0,49483,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(512, 1, 1)",0,7.5,Memory Workload Analysis,Mem Busy,%,15.67,,,,,
0,49483,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(512, 1, 1)",0,7.5,Memory Workload Analysis,Max Bandwidth,%,18.00,,,,,
0,49483,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(512, 1, 1)",0,7.5,Memory Workload Analysis,L1/TEX Hit Rate,%,0,,,,,
0,49483,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(512, 1, 1)",0,7.5,Memory Workload Analysis,L2 Hit Rate,%,35.14,,,,,
0,49483,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(512, 1, 1)",0,7.5,Memory Workload Analysis,Mem Pipes Busy,%,5.56,,,,,
0,49483,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(512, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Chart,,,,MemoryL2Compression,WRN,The optional metric lts__average_gcomp_input_sector_success_rate.pct could not be found. Collecting it as an additional metric could enable the rule to provide more guidance.,,
0,49483,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(512, 1, 1)",0,7.5,Scheduler Statistics,One or More Eligible,%,4.79,,,,,
0,49483,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(512, 1, 1)",0,7.5,Scheduler Statistics,Issued Warp Per Scheduler,,0.05,,,,,
0,49483,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(512, 1, 1)",0,7.5,Scheduler Statistics,No Eligible,%,95.21,,,,,
0,49483,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(512, 1, 1)",0,7.5,Scheduler Statistics,Active Warps Per Scheduler,warp,2.95,,,,,
0,49483,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(512, 1, 1)",0,7.5,Scheduler Statistics,Eligible Warps Per Scheduler,warp,0.05,,,,,
0,49483,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(512, 1, 1)",0,7.5,SchedulerStats,,,,IssueSlotUtilization,OPT,"Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 20.9 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of 2.95 active warps per scheduler, but only an average of 0.05 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections.",local,82.0
0,49483,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(512, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Issued Instruction,cycle,61.67,,,,,
0,49483,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(512, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Executed Instruction,cycle,68.75,,,,,
0,49483,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(512, 1, 1)",0,7.5,Warp State Statistics,Avg. Active Threads Per Warp,,32,,,,,
0,49483,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(512, 1, 1)",0,7.5,Warp State Statistics,Avg. Not Predicated Off Threads Per Warp,,32,,,,,
0,49483,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(512, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,OPT,"On average, each warp of this kernel spends 39.3 cycles being stalled waiting for a scoreboard dependency on a L1TEX (local, global, surface, texture) operation. Find the instruction producing the data being waited upon to identify the culprit. To reduce the number of cycles waiting on L1TEX data accesses verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit rates by increasing data locality (coalescing), or by changing the cache configuration. Consider moving frequently used data to shared memory. This stall type represents about 63.8% of the total average of 61.7 cycles between issuing two instructions.",global,63.76
0,49483,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(512, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,INF,Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.,,
0,49483,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(512, 1, 1)",0,7.5,Instruction Statistics,Avg. Executed Instructions Per Scheduler,inst,118.86,,,,,
0,49483,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(512, 1, 1)",0,7.5,Instruction Statistics,Executed Instructions,inst,"6,656",,,,,
0,49483,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(512, 1, 1)",0,7.5,Instruction Statistics,Avg. Issued Instructions Per Scheduler,inst,132.50,,,,,
0,49483,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(512, 1, 1)",0,7.5,Instruction Statistics,Issued Instructions,inst,"7,420",,,,,
0,49483,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(512, 1, 1)",0,7.5,InstructionStats,,,,FPInstructions,OPT,"This kernel executes 0 fused and 512 non-fused FP32 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP32 performance could be increased by up to 50% (relative to its current performance). Check the Source page to identify where this kernel executes FP32 instructions.",global,1.569
0,49483,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(512, 1, 1)",0,7.5,Launch Statistics,Block Size,,32,,,,,
0,49483,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(512, 1, 1)",0,7.5,Launch Statistics,Function Cache Configuration,,CachePreferNone,,,,,
0,49483,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(512, 1, 1)",0,7.5,Launch Statistics,Grid Size,,512,,,,,
0,49483,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(512, 1, 1)",0,7.5,Launch Statistics,Registers Per Thread,register/thread,16,,,,,
0,49483,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(512, 1, 1)",0,7.5,Launch Statistics,Shared Memory Configuration Size,byte,"32,768",,,,,
0,49483,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(512, 1, 1)",0,7.5,Launch Statistics,Driver Shared Memory Per Block,byte/block,0,,,,,
0,49483,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(512, 1, 1)",0,7.5,Launch Statistics,Dynamic Shared Memory Per Block,byte/block,0,,,,,
0,49483,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(512, 1, 1)",0,7.5,Launch Statistics,Static Shared Memory Per Block,byte/block,0,,,,,
0,49483,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(512, 1, 1)",0,7.5,Launch Statistics,Threads,thread,"16,384",,,,,
0,49483,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(512, 1, 1)",0,7.5,Launch Statistics,Waves Per SM,,2.29,,,,,
0,49483,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(512, 1, 1)",0,7.5,LaunchStats,,,,LaunchConfiguration,OPT,"A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical occupancy of the kernel. This kernel launch results in 2 full waves and a partial wave of 63 thread blocks. Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for up to 33.3% of the total kernel runtime with a lower occupancy of 27.3%. Try launching a grid with no partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for a grid. See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations.",global,33.33
0,49483,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(512, 1, 1)",0,7.5,Occupancy,Block Limit SM,block,16,,,,,
0,49483,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(512, 1, 1)",0,7.5,Occupancy,Block Limit Registers,block,128,,,,,
0,49483,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(512, 1, 1)",0,7.5,Occupancy,Block Limit Shared Mem,block,16,,,,,
0,49483,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(512, 1, 1)",0,7.5,Occupancy,Block Limit Warps,block,32,,,,,
0,49483,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(512, 1, 1)",0,7.5,Occupancy,Theoretical Active Warps per SM,warp,16,,,,,
0,49483,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(512, 1, 1)",0,7.5,Occupancy,Theoretical Occupancy,%,50,,,,,
0,49483,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(512, 1, 1)",0,7.5,Occupancy,Achieved Occupancy,%,36.35,,,,,
0,49483,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(512, 1, 1)",0,7.5,Occupancy,Achieved Active Warps Per SM,warp,11.63,,,,,
0,49483,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(512, 1, 1)",0,7.5,Occupancy,,,,AchievedOccupancy,OPT,The difference between calculated theoretical (50.0%) and measured achieved occupancy (36.3%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy.,global,27.3
0,49483,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(512, 1, 1)",0,7.5,Occupancy,,,,TheoreticalOccupancy,OPT,The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared memory.,global,50.0
0,49483,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(512, 1, 1)",0,7.5,Source Counters,Branch Instructions Ratio,%,0.08,,,,,
0,49483,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(512, 1, 1)",0,7.5,Source Counters,Branch Instructions,inst,512,,,,,
0,49483,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(512, 1, 1)",0,7.5,Source Counters,Branch Efficiency,%,0,,,,,
0,49483,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(512, 1, 1)",0,7.5,Source Counters,Avg. Divergent Branches,,0,,,,,
0,49568,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(256, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Frequency,cycle/second,"5,662,921,348.31",,,,,
0,49568,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(256, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Frequency,cycle/second,"1,279,143,258.43",,,,,
0,49568,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(256, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Elapsed Cycles,cycle,"3,646",,,,,
0,49568,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(256, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Memory Throughput,%,25.43,,,,,
0,49568,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(256, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Throughput,%,25.43,,,,,
0,49568,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(256, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Duration,nsecond,"2,848",,,,,
0,49568,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(256, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L1/TEX Cache Throughput,%,13.87,,,,,
0,49568,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(256, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L2 Cache Throughput,%,22.63,,,,,
0,49568,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(256, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Active Cycles,cycle,"2,108.79",,,,,
0,49568,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(256, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Compute (SM) Throughput,%,8.03,,,,,
0,49568,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(256, 1, 1)",0,7.5,SpeedOfLight,,,,SOLBottleneck,OPT,This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.,,
0,49568,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(256, 1, 1)",0,7.5,SpeedOfLight_RooflineChart,,,,SOLFPRoofline,INF,The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved  close to 0% of this device's fp32 peak performance and 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.,,
0,49568,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(256, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Active,inst/cycle,0.23,,,,,
0,49568,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(256, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Elapsed,inst/cycle,0.13,,,,,
0,49568,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(256, 1, 1)",0,7.5,Compute Workload Analysis,Issue Slots Busy,%,6.84,,,,,
0,49568,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(256, 1, 1)",0,7.5,Compute Workload Analysis,Issued Ipc Active,inst/cycle,0.27,,,,,
0,49568,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(256, 1, 1)",0,7.5,Compute Workload Analysis,SM Busy,%,6.84,,,,,
0,49568,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(256, 1, 1)",0,7.5,ComputeWorkloadAnalysis,,,,HighPipeUtilization,OPT,All compute pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.,local,95.66
0,49568,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(256, 1, 1)",0,7.5,Memory Workload Analysis,Memory Throughput,byte/second,"46,078,651,685.39",,,,,
0,49568,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(256, 1, 1)",0,7.5,Memory Workload Analysis,Mem Busy,%,22.63,,,,,
0,49568,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(256, 1, 1)",0,7.5,Memory Workload Analysis,Max Bandwidth,%,25.43,,,,,
0,49568,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(256, 1, 1)",0,7.5,Memory Workload Analysis,L1/TEX Hit Rate,%,0,,,,,
0,49568,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(256, 1, 1)",0,7.5,Memory Workload Analysis,L2 Hit Rate,%,35.13,,,,,
0,49568,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(256, 1, 1)",0,7.5,Memory Workload Analysis,Mem Pipes Busy,%,8.03,,,,,
0,49568,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(256, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Chart,,,,MemoryL2Compression,WRN,The optional metric lts__average_gcomp_input_sector_success_rate.pct could not be found. Collecting it as an additional metric could enable the rule to provide more guidance.,,
0,49568,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(256, 1, 1)",0,7.5,Scheduler Statistics,One or More Eligible,%,7.27,,,,,
0,49568,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(256, 1, 1)",0,7.5,Scheduler Statistics,Issued Warp Per Scheduler,,0.07,,,,,
0,49568,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(256, 1, 1)",0,7.5,Scheduler Statistics,No Eligible,%,92.73,,,,,
0,49568,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(256, 1, 1)",0,7.5,Scheduler Statistics,Active Warps Per Scheduler,warp,7.08,,,,,
0,49568,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(256, 1, 1)",0,7.5,Scheduler Statistics,Eligible Warps Per Scheduler,warp,0.12,,,,,
0,49568,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(256, 1, 1)",0,7.5,SchedulerStats,,,,IssueSlotUtilization,OPT,"Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 13.8 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of 7.08 active warps per scheduler, but only an average of 0.12 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, avoid possible load imbalances due to highly different execution durations per warp. Reducing stalls indicated on the Warp State Statistics and Source Counters sections can help, too.",local,74.57
0,49568,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(256, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Issued Instruction,cycle,97.44,,,,,
0,49568,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(256, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Executed Instruction,cycle,118.18,,,,,
0,49568,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(256, 1, 1)",0,7.5,Warp State Statistics,Avg. Active Threads Per Warp,,32,,,,,
0,49568,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(256, 1, 1)",0,7.5,Warp State Statistics,Avg. Not Predicated Off Threads Per Warp,,32,,,,,
0,49568,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(256, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,OPT,"On average, each warp of this kernel spends 50.6 cycles being stalled waiting for a scoreboard dependency on a L1TEX (local, global, surface, texture) operation. Find the instruction producing the data being waited upon to identify the culprit. To reduce the number of cycles waiting on L1TEX data accesses verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit rates by increasing data locality (coalescing), or by changing the cache configuration. Consider moving frequently used data to shared memory. This stall type represents about 51.9% of the total average of 97.4 cycles between issuing two instructions.",global,51.93
0,49568,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(256, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,INF,Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.,,
0,49568,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(256, 1, 1)",0,7.5,Instruction Statistics,Avg. Executed Instructions Per Scheduler,inst,118.86,,,,,
0,49568,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(256, 1, 1)",0,7.5,Instruction Statistics,Executed Instructions,inst,"6,656",,,,,
0,49568,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(256, 1, 1)",0,7.5,Instruction Statistics,Avg. Issued Instructions Per Scheduler,inst,144.16,,,,,
0,49568,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(256, 1, 1)",0,7.5,Instruction Statistics,Issued Instructions,inst,"8,073",,,,,
0,49568,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(256, 1, 1)",0,7.5,InstructionStats,,,,FPInstructions,OPT,"This kernel executes 0 fused and 512 non-fused FP32 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP32 performance could be increased by up to 50% (relative to its current performance). Check the Source page to identify where this kernel executes FP32 instructions.",global,2.168
0,49568,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(256, 1, 1)",0,7.5,Launch Statistics,Block Size,,64,,,,,
0,49568,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(256, 1, 1)",0,7.5,Launch Statistics,Function Cache Configuration,,CachePreferNone,,,,,
0,49568,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(256, 1, 1)",0,7.5,Launch Statistics,Grid Size,,256,,,,,
0,49568,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(256, 1, 1)",0,7.5,Launch Statistics,Registers Per Thread,register/thread,16,,,,,
0,49568,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(256, 1, 1)",0,7.5,Launch Statistics,Shared Memory Configuration Size,byte,"32,768",,,,,
0,49568,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(256, 1, 1)",0,7.5,Launch Statistics,Driver Shared Memory Per Block,byte/block,0,,,,,
0,49568,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(256, 1, 1)",0,7.5,Launch Statistics,Dynamic Shared Memory Per Block,byte/block,0,,,,,
0,49568,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(256, 1, 1)",0,7.5,Launch Statistics,Static Shared Memory Per Block,byte/block,0,,,,,
0,49568,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(256, 1, 1)",0,7.5,Launch Statistics,Threads,thread,"16,384",,,,,
0,49568,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(256, 1, 1)",0,7.5,Launch Statistics,Waves Per SM,,1.14,,,,,
0,49568,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(256, 1, 1)",0,7.5,LaunchStats,,,,LaunchConfiguration,OPT,"A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical occupancy of the kernel. This kernel launch results in 1 full waves and a partial wave of 31 thread blocks. Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for up to 50.0% of the total kernel runtime with a lower occupancy of 24.4%. Try launching a grid with no partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for a grid. See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations.",global,50.0
0,49568,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(256, 1, 1)",0,7.5,Occupancy,Block Limit SM,block,16,,,,,
0,49568,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(256, 1, 1)",0,7.5,Occupancy,Block Limit Registers,block,64,,,,,
0,49568,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(256, 1, 1)",0,7.5,Occupancy,Block Limit Shared Mem,block,16,,,,,
0,49568,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(256, 1, 1)",0,7.5,Occupancy,Block Limit Warps,block,16,,,,,
0,49568,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(256, 1, 1)",0,7.5,Occupancy,Theoretical Active Warps per SM,warp,32,,,,,
0,49568,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(256, 1, 1)",0,7.5,Occupancy,Theoretical Occupancy,%,100,,,,,
0,49568,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(256, 1, 1)",0,7.5,Occupancy,Achieved Occupancy,%,75.64,,,,,
0,49568,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(256, 1, 1)",0,7.5,Occupancy,Achieved Active Warps Per SM,warp,24.21,,,,,
0,49568,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(256, 1, 1)",0,7.5,Occupancy,,,,AchievedOccupancy,OPT,The difference between calculated theoretical (100.0%) and measured achieved occupancy (75.6%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy.,global,24.36
0,49568,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(256, 1, 1)",0,7.5,Source Counters,Branch Instructions Ratio,%,0.08,,,,,
0,49568,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(256, 1, 1)",0,7.5,Source Counters,Branch Instructions,inst,512,,,,,
0,49568,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(256, 1, 1)",0,7.5,Source Counters,Branch Efficiency,%,0,,,,,
0,49568,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(256, 1, 1)",0,7.5,Source Counters,Avg. Divergent Branches,,0,,,,,
0,49645,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(128, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Frequency,cycle/second,"5,272,727,272.73",,,,,
0,49645,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(128, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Frequency,cycle/second,"1,193,536,931.82",,,,,
0,49645,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(128, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Elapsed Cycles,cycle,"3,364",,,,,
0,49645,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(128, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Memory Throughput,%,27.62,,,,,
0,49645,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(128, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Throughput,%,27.62,,,,,
0,49645,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(128, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Duration,nsecond,"2,816",,,,,
0,49645,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(128, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L1/TEX Cache Throughput,%,14.77,,,,,
0,49645,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(128, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L2 Cache Throughput,%,24.51,,,,,
0,49645,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(128, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Active Cycles,cycle,"1,980.36",,,,,
0,49645,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(128, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Compute (SM) Throughput,%,8.70,,,,,
0,49645,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(128, 1, 1)",0,7.5,SpeedOfLight,,,,SOLBottleneck,OPT,This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.,,
0,49645,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(128, 1, 1)",0,7.5,SpeedOfLight_RooflineChart,,,,SOLFPRoofline,INF,The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved  close to 0% of this device's fp32 peak performance and 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.,,
0,49645,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(128, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Active,inst/cycle,0.24,,,,,
0,49645,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(128, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Elapsed,inst/cycle,0.14,,,,,
0,49645,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(128, 1, 1)",0,7.5,Compute Workload Analysis,Issue Slots Busy,%,7.62,,,,,
0,49645,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(128, 1, 1)",0,7.5,Compute Workload Analysis,Issued Ipc Active,inst/cycle,0.30,,,,,
0,49645,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(128, 1, 1)",0,7.5,Compute Workload Analysis,SM Busy,%,7.62,,,,,
0,49645,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(128, 1, 1)",0,7.5,ComputeWorkloadAnalysis,,,,HighPipeUtilization,OPT,All compute pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.,local,95.38
0,49645,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(128, 1, 1)",0,7.5,Memory Workload Analysis,Memory Throughput,byte/second,"46,602,272,727.27",,,,,
0,49645,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(128, 1, 1)",0,7.5,Memory Workload Analysis,Mem Busy,%,24.51,,,,,
0,49645,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(128, 1, 1)",0,7.5,Memory Workload Analysis,Max Bandwidth,%,27.62,,,,,
0,49645,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(128, 1, 1)",0,7.5,Memory Workload Analysis,L1/TEX Hit Rate,%,0,,,,,
0,49645,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(128, 1, 1)",0,7.5,Memory Workload Analysis,L2 Hit Rate,%,35.14,,,,,
0,49645,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(128, 1, 1)",0,7.5,Memory Workload Analysis,Mem Pipes Busy,%,8.70,,,,,
0,49645,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(128, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Chart,,,,MemoryL2Compression,WRN,The optional metric lts__average_gcomp_input_sector_success_rate.pct could not be found. Collecting it as an additional metric could enable the rule to provide more guidance.,,
0,49645,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(128, 1, 1)",0,7.5,Scheduler Statistics,One or More Eligible,%,7.90,,,,,
0,49645,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(128, 1, 1)",0,7.5,Scheduler Statistics,Issued Warp Per Scheduler,,0.08,,,,,
0,49645,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(128, 1, 1)",0,7.5,Scheduler Statistics,No Eligible,%,92.10,,,,,
0,49645,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(128, 1, 1)",0,7.5,Scheduler Statistics,Active Warps Per Scheduler,warp,6.80,,,,,
0,49645,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(128, 1, 1)",0,7.5,Scheduler Statistics,Eligible Warps Per Scheduler,warp,0.14,,,,,
0,49645,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(128, 1, 1)",0,7.5,SchedulerStats,,,,IssueSlotUtilization,OPT,"Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 12.7 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of 6.80 active warps per scheduler, but only an average of 0.14 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, avoid possible load imbalances due to highly different execution durations per warp. Reducing stalls indicated on the Warp State Statistics and Source Counters sections can help, too.",local,72.38
0,49645,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(128, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Issued Instruction,cycle,86.02,,,,,
0,49645,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(128, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Executed Instruction,cycle,109.18,,,,,
0,49645,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(128, 1, 1)",0,7.5,Warp State Statistics,Avg. Active Threads Per Warp,,32,,,,,
0,49645,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(128, 1, 1)",0,7.5,Warp State Statistics,Avg. Not Predicated Off Threads Per Warp,,32,,,,,
0,49645,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(128, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,OPT,"On average, each warp of this kernel spends 47.0 cycles being stalled waiting for a scoreboard dependency on a L1TEX (local, global, surface, texture) operation. Find the instruction producing the data being waited upon to identify the culprit. To reduce the number of cycles waiting on L1TEX data accesses verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit rates by increasing data locality (coalescing), or by changing the cache configuration. Consider moving frequently used data to shared memory. This stall type represents about 54.7% of the total average of 86.0 cycles between issuing two instructions.",global,54.67
0,49645,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(128, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,INF,Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.,,
0,49645,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(128, 1, 1)",0,7.5,Instruction Statistics,Avg. Executed Instructions Per Scheduler,inst,118.86,,,,,
0,49645,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(128, 1, 1)",0,7.5,Instruction Statistics,Executed Instructions,inst,"6,656",,,,,
0,49645,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(128, 1, 1)",0,7.5,Instruction Statistics,Avg. Issued Instructions Per Scheduler,inst,150.86,,,,,
0,49645,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(128, 1, 1)",0,7.5,Instruction Statistics,Issued Instructions,inst,"8,448",,,,,
0,49645,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(128, 1, 1)",0,7.5,InstructionStats,,,,FPInstructions,OPT,"This kernel executes 0 fused and 512 non-fused FP32 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP32 performance could be increased by up to 50% (relative to its current performance). Check the Source page to identify where this kernel executes FP32 instructions.",global,2.308
0,49645,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(128, 1, 1)",0,7.5,Launch Statistics,Block Size,,128,,,,,
0,49645,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(128, 1, 1)",0,7.5,Launch Statistics,Function Cache Configuration,,CachePreferNone,,,,,
0,49645,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(128, 1, 1)",0,7.5,Launch Statistics,Grid Size,,128,,,,,
0,49645,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(128, 1, 1)",0,7.5,Launch Statistics,Registers Per Thread,register/thread,16,,,,,
0,49645,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(128, 1, 1)",0,7.5,Launch Statistics,Shared Memory Configuration Size,byte,"32,768",,,,,
0,49645,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(128, 1, 1)",0,7.5,Launch Statistics,Driver Shared Memory Per Block,byte/block,0,,,,,
0,49645,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(128, 1, 1)",0,7.5,Launch Statistics,Dynamic Shared Memory Per Block,byte/block,0,,,,,
0,49645,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(128, 1, 1)",0,7.5,Launch Statistics,Static Shared Memory Per Block,byte/block,0,,,,,
0,49645,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(128, 1, 1)",0,7.5,Launch Statistics,Threads,thread,"16,384",,,,,
0,49645,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(128, 1, 1)",0,7.5,Launch Statistics,Waves Per SM,,1.14,,,,,
0,49645,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(128, 1, 1)",0,7.5,Occupancy,Block Limit SM,block,16,,,,,
0,49645,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(128, 1, 1)",0,7.5,Occupancy,Block Limit Registers,block,32,,,,,
0,49645,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(128, 1, 1)",0,7.5,Occupancy,Block Limit Shared Mem,block,16,,,,,
0,49645,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(128, 1, 1)",0,7.5,Occupancy,Block Limit Warps,block,8,,,,,
0,49645,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(128, 1, 1)",0,7.5,Occupancy,Theoretical Active Warps per SM,warp,32,,,,,
0,49645,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(128, 1, 1)",0,7.5,Occupancy,Theoretical Occupancy,%,100,,,,,
0,49645,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(128, 1, 1)",0,7.5,Occupancy,Achieved Occupancy,%,82.29,,,,,
0,49645,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(128, 1, 1)",0,7.5,Occupancy,Achieved Active Warps Per SM,warp,26.33,,,,,
0,49645,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(128, 1, 1)",0,7.5,Occupancy,,,,AchievedOccupancy,OPT,The difference between calculated theoretical (100.0%) and measured achieved occupancy (82.3%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy.,global,17.71
0,49645,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(128, 1, 1)",0,7.5,Source Counters,Branch Instructions Ratio,%,0.08,,,,,
0,49645,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(128, 1, 1)",0,7.5,Source Counters,Branch Instructions,inst,512,,,,,
0,49645,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(128, 1, 1)",0,7.5,Source Counters,Branch Efficiency,%,0,,,,,
0,49645,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(128, 1, 1)",0,7.5,Source Counters,Avg. Divergent Branches,,0,,,,,
0,49731,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(64, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Frequency,cycle/second,"5,303,370,786.52",,,,,
0,49731,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(64, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Frequency,cycle/second,"1,222,787,921.35",,,,,
0,49731,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(64, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Elapsed Cycles,cycle,"3,489",,,,,
0,49731,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(64, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Memory Throughput,%,27.15,,,,,
0,49731,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(64, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Throughput,%,27.15,,,,,
0,49731,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(64, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Duration,nsecond,"2,848",,,,,
0,49731,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(64, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L1/TEX Cache Throughput,%,14.96,,,,,
0,49731,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(64, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L2 Cache Throughput,%,23.66,,,,,
0,49731,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(64, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Active Cycles,cycle,"1,955.43",,,,,
0,49731,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(64, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Compute (SM) Throughput,%,8.40,,,,,
0,49731,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(64, 1, 1)",0,7.5,SpeedOfLight,,,,SOLBottleneck,OPT,This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.,,
0,49731,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(64, 1, 1)",0,7.5,SpeedOfLight_RooflineChart,,,,SOLFPRoofline,INF,The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved  close to 0% of this device's fp32 peak performance and 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.,,
0,49731,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(64, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Active,inst/cycle,0.24,,,,,
0,49731,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(64, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Elapsed,inst/cycle,0.14,,,,,
0,49731,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(64, 1, 1)",0,7.5,Compute Workload Analysis,Issue Slots Busy,%,7.69,,,,,
0,49731,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(64, 1, 1)",0,7.5,Compute Workload Analysis,Issued Ipc Active,inst/cycle,0.31,,,,,
0,49731,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(64, 1, 1)",0,7.5,Compute Workload Analysis,SM Busy,%,7.69,,,,,
0,49731,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(64, 1, 1)",0,7.5,ComputeWorkloadAnalysis,,,,HighPipeUtilization,OPT,All compute pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.,local,95.32
0,49731,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(64, 1, 1)",0,7.5,Memory Workload Analysis,Memory Throughput,byte/second,"46,078,651,685.39",,,,,
0,49731,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(64, 1, 1)",0,7.5,Memory Workload Analysis,Mem Busy,%,23.66,,,,,
0,49731,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(64, 1, 1)",0,7.5,Memory Workload Analysis,Max Bandwidth,%,27.15,,,,,
0,49731,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(64, 1, 1)",0,7.5,Memory Workload Analysis,L1/TEX Hit Rate,%,0,,,,,
0,49731,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(64, 1, 1)",0,7.5,Memory Workload Analysis,L2 Hit Rate,%,35.13,,,,,
0,49731,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(64, 1, 1)",0,7.5,Memory Workload Analysis,Mem Pipes Busy,%,8.40,,,,,
0,49731,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(64, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Chart,,,,MemoryL2Compression,WRN,The optional metric lts__average_gcomp_input_sector_success_rate.pct could not be found. Collecting it as an additional metric could enable the rule to provide more guidance.,,
0,49731,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(64, 1, 1)",0,7.5,Scheduler Statistics,One or More Eligible,%,7.92,,,,,
0,49731,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(64, 1, 1)",0,7.5,Scheduler Statistics,Issued Warp Per Scheduler,,0.08,,,,,
0,49731,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(64, 1, 1)",0,7.5,Scheduler Statistics,No Eligible,%,92.08,,,,,
0,49731,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(64, 1, 1)",0,7.5,Scheduler Statistics,Active Warps Per Scheduler,warp,6.85,,,,,
0,49731,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(64, 1, 1)",0,7.5,Scheduler Statistics,Eligible Warps Per Scheduler,warp,0.14,,,,,
0,49731,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(64, 1, 1)",0,7.5,SchedulerStats,,,,IssueSlotUtilization,OPT,"Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 12.6 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of 6.85 active warps per scheduler, but only an average of 0.14 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, avoid possible load imbalances due to highly different execution durations per warp. Reducing stalls indicated on the Warp State Statistics and Source Counters sections can help, too.",local,72.85
0,49731,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(64, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Issued Instruction,cycle,86.40,,,,,
0,49731,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(64, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Executed Instruction,cycle,109.30,,,,,
0,49731,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(64, 1, 1)",0,7.5,Warp State Statistics,Avg. Active Threads Per Warp,,32,,,,,
0,49731,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(64, 1, 1)",0,7.5,Warp State Statistics,Avg. Not Predicated Off Threads Per Warp,,32,,,,,
0,49731,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(64, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,OPT,"On average, each warp of this kernel spends 47.4 cycles being stalled waiting for a scoreboard dependency on a L1TEX (local, global, surface, texture) operation. Find the instruction producing the data being waited upon to identify the culprit. To reduce the number of cycles waiting on L1TEX data accesses verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit rates by increasing data locality (coalescing), or by changing the cache configuration. Consider moving frequently used data to shared memory. This stall type represents about 54.9% of the total average of 86.4 cycles between issuing two instructions.",global,54.86
0,49731,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(64, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,OPT,"On average, each warp of this kernel spends 27.1 cycles being stalled waiting for an immediate constant cache (IMC) miss. A read from constant memory costs one memory read from device memory only on a cache miss; otherwise, it just costs one read from the constant cache. Immediate constants are encoded into the SASS instruction as 'c[bank][offset]'. Accesses to different addresses by threads within a warp are serialized, thus the cost scales linearly with the number of unique addresses read by all threads within a warp. As such, the constant cache is best when threads in the same warp access only a few distinct locations. If all threads of a warp access the same location, then constant memory can be as fast as a register access. This stall type represents about 31.3% of the total average of 86.4 cycles between issuing two instructions.",global,31.35
0,49731,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(64, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,INF,Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.,,
0,49731,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(64, 1, 1)",0,7.5,Instruction Statistics,Avg. Executed Instructions Per Scheduler,inst,118.86,,,,,
0,49731,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(64, 1, 1)",0,7.5,Instruction Statistics,Executed Instructions,inst,"6,656",,,,,
0,49731,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(64, 1, 1)",0,7.5,Instruction Statistics,Avg. Issued Instructions Per Scheduler,inst,150.36,,,,,
0,49731,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(64, 1, 1)",0,7.5,Instruction Statistics,Issued Instructions,inst,"8,420",,,,,
0,49731,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(64, 1, 1)",0,7.5,InstructionStats,,,,FPInstructions,OPT,"This kernel executes 0 fused and 512 non-fused FP32 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP32 performance could be increased by up to 50% (relative to its current performance). Check the Source page to identify where this kernel executes FP32 instructions.",global,2.338
0,49731,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(64, 1, 1)",0,7.5,Launch Statistics,Block Size,,256,,,,,
0,49731,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(64, 1, 1)",0,7.5,Launch Statistics,Function Cache Configuration,,CachePreferNone,,,,,
0,49731,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(64, 1, 1)",0,7.5,Launch Statistics,Grid Size,,64,,,,,
0,49731,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(64, 1, 1)",0,7.5,Launch Statistics,Registers Per Thread,register/thread,16,,,,,
0,49731,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(64, 1, 1)",0,7.5,Launch Statistics,Shared Memory Configuration Size,byte,"32,768",,,,,
0,49731,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(64, 1, 1)",0,7.5,Launch Statistics,Driver Shared Memory Per Block,byte/block,0,,,,,
0,49731,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(64, 1, 1)",0,7.5,Launch Statistics,Dynamic Shared Memory Per Block,byte/block,0,,,,,
0,49731,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(64, 1, 1)",0,7.5,Launch Statistics,Static Shared Memory Per Block,byte/block,0,,,,,
0,49731,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(64, 1, 1)",0,7.5,Launch Statistics,Threads,thread,"16,384",,,,,
0,49731,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(64, 1, 1)",0,7.5,Launch Statistics,Waves Per SM,,1.14,,,,,
0,49731,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(64, 1, 1)",0,7.5,Occupancy,Block Limit SM,block,16,,,,,
0,49731,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(64, 1, 1)",0,7.5,Occupancy,Block Limit Registers,block,16,,,,,
0,49731,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(64, 1, 1)",0,7.5,Occupancy,Block Limit Shared Mem,block,16,,,,,
0,49731,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(64, 1, 1)",0,7.5,Occupancy,Block Limit Warps,block,4,,,,,
0,49731,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(64, 1, 1)",0,7.5,Occupancy,Theoretical Active Warps per SM,warp,32,,,,,
0,49731,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(64, 1, 1)",0,7.5,Occupancy,Theoretical Occupancy,%,100,,,,,
0,49731,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(64, 1, 1)",0,7.5,Occupancy,Achieved Occupancy,%,84.60,,,,,
0,49731,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(64, 1, 1)",0,7.5,Occupancy,Achieved Active Warps Per SM,warp,27.07,,,,,
0,49731,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(64, 1, 1)",0,7.5,Occupancy,,,,AchievedOccupancy,OPT,The difference between calculated theoretical (100.0%) and measured achieved occupancy (84.6%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy.,global,15.4
0,49731,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(64, 1, 1)",0,7.5,Source Counters,Branch Instructions Ratio,%,0.08,,,,,
0,49731,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(64, 1, 1)",0,7.5,Source Counters,Branch Instructions,inst,512,,,,,
0,49731,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(64, 1, 1)",0,7.5,Source Counters,Branch Efficiency,%,0,,,,,
0,49731,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(64, 1, 1)",0,7.5,Source Counters,Avg. Divergent Branches,,0,,,,,
0,49817,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(32, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Frequency,cycle/second,"5,636,363,636.36",,,,,
0,49817,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(32, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Frequency,cycle/second,"1,278,941,761.36",,,,,
0,49817,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(32, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Elapsed Cycles,cycle,"3,607",,,,,
0,49817,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(32, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Memory Throughput,%,25.84,,,,,
0,49817,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(32, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Throughput,%,25.84,,,,,
0,49817,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(32, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Duration,nsecond,"2,816",,,,,
0,49817,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(32, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L1/TEX Cache Throughput,%,14.45,,,,,
0,49817,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(32, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L2 Cache Throughput,%,22.84,,,,,
0,49817,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(32, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Active Cycles,cycle,"2,024.50",,,,,
0,49817,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(32, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Compute (SM) Throughput,%,8.12,,,,,
0,49817,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(32, 1, 1)",0,7.5,SpeedOfLight,,,,SOLBottleneck,OPT,This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.,,
0,49817,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(32, 1, 1)",0,7.5,SpeedOfLight_RooflineChart,,,,SOLFPRoofline,INF,The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved  close to 0% of this device's fp32 peak performance and 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.,,
0,49817,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(32, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Active,inst/cycle,0.23,,,,,
0,49817,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(32, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Elapsed,inst/cycle,0.13,,,,,
0,49817,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(32, 1, 1)",0,7.5,Compute Workload Analysis,Issue Slots Busy,%,7.45,,,,,
0,49817,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(32, 1, 1)",0,7.5,Compute Workload Analysis,Issued Ipc Active,inst/cycle,0.30,,,,,
0,49817,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(32, 1, 1)",0,7.5,Compute Workload Analysis,SM Busy,%,7.45,,,,,
0,49817,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(32, 1, 1)",0,7.5,ComputeWorkloadAnalysis,,,,HighPipeUtilization,OPT,All compute pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.,local,95.48
0,49817,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(32, 1, 1)",0,7.5,Memory Workload Analysis,Memory Throughput,byte/second,"46,602,272,727.27",,,,,
0,49817,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(32, 1, 1)",0,7.5,Memory Workload Analysis,Mem Busy,%,22.84,,,,,
0,49817,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(32, 1, 1)",0,7.5,Memory Workload Analysis,Max Bandwidth,%,25.84,,,,,
0,49817,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(32, 1, 1)",0,7.5,Memory Workload Analysis,L1/TEX Hit Rate,%,0,,,,,
0,49817,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(32, 1, 1)",0,7.5,Memory Workload Analysis,L2 Hit Rate,%,35.14,,,,,
0,49817,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(32, 1, 1)",0,7.5,Memory Workload Analysis,Mem Pipes Busy,%,8.12,,,,,
0,49817,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(32, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Chart,,,,MemoryL2Compression,WRN,The optional metric lts__average_gcomp_input_sector_success_rate.pct could not be found. Collecting it as an additional metric could enable the rule to provide more guidance.,,
0,49817,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(32, 1, 1)",0,7.5,Scheduler Statistics,One or More Eligible,%,7.61,,,,,
0,49817,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(32, 1, 1)",0,7.5,Scheduler Statistics,Issued Warp Per Scheduler,,0.08,,,,,
0,49817,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(32, 1, 1)",0,7.5,Scheduler Statistics,No Eligible,%,92.39,,,,,
0,49817,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(32, 1, 1)",0,7.5,Scheduler Statistics,Active Warps Per Scheduler,warp,6.60,,,,,
0,49817,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(32, 1, 1)",0,7.5,Scheduler Statistics,Eligible Warps Per Scheduler,warp,0.14,,,,,
0,49817,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(32, 1, 1)",0,7.5,SchedulerStats,,,,IssueSlotUtilization,OPT,"Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 13.1 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of 6.60 active warps per scheduler, but only an average of 0.14 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, avoid possible load imbalances due to highly different execution durations per warp. Reducing stalls indicated on the Warp State Statistics and Source Counters sections can help, too.",local,74.16
0,49817,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(32, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Issued Instruction,cycle,86.80,,,,,
0,49817,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(32, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Executed Instruction,cycle,110.16,,,,,
0,49817,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(32, 1, 1)",0,7.5,Warp State Statistics,Avg. Active Threads Per Warp,,32,,,,,
0,49817,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(32, 1, 1)",0,7.5,Warp State Statistics,Avg. Not Predicated Off Threads Per Warp,,32,,,,,
0,49817,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(32, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,OPT,"On average, each warp of this kernel spends 58.9 cycles being stalled waiting for a scoreboard dependency on a L1TEX (local, global, surface, texture) operation. Find the instruction producing the data being waited upon to identify the culprit. To reduce the number of cycles waiting on L1TEX data accesses verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit rates by increasing data locality (coalescing), or by changing the cache configuration. Consider moving frequently used data to shared memory. This stall type represents about 67.9% of the total average of 86.8 cycles between issuing two instructions.",global,67.89
0,49817,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(32, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,OPT,"On average, each warp of this kernel spends 27.5 cycles being stalled waiting for an immediate constant cache (IMC) miss. A read from constant memory costs one memory read from device memory only on a cache miss; otherwise, it just costs one read from the constant cache. Immediate constants are encoded into the SASS instruction as 'c[bank][offset]'. Accesses to different addresses by threads within a warp are serialized, thus the cost scales linearly with the number of unique addresses read by all threads within a warp. As such, the constant cache is best when threads in the same warp access only a few distinct locations. If all threads of a warp access the same location, then constant memory can be as fast as a register access. This stall type represents about 31.7% of the total average of 86.8 cycles between issuing two instructions.",global,31.65
0,49817,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(32, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,INF,Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.,,
0,49817,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(32, 1, 1)",0,7.5,Instruction Statistics,Avg. Executed Instructions Per Scheduler,inst,118.86,,,,,
0,49817,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(32, 1, 1)",0,7.5,Instruction Statistics,Executed Instructions,inst,"6,656",,,,,
0,49817,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(32, 1, 1)",0,7.5,Instruction Statistics,Avg. Issued Instructions Per Scheduler,inst,150.86,,,,,
0,49817,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(32, 1, 1)",0,7.5,Instruction Statistics,Issued Instructions,inst,"8,448",,,,,
0,49817,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(32, 1, 1)",0,7.5,InstructionStats,,,,FPInstructions,OPT,"This kernel executes 0 fused and 512 non-fused FP32 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP32 performance could be increased by up to 50% (relative to its current performance). Check the Source page to identify where this kernel executes FP32 instructions.",global,2.258
0,49817,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(32, 1, 1)",0,7.5,Launch Statistics,Block Size,,512,,,,,
0,49817,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(32, 1, 1)",0,7.5,Launch Statistics,Function Cache Configuration,,CachePreferNone,,,,,
0,49817,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(32, 1, 1)",0,7.5,Launch Statistics,Grid Size,,32,,,,,
0,49817,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(32, 1, 1)",0,7.5,Launch Statistics,Registers Per Thread,register/thread,16,,,,,
0,49817,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(32, 1, 1)",0,7.5,Launch Statistics,Shared Memory Configuration Size,byte,"32,768",,,,,
0,49817,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(32, 1, 1)",0,7.5,Launch Statistics,Driver Shared Memory Per Block,byte/block,0,,,,,
0,49817,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(32, 1, 1)",0,7.5,Launch Statistics,Dynamic Shared Memory Per Block,byte/block,0,,,,,
0,49817,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(32, 1, 1)",0,7.5,Launch Statistics,Static Shared Memory Per Block,byte/block,0,,,,,
0,49817,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(32, 1, 1)",0,7.5,Launch Statistics,Threads,thread,"16,384",,,,,
0,49817,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(32, 1, 1)",0,7.5,Launch Statistics,Waves Per SM,,1.14,,,,,
0,49817,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(32, 1, 1)",0,7.5,Occupancy,Block Limit SM,block,16,,,,,
0,49817,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(32, 1, 1)",0,7.5,Occupancy,Block Limit Registers,block,8,,,,,
0,49817,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(32, 1, 1)",0,7.5,Occupancy,Block Limit Shared Mem,block,16,,,,,
0,49817,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(32, 1, 1)",0,7.5,Occupancy,Block Limit Warps,block,2,,,,,
0,49817,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(32, 1, 1)",0,7.5,Occupancy,Theoretical Active Warps per SM,warp,32,,,,,
0,49817,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(32, 1, 1)",0,7.5,Occupancy,Theoretical Occupancy,%,100,,,,,
0,49817,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(32, 1, 1)",0,7.5,Occupancy,Achieved Occupancy,%,83.28,,,,,
0,49817,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(32, 1, 1)",0,7.5,Occupancy,Achieved Active Warps Per SM,warp,26.65,,,,,
0,49817,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(32, 1, 1)",0,7.5,Occupancy,,,,AchievedOccupancy,OPT,The difference between calculated theoretical (100.0%) and measured achieved occupancy (83.3%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy.,global,16.72
0,49817,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(32, 1, 1)",0,7.5,Source Counters,Branch Instructions Ratio,%,0.08,,,,,
0,49817,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(32, 1, 1)",0,7.5,Source Counters,Branch Instructions,inst,512,,,,,
0,49817,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(32, 1, 1)",0,7.5,Source Counters,Branch Efficiency,%,0,,,,,
0,49817,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(32, 1, 1)",0,7.5,Source Counters,Avg. Divergent Branches,,0,,,,,
0,49894,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(16, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Frequency,cycle/second,"5,465,346,534.65",,,,,
0,49894,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(16, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Frequency,cycle/second,"1,231,126,237.62",,,,,
0,49894,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(16, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Elapsed Cycles,cycle,"3,994",,,,,
0,49894,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(16, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Memory Throughput,%,23.22,,,,,
0,49894,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(16, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Throughput,%,23.22,,,,,
0,49894,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(16, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Duration,nsecond,"3,232",,,,,
0,49894,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(16, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L1/TEX Cache Throughput,%,14.71,,,,,
0,49894,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(16, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L2 Cache Throughput,%,20.63,,,,,
0,49894,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(16, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Active Cycles,cycle,"1,989.29",,,,,
0,49894,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(16, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Compute (SM) Throughput,%,7.35,,,,,
0,49894,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(16, 1, 1)",0,7.5,SpeedOfLight,,,,SOLBottleneck,OPT,This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.,,
0,49894,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(16, 1, 1)",0,7.5,SpeedOfLight_RooflineChart,,,,SOLFPRoofline,INF,The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved  close to 0% of this device's fp32 peak performance and 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.,,
0,49894,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(16, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Active,inst/cycle,0.24,,,,,
0,49894,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(16, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Elapsed,inst/cycle,0.12,,,,,
0,49894,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(16, 1, 1)",0,7.5,Compute Workload Analysis,Issue Slots Busy,%,7.58,,,,,
0,49894,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(16, 1, 1)",0,7.5,Compute Workload Analysis,Issued Ipc Active,inst/cycle,0.30,,,,,
0,49894,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(16, 1, 1)",0,7.5,Compute Workload Analysis,SM Busy,%,7.58,,,,,
0,49894,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(16, 1, 1)",0,7.5,ComputeWorkloadAnalysis,,,,HighPipeUtilization,OPT,All compute pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.,local,95.4
0,49894,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(16, 1, 1)",0,7.5,Memory Workload Analysis,Memory Throughput,byte/second,"40,603,960,396.04",,,,,
0,49894,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(16, 1, 1)",0,7.5,Memory Workload Analysis,Mem Busy,%,20.63,,,,,
0,49894,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(16, 1, 1)",0,7.5,Memory Workload Analysis,Max Bandwidth,%,23.22,,,,,
0,49894,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(16, 1, 1)",0,7.5,Memory Workload Analysis,L1/TEX Hit Rate,%,0,,,,,
0,49894,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(16, 1, 1)",0,7.5,Memory Workload Analysis,L2 Hit Rate,%,35.14,,,,,
0,49894,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(16, 1, 1)",0,7.5,Memory Workload Analysis,Mem Pipes Busy,%,7.35,,,,,
0,49894,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(16, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Chart,,,,MemoryL2Compression,WRN,The optional metric lts__average_gcomp_input_sector_success_rate.pct could not be found. Collecting it as an additional metric could enable the rule to provide more guidance.,,
0,49894,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(16, 1, 1)",0,7.5,Scheduler Statistics,One or More Eligible,%,7.55,,,,,
0,49894,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(16, 1, 1)",0,7.5,Scheduler Statistics,Issued Warp Per Scheduler,,0.08,,,,,
0,49894,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(16, 1, 1)",0,7.5,Scheduler Statistics,No Eligible,%,92.45,,,,,
0,49894,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(16, 1, 1)",0,7.5,Scheduler Statistics,Active Warps Per Scheduler,warp,6.75,,,,,
0,49894,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(16, 1, 1)",0,7.5,Scheduler Statistics,Eligible Warps Per Scheduler,warp,0.15,,,,,
0,49894,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(16, 1, 1)",0,7.5,SchedulerStats,,,,IssueSlotUtilization,OPT,"Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 13.2 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of 6.75 active warps per scheduler, but only an average of 0.15 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, avoid possible load imbalances due to highly different execution durations per warp. Reducing stalls indicated on the Warp State Statistics and Source Counters sections can help, too.",local,76.78
0,49894,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(16, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Issued Instruction,cycle,89.36,,,,,
0,49894,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(16, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Executed Instruction,cycle,113.42,,,,,
0,49894,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(16, 1, 1)",0,7.5,Warp State Statistics,Avg. Active Threads Per Warp,,32,,,,,
0,49894,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(16, 1, 1)",0,7.5,Warp State Statistics,Avg. Not Predicated Off Threads Per Warp,,32,,,,,
0,49894,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(16, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,OPT,"On average, each warp of this kernel spends 49.4 cycles being stalled waiting for a scoreboard dependency on a L1TEX (local, global, surface, texture) operation. Find the instruction producing the data being waited upon to identify the culprit. To reduce the number of cycles waiting on L1TEX data accesses verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit rates by increasing data locality (coalescing), or by changing the cache configuration. Consider moving frequently used data to shared memory. This stall type represents about 55.3% of the total average of 89.4 cycles between issuing two instructions.",global,55.3
0,49894,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(16, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,OPT,"On average, each warp of this kernel spends 27.2 cycles being stalled waiting for an immediate constant cache (IMC) miss. A read from constant memory costs one memory read from device memory only on a cache miss; otherwise, it just costs one read from the constant cache. Immediate constants are encoded into the SASS instruction as 'c[bank][offset]'. Accesses to different addresses by threads within a warp are serialized, thus the cost scales linearly with the number of unique addresses read by all threads within a warp. As such, the constant cache is best when threads in the same warp access only a few distinct locations. If all threads of a warp access the same location, then constant memory can be as fast as a register access. This stall type represents about 30.5% of the total average of 89.4 cycles between issuing two instructions.",global,30.47
0,49894,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(16, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,INF,Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.,,
0,49894,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(16, 1, 1)",0,7.5,Instruction Statistics,Avg. Executed Instructions Per Scheduler,inst,118.86,,,,,
0,49894,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(16, 1, 1)",0,7.5,Instruction Statistics,Executed Instructions,inst,"6,656",,,,,
0,49894,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(16, 1, 1)",0,7.5,Instruction Statistics,Avg. Issued Instructions Per Scheduler,inst,150.86,,,,,
0,49894,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(16, 1, 1)",0,7.5,Instruction Statistics,Issued Instructions,inst,"8,448",,,,,
0,49894,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(16, 1, 1)",0,7.5,InstructionStats,,,,FPInstructions,OPT,"This kernel executes 0 fused and 512 non-fused FP32 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP32 performance could be increased by up to 50% (relative to its current performance). Check the Source page to identify where this kernel executes FP32 instructions.",global,2.298
0,49894,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(16, 1, 1)",0,7.5,Launch Statistics,Block Size,,"1,024",,,,,
0,49894,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(16, 1, 1)",0,7.5,Launch Statistics,Function Cache Configuration,,CachePreferNone,,,,,
0,49894,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(16, 1, 1)",0,7.5,Launch Statistics,Grid Size,,16,,,,,
0,49894,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(16, 1, 1)",0,7.5,Launch Statistics,Registers Per Thread,register/thread,16,,,,,
0,49894,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(16, 1, 1)",0,7.5,Launch Statistics,Shared Memory Configuration Size,byte,"32,768",,,,,
0,49894,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(16, 1, 1)",0,7.5,Launch Statistics,Driver Shared Memory Per Block,byte/block,0,,,,,
0,49894,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(16, 1, 1)",0,7.5,Launch Statistics,Dynamic Shared Memory Per Block,byte/block,0,,,,,
0,49894,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(16, 1, 1)",0,7.5,Launch Statistics,Static Shared Memory Per Block,byte/block,0,,,,,
0,49894,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(16, 1, 1)",0,7.5,Launch Statistics,Threads,thread,"16,384",,,,,
0,49894,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(16, 1, 1)",0,7.5,Launch Statistics,Waves Per SM,,1.14,,,,,
0,49894,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(16, 1, 1)",0,7.5,LaunchStats,,,,LaunchConfiguration,OPT,"If you execute __syncthreads() to synchronize the threads of a block, it is recommended to have more than the achieved 1 blocks per multiprocessor. This way, blocks that aren't waiting for __syncthreads() can keep the hardware busy.",,
0,49894,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(16, 1, 1)",0,7.5,Occupancy,Block Limit SM,block,16,,,,,
0,49894,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(16, 1, 1)",0,7.5,Occupancy,Block Limit Registers,block,4,,,,,
0,49894,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(16, 1, 1)",0,7.5,Occupancy,Block Limit Shared Mem,block,16,,,,,
0,49894,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(16, 1, 1)",0,7.5,Occupancy,Block Limit Warps,block,1,,,,,
0,49894,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(16, 1, 1)",0,7.5,Occupancy,Theoretical Active Warps per SM,warp,32,,,,,
0,49894,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(16, 1, 1)",0,7.5,Occupancy,Theoretical Occupancy,%,100,,,,,
0,49894,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(16, 1, 1)",0,7.5,Occupancy,Achieved Occupancy,%,85.96,,,,,
0,49894,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(16, 1, 1)",0,7.5,Occupancy,Achieved Active Warps Per SM,warp,27.51,,,,,
0,49894,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(16, 1, 1)",0,7.5,Occupancy,,,,AchievedOccupancy,OPT,The difference between calculated theoretical (100.0%) and measured achieved occupancy (86.0%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy.,global,14.04
0,49894,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(16, 1, 1)",0,7.5,Source Counters,Branch Instructions Ratio,%,0.08,,,,,
0,49894,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(16, 1, 1)",0,7.5,Source Counters,Branch Instructions,inst,512,,,,,
0,49894,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(16, 1, 1)",0,7.5,Source Counters,Branch Efficiency,%,0,,,,,
0,49894,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(16, 1, 1)",0,7.5,Source Counters,Avg. Divergent Branches,,0,,,,,
0,49990,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(32768, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Frequency,cycle/second,"6,148,435,479.70",,,,,
0,49990,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(32768, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Frequency,cycle/second,"1,414,327,159.30",,,,,
0,49990,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(32768, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Elapsed Cycles,cycle,"175,154",,,,,
0,49990,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(32768, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Memory Throughput,%,10.70,,,,,
0,49990,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(32768, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Throughput,%,1.08,,,,,
0,49990,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(32768, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Duration,nsecond,"123,744",,,,,
0,49990,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(32768, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L1/TEX Cache Throughput,%,15.57,,,,,
0,49990,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(32768, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L2 Cache Throughput,%,8.34,,,,,
0,49990,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(32768, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Active Cycles,cycle,"120,294.86",,,,,
0,49990,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(32768, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Compute (SM) Throughput,%,10.70,,,,,
0,49990,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(32768, 1, 1)",0,7.5,SpeedOfLight,,,,SOLBottleneck,OPT,This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.,,
0,49990,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(32768, 1, 1)",0,7.5,SpeedOfLight_RooflineChart,,,,SOLFPRoofline,INF,The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved  close to 0% of this device's fp32 peak performance and 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.,,
0,49990,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(32768, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Active,inst/cycle,0.25,,,,,
0,49990,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(32768, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Elapsed,inst/cycle,0.17,,,,,
0,49990,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(32768, 1, 1)",0,7.5,Compute Workload Analysis,Issue Slots Busy,%,6.33,,,,,
0,49990,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(32768, 1, 1)",0,7.5,Compute Workload Analysis,Issued Ipc Active,inst/cycle,0.25,,,,,
0,49990,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(32768, 1, 1)",0,7.5,Compute Workload Analysis,SM Busy,%,6.49,,,,,
0,49990,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(32768, 1, 1)",0,7.5,ComputeWorkloadAnalysis,,,,HighPipeUtilization,OPT,All compute pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.,local,95.14
0,49990,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(32768, 1, 1)",0,7.5,Memory Workload Analysis,Memory Throughput,byte/second,"2,120,248,254.46",,,,,
0,49990,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(32768, 1, 1)",0,7.5,Memory Workload Analysis,Mem Busy,%,6.93,,,,,
0,49990,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(32768, 1, 1)",0,7.5,Memory Workload Analysis,Max Bandwidth,%,10.70,,,,,
0,49990,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(32768, 1, 1)",0,7.5,Memory Workload Analysis,L1/TEX Hit Rate,%,23.09,,,,,
0,49990,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(32768, 1, 1)",0,7.5,Memory Workload Analysis,L2 Hit Rate,%,95.61,,,,,
0,49990,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(32768, 1, 1)",0,7.5,Memory Workload Analysis,Mem Pipes Busy,%,10.70,,,,,
0,49990,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(32768, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Chart,,,,MemoryL2Compression,WRN,The optional metric lts__average_gcomp_input_sector_success_rate.pct could not be found. Collecting it as an additional metric could enable the rule to provide more guidance.,,
0,49990,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(32768, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for loads from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced loads and try to minimize how many cache lines need to be accessed per memory request.",global,3.44
0,49990,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(32768, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for stores from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.5 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced stores and try to minimize how many cache lines need to be accessed per memory request.",global,1.419
0,49990,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(32768, 1, 1)",0,7.5,Scheduler Statistics,One or More Eligible,%,6.99,,,,,
0,49990,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(32768, 1, 1)",0,7.5,Scheduler Statistics,Issued Warp Per Scheduler,,0.07,,,,,
0,49990,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(32768, 1, 1)",0,7.5,Scheduler Statistics,No Eligible,%,93.01,,,,,
0,49990,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(32768, 1, 1)",0,7.5,Scheduler Statistics,Active Warps Per Scheduler,warp,2.77,,,,,
0,49990,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(32768, 1, 1)",0,7.5,Scheduler Statistics,Eligible Warps Per Scheduler,warp,0.07,,,,,
0,49990,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(32768, 1, 1)",0,7.5,SchedulerStats,,,,IssueSlotUtilization,OPT,"Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 14.3 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of 2.77 active warps per scheduler, but only an average of 0.07 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections.",local,89.3
0,49990,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(32768, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Issued Instruction,cycle,39.68,,,,,
0,49990,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(32768, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Executed Instruction,cycle,39.75,,,,,
0,49990,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(32768, 1, 1)",0,7.5,Warp State Statistics,Avg. Active Threads Per Warp,,1,,,,,
0,49990,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(32768, 1, 1)",0,7.5,Warp State Statistics,Avg. Not Predicated Off Threads Per Warp,,1,,,,,
0,49990,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(32768, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,OPT,"On average, each warp of this kernel spends 31.6 cycles being stalled waiting for a scoreboard dependency on a L1TEX (local, global, surface, texture) operation. Find the instruction producing the data being waited upon to identify the culprit. To reduce the number of cycles waiting on L1TEX data accesses verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit rates by increasing data locality (coalescing), or by changing the cache configuration. Consider moving frequently used data to shared memory. This stall type represents about 79.6% of the total average of 39.7 cycles between issuing two instructions.",global,79.62
0,49990,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(32768, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,INF,Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.,,
0,49990,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(32768, 1, 1)",0,7.5,WarpStateStats,,,,ThreadDivergence,OPT,"Instructions are executed in warps, which are groups of 32 threads. Optimal instruction throughput is achieved if all 32 threads of a warp execute the same instruction. The chosen launch configuration, early thread completion, and divergent flow control can significantly lower the number of active threads in a warp per cycle. This kernel achieves an average of 1.0 threads being active per cycle.",global,10.36
0,49990,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(32768, 1, 1)",0,7.5,Instruction Statistics,Avg. Executed Instructions Per Scheduler,inst,"7,606.86",,,,,
0,49990,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(32768, 1, 1)",0,7.5,Instruction Statistics,Executed Instructions,inst,"425,984",,,,,
0,49990,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(32768, 1, 1)",0,7.5,Instruction Statistics,Avg. Issued Instructions Per Scheduler,inst,"7,620.50",,,,,
0,49990,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(32768, 1, 1)",0,7.5,Instruction Statistics,Issued Instructions,inst,"426,748",,,,,
0,49990,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(32768, 1, 1)",0,7.5,InstructionStats,,,,FPInstructions,OPT,"This kernel executes 0 fused and 32768 non-fused FP32 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP32 performance could be increased by up to 50% (relative to its current performance). Check the Source page to identify where this kernel executes FP32 instructions.",global,2.432
0,49990,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(32768, 1, 1)",0,7.5,Launch Statistics,Block Size,,1,,,,,
0,49990,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(32768, 1, 1)",0,7.5,Launch Statistics,Function Cache Configuration,,CachePreferNone,,,,,
0,49990,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(32768, 1, 1)",0,7.5,Launch Statistics,Grid Size,,"32,768",,,,,
0,49990,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(32768, 1, 1)",0,7.5,Launch Statistics,Registers Per Thread,register/thread,16,,,,,
0,49990,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(32768, 1, 1)",0,7.5,Launch Statistics,Shared Memory Configuration Size,byte,"32,768",,,,,
0,49990,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(32768, 1, 1)",0,7.5,Launch Statistics,Driver Shared Memory Per Block,byte/block,0,,,,,
0,49990,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(32768, 1, 1)",0,7.5,Launch Statistics,Dynamic Shared Memory Per Block,byte/block,0,,,,,
0,49990,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(32768, 1, 1)",0,7.5,Launch Statistics,Static Shared Memory Per Block,byte/block,0,,,,,
0,49990,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(32768, 1, 1)",0,7.5,Launch Statistics,Threads,thread,"32,768",,,,,
0,49990,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(32768, 1, 1)",0,7.5,Launch Statistics,Waves Per SM,,146.29,,,,,
0,49990,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(32768, 1, 1)",0,7.5,LaunchStats,,,,LaunchConfiguration,OPT,"Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 1 threads per block. Consequently, some threads in a warp are masked off and those hardware resources are unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256 threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to kernels that frequently call __syncthreads(). See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations.",global,96.88
0,49990,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(32768, 1, 1)",0,7.5,Occupancy,Block Limit SM,block,16,,,,,
0,49990,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(32768, 1, 1)",0,7.5,Occupancy,Block Limit Registers,block,128,,,,,
0,49990,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(32768, 1, 1)",0,7.5,Occupancy,Block Limit Shared Mem,block,16,,,,,
0,49990,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(32768, 1, 1)",0,7.5,Occupancy,Block Limit Warps,block,32,,,,,
0,49990,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(32768, 1, 1)",0,7.5,Occupancy,Theoretical Active Warps per SM,warp,16,,,,,
0,49990,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(32768, 1, 1)",0,7.5,Occupancy,Theoretical Occupancy,%,50,,,,,
0,49990,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(32768, 1, 1)",0,7.5,Occupancy,Achieved Occupancy,%,32.84,,,,,
0,49990,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(32768, 1, 1)",0,7.5,Occupancy,Achieved Active Warps Per SM,warp,10.51,,,,,
0,49990,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(32768, 1, 1)",0,7.5,Occupancy,,,,AchievedOccupancy,OPT,The difference between calculated theoretical (50.0%) and measured achieved occupancy (32.8%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy.,global,34.33
0,49990,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(32768, 1, 1)",0,7.5,Occupancy,,,,TheoreticalOccupancy,OPT,The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared memory.,global,50.0
0,49990,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(32768, 1, 1)",0,7.5,Source Counters,Branch Instructions Ratio,%,0.08,,,,,
0,49990,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(32768, 1, 1)",0,7.5,Source Counters,Branch Instructions,inst,"32,768",,,,,
0,49990,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(32768, 1, 1)",0,7.5,Source Counters,Branch Efficiency,%,0,,,,,
0,49990,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(32768, 1, 1)",0,7.5,Source Counters,Avg. Divergent Branches,,0,,,,,
0,50075,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(16384, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Frequency,cycle/second,"6,064,257,028.11",,,,,
0,50075,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(16384, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Frequency,cycle/second,"1,391,276,041.67",,,,,
0,50075,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(16384, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Elapsed Cycles,cycle,"88,907",,,,,
0,50075,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(16384, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Memory Throughput,%,10.55,,,,,
0,50075,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(16384, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Throughput,%,2.12,,,,,
0,50075,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(16384, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Duration,nsecond,"63,744",,,,,
0,50075,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(16384, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L1/TEX Cache Throughput,%,16.60,,,,,
0,50075,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(16384, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L2 Cache Throughput,%,8.94,,,,,
0,50075,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(16384, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Active Cycles,cycle,"56,394.07",,,,,
0,50075,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(16384, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Compute (SM) Throughput,%,10.55,,,,,
0,50075,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(16384, 1, 1)",0,7.5,SpeedOfLight,,,,SOLBottleneck,OPT,This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.,,
0,50075,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(16384, 1, 1)",0,7.5,SpeedOfLight_RooflineChart,,,,SOLFPRoofline,INF,The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved  close to 0% of this device's fp32 peak performance and 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.,,
0,50075,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(16384, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Active,inst/cycle,0.27,,,,,
0,50075,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(16384, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Elapsed,inst/cycle,0.17,,,,,
0,50075,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(16384, 1, 1)",0,7.5,Compute Workload Analysis,Issue Slots Busy,%,6.77,,,,,
0,50075,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(16384, 1, 1)",0,7.5,Compute Workload Analysis,Issued Ipc Active,inst/cycle,0.27,,,,,
0,50075,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(16384, 1, 1)",0,7.5,Compute Workload Analysis,SM Busy,%,6.92,,,,,
0,50075,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(16384, 1, 1)",0,7.5,ComputeWorkloadAnalysis,,,,HighPipeUtilization,OPT,All compute pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.,local,94.81
0,50075,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(16384, 1, 1)",0,7.5,Memory Workload Analysis,Memory Throughput,byte/second,"4,115,963,855.42",,,,,
0,50075,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(16384, 1, 1)",0,7.5,Memory Workload Analysis,Mem Busy,%,7.18,,,,,
0,50075,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(16384, 1, 1)",0,7.5,Memory Workload Analysis,Max Bandwidth,%,10.55,,,,,
0,50075,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(16384, 1, 1)",0,7.5,Memory Workload Analysis,L1/TEX Hit Rate,%,9.87,,,,,
0,50075,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(16384, 1, 1)",0,7.5,Memory Workload Analysis,L2 Hit Rate,%,91.84,,,,,
0,50075,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(16384, 1, 1)",0,7.5,Memory Workload Analysis,Mem Pipes Busy,%,10.55,,,,,
0,50075,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(16384, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Chart,,,,MemoryL2Compression,WRN,The optional metric lts__average_gcomp_input_sector_success_rate.pct could not be found. Collecting it as an additional metric could enable the rule to provide more guidance.,,
0,50075,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(16384, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for loads from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced loads and try to minimize how many cache lines need to be accessed per memory request.",global,3.556
0,50075,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(16384, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for stores from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.3 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced stores and try to minimize how many cache lines need to be accessed per memory request.",global,1.622
0,50075,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(16384, 1, 1)",0,7.5,Scheduler Statistics,One or More Eligible,%,7.38,,,,,
0,50075,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(16384, 1, 1)",0,7.5,Scheduler Statistics,Issued Warp Per Scheduler,,0.07,,,,,
0,50075,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(16384, 1, 1)",0,7.5,Scheduler Statistics,No Eligible,%,92.62,,,,,
0,50075,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(16384, 1, 1)",0,7.5,Scheduler Statistics,Active Warps Per Scheduler,warp,2.83,,,,,
0,50075,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(16384, 1, 1)",0,7.5,Scheduler Statistics,Eligible Warps Per Scheduler,warp,0.08,,,,,
0,50075,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(16384, 1, 1)",0,7.5,SchedulerStats,,,,IssueSlotUtilization,OPT,"Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 13.5 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of 2.83 active warps per scheduler, but only an average of 0.08 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections.",local,89.45
0,50075,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(16384, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Issued Instruction,cycle,38.36,,,,,
0,50075,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(16384, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Executed Instruction,cycle,38.50,,,,,
0,50075,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(16384, 1, 1)",0,7.5,Warp State Statistics,Avg. Active Threads Per Warp,,2,,,,,
0,50075,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(16384, 1, 1)",0,7.5,Warp State Statistics,Avg. Not Predicated Off Threads Per Warp,,2,,,,,
0,50075,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(16384, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,OPT,"On average, each warp of this kernel spends 29.5 cycles being stalled waiting for a scoreboard dependency on a L1TEX (local, global, surface, texture) operation. Find the instruction producing the data being waited upon to identify the culprit. To reduce the number of cycles waiting on L1TEX data accesses verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit rates by increasing data locality (coalescing), or by changing the cache configuration. Consider moving frequently used data to shared memory. This stall type represents about 76.9% of the total average of 38.4 cycles between issuing two instructions.",global,76.9
0,50075,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(16384, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,INF,Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.,,
0,50075,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(16384, 1, 1)",0,7.5,WarpStateStats,,,,ThreadDivergence,OPT,"Instructions are executed in warps, which are groups of 32 threads. Optimal instruction throughput is achieved if all 32 threads of a warp execute the same instruction. The chosen launch configuration, early thread completion, and divergent flow control can significantly lower the number of active threads in a warp per cycle. This kernel achieves an average of 2.0 threads being active per cycle.",global,9.893
0,50075,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(16384, 1, 1)",0,7.5,Instruction Statistics,Avg. Executed Instructions Per Scheduler,inst,"3,803.43",,,,,
0,50075,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(16384, 1, 1)",0,7.5,Instruction Statistics,Executed Instructions,inst,"212,992",,,,,
0,50075,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(16384, 1, 1)",0,7.5,Instruction Statistics,Avg. Issued Instructions Per Scheduler,inst,"3,817.07",,,,,
0,50075,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(16384, 1, 1)",0,7.5,Instruction Statistics,Issued Instructions,inst,"213,756",,,,,
0,50075,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(16384, 1, 1)",0,7.5,InstructionStats,,,,FPInstructions,OPT,"This kernel executes 0 fused and 16384 non-fused FP32 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP32 performance could be increased by up to 50% (relative to its current performance). Check the Source page to identify where this kernel executes FP32 instructions.",global,2.594
0,50075,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(16384, 1, 1)",0,7.5,Launch Statistics,Block Size,,2,,,,,
0,50075,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(16384, 1, 1)",0,7.5,Launch Statistics,Function Cache Configuration,,CachePreferNone,,,,,
0,50075,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(16384, 1, 1)",0,7.5,Launch Statistics,Grid Size,,"16,384",,,,,
0,50075,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(16384, 1, 1)",0,7.5,Launch Statistics,Registers Per Thread,register/thread,16,,,,,
0,50075,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(16384, 1, 1)",0,7.5,Launch Statistics,Shared Memory Configuration Size,byte,"32,768",,,,,
0,50075,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(16384, 1, 1)",0,7.5,Launch Statistics,Driver Shared Memory Per Block,byte/block,0,,,,,
0,50075,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(16384, 1, 1)",0,7.5,Launch Statistics,Dynamic Shared Memory Per Block,byte/block,0,,,,,
0,50075,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(16384, 1, 1)",0,7.5,Launch Statistics,Static Shared Memory Per Block,byte/block,0,,,,,
0,50075,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(16384, 1, 1)",0,7.5,Launch Statistics,Threads,thread,"32,768",,,,,
0,50075,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(16384, 1, 1)",0,7.5,Launch Statistics,Waves Per SM,,73.14,,,,,
0,50075,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(16384, 1, 1)",0,7.5,LaunchStats,,,,LaunchConfiguration,OPT,"Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 2 threads per block. Consequently, some threads in a warp are masked off and those hardware resources are unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256 threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to kernels that frequently call __syncthreads(). See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations.",global,93.75
0,50075,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(16384, 1, 1)",0,7.5,Occupancy,Block Limit SM,block,16,,,,,
0,50075,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(16384, 1, 1)",0,7.5,Occupancy,Block Limit Registers,block,128,,,,,
0,50075,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(16384, 1, 1)",0,7.5,Occupancy,Block Limit Shared Mem,block,16,,,,,
0,50075,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(16384, 1, 1)",0,7.5,Occupancy,Block Limit Warps,block,32,,,,,
0,50075,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(16384, 1, 1)",0,7.5,Occupancy,Theoretical Active Warps per SM,warp,16,,,,,
0,50075,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(16384, 1, 1)",0,7.5,Occupancy,Theoretical Occupancy,%,50,,,,,
0,50075,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(16384, 1, 1)",0,7.5,Occupancy,Achieved Occupancy,%,33.55,,,,,
0,50075,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(16384, 1, 1)",0,7.5,Occupancy,Achieved Active Warps Per SM,warp,10.74,,,,,
0,50075,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(16384, 1, 1)",0,7.5,Occupancy,,,,AchievedOccupancy,OPT,The difference between calculated theoretical (50.0%) and measured achieved occupancy (33.5%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy.,global,32.9
0,50075,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(16384, 1, 1)",0,7.5,Occupancy,,,,TheoreticalOccupancy,OPT,The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared memory.,global,50.0
0,50075,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(16384, 1, 1)",0,7.5,Source Counters,Branch Instructions Ratio,%,0.08,,,,,
0,50075,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(16384, 1, 1)",0,7.5,Source Counters,Branch Instructions,inst,"16,384",,,,,
0,50075,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(16384, 1, 1)",0,7.5,Source Counters,Branch Efficiency,%,0,,,,,
0,50075,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(16384, 1, 1)",0,7.5,Source Counters,Avg. Divergent Branches,,0,,,,,
0,50152,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(8192, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Frequency,cycle/second,"6,388,721,047.33",,,,,
0,50152,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(8192, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Frequency,cycle/second,"1,468,120,594.16",,,,,
0,50152,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(8192, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Elapsed Cycles,cycle,"46,716",,,,,
0,50152,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(8192, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Memory Throughput,%,10.03,,,,,
0,50152,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(8192, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Throughput,%,4.04,,,,,
0,50152,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(8192, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Duration,nsecond,"31,776",,,,,
0,50152,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(8192, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L1/TEX Cache Throughput,%,14.36,,,,,
0,50152,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(8192, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L2 Cache Throughput,%,8.71,,,,,
0,50152,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(8192, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Active Cycles,cycle,"32,609.71",,,,,
0,50152,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(8192, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Compute (SM) Throughput,%,10.03,,,,,
0,50152,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(8192, 1, 1)",0,7.5,SpeedOfLight,,,,SOLBottleneck,OPT,This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.,,
0,50152,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(8192, 1, 1)",0,7.5,SpeedOfLight_RooflineChart,,,,SOLFPRoofline,INF,The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved  close to 0% of this device's fp32 peak performance and 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.,,
0,50152,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(8192, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Active,inst/cycle,0.23,,,,,
0,50152,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(8192, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Elapsed,inst/cycle,0.16,,,,,
0,50152,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(8192, 1, 1)",0,7.5,Compute Workload Analysis,Issue Slots Busy,%,5.87,,,,,
0,50152,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(8192, 1, 1)",0,7.5,Compute Workload Analysis,Issued Ipc Active,inst/cycle,0.23,,,,,
0,50152,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(8192, 1, 1)",0,7.5,Compute Workload Analysis,SM Busy,%,5.98,,,,,
0,50152,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(8192, 1, 1)",0,7.5,ComputeWorkloadAnalysis,,,,HighPipeUtilization,OPT,All compute pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.,local,95.51
0,50152,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(8192, 1, 1)",0,7.5,Memory Workload Analysis,Memory Throughput,byte/second,"8,256,797,583.08",,,,,
0,50152,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(8192, 1, 1)",0,7.5,Memory Workload Analysis,Mem Busy,%,6.83,,,,,
0,50152,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(8192, 1, 1)",0,7.5,Memory Workload Analysis,Max Bandwidth,%,10.03,,,,,
0,50152,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(8192, 1, 1)",0,7.5,Memory Workload Analysis,L1/TEX Hit Rate,%,5.23,,,,,
0,50152,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(8192, 1, 1)",0,7.5,Memory Workload Analysis,L2 Hit Rate,%,83.10,,,,,
0,50152,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(8192, 1, 1)",0,7.5,Memory Workload Analysis,Mem Pipes Busy,%,10.03,,,,,
0,50152,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(8192, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Chart,,,,MemoryL2Compression,WRN,The optional metric lts__average_gcomp_input_sector_success_rate.pct could not be found. Collecting it as an additional metric could enable the rule to provide more guidance.,,
0,50152,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(8192, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for loads from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced loads and try to minimize how many cache lines need to be accessed per memory request.",global,3.372
0,50152,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(8192, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for stores from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.1 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced stores and try to minimize how many cache lines need to be accessed per memory request.",global,1.629
0,50152,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(8192, 1, 1)",0,7.5,Scheduler Statistics,One or More Eligible,%,6.68,,,,,
0,50152,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(8192, 1, 1)",0,7.5,Scheduler Statistics,Issued Warp Per Scheduler,,0.07,,,,,
0,50152,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(8192, 1, 1)",0,7.5,Scheduler Statistics,No Eligible,%,93.32,,,,,
0,50152,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(8192, 1, 1)",0,7.5,Scheduler Statistics,Active Warps Per Scheduler,warp,2.62,,,,,
0,50152,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(8192, 1, 1)",0,7.5,Scheduler Statistics,Eligible Warps Per Scheduler,warp,0.07,,,,,
0,50152,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(8192, 1, 1)",0,7.5,SchedulerStats,,,,IssueSlotUtilization,OPT,"Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 15.0 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of 2.62 active warps per scheduler, but only an average of 0.07 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections.",local,89.97
0,50152,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(8192, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Issued Instruction,cycle,39.23,,,,,
0,50152,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(8192, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Executed Instruction,cycle,39.52,,,,,
0,50152,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(8192, 1, 1)",0,7.5,Warp State Statistics,Avg. Active Threads Per Warp,,4,,,,,
0,50152,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(8192, 1, 1)",0,7.5,Warp State Statistics,Avg. Not Predicated Off Threads Per Warp,,4,,,,,
0,50152,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(8192, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,OPT,"On average, each warp of this kernel spends 29.4 cycles being stalled waiting for a scoreboard dependency on a L1TEX (local, global, surface, texture) operation. Find the instruction producing the data being waited upon to identify the culprit. To reduce the number of cycles waiting on L1TEX data accesses verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit rates by increasing data locality (coalescing), or by changing the cache configuration. Consider moving frequently used data to shared memory. This stall type represents about 75.0% of the total average of 39.2 cycles between issuing two instructions.",global,75.0
0,50152,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(8192, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,INF,Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.,,
0,50152,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(8192, 1, 1)",0,7.5,WarpStateStats,,,,ThreadDivergence,OPT,"Instructions are executed in warps, which are groups of 32 threads. Optimal instruction throughput is achieved if all 32 threads of a warp execute the same instruction. The chosen launch configuration, early thread completion, and divergent flow control can significantly lower the number of active threads in a warp per cycle. This kernel achieves an average of 4.0 threads being active per cycle.",global,8.778
0,50152,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(8192, 1, 1)",0,7.5,Instruction Statistics,Avg. Executed Instructions Per Scheduler,inst,"1,901.71",,,,,
0,50152,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(8192, 1, 1)",0,7.5,Instruction Statistics,Executed Instructions,inst,"106,496",,,,,
0,50152,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(8192, 1, 1)",0,7.5,Instruction Statistics,Avg. Issued Instructions Per Scheduler,inst,"1,915.41",,,,,
0,50152,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(8192, 1, 1)",0,7.5,Instruction Statistics,Issued Instructions,inst,"107,263",,,,,
0,50152,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(8192, 1, 1)",0,7.5,InstructionStats,,,,FPInstructions,OPT,"This kernel executes 0 fused and 8192 non-fused FP32 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP32 performance could be increased by up to 50% (relative to its current performance). Check the Source page to identify where this kernel executes FP32 instructions.",global,2.243
0,50152,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(8192, 1, 1)",0,7.5,Launch Statistics,Block Size,,4,,,,,
0,50152,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(8192, 1, 1)",0,7.5,Launch Statistics,Function Cache Configuration,,CachePreferNone,,,,,
0,50152,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(8192, 1, 1)",0,7.5,Launch Statistics,Grid Size,,"8,192",,,,,
0,50152,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(8192, 1, 1)",0,7.5,Launch Statistics,Registers Per Thread,register/thread,16,,,,,
0,50152,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(8192, 1, 1)",0,7.5,Launch Statistics,Shared Memory Configuration Size,byte,"32,768",,,,,
0,50152,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(8192, 1, 1)",0,7.5,Launch Statistics,Driver Shared Memory Per Block,byte/block,0,,,,,
0,50152,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(8192, 1, 1)",0,7.5,Launch Statistics,Dynamic Shared Memory Per Block,byte/block,0,,,,,
0,50152,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(8192, 1, 1)",0,7.5,Launch Statistics,Static Shared Memory Per Block,byte/block,0,,,,,
0,50152,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(8192, 1, 1)",0,7.5,Launch Statistics,Threads,thread,"32,768",,,,,
0,50152,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(8192, 1, 1)",0,7.5,Launch Statistics,Waves Per SM,,36.57,,,,,
0,50152,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(8192, 1, 1)",0,7.5,LaunchStats,,,,LaunchConfiguration,OPT,"Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 4 threads per block. Consequently, some threads in a warp are masked off and those hardware resources are unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256 threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to kernels that frequently call __syncthreads(). See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations.",global,87.5
0,50152,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(8192, 1, 1)",0,7.5,Occupancy,Block Limit SM,block,16,,,,,
0,50152,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(8192, 1, 1)",0,7.5,Occupancy,Block Limit Registers,block,128,,,,,
0,50152,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(8192, 1, 1)",0,7.5,Occupancy,Block Limit Shared Mem,block,16,,,,,
0,50152,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(8192, 1, 1)",0,7.5,Occupancy,Block Limit Warps,block,32,,,,,
0,50152,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(8192, 1, 1)",0,7.5,Occupancy,Theoretical Active Warps per SM,warp,16,,,,,
0,50152,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(8192, 1, 1)",0,7.5,Occupancy,Theoretical Occupancy,%,50,,,,,
0,50152,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(8192, 1, 1)",0,7.5,Occupancy,Achieved Occupancy,%,30.09,,,,,
0,50152,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(8192, 1, 1)",0,7.5,Occupancy,Achieved Active Warps Per SM,warp,9.63,,,,,
0,50152,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(8192, 1, 1)",0,7.5,Occupancy,,,,AchievedOccupancy,OPT,The difference between calculated theoretical (50.0%) and measured achieved occupancy (30.1%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy.,global,39.81
0,50152,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(8192, 1, 1)",0,7.5,Occupancy,,,,TheoreticalOccupancy,OPT,The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared memory.,global,50.0
0,50152,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(8192, 1, 1)",0,7.5,Source Counters,Branch Instructions Ratio,%,0.08,,,,,
0,50152,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(8192, 1, 1)",0,7.5,Source Counters,Branch Instructions,inst,"8,192",,,,,
0,50152,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(8192, 1, 1)",0,7.5,Source Counters,Branch Efficiency,%,0,,,,,
0,50152,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(8192, 1, 1)",0,7.5,Source Counters,Avg. Divergent Branches,,0,,,,,
0,50238,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(4096, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Frequency,cycle/second,"6,139,886,578.45",,,,,
0,50238,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(4096, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Frequency,cycle/second,"1,410,857,750.47",,,,,
0,50238,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(4096, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Elapsed Cycles,cycle,"23,916",,,,,
0,50238,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(4096, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Memory Throughput,%,9.80,,,,,
0,50238,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(4096, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Throughput,%,7.89,,,,,
0,50238,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(4096, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Duration,nsecond,"16,928",,,,,
0,50238,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(4096, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L1/TEX Cache Throughput,%,13.95,,,,,
0,50238,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(4096, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L2 Cache Throughput,%,6.81,,,,,
0,50238,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(4096, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Active Cycles,cycle,"16,778.36",,,,,
0,50238,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(4096, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Compute (SM) Throughput,%,9.80,,,,,
0,50238,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(4096, 1, 1)",0,7.5,SpeedOfLight,,,,SOLBottleneck,OPT,This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.,,
0,50238,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(4096, 1, 1)",0,7.5,SpeedOfLight_RooflineChart,,,,SOLFPRoofline,INF,The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved  close to 0% of this device's fp32 peak performance and 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.,,
0,50238,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(4096, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Active,inst/cycle,0.23,,,,,
0,50238,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(4096, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Elapsed,inst/cycle,0.16,,,,,
0,50238,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(4096, 1, 1)",0,7.5,Compute Workload Analysis,Issue Slots Busy,%,5.75,,,,,
0,50238,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(4096, 1, 1)",0,7.5,Compute Workload Analysis,Issued Ipc Active,inst/cycle,0.23,,,,,
0,50238,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(4096, 1, 1)",0,7.5,Compute Workload Analysis,SM Busy,%,5.81,,,,,
0,50238,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(4096, 1, 1)",0,7.5,ComputeWorkloadAnalysis,,,,HighPipeUtilization,OPT,All compute pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.,local,95.64
0,50238,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(4096, 1, 1)",0,7.5,Memory Workload Analysis,Memory Throughput,byte/second,"15,499,054,820.42",,,,,
0,50238,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(4096, 1, 1)",0,7.5,Memory Workload Analysis,Mem Busy,%,6.81,,,,,
0,50238,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(4096, 1, 1)",0,7.5,Memory Workload Analysis,Max Bandwidth,%,9.80,,,,,
0,50238,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(4096, 1, 1)",0,7.5,Memory Workload Analysis,L1/TEX Hit Rate,%,2.22,,,,,
0,50238,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(4096, 1, 1)",0,7.5,Memory Workload Analysis,L2 Hit Rate,%,65.81,,,,,
0,50238,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(4096, 1, 1)",0,7.5,Memory Workload Analysis,Mem Pipes Busy,%,9.80,,,,,
0,50238,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(4096, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Chart,,,,MemoryL2Compression,WRN,The optional metric lts__average_gcomp_input_sector_success_rate.pct could not be found. Collecting it as an additional metric could enable the rule to provide more guidance.,,
0,50238,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(4096, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for loads from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced loads and try to minimize how many cache lines need to be accessed per memory request.",global,3.341
0,50238,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(4096, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for stores from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.1 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced stores and try to minimize how many cache lines need to be accessed per memory request.",global,1.648
0,50238,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(4096, 1, 1)",0,7.5,Scheduler Statistics,One or More Eligible,%,6.45,,,,,
0,50238,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(4096, 1, 1)",0,7.5,Scheduler Statistics,Issued Warp Per Scheduler,,0.06,,,,,
0,50238,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(4096, 1, 1)",0,7.5,Scheduler Statistics,No Eligible,%,93.55,,,,,
0,50238,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(4096, 1, 1)",0,7.5,Scheduler Statistics,Active Warps Per Scheduler,warp,2.70,,,,,
0,50238,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(4096, 1, 1)",0,7.5,Scheduler Statistics,Eligible Warps Per Scheduler,warp,0.07,,,,,
0,50238,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(4096, 1, 1)",0,7.5,SchedulerStats,,,,IssueSlotUtilization,OPT,"Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 15.5 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of 2.70 active warps per scheduler, but only an average of 0.07 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections.",local,90.2
0,50238,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(4096, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Issued Instruction,cycle,41.84,,,,,
0,50238,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(4096, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Executed Instruction,cycle,42.44,,,,,
0,50238,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(4096, 1, 1)",0,7.5,Warp State Statistics,Avg. Active Threads Per Warp,,8,,,,,
0,50238,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(4096, 1, 1)",0,7.5,Warp State Statistics,Avg. Not Predicated Off Threads Per Warp,,8,,,,,
0,50238,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(4096, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,OPT,"On average, each warp of this kernel spends 32.5 cycles being stalled waiting for a scoreboard dependency on a L1TEX (local, global, surface, texture) operation. Find the instruction producing the data being waited upon to identify the culprit. To reduce the number of cycles waiting on L1TEX data accesses verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit rates by increasing data locality (coalescing), or by changing the cache configuration. Consider moving frequently used data to shared memory. This stall type represents about 77.6% of the total average of 41.8 cycles between issuing two instructions.",global,77.55
0,50238,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(4096, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,INF,Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.,,
0,50238,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(4096, 1, 1)",0,7.5,WarpStateStats,,,,ThreadDivergence,OPT,"Instructions are executed in warps, which are groups of 32 threads. Optimal instruction throughput is achieved if all 32 threads of a warp execute the same instruction. The chosen launch configuration, early thread completion, and divergent flow control can significantly lower the number of active threads in a warp per cycle. This kernel achieves an average of 8.0 threads being active per cycle.",global,7.349
0,50238,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(4096, 1, 1)",0,7.5,Instruction Statistics,Avg. Executed Instructions Per Scheduler,inst,950.86,,,,,
0,50238,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(4096, 1, 1)",0,7.5,Instruction Statistics,Executed Instructions,inst,"53,248",,,,,
0,50238,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(4096, 1, 1)",0,7.5,Instruction Statistics,Avg. Issued Instructions Per Scheduler,inst,964.50,,,,,
0,50238,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(4096, 1, 1)",0,7.5,Instruction Statistics,Issued Instructions,inst,"54,012",,,,,
0,50238,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(4096, 1, 1)",0,7.5,InstructionStats,,,,FPInstructions,OPT,"This kernel executes 0 fused and 4096 non-fused FP32 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP32 performance could be increased by up to 50% (relative to its current performance). Check the Source page to identify where this kernel executes FP32 instructions.",global,2.18
0,50238,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(4096, 1, 1)",0,7.5,Launch Statistics,Block Size,,8,,,,,
0,50238,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(4096, 1, 1)",0,7.5,Launch Statistics,Function Cache Configuration,,CachePreferNone,,,,,
0,50238,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(4096, 1, 1)",0,7.5,Launch Statistics,Grid Size,,"4,096",,,,,
0,50238,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(4096, 1, 1)",0,7.5,Launch Statistics,Registers Per Thread,register/thread,16,,,,,
0,50238,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(4096, 1, 1)",0,7.5,Launch Statistics,Shared Memory Configuration Size,byte,"32,768",,,,,
0,50238,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(4096, 1, 1)",0,7.5,Launch Statistics,Driver Shared Memory Per Block,byte/block,0,,,,,
0,50238,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(4096, 1, 1)",0,7.5,Launch Statistics,Dynamic Shared Memory Per Block,byte/block,0,,,,,
0,50238,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(4096, 1, 1)",0,7.5,Launch Statistics,Static Shared Memory Per Block,byte/block,0,,,,,
0,50238,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(4096, 1, 1)",0,7.5,Launch Statistics,Threads,thread,"32,768",,,,,
0,50238,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(4096, 1, 1)",0,7.5,Launch Statistics,Waves Per SM,,18.29,,,,,
0,50238,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(4096, 1, 1)",0,7.5,LaunchStats,,,,LaunchConfiguration,OPT,"Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 8 threads per block. Consequently, some threads in a warp are masked off and those hardware resources are unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256 threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to kernels that frequently call __syncthreads(). See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations.",global,75.0
0,50238,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(4096, 1, 1)",0,7.5,Occupancy,Block Limit SM,block,16,,,,,
0,50238,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(4096, 1, 1)",0,7.5,Occupancy,Block Limit Registers,block,128,,,,,
0,50238,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(4096, 1, 1)",0,7.5,Occupancy,Block Limit Shared Mem,block,16,,,,,
0,50238,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(4096, 1, 1)",0,7.5,Occupancy,Block Limit Warps,block,32,,,,,
0,50238,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(4096, 1, 1)",0,7.5,Occupancy,Theoretical Active Warps per SM,warp,16,,,,,
0,50238,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(4096, 1, 1)",0,7.5,Occupancy,Theoretical Occupancy,%,50,,,,,
0,50238,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(4096, 1, 1)",0,7.5,Occupancy,Achieved Occupancy,%,31.41,,,,,
0,50238,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(4096, 1, 1)",0,7.5,Occupancy,Achieved Active Warps Per SM,warp,10.05,,,,,
0,50238,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(4096, 1, 1)",0,7.5,Occupancy,,,,AchievedOccupancy,OPT,The difference between calculated theoretical (50.0%) and measured achieved occupancy (31.4%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy.,global,37.17
0,50238,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(4096, 1, 1)",0,7.5,Occupancy,,,,TheoreticalOccupancy,OPT,The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared memory.,global,50.0
0,50238,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(4096, 1, 1)",0,7.5,Source Counters,Branch Instructions Ratio,%,0.08,,,,,
0,50238,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(4096, 1, 1)",0,7.5,Source Counters,Branch Instructions,inst,"4,096",,,,,
0,50238,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(4096, 1, 1)",0,7.5,Source Counters,Branch Efficiency,%,0,,,,,
0,50238,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(4096, 1, 1)",0,7.5,Source Counters,Avg. Divergent Branches,,0,,,,,
0,50315,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(2048, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Frequency,cycle/second,"5,890,675,241.16",,,,,
0,50315,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(2048, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Frequency,cycle/second,"1,347,568,327.97",,,,,
0,50315,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(2048, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Elapsed Cycles,cycle,"13,432",,,,,
0,50315,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(2048, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Memory Throughput,%,13.99,,,,,
0,50315,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(2048, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Throughput,%,13.99,,,,,
0,50315,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(2048, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Duration,nsecond,"9,952",,,,,
0,50315,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(2048, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L1/TEX Cache Throughput,%,12.75,,,,,
0,50315,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(2048, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L2 Cache Throughput,%,12.13,,,,,
0,50315,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(2048, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Active Cycles,cycle,"9,181.57",,,,,
0,50315,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(2048, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Compute (SM) Throughput,%,8.72,,,,,
0,50315,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(2048, 1, 1)",0,7.5,SpeedOfLight,,,,SOLBottleneck,OPT,This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.,,
0,50315,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(2048, 1, 1)",0,7.5,SpeedOfLight_RooflineChart,,,,SOLFPRoofline,INF,The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved  close to 0% of this device's fp32 peak performance and 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.,,
0,50315,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(2048, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Active,inst/cycle,0.21,,,,,
0,50315,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(2048, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Elapsed,inst/cycle,0.14,,,,,
0,50315,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(2048, 1, 1)",0,7.5,Compute Workload Analysis,Issue Slots Busy,%,5.33,,,,,
0,50315,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(2048, 1, 1)",0,7.5,Compute Workload Analysis,Issued Ipc Active,inst/cycle,0.21,,,,,
0,50315,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(2048, 1, 1)",0,7.5,Compute Workload Analysis,SM Busy,%,5.33,,,,,
0,50315,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(2048, 1, 1)",0,7.5,ComputeWorkloadAnalysis,,,,HighPipeUtilization,OPT,All compute pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.,local,96.02
0,50315,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(2048, 1, 1)",0,7.5,Memory Workload Analysis,Memory Throughput,byte/second,"26,363,344,051.45",,,,,
0,50315,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(2048, 1, 1)",0,7.5,Memory Workload Analysis,Mem Busy,%,12.13,,,,,
0,50315,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(2048, 1, 1)",0,7.5,Memory Workload Analysis,Max Bandwidth,%,13.99,,,,,
0,50315,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(2048, 1, 1)",0,7.5,Memory Workload Analysis,L1/TEX Hit Rate,%,2.15,,,,,
0,50315,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(2048, 1, 1)",0,7.5,Memory Workload Analysis,L2 Hit Rate,%,34.27,,,,,
0,50315,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(2048, 1, 1)",0,7.5,Memory Workload Analysis,Mem Pipes Busy,%,8.72,,,,,
0,50315,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(2048, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Chart,,,,MemoryL2Compression,WRN,The optional metric lts__average_gcomp_input_sector_success_rate.pct could not be found. Collecting it as an additional metric could enable the rule to provide more guidance.,,
0,50315,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(2048, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for loads from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 2.1 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced loads and try to minimize how many cache lines need to be accessed per memory request.",global,3.816
0,50315,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(2048, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for stores from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 2.1 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced stores and try to minimize how many cache lines need to be accessed per memory request.",global,1.901
0,50315,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(2048, 1, 1)",0,7.5,Scheduler Statistics,One or More Eligible,%,5.97,,,,,
0,50315,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(2048, 1, 1)",0,7.5,Scheduler Statistics,Issued Warp Per Scheduler,,0.06,,,,,
0,50315,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(2048, 1, 1)",0,7.5,Scheduler Statistics,No Eligible,%,94.03,,,,,
0,50315,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(2048, 1, 1)",0,7.5,Scheduler Statistics,Active Warps Per Scheduler,warp,2.85,,,,,
0,50315,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(2048, 1, 1)",0,7.5,Scheduler Statistics,Eligible Warps Per Scheduler,warp,0.06,,,,,
0,50315,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(2048, 1, 1)",0,7.5,SchedulerStats,,,,IssueSlotUtilization,OPT,"Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 16.8 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of 2.85 active warps per scheduler, but only an average of 0.06 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections.",local,86.01
0,50315,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(2048, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Issued Instruction,cycle,47.71,,,,,
0,50315,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(2048, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Executed Instruction,cycle,49.08,,,,,
0,50315,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(2048, 1, 1)",0,7.5,Warp State Statistics,Avg. Active Threads Per Warp,,16,,,,,
0,50315,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(2048, 1, 1)",0,7.5,Warp State Statistics,Avg. Not Predicated Off Threads Per Warp,,16,,,,,
0,50315,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(2048, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,OPT,"On average, each warp of this kernel spends 33.9 cycles being stalled waiting for a scoreboard dependency on a L1TEX (local, global, surface, texture) operation. Find the instruction producing the data being waited upon to identify the culprit. To reduce the number of cycles waiting on L1TEX data accesses verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit rates by increasing data locality (coalescing), or by changing the cache configuration. Consider moving frequently used data to shared memory. This stall type represents about 71.0% of the total average of 47.7 cycles between issuing two instructions.",global,71.0
0,50315,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(2048, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,INF,Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.,,
0,50315,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(2048, 1, 1)",0,7.5,WarpStateStats,,,,ThreadDivergence,OPT,"Instructions are executed in warps, which are groups of 32 threads. Optimal instruction throughput is achieved if all 32 threads of a warp execute the same instruction. The chosen launch configuration, early thread completion, and divergent flow control can significantly lower the number of active threads in a warp per cycle. This kernel achieves an average of 16.0 threads being active per cycle.",global,4.362
0,50315,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(2048, 1, 1)",0,7.5,Instruction Statistics,Avg. Executed Instructions Per Scheduler,inst,475.43,,,,,
0,50315,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(2048, 1, 1)",0,7.5,Instruction Statistics,Executed Instructions,inst,"26,624",,,,,
0,50315,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(2048, 1, 1)",0,7.5,Instruction Statistics,Avg. Issued Instructions Per Scheduler,inst,489.07,,,,,
0,50315,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(2048, 1, 1)",0,7.5,Instruction Statistics,Issued Instructions,inst,"27,388",,,,,
0,50315,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(2048, 1, 1)",0,7.5,InstructionStats,,,,FPInstructions,OPT,"This kernel executes 0 fused and 2048 non-fused FP32 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP32 performance could be increased by up to 50% (relative to its current performance). Check the Source page to identify where this kernel executes FP32 instructions.",global,1.992
0,50315,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(2048, 1, 1)",0,7.5,Launch Statistics,Block Size,,16,,,,,
0,50315,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(2048, 1, 1)",0,7.5,Launch Statistics,Function Cache Configuration,,CachePreferNone,,,,,
0,50315,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(2048, 1, 1)",0,7.5,Launch Statistics,Grid Size,,"2,048",,,,,
0,50315,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(2048, 1, 1)",0,7.5,Launch Statistics,Registers Per Thread,register/thread,16,,,,,
0,50315,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(2048, 1, 1)",0,7.5,Launch Statistics,Shared Memory Configuration Size,byte,"32,768",,,,,
0,50315,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(2048, 1, 1)",0,7.5,Launch Statistics,Driver Shared Memory Per Block,byte/block,0,,,,,
0,50315,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(2048, 1, 1)",0,7.5,Launch Statistics,Dynamic Shared Memory Per Block,byte/block,0,,,,,
0,50315,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(2048, 1, 1)",0,7.5,Launch Statistics,Static Shared Memory Per Block,byte/block,0,,,,,
0,50315,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(2048, 1, 1)",0,7.5,Launch Statistics,Threads,thread,"32,768",,,,,
0,50315,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(2048, 1, 1)",0,7.5,Launch Statistics,Waves Per SM,,9.14,,,,,
0,50315,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(2048, 1, 1)",0,7.5,LaunchStats,,,,LaunchConfiguration,OPT,"Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 16 threads per block. Consequently, some threads in a warp are masked off and those hardware resources are unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256 threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to kernels that frequently call __syncthreads(). See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations.",global,50.0
0,50315,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(2048, 1, 1)",0,7.5,Occupancy,Block Limit SM,block,16,,,,,
0,50315,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(2048, 1, 1)",0,7.5,Occupancy,Block Limit Registers,block,128,,,,,
0,50315,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(2048, 1, 1)",0,7.5,Occupancy,Block Limit Shared Mem,block,16,,,,,
0,50315,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(2048, 1, 1)",0,7.5,Occupancy,Block Limit Warps,block,32,,,,,
0,50315,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(2048, 1, 1)",0,7.5,Occupancy,Theoretical Active Warps per SM,warp,16,,,,,
0,50315,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(2048, 1, 1)",0,7.5,Occupancy,Theoretical Occupancy,%,50,,,,,
0,50315,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(2048, 1, 1)",0,7.5,Occupancy,Achieved Occupancy,%,32.62,,,,,
0,50315,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(2048, 1, 1)",0,7.5,Occupancy,Achieved Active Warps Per SM,warp,10.44,,,,,
0,50315,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(2048, 1, 1)",0,7.5,Occupancy,,,,AchievedOccupancy,OPT,The difference between calculated theoretical (50.0%) and measured achieved occupancy (32.6%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy.,global,34.75
0,50315,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(2048, 1, 1)",0,7.5,Occupancy,,,,TheoreticalOccupancy,OPT,The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared memory.,global,50.0
0,50315,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(2048, 1, 1)",0,7.5,Source Counters,Branch Instructions Ratio,%,0.08,,,,,
0,50315,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(2048, 1, 1)",0,7.5,Source Counters,Branch Instructions,inst,"2,048",,,,,
0,50315,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(2048, 1, 1)",0,7.5,Source Counters,Branch Efficiency,%,0,,,,,
0,50315,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(2048, 1, 1)",0,7.5,Source Counters,Avg. Divergent Branches,,0,,,,,
0,50401,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(1024, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Frequency,cycle/second,"5,794,594,594.59",,,,,
0,50401,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(1024, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Frequency,cycle/second,"1,328,125,000",,,,,
0,50401,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(1024, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Elapsed Cycles,cycle,"7,877",,,,,
0,50401,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(1024, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Memory Throughput,%,23.90,,,,,
0,50401,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(1024, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Throughput,%,23.90,,,,,
0,50401,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(1024, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Duration,nsecond,"5,920",,,,,
0,50401,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(1024, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L1/TEX Cache Throughput,%,11.03,,,,,
0,50401,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(1024, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L2 Cache Throughput,%,20.69,,,,,
0,50401,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(1024, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Active Cycles,cycle,"5,384.21",,,,,
0,50401,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(1024, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Compute (SM) Throughput,%,7.44,,,,,
0,50401,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(1024, 1, 1)",0,7.5,SpeedOfLight,,,,SOLBottleneck,OPT,This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.,,
0,50401,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(1024, 1, 1)",0,7.5,SpeedOfLight_RooflineChart,,,,SOLFPRoofline,INF,The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved  close to 0% of this device's fp32 peak performance and 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.,,
0,50401,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(1024, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Active,inst/cycle,0.18,,,,,
0,50401,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(1024, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Elapsed,inst/cycle,0.12,,,,,
0,50401,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(1024, 1, 1)",0,7.5,Compute Workload Analysis,Issue Slots Busy,%,4.67,,,,,
0,50401,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(1024, 1, 1)",0,7.5,Compute Workload Analysis,Issued Ipc Active,inst/cycle,0.19,,,,,
0,50401,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(1024, 1, 1)",0,7.5,Compute Workload Analysis,SM Busy,%,4.67,,,,,
0,50401,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(1024, 1, 1)",0,7.5,ComputeWorkloadAnalysis,,,,HighPipeUtilization,OPT,All compute pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.,local,96.6
0,50401,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(1024, 1, 1)",0,7.5,Memory Workload Analysis,Memory Throughput,byte/second,"44,308,108,108.11",,,,,
0,50401,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(1024, 1, 1)",0,7.5,Memory Workload Analysis,Mem Busy,%,20.69,,,,,
0,50401,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(1024, 1, 1)",0,7.5,Memory Workload Analysis,Max Bandwidth,%,23.90,,,,,
0,50401,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(1024, 1, 1)",0,7.5,Memory Workload Analysis,L1/TEX Hit Rate,%,0,,,,,
0,50401,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(1024, 1, 1)",0,7.5,Memory Workload Analysis,L2 Hit Rate,%,34.64,,,,,
0,50401,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(1024, 1, 1)",0,7.5,Memory Workload Analysis,Mem Pipes Busy,%,7.44,,,,,
0,50401,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(1024, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Chart,,,,MemoryL2Compression,WRN,The optional metric lts__average_gcomp_input_sector_success_rate.pct could not be found. Collecting it as an additional metric could enable the rule to provide more guidance.,,
0,50401,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(1024, 1, 1)",0,7.5,Scheduler Statistics,One or More Eligible,%,5.27,,,,,
0,50401,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(1024, 1, 1)",0,7.5,Scheduler Statistics,Issued Warp Per Scheduler,,0.05,,,,,
0,50401,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(1024, 1, 1)",0,7.5,Scheduler Statistics,No Eligible,%,94.73,,,,,
0,50401,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(1024, 1, 1)",0,7.5,Scheduler Statistics,Active Warps Per Scheduler,warp,2.87,,,,,
0,50401,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(1024, 1, 1)",0,7.5,Scheduler Statistics,Eligible Warps Per Scheduler,warp,0.06,,,,,
0,50401,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(1024, 1, 1)",0,7.5,SchedulerStats,,,,IssueSlotUtilization,OPT,"Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 19.0 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of 2.87 active warps per scheduler, but only an average of 0.06 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections.",local,76.1
0,50401,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(1024, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Issued Instruction,cycle,54.47,,,,,
0,50401,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(1024, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Executed Instruction,cycle,57.60,,,,,
0,50401,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(1024, 1, 1)",0,7.5,Warp State Statistics,Avg. Active Threads Per Warp,,32,,,,,
0,50401,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(1024, 1, 1)",0,7.5,Warp State Statistics,Avg. Not Predicated Off Threads Per Warp,,32,,,,,
0,50401,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(1024, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,OPT,"On average, each warp of this kernel spends 39.4 cycles being stalled waiting for a scoreboard dependency on a L1TEX (local, global, surface, texture) operation. Find the instruction producing the data being waited upon to identify the culprit. To reduce the number of cycles waiting on L1TEX data accesses verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit rates by increasing data locality (coalescing), or by changing the cache configuration. Consider moving frequently used data to shared memory. This stall type represents about 72.4% of the total average of 54.5 cycles between issuing two instructions.",global,72.38
0,50401,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(1024, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,INF,Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.,,
0,50401,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(1024, 1, 1)",0,7.5,Instruction Statistics,Avg. Executed Instructions Per Scheduler,inst,237.71,,,,,
0,50401,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(1024, 1, 1)",0,7.5,Instruction Statistics,Executed Instructions,inst,"13,312",,,,,
0,50401,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(1024, 1, 1)",0,7.5,Instruction Statistics,Avg. Issued Instructions Per Scheduler,inst,251.36,,,,,
0,50401,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(1024, 1, 1)",0,7.5,Instruction Statistics,Issued Instructions,inst,"14,076",,,,,
0,50401,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(1024, 1, 1)",0,7.5,InstructionStats,,,,FPInstructions,OPT,"This kernel executes 0 fused and 1024 non-fused FP32 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP32 performance could be increased by up to 50% (relative to its current performance). Check the Source page to identify where this kernel executes FP32 instructions.",global,1.698
0,50401,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(1024, 1, 1)",0,7.5,Launch Statistics,Block Size,,32,,,,,
0,50401,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(1024, 1, 1)",0,7.5,Launch Statistics,Function Cache Configuration,,CachePreferNone,,,,,
0,50401,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(1024, 1, 1)",0,7.5,Launch Statistics,Grid Size,,"1,024",,,,,
0,50401,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(1024, 1, 1)",0,7.5,Launch Statistics,Registers Per Thread,register/thread,16,,,,,
0,50401,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(1024, 1, 1)",0,7.5,Launch Statistics,Shared Memory Configuration Size,byte,"32,768",,,,,
0,50401,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(1024, 1, 1)",0,7.5,Launch Statistics,Driver Shared Memory Per Block,byte/block,0,,,,,
0,50401,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(1024, 1, 1)",0,7.5,Launch Statistics,Dynamic Shared Memory Per Block,byte/block,0,,,,,
0,50401,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(1024, 1, 1)",0,7.5,Launch Statistics,Static Shared Memory Per Block,byte/block,0,,,,,
0,50401,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(1024, 1, 1)",0,7.5,Launch Statistics,Threads,thread,"32,768",,,,,
0,50401,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(1024, 1, 1)",0,7.5,Launch Statistics,Waves Per SM,,4.57,,,,,
0,50401,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(1024, 1, 1)",0,7.5,LaunchStats,,,,LaunchConfiguration,OPT,"A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical occupancy of the kernel. This kernel launch results in 4 full waves and a partial wave of 127 thread blocks. Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for up to 20.0% of the total kernel runtime with a lower occupancy of 34.2%. Try launching a grid with no partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for a grid. See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations.",global,20.0
0,50401,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(1024, 1, 1)",0,7.5,Occupancy,Block Limit SM,block,16,,,,,
0,50401,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(1024, 1, 1)",0,7.5,Occupancy,Block Limit Registers,block,128,,,,,
0,50401,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(1024, 1, 1)",0,7.5,Occupancy,Block Limit Shared Mem,block,16,,,,,
0,50401,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(1024, 1, 1)",0,7.5,Occupancy,Block Limit Warps,block,32,,,,,
0,50401,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(1024, 1, 1)",0,7.5,Occupancy,Theoretical Active Warps per SM,warp,16,,,,,
0,50401,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(1024, 1, 1)",0,7.5,Occupancy,Theoretical Occupancy,%,50,,,,,
0,50401,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(1024, 1, 1)",0,7.5,Occupancy,Achieved Occupancy,%,32.89,,,,,
0,50401,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(1024, 1, 1)",0,7.5,Occupancy,Achieved Active Warps Per SM,warp,10.52,,,,,
0,50401,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(1024, 1, 1)",0,7.5,Occupancy,,,,AchievedOccupancy,OPT,The difference between calculated theoretical (50.0%) and measured achieved occupancy (32.9%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy.,global,34.23
0,50401,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(1024, 1, 1)",0,7.5,Occupancy,,,,TheoreticalOccupancy,OPT,The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared memory.,global,50.0
0,50401,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(1024, 1, 1)",0,7.5,Source Counters,Branch Instructions Ratio,%,0.08,,,,,
0,50401,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(1024, 1, 1)",0,7.5,Source Counters,Branch Instructions,inst,"1,024",,,,,
0,50401,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(1024, 1, 1)",0,7.5,Source Counters,Branch Efficiency,%,0,,,,,
0,50401,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(1024, 1, 1)",0,7.5,Source Counters,Avg. Divergent Branches,,0,,,,,
0,50478,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(512, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Frequency,cycle/second,"5,248,000,000",,,,,
0,50478,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(512, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Frequency,cycle/second,"1,197,875,000",,,,,
0,50478,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(512, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Elapsed Cycles,cycle,"4,804",,,,,
0,50478,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(512, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Memory Throughput,%,39.06,,,,,
0,50478,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(512, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Throughput,%,39.06,,,,,
0,50478,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(512, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Duration,nsecond,"4,000",,,,,
0,50478,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(512, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L1/TEX Cache Throughput,%,17.47,,,,,
0,50478,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(512, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L2 Cache Throughput,%,33.97,,,,,
0,50478,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(512, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Active Cycles,cycle,"3,348.86",,,,,
0,50478,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(512, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Compute (SM) Throughput,%,12.21,,,,,
0,50478,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(512, 1, 1)",0,7.5,SpeedOfLight,,,,SOLBottleneck,OPT,This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.,,
0,50478,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(512, 1, 1)",0,7.5,SpeedOfLight_RooflineChart,,,,SOLFPRoofline,INF,The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved  close to 0% of this device's fp32 peak performance and 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.,,
0,50478,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(512, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Active,inst/cycle,0.28,,,,,
0,50478,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(512, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Elapsed,inst/cycle,0.20,,,,,
0,50478,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(512, 1, 1)",0,7.5,Compute Workload Analysis,Issue Slots Busy,%,7.84,,,,,
0,50478,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(512, 1, 1)",0,7.5,Compute Workload Analysis,Issued Ipc Active,inst/cycle,0.31,,,,,
0,50478,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(512, 1, 1)",0,7.5,Compute Workload Analysis,SM Busy,%,7.84,,,,,
0,50478,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(512, 1, 1)",0,7.5,ComputeWorkloadAnalysis,,,,HighPipeUtilization,OPT,All compute pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.,local,94.54
0,50478,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(512, 1, 1)",0,7.5,Memory Workload Analysis,Memory Throughput,byte/second,"65,592,000,000",,,,,
0,50478,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(512, 1, 1)",0,7.5,Memory Workload Analysis,Mem Busy,%,33.97,,,,,
0,50478,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(512, 1, 1)",0,7.5,Memory Workload Analysis,Max Bandwidth,%,39.06,,,,,
0,50478,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(512, 1, 1)",0,7.5,Memory Workload Analysis,L1/TEX Hit Rate,%,0,,,,,
0,50478,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(512, 1, 1)",0,7.5,Memory Workload Analysis,L2 Hit Rate,%,34.25,,,,,
0,50478,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(512, 1, 1)",0,7.5,Memory Workload Analysis,Mem Pipes Busy,%,12.21,,,,,
0,50478,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(512, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Chart,,,,MemoryL2Compression,WRN,The optional metric lts__average_gcomp_input_sector_success_rate.pct could not be found. Collecting it as an additional metric could enable the rule to provide more guidance.,,
0,50478,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(512, 1, 1)",0,7.5,Scheduler Statistics,One or More Eligible,%,8.23,,,,,
0,50478,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(512, 1, 1)",0,7.5,Scheduler Statistics,Issued Warp Per Scheduler,,0.08,,,,,
0,50478,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(512, 1, 1)",0,7.5,Scheduler Statistics,No Eligible,%,91.77,,,,,
0,50478,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(512, 1, 1)",0,7.5,Scheduler Statistics,Active Warps Per Scheduler,warp,5.90,,,,,
0,50478,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(512, 1, 1)",0,7.5,Scheduler Statistics,Eligible Warps Per Scheduler,warp,0.12,,,,,
0,50478,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(512, 1, 1)",0,7.5,SchedulerStats,,,,IssueSlotUtilization,OPT,"Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 12.2 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of 5.90 active warps per scheduler, but only an average of 0.12 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections.",local,60.94
0,50478,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(512, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Issued Instruction,cycle,71.72,,,,,
0,50478,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(512, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Executed Instruction,cycle,79.25,,,,,
0,50478,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(512, 1, 1)",0,7.5,Warp State Statistics,Avg. Active Threads Per Warp,,32,,,,,
0,50478,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(512, 1, 1)",0,7.5,Warp State Statistics,Avg. Not Predicated Off Threads Per Warp,,32,,,,,
0,50478,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(512, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,OPT,"On average, each warp of this kernel spends 47.3 cycles being stalled waiting for a scoreboard dependency on a L1TEX (local, global, surface, texture) operation. Find the instruction producing the data being waited upon to identify the culprit. To reduce the number of cycles waiting on L1TEX data accesses verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit rates by increasing data locality (coalescing), or by changing the cache configuration. Consider moving frequently used data to shared memory. This stall type represents about 66.0% of the total average of 71.7 cycles between issuing two instructions.",global,60.94
0,50478,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(512, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,INF,Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.,,
0,50478,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(512, 1, 1)",0,7.5,Instruction Statistics,Avg. Executed Instructions Per Scheduler,inst,237.71,,,,,
0,50478,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(512, 1, 1)",0,7.5,Instruction Statistics,Executed Instructions,inst,"13,312",,,,,
0,50478,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(512, 1, 1)",0,7.5,Instruction Statistics,Avg. Issued Instructions Per Scheduler,inst,262.70,,,,,
0,50478,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(512, 1, 1)",0,7.5,Instruction Statistics,Issued Instructions,inst,"14,711",,,,,
0,50478,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(512, 1, 1)",0,7.5,InstructionStats,,,,FPInstructions,OPT,"This kernel executes 0 fused and 1024 non-fused FP32 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP32 performance could be increased by up to 50% (relative to its current performance). Check the Source page to identify where this kernel executes FP32 instructions.",global,2.73
0,50478,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(512, 1, 1)",0,7.5,Launch Statistics,Block Size,,64,,,,,
0,50478,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(512, 1, 1)",0,7.5,Launch Statistics,Function Cache Configuration,,CachePreferNone,,,,,
0,50478,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(512, 1, 1)",0,7.5,Launch Statistics,Grid Size,,512,,,,,
0,50478,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(512, 1, 1)",0,7.5,Launch Statistics,Registers Per Thread,register/thread,16,,,,,
0,50478,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(512, 1, 1)",0,7.5,Launch Statistics,Shared Memory Configuration Size,byte,"32,768",,,,,
0,50478,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(512, 1, 1)",0,7.5,Launch Statistics,Driver Shared Memory Per Block,byte/block,0,,,,,
0,50478,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(512, 1, 1)",0,7.5,Launch Statistics,Dynamic Shared Memory Per Block,byte/block,0,,,,,
0,50478,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(512, 1, 1)",0,7.5,Launch Statistics,Static Shared Memory Per Block,byte/block,0,,,,,
0,50478,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(512, 1, 1)",0,7.5,Launch Statistics,Threads,thread,"32,768",,,,,
0,50478,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(512, 1, 1)",0,7.5,Launch Statistics,Waves Per SM,,2.29,,,,,
0,50478,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(512, 1, 1)",0,7.5,LaunchStats,,,,LaunchConfiguration,OPT,"A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical occupancy of the kernel. This kernel launch results in 2 full waves and a partial wave of 63 thread blocks. Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for up to 33.3% of the total kernel runtime with a lower occupancy of 27.5%. Try launching a grid with no partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for a grid. See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations.",global,33.33
0,50478,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(512, 1, 1)",0,7.5,Occupancy,Block Limit SM,block,16,,,,,
0,50478,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(512, 1, 1)",0,7.5,Occupancy,Block Limit Registers,block,64,,,,,
0,50478,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(512, 1, 1)",0,7.5,Occupancy,Block Limit Shared Mem,block,16,,,,,
0,50478,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(512, 1, 1)",0,7.5,Occupancy,Block Limit Warps,block,16,,,,,
0,50478,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(512, 1, 1)",0,7.5,Occupancy,Theoretical Active Warps per SM,warp,32,,,,,
0,50478,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(512, 1, 1)",0,7.5,Occupancy,Theoretical Occupancy,%,100,,,,,
0,50478,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(512, 1, 1)",0,7.5,Occupancy,Achieved Occupancy,%,72.50,,,,,
0,50478,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(512, 1, 1)",0,7.5,Occupancy,Achieved Active Warps Per SM,warp,23.20,,,,,
0,50478,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(512, 1, 1)",0,7.5,Occupancy,,,,AchievedOccupancy,OPT,The difference between calculated theoretical (100.0%) and measured achieved occupancy (72.5%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy.,global,27.5
0,50478,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(512, 1, 1)",0,7.5,Source Counters,Branch Instructions Ratio,%,0.08,,,,,
0,50478,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(512, 1, 1)",0,7.5,Source Counters,Branch Instructions,inst,"1,024",,,,,
0,50478,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(512, 1, 1)",0,7.5,Source Counters,Branch Efficiency,%,0,,,,,
0,50478,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(512, 1, 1)",0,7.5,Source Counters,Avg. Divergent Branches,,0,,,,,
0,50565,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(256, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Frequency,cycle/second,"5,333,333,333.33",,,,,
0,50565,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(256, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Frequency,cycle/second,"1,198,551,829.27",,,,,
0,50565,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(256, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Elapsed Cycles,cycle,"4,726",,,,,
0,50565,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(256, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Memory Throughput,%,39.05,,,,,
0,50565,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(256, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Throughput,%,39.05,,,,,
0,50565,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(256, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Duration,nsecond,"3,936",,,,,
0,50565,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(256, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L1/TEX Cache Throughput,%,18.57,,,,,
0,50565,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(256, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L2 Cache Throughput,%,34.54,,,,,
0,50565,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(256, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Active Cycles,cycle,"3,151.36",,,,,
0,50565,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(256, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Compute (SM) Throughput,%,12.40,,,,,
0,50565,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(256, 1, 1)",0,7.5,SpeedOfLight,,,,SOLBottleneck,OPT,This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.,,
0,50565,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(256, 1, 1)",0,7.5,SpeedOfLight_RooflineChart,,,,SOLFPRoofline,INF,The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved  close to 0% of this device's fp32 peak performance and 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.,,
0,50565,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(256, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Active,inst/cycle,0.30,,,,,
0,50565,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(256, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Elapsed,inst/cycle,0.20,,,,,
0,50565,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(256, 1, 1)",0,7.5,Compute Workload Analysis,Issue Slots Busy,%,8.56,,,,,
0,50565,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(256, 1, 1)",0,7.5,Compute Workload Analysis,Issued Ipc Active,inst/cycle,0.34,,,,,
0,50565,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(256, 1, 1)",0,7.5,Compute Workload Analysis,SM Busy,%,8.56,,,,,
0,50565,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(256, 1, 1)",0,7.5,ComputeWorkloadAnalysis,,,,HighPipeUtilization,OPT,All compute pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.,local,94.2
0,50565,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(256, 1, 1)",0,7.5,Memory Workload Analysis,Memory Throughput,byte/second,"66,642,276,422.76",,,,,
0,50565,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(256, 1, 1)",0,7.5,Memory Workload Analysis,Mem Busy,%,34.54,,,,,
0,50565,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(256, 1, 1)",0,7.5,Memory Workload Analysis,Max Bandwidth,%,39.05,,,,,
0,50565,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(256, 1, 1)",0,7.5,Memory Workload Analysis,L1/TEX Hit Rate,%,0,,,,,
0,50565,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(256, 1, 1)",0,7.5,Memory Workload Analysis,L2 Hit Rate,%,34.25,,,,,
0,50565,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(256, 1, 1)",0,7.5,Memory Workload Analysis,Mem Pipes Busy,%,12.40,,,,,
0,50565,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(256, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Chart,,,,MemoryL2Compression,WRN,The optional metric lts__average_gcomp_input_sector_success_rate.pct could not be found. Collecting it as an additional metric could enable the rule to provide more guidance.,,
0,50565,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(256, 1, 1)",0,7.5,Scheduler Statistics,One or More Eligible,%,8.26,,,,,
0,50565,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(256, 1, 1)",0,7.5,Scheduler Statistics,Issued Warp Per Scheduler,,0.08,,,,,
0,50565,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(256, 1, 1)",0,7.5,Scheduler Statistics,No Eligible,%,91.74,,,,,
0,50565,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(256, 1, 1)",0,7.5,Scheduler Statistics,Active Warps Per Scheduler,warp,6.46,,,,,
0,50565,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(256, 1, 1)",0,7.5,Scheduler Statistics,Eligible Warps Per Scheduler,warp,0.12,,,,,
0,50565,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(256, 1, 1)",0,7.5,SchedulerStats,,,,IssueSlotUtilization,OPT,"Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 12.1 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of 6.46 active warps per scheduler, but only an average of 0.12 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, avoid possible load imbalances due to highly different execution durations per warp. Reducing stalls indicated on the Warp State Statistics and Source Counters sections can help, too.",local,60.95
0,50565,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(256, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Issued Instruction,cycle,78.23,,,,,
0,50565,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(256, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Executed Instruction,cycle,88.76,,,,,
0,50565,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(256, 1, 1)",0,7.5,Warp State Statistics,Avg. Active Threads Per Warp,,32,,,,,
0,50565,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(256, 1, 1)",0,7.5,Warp State Statistics,Avg. Not Predicated Off Threads Per Warp,,32,,,,,
0,50565,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(256, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,OPT,"On average, each warp of this kernel spends 46.9 cycles being stalled waiting for a scoreboard dependency on a L1TEX (local, global, surface, texture) operation. Find the instruction producing the data being waited upon to identify the culprit. To reduce the number of cycles waiting on L1TEX data accesses verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit rates by increasing data locality (coalescing), or by changing the cache configuration. Consider moving frequently used data to shared memory. This stall type represents about 60.0% of the total average of 78.2 cycles between issuing two instructions.",global,59.99
0,50565,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(256, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,INF,Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.,,
0,50565,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(256, 1, 1)",0,7.5,Instruction Statistics,Avg. Executed Instructions Per Scheduler,inst,237.71,,,,,
0,50565,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(256, 1, 1)",0,7.5,Instruction Statistics,Executed Instructions,inst,"13,312",,,,,
0,50565,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(256, 1, 1)",0,7.5,Instruction Statistics,Avg. Issued Instructions Per Scheduler,inst,269.71,,,,,
0,50565,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(256, 1, 1)",0,7.5,Instruction Statistics,Issued Instructions,inst,"15,104",,,,,
0,50565,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(256, 1, 1)",0,7.5,InstructionStats,,,,FPInstructions,OPT,"This kernel executes 0 fused and 1024 non-fused FP32 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP32 performance could be increased by up to 50% (relative to its current performance). Check the Source page to identify where this kernel executes FP32 instructions.",global,2.901
0,50565,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(256, 1, 1)",0,7.5,Launch Statistics,Block Size,,128,,,,,
0,50565,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(256, 1, 1)",0,7.5,Launch Statistics,Function Cache Configuration,,CachePreferNone,,,,,
0,50565,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(256, 1, 1)",0,7.5,Launch Statistics,Grid Size,,256,,,,,
0,50565,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(256, 1, 1)",0,7.5,Launch Statistics,Registers Per Thread,register/thread,16,,,,,
0,50565,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(256, 1, 1)",0,7.5,Launch Statistics,Shared Memory Configuration Size,byte,"32,768",,,,,
0,50565,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(256, 1, 1)",0,7.5,Launch Statistics,Driver Shared Memory Per Block,byte/block,0,,,,,
0,50565,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(256, 1, 1)",0,7.5,Launch Statistics,Dynamic Shared Memory Per Block,byte/block,0,,,,,
0,50565,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(256, 1, 1)",0,7.5,Launch Statistics,Static Shared Memory Per Block,byte/block,0,,,,,
0,50565,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(256, 1, 1)",0,7.5,Launch Statistics,Threads,thread,"32,768",,,,,
0,50565,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(256, 1, 1)",0,7.5,Launch Statistics,Waves Per SM,,2.29,,,,,
0,50565,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(256, 1, 1)",0,7.5,Occupancy,Block Limit SM,block,16,,,,,
0,50565,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(256, 1, 1)",0,7.5,Occupancy,Block Limit Registers,block,32,,,,,
0,50565,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(256, 1, 1)",0,7.5,Occupancy,Block Limit Shared Mem,block,16,,,,,
0,50565,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(256, 1, 1)",0,7.5,Occupancy,Block Limit Warps,block,8,,,,,
0,50565,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(256, 1, 1)",0,7.5,Occupancy,Theoretical Active Warps per SM,warp,32,,,,,
0,50565,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(256, 1, 1)",0,7.5,Occupancy,Theoretical Occupancy,%,100,,,,,
0,50565,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(256, 1, 1)",0,7.5,Occupancy,Achieved Occupancy,%,80.72,,,,,
0,50565,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(256, 1, 1)",0,7.5,Occupancy,Achieved Active Warps Per SM,warp,25.83,,,,,
0,50565,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(256, 1, 1)",0,7.5,Occupancy,,,,AchievedOccupancy,OPT,The difference between calculated theoretical (100.0%) and measured achieved occupancy (80.7%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy.,global,19.28
0,50565,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(256, 1, 1)",0,7.5,Source Counters,Branch Instructions Ratio,%,0.08,,,,,
0,50565,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(256, 1, 1)",0,7.5,Source Counters,Branch Instructions,inst,"1,024",,,,,
0,50565,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(256, 1, 1)",0,7.5,Source Counters,Branch Efficiency,%,0,,,,,
0,50565,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(256, 1, 1)",0,7.5,Source Counters,Avg. Divergent Branches,,0,,,,,
0,50659,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(128, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Frequency,cycle/second,"5,015,873,015.87",,,,,
0,50659,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(128, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Frequency,cycle/second,"1,144,717,261.90",,,,,
0,50659,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(128, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Elapsed Cycles,cycle,"4,628",,,,,
0,50659,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(128, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Memory Throughput,%,40.54,,,,,
0,50659,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(128, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Throughput,%,40.54,,,,,
0,50659,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(128, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Duration,nsecond,"4,032",,,,,
0,50659,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(128, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L1/TEX Cache Throughput,%,18.11,,,,,
0,50659,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(128, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L2 Cache Throughput,%,35.22,,,,,
0,50659,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(128, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Active Cycles,cycle,"3,231.50",,,,,
0,50659,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(128, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Compute (SM) Throughput,%,12.67,,,,,
0,50659,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(128, 1, 1)",0,7.5,SpeedOfLight,,,,SOLBottleneck,OPT,This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.,,
0,50659,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(128, 1, 1)",0,7.5,SpeedOfLight_RooflineChart,,,,SOLFPRoofline,INF,The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved  close to 0% of this device's fp32 peak performance and 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.,,
0,50659,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(128, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Active,inst/cycle,0.29,,,,,
0,50659,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(128, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Elapsed,inst/cycle,0.21,,,,,
0,50659,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(128, 1, 1)",0,7.5,Compute Workload Analysis,Issue Slots Busy,%,8.33,,,,,
0,50659,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(128, 1, 1)",0,7.5,Compute Workload Analysis,Issued Ipc Active,inst/cycle,0.33,,,,,
0,50659,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(128, 1, 1)",0,7.5,Compute Workload Analysis,SM Busy,%,8.33,,,,,
0,50659,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(128, 1, 1)",0,7.5,ComputeWorkloadAnalysis,,,,HighPipeUtilization,OPT,All compute pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.,local,94.34
0,50659,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(128, 1, 1)",0,7.5,Memory Workload Analysis,Memory Throughput,byte/second,"65,071,428,571.43",,,,,
0,50659,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(128, 1, 1)",0,7.5,Memory Workload Analysis,Mem Busy,%,35.22,,,,,
0,50659,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(128, 1, 1)",0,7.5,Memory Workload Analysis,Max Bandwidth,%,40.54,,,,,
0,50659,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(128, 1, 1)",0,7.5,Memory Workload Analysis,L1/TEX Hit Rate,%,0,,,,,
0,50659,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(128, 1, 1)",0,7.5,Memory Workload Analysis,L2 Hit Rate,%,34.25,,,,,
0,50659,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(128, 1, 1)",0,7.5,Memory Workload Analysis,Mem Pipes Busy,%,12.67,,,,,
0,50659,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(128, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Chart,,,,MemoryL2Compression,WRN,The optional metric lts__average_gcomp_input_sector_success_rate.pct could not be found. Collecting it as an additional metric could enable the rule to provide more guidance.,,
0,50659,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(128, 1, 1)",0,7.5,Scheduler Statistics,One or More Eligible,%,8.64,,,,,
0,50659,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(128, 1, 1)",0,7.5,Scheduler Statistics,Issued Warp Per Scheduler,,0.09,,,,,
0,50659,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(128, 1, 1)",0,7.5,Scheduler Statistics,No Eligible,%,91.36,,,,,
0,50659,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(128, 1, 1)",0,7.5,Scheduler Statistics,Active Warps Per Scheduler,warp,6.40,,,,,
0,50659,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(128, 1, 1)",0,7.5,Scheduler Statistics,Eligible Warps Per Scheduler,warp,0.13,,,,,
0,50659,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(128, 1, 1)",0,7.5,SchedulerStats,,,,IssueSlotUtilization,OPT,"Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 11.6 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of 6.40 active warps per scheduler, but only an average of 0.13 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections.",local,59.46
0,50659,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(128, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Issued Instruction,cycle,74.02,,,,,
0,50659,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(128, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Executed Instruction,cycle,83.83,,,,,
0,50659,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(128, 1, 1)",0,7.5,Warp State Statistics,Avg. Active Threads Per Warp,,32,,,,,
0,50659,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(128, 1, 1)",0,7.5,Warp State Statistics,Avg. Not Predicated Off Threads Per Warp,,32,,,,,
0,50659,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(128, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,OPT,"On average, each warp of this kernel spends 47.3 cycles being stalled waiting for a scoreboard dependency on a L1TEX (local, global, surface, texture) operation. Find the instruction producing the data being waited upon to identify the culprit. To reduce the number of cycles waiting on L1TEX data accesses verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit rates by increasing data locality (coalescing), or by changing the cache configuration. Consider moving frequently used data to shared memory. This stall type represents about 63.9% of the total average of 74.0 cycles between issuing two instructions.",global,59.46
0,50659,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(128, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,INF,Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.,,
0,50659,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(128, 1, 1)",0,7.5,Instruction Statistics,Avg. Executed Instructions Per Scheduler,inst,237.71,,,,,
0,50659,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(128, 1, 1)",0,7.5,Instruction Statistics,Executed Instructions,inst,"13,312",,,,,
0,50659,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(128, 1, 1)",0,7.5,Instruction Statistics,Avg. Issued Instructions Per Scheduler,inst,269.21,,,,,
0,50659,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(128, 1, 1)",0,7.5,Instruction Statistics,Issued Instructions,inst,"15,076",,,,,
0,50659,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(128, 1, 1)",0,7.5,InstructionStats,,,,FPInstructions,OPT,"This kernel executes 0 fused and 1024 non-fused FP32 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP32 performance could be increased by up to 50% (relative to its current performance). Check the Source page to identify where this kernel executes FP32 instructions.",global,2.829
0,50659,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(128, 1, 1)",0,7.5,Launch Statistics,Block Size,,256,,,,,
0,50659,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(128, 1, 1)",0,7.5,Launch Statistics,Function Cache Configuration,,CachePreferNone,,,,,
0,50659,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(128, 1, 1)",0,7.5,Launch Statistics,Grid Size,,128,,,,,
0,50659,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(128, 1, 1)",0,7.5,Launch Statistics,Registers Per Thread,register/thread,16,,,,,
0,50659,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(128, 1, 1)",0,7.5,Launch Statistics,Shared Memory Configuration Size,byte,"32,768",,,,,
0,50659,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(128, 1, 1)",0,7.5,Launch Statistics,Driver Shared Memory Per Block,byte/block,0,,,,,
0,50659,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(128, 1, 1)",0,7.5,Launch Statistics,Dynamic Shared Memory Per Block,byte/block,0,,,,,
0,50659,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(128, 1, 1)",0,7.5,Launch Statistics,Static Shared Memory Per Block,byte/block,0,,,,,
0,50659,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(128, 1, 1)",0,7.5,Launch Statistics,Threads,thread,"32,768",,,,,
0,50659,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(128, 1, 1)",0,7.5,Launch Statistics,Waves Per SM,,2.29,,,,,
0,50659,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(128, 1, 1)",0,7.5,Occupancy,Block Limit SM,block,16,,,,,
0,50659,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(128, 1, 1)",0,7.5,Occupancy,Block Limit Registers,block,16,,,,,
0,50659,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(128, 1, 1)",0,7.5,Occupancy,Block Limit Shared Mem,block,16,,,,,
0,50659,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(128, 1, 1)",0,7.5,Occupancy,Block Limit Warps,block,4,,,,,
0,50659,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(128, 1, 1)",0,7.5,Occupancy,Theoretical Active Warps per SM,warp,32,,,,,
0,50659,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(128, 1, 1)",0,7.5,Occupancy,Theoretical Occupancy,%,100,,,,,
0,50659,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(128, 1, 1)",0,7.5,Occupancy,Achieved Occupancy,%,80.20,,,,,
0,50659,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(128, 1, 1)",0,7.5,Occupancy,Achieved Active Warps Per SM,warp,25.66,,,,,
0,50659,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(128, 1, 1)",0,7.5,Occupancy,,,,AchievedOccupancy,OPT,The difference between calculated theoretical (100.0%) and measured achieved occupancy (80.2%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy.,global,19.8
0,50659,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(128, 1, 1)",0,7.5,Source Counters,Branch Instructions Ratio,%,0.08,,,,,
0,50659,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(128, 1, 1)",0,7.5,Source Counters,Branch Instructions,inst,"1,024",,,,,
0,50659,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(128, 1, 1)",0,7.5,Source Counters,Branch Efficiency,%,0,,,,,
0,50659,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(128, 1, 1)",0,7.5,Source Counters,Avg. Divergent Branches,,0,,,,,
0,50746,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(64, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Frequency,cycle/second,"5,487,603,305.79",,,,,
0,50746,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(64, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Frequency,cycle/second,"1,249,870,867.77",,,,,
0,50746,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(64, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Elapsed Cycles,cycle,"4,848",,,,,
0,50746,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(64, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Memory Throughput,%,38.59,,,,,
0,50746,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(64, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Throughput,%,38.59,,,,,
0,50746,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(64, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Duration,nsecond,"3,872",,,,,
0,50746,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(64, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L1/TEX Cache Throughput,%,17.22,,,,,
0,50746,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(64, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L2 Cache Throughput,%,33.61,,,,,
0,50746,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(64, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Active Cycles,cycle,"3,398.14",,,,,
0,50746,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(64, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Compute (SM) Throughput,%,12.09,,,,,
0,50746,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(64, 1, 1)",0,7.5,SpeedOfLight,,,,SOLBottleneck,OPT,This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.,,
0,50746,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(64, 1, 1)",0,7.5,SpeedOfLight_RooflineChart,,,,SOLFPRoofline,INF,The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved  close to 0% of this device's fp32 peak performance and 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.,,
0,50746,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(64, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Active,inst/cycle,0.28,,,,,
0,50746,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(64, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Elapsed,inst/cycle,0.20,,,,,
0,50746,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(64, 1, 1)",0,7.5,Compute Workload Analysis,Issue Slots Busy,%,7.94,,,,,
0,50746,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(64, 1, 1)",0,7.5,Compute Workload Analysis,Issued Ipc Active,inst/cycle,0.32,,,,,
0,50746,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(64, 1, 1)",0,7.5,Compute Workload Analysis,SM Busy,%,7.94,,,,,
0,50746,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(64, 1, 1)",0,7.5,ComputeWorkloadAnalysis,,,,HighPipeUtilization,OPT,All compute pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.,local,94.62
0,50746,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(64, 1, 1)",0,7.5,Memory Workload Analysis,Memory Throughput,byte/second,"67,760,330,578.51",,,,,
0,50746,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(64, 1, 1)",0,7.5,Memory Workload Analysis,Mem Busy,%,33.61,,,,,
0,50746,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(64, 1, 1)",0,7.5,Memory Workload Analysis,Max Bandwidth,%,38.59,,,,,
0,50746,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(64, 1, 1)",0,7.5,Memory Workload Analysis,L1/TEX Hit Rate,%,0,,,,,
0,50746,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(64, 1, 1)",0,7.5,Memory Workload Analysis,L2 Hit Rate,%,34.23,,,,,
0,50746,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(64, 1, 1)",0,7.5,Memory Workload Analysis,Mem Pipes Busy,%,12.09,,,,,
0,50746,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(64, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Chart,,,,MemoryL2Compression,WRN,The optional metric lts__average_gcomp_input_sector_success_rate.pct could not be found. Collecting it as an additional metric could enable the rule to provide more guidance.,,
0,50746,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(64, 1, 1)",0,7.5,Scheduler Statistics,One or More Eligible,%,8.46,,,,,
0,50746,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(64, 1, 1)",0,7.5,Scheduler Statistics,Issued Warp Per Scheduler,,0.08,,,,,
0,50746,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(64, 1, 1)",0,7.5,Scheduler Statistics,No Eligible,%,91.54,,,,,
0,50746,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(64, 1, 1)",0,7.5,Scheduler Statistics,Active Warps Per Scheduler,warp,6.88,,,,,
0,50746,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(64, 1, 1)",0,7.5,Scheduler Statistics,Eligible Warps Per Scheduler,warp,0.14,,,,,
0,50746,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(64, 1, 1)",0,7.5,SchedulerStats,,,,IssueSlotUtilization,OPT,"Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 11.8 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of 6.88 active warps per scheduler, but only an average of 0.14 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, avoid possible load imbalances due to highly different execution durations per warp. Reducing stalls indicated on the Warp State Statistics and Source Counters sections can help, too.",local,61.41
0,50746,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(64, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Issued Instruction,cycle,81.31,,,,,
0,50746,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(64, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Executed Instruction,cycle,92.26,,,,,
0,50746,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(64, 1, 1)",0,7.5,Warp State Statistics,Avg. Active Threads Per Warp,,32,,,,,
0,50746,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(64, 1, 1)",0,7.5,Warp State Statistics,Avg. Not Predicated Off Threads Per Warp,,32,,,,,
0,50746,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(64, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,OPT,"On average, each warp of this kernel spends 50.4 cycles being stalled waiting for a scoreboard dependency on a L1TEX (local, global, surface, texture) operation. Find the instruction producing the data being waited upon to identify the culprit. To reduce the number of cycles waiting on L1TEX data accesses verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit rates by increasing data locality (coalescing), or by changing the cache configuration. Consider moving frequently used data to shared memory. This stall type represents about 62.0% of the total average of 81.3 cycles between issuing two instructions.",global,61.41
0,50746,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(64, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,INF,Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.,,
0,50746,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(64, 1, 1)",0,7.5,Instruction Statistics,Avg. Executed Instructions Per Scheduler,inst,237.71,,,,,
0,50746,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(64, 1, 1)",0,7.5,Instruction Statistics,Executed Instructions,inst,"13,312",,,,,
0,50746,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(64, 1, 1)",0,7.5,Instruction Statistics,Avg. Issued Instructions Per Scheduler,inst,269.71,,,,,
0,50746,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(64, 1, 1)",0,7.5,Instruction Statistics,Issued Instructions,inst,"15,104",,,,,
0,50746,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(64, 1, 1)",0,7.5,InstructionStats,,,,FPInstructions,OPT,"This kernel executes 0 fused and 1024 non-fused FP32 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP32 performance could be increased by up to 50% (relative to its current performance). Check the Source page to identify where this kernel executes FP32 instructions.",global,2.691
0,50746,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(64, 1, 1)",0,7.5,Launch Statistics,Block Size,,512,,,,,
0,50746,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(64, 1, 1)",0,7.5,Launch Statistics,Function Cache Configuration,,CachePreferNone,,,,,
0,50746,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(64, 1, 1)",0,7.5,Launch Statistics,Grid Size,,64,,,,,
0,50746,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(64, 1, 1)",0,7.5,Launch Statistics,Registers Per Thread,register/thread,16,,,,,
0,50746,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(64, 1, 1)",0,7.5,Launch Statistics,Shared Memory Configuration Size,byte,"32,768",,,,,
0,50746,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(64, 1, 1)",0,7.5,Launch Statistics,Driver Shared Memory Per Block,byte/block,0,,,,,
0,50746,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(64, 1, 1)",0,7.5,Launch Statistics,Dynamic Shared Memory Per Block,byte/block,0,,,,,
0,50746,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(64, 1, 1)",0,7.5,Launch Statistics,Static Shared Memory Per Block,byte/block,0,,,,,
0,50746,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(64, 1, 1)",0,7.5,Launch Statistics,Threads,thread,"32,768",,,,,
0,50746,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(64, 1, 1)",0,7.5,Launch Statistics,Waves Per SM,,2.29,,,,,
0,50746,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(64, 1, 1)",0,7.5,Occupancy,Block Limit SM,block,16,,,,,
0,50746,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(64, 1, 1)",0,7.5,Occupancy,Block Limit Registers,block,8,,,,,
0,50746,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(64, 1, 1)",0,7.5,Occupancy,Block Limit Shared Mem,block,16,,,,,
0,50746,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(64, 1, 1)",0,7.5,Occupancy,Block Limit Warps,block,2,,,,,
0,50746,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(64, 1, 1)",0,7.5,Occupancy,Theoretical Active Warps per SM,warp,32,,,,,
0,50746,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(64, 1, 1)",0,7.5,Occupancy,Theoretical Occupancy,%,100,,,,,
0,50746,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(64, 1, 1)",0,7.5,Occupancy,Achieved Occupancy,%,81.70,,,,,
0,50746,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(64, 1, 1)",0,7.5,Occupancy,Achieved Active Warps Per SM,warp,26.14,,,,,
0,50746,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(64, 1, 1)",0,7.5,Occupancy,,,,AchievedOccupancy,OPT,The difference between calculated theoretical (100.0%) and measured achieved occupancy (81.7%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy.,global,18.3
0,50746,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(64, 1, 1)",0,7.5,Source Counters,Branch Instructions Ratio,%,0.08,,,,,
0,50746,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(64, 1, 1)",0,7.5,Source Counters,Branch Instructions,inst,"1,024",,,,,
0,50746,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(64, 1, 1)",0,7.5,Source Counters,Branch Efficiency,%,0,,,,,
0,50746,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(64, 1, 1)",0,7.5,Source Counters,Avg. Divergent Branches,,0,,,,,
0,50823,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(32, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Frequency,cycle/second,"5,314,285,714.29",,,,,
0,50823,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(32, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Frequency,cycle/second,"1,208,147,321.43",,,,,
0,50823,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(32, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Elapsed Cycles,cycle,"5,422",,,,,
0,50823,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(32, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Memory Throughput,%,34.44,,,,,
0,50823,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(32, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Throughput,%,34.44,,,,,
0,50823,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(32, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Duration,nsecond,"4,480",,,,,
0,50823,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(32, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L1/TEX Cache Throughput,%,18.08,,,,,
0,50823,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(32, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L2 Cache Throughput,%,30.04,,,,,
0,50823,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(32, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Active Cycles,cycle,"3,235.79",,,,,
0,50823,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(32, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Compute (SM) Throughput,%,10.81,,,,,
0,50823,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(32, 1, 1)",0,7.5,SpeedOfLight,,,,SOLBottleneck,OPT,This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.,,
0,50823,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(32, 1, 1)",0,7.5,SpeedOfLight_RooflineChart,,,,SOLFPRoofline,INF,The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved  close to 0% of this device's fp32 peak performance and 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.,,
0,50823,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(32, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Active,inst/cycle,0.29,,,,,
0,50823,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(32, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Elapsed,inst/cycle,0.18,,,,,
0,50823,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(32, 1, 1)",0,7.5,Compute Workload Analysis,Issue Slots Busy,%,8.34,,,,,
0,50823,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(32, 1, 1)",0,7.5,Compute Workload Analysis,Issued Ipc Active,inst/cycle,0.33,,,,,
0,50823,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(32, 1, 1)",0,7.5,Compute Workload Analysis,SM Busy,%,8.34,,,,,
0,50823,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(32, 1, 1)",0,7.5,ComputeWorkloadAnalysis,,,,HighPipeUtilization,OPT,All compute pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.,local,94.35
0,50823,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(32, 1, 1)",0,7.5,Memory Workload Analysis,Memory Throughput,byte/second,"58,564,285,714.29",,,,,
0,50823,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(32, 1, 1)",0,7.5,Memory Workload Analysis,Mem Busy,%,30.04,,,,,
0,50823,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(32, 1, 1)",0,7.5,Memory Workload Analysis,Max Bandwidth,%,34.44,,,,,
0,50823,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(32, 1, 1)",0,7.5,Memory Workload Analysis,L1/TEX Hit Rate,%,0,,,,,
0,50823,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(32, 1, 1)",0,7.5,Memory Workload Analysis,L2 Hit Rate,%,34.84,,,,,
0,50823,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(32, 1, 1)",0,7.5,Memory Workload Analysis,Mem Pipes Busy,%,10.81,,,,,
0,50823,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(32, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Chart,,,,MemoryL2Compression,WRN,The optional metric lts__average_gcomp_input_sector_success_rate.pct could not be found. Collecting it as an additional metric could enable the rule to provide more guidance.,,
0,50823,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(32, 1, 1)",0,7.5,Scheduler Statistics,One or More Eligible,%,8.46,,,,,
0,50823,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(32, 1, 1)",0,7.5,Scheduler Statistics,Issued Warp Per Scheduler,,0.08,,,,,
0,50823,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(32, 1, 1)",0,7.5,Scheduler Statistics,No Eligible,%,91.54,,,,,
0,50823,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(32, 1, 1)",0,7.5,Scheduler Statistics,Active Warps Per Scheduler,warp,6.79,,,,,
0,50823,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(32, 1, 1)",0,7.5,Scheduler Statistics,Eligible Warps Per Scheduler,warp,0.18,,,,,
0,50823,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(32, 1, 1)",0,7.5,SchedulerStats,,,,IssueSlotUtilization,OPT,"Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 11.8 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of 6.79 active warps per scheduler, but only an average of 0.18 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, avoid possible load imbalances due to highly different execution durations per warp. Reducing stalls indicated on the Warp State Statistics and Source Counters sections can help, too.",local,65.56
0,50823,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(32, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Issued Instruction,cycle,80.29,,,,,
0,50823,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(32, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Executed Instruction,cycle,91.10,,,,,
0,50823,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(32, 1, 1)",0,7.5,Warp State Statistics,Avg. Active Threads Per Warp,,32,,,,,
0,50823,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(32, 1, 1)",0,7.5,Warp State Statistics,Avg. Not Predicated Off Threads Per Warp,,32,,,,,
0,50823,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(32, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,OPT,"On average, each warp of this kernel spends 53.8 cycles being stalled waiting for a scoreboard dependency on a L1TEX (local, global, surface, texture) operation. Find the instruction producing the data being waited upon to identify the culprit. To reduce the number of cycles waiting on L1TEX data accesses verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit rates by increasing data locality (coalescing), or by changing the cache configuration. Consider moving frequently used data to shared memory. This stall type represents about 67.0% of the total average of 80.3 cycles between issuing two instructions.",global,65.56
0,50823,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(32, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,INF,Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.,,
0,50823,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(32, 1, 1)",0,7.5,Instruction Statistics,Avg. Executed Instructions Per Scheduler,inst,237.71,,,,,
0,50823,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(32, 1, 1)",0,7.5,Instruction Statistics,Executed Instructions,inst,"13,312",,,,,
0,50823,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(32, 1, 1)",0,7.5,Instruction Statistics,Avg. Issued Instructions Per Scheduler,inst,269.71,,,,,
0,50823,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(32, 1, 1)",0,7.5,Instruction Statistics,Issued Instructions,inst,"15,104",,,,,
0,50823,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(32, 1, 1)",0,7.5,InstructionStats,,,,FPInstructions,OPT,"This kernel executes 0 fused and 1024 non-fused FP32 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP32 performance could be increased by up to 50% (relative to its current performance). Check the Source page to identify where this kernel executes FP32 instructions.",global,2.826
0,50823,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(32, 1, 1)",0,7.5,Launch Statistics,Block Size,,"1,024",,,,,
0,50823,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(32, 1, 1)",0,7.5,Launch Statistics,Function Cache Configuration,,CachePreferNone,,,,,
0,50823,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(32, 1, 1)",0,7.5,Launch Statistics,Grid Size,,32,,,,,
0,50823,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(32, 1, 1)",0,7.5,Launch Statistics,Registers Per Thread,register/thread,16,,,,,
0,50823,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(32, 1, 1)",0,7.5,Launch Statistics,Shared Memory Configuration Size,byte,"32,768",,,,,
0,50823,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(32, 1, 1)",0,7.5,Launch Statistics,Driver Shared Memory Per Block,byte/block,0,,,,,
0,50823,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(32, 1, 1)",0,7.5,Launch Statistics,Dynamic Shared Memory Per Block,byte/block,0,,,,,
0,50823,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(32, 1, 1)",0,7.5,Launch Statistics,Static Shared Memory Per Block,byte/block,0,,,,,
0,50823,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(32, 1, 1)",0,7.5,Launch Statistics,Threads,thread,"32,768",,,,,
0,50823,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(32, 1, 1)",0,7.5,Launch Statistics,Waves Per SM,,2.29,,,,,
0,50823,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(32, 1, 1)",0,7.5,Occupancy,Block Limit SM,block,16,,,,,
0,50823,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(32, 1, 1)",0,7.5,Occupancy,Block Limit Registers,block,4,,,,,
0,50823,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(32, 1, 1)",0,7.5,Occupancy,Block Limit Shared Mem,block,16,,,,,
0,50823,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(32, 1, 1)",0,7.5,Occupancy,Block Limit Warps,block,1,,,,,
0,50823,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(32, 1, 1)",0,7.5,Occupancy,Theoretical Active Warps per SM,warp,32,,,,,
0,50823,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(32, 1, 1)",0,7.5,Occupancy,Theoretical Occupancy,%,100,,,,,
0,50823,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(32, 1, 1)",0,7.5,Occupancy,Achieved Occupancy,%,85.21,,,,,
0,50823,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(32, 1, 1)",0,7.5,Occupancy,Achieved Active Warps Per SM,warp,27.27,,,,,
0,50823,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(32, 1, 1)",0,7.5,Occupancy,,,,AchievedOccupancy,OPT,The difference between calculated theoretical (100.0%) and measured achieved occupancy (85.2%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy.,global,14.79
0,50823,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(32, 1, 1)",0,7.5,Source Counters,Branch Instructions Ratio,%,0.08,,,,,
0,50823,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(32, 1, 1)",0,7.5,Source Counters,Branch Instructions,inst,"1,024",,,,,
0,50823,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(32, 1, 1)",0,7.5,Source Counters,Branch Efficiency,%,0,,,,,
0,50823,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(32, 1, 1)",0,7.5,Source Counters,Avg. Divergent Branches,,0,,,,,
0,50916,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(65536, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Frequency,cycle/second,"5,884,585,791.23",,,,,
0,50916,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(65536, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Frequency,cycle/second,"1,352,554,340.86",,,,,
0,50916,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(65536, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Elapsed Cycles,cycle,"338,089",,,,,
0,50916,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(65536, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Memory Throughput,%,11.09,,,,,
0,50916,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(65536, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Throughput,%,1.12,,,,,
0,50916,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(65536, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Duration,nsecond,"249,536",,,,,
0,50916,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(65536, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L1/TEX Cache Throughput,%,15.39,,,,,
0,50916,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(65536, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L2 Cache Throughput,%,8.50,,,,,
0,50916,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(65536, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Active Cycles,cycle,"243,313.57",,,,,
0,50916,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(65536, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Compute (SM) Throughput,%,11.09,,,,,
0,50916,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(65536, 1, 1)",0,7.5,SpeedOfLight,,,,SOLBottleneck,OPT,This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.,,
0,50916,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(65536, 1, 1)",0,7.5,SpeedOfLight_RooflineChart,,,,SOLFPRoofline,INF,The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved  close to 0% of this device's fp32 peak performance and 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.,,
0,50916,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(65536, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Active,inst/cycle,0.25,,,,,
0,50916,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(65536, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Elapsed,inst/cycle,0.18,,,,,
0,50916,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(65536, 1, 1)",0,7.5,Compute Workload Analysis,Issue Slots Busy,%,6.26,,,,,
0,50916,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(65536, 1, 1)",0,7.5,Compute Workload Analysis,Issued Ipc Active,inst/cycle,0.25,,,,,
0,50916,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(65536, 1, 1)",0,7.5,Compute Workload Analysis,SM Busy,%,6.41,,,,,
0,50916,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(65536, 1, 1)",0,7.5,ComputeWorkloadAnalysis,,,,HighPipeUtilization,OPT,All compute pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.,local,95.19
0,50916,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(65536, 1, 1)",0,7.5,Memory Workload Analysis,Memory Throughput,byte/second,"2,112,208,258.53",,,,,
0,50916,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(65536, 1, 1)",0,7.5,Memory Workload Analysis,Mem Busy,%,7.11,,,,,
0,50916,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(65536, 1, 1)",0,7.5,Memory Workload Analysis,Max Bandwidth,%,11.09,,,,,
0,50916,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(65536, 1, 1)",0,7.5,Memory Workload Analysis,L1/TEX Hit Rate,%,23.47,,,,,
0,50916,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(65536, 1, 1)",0,7.5,Memory Workload Analysis,L2 Hit Rate,%,95.42,,,,,
0,50916,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(65536, 1, 1)",0,7.5,Memory Workload Analysis,Mem Pipes Busy,%,11.09,,,,,
0,50916,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(65536, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Chart,,,,MemoryL2Compression,WRN,The optional metric lts__average_gcomp_input_sector_success_rate.pct could not be found. Collecting it as an additional metric could enable the rule to provide more guidance.,,
0,50916,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(65536, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for loads from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced loads and try to minimize how many cache lines need to be accessed per memory request.",global,3.533
0,50916,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(65536, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for stores from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.5 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced stores and try to minimize how many cache lines need to be accessed per memory request.",global,1.487
0,50916,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(65536, 1, 1)",0,7.5,Scheduler Statistics,One or More Eligible,%,6.92,,,,,
0,50916,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(65536, 1, 1)",0,7.5,Scheduler Statistics,Issued Warp Per Scheduler,,0.07,,,,,
0,50916,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(65536, 1, 1)",0,7.5,Scheduler Statistics,No Eligible,%,93.08,,,,,
0,50916,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(65536, 1, 1)",0,7.5,Scheduler Statistics,Active Warps Per Scheduler,warp,2.75,,,,,
0,50916,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(65536, 1, 1)",0,7.5,Scheduler Statistics,Eligible Warps Per Scheduler,warp,0.07,,,,,
0,50916,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(65536, 1, 1)",0,7.5,SchedulerStats,,,,IssueSlotUtilization,OPT,"Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 14.4 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of 2.75 active warps per scheduler, but only an average of 0.07 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections.",local,88.91
0,50916,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(65536, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Issued Instruction,cycle,39.78,,,,,
0,50916,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(65536, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Executed Instruction,cycle,39.82,,,,,
0,50916,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(65536, 1, 1)",0,7.5,Warp State Statistics,Avg. Active Threads Per Warp,,1,,,,,
0,50916,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(65536, 1, 1)",0,7.5,Warp State Statistics,Avg. Not Predicated Off Threads Per Warp,,1,,,,,
0,50916,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(65536, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,OPT,"On average, each warp of this kernel spends 31.5 cycles being stalled waiting for a scoreboard dependency on a L1TEX (local, global, surface, texture) operation. Find the instruction producing the data being waited upon to identify the culprit. To reduce the number of cycles waiting on L1TEX data accesses verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit rates by increasing data locality (coalescing), or by changing the cache configuration. Consider moving frequently used data to shared memory. This stall type represents about 79.2% of the total average of 39.8 cycles between issuing two instructions.",global,79.2
0,50916,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(65536, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,INF,Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.,,
0,50916,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(65536, 1, 1)",0,7.5,WarpStateStats,,,,ThreadDivergence,OPT,"Instructions are executed in warps, which are groups of 32 threads. Optimal instruction throughput is achieved if all 32 threads of a warp execute the same instruction. The chosen launch configuration, early thread completion, and divergent flow control can significantly lower the number of active threads in a warp per cycle. This kernel achieves an average of 1.0 threads being active per cycle.",global,10.75
0,50916,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(65536, 1, 1)",0,7.5,Instruction Statistics,Avg. Executed Instructions Per Scheduler,inst,"15,213.71",,,,,
0,50916,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(65536, 1, 1)",0,7.5,Instruction Statistics,Executed Instructions,inst,"851,968",,,,,
0,50916,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(65536, 1, 1)",0,7.5,Instruction Statistics,Avg. Issued Instructions Per Scheduler,inst,"15,227.36",,,,,
0,50916,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(65536, 1, 1)",0,7.5,Instruction Statistics,Issued Instructions,inst,"852,732",,,,,
0,50916,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(65536, 1, 1)",0,7.5,InstructionStats,,,,FPInstructions,OPT,"This kernel executes 0 fused and 65536 non-fused FP32 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP32 performance could be increased by up to 50% (relative to its current performance). Check the Source page to identify where this kernel executes FP32 instructions.",global,2.405
0,50916,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(65536, 1, 1)",0,7.5,Launch Statistics,Block Size,,1,,,,,
0,50916,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(65536, 1, 1)",0,7.5,Launch Statistics,Function Cache Configuration,,CachePreferNone,,,,,
0,50916,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(65536, 1, 1)",0,7.5,Launch Statistics,Grid Size,,"65,536",,,,,
0,50916,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(65536, 1, 1)",0,7.5,Launch Statistics,Registers Per Thread,register/thread,16,,,,,
0,50916,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(65536, 1, 1)",0,7.5,Launch Statistics,Shared Memory Configuration Size,byte,"32,768",,,,,
0,50916,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(65536, 1, 1)",0,7.5,Launch Statistics,Driver Shared Memory Per Block,byte/block,0,,,,,
0,50916,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(65536, 1, 1)",0,7.5,Launch Statistics,Dynamic Shared Memory Per Block,byte/block,0,,,,,
0,50916,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(65536, 1, 1)",0,7.5,Launch Statistics,Static Shared Memory Per Block,byte/block,0,,,,,
0,50916,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(65536, 1, 1)",0,7.5,Launch Statistics,Threads,thread,"65,536",,,,,
0,50916,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(65536, 1, 1)",0,7.5,Launch Statistics,Waves Per SM,,292.57,,,,,
0,50916,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(65536, 1, 1)",0,7.5,LaunchStats,,,,LaunchConfiguration,OPT,"Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 1 threads per block. Consequently, some threads in a warp are masked off and those hardware resources are unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256 threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to kernels that frequently call __syncthreads(). See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations.",global,96.88
0,50916,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(65536, 1, 1)",0,7.5,Occupancy,Block Limit SM,block,16,,,,,
0,50916,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(65536, 1, 1)",0,7.5,Occupancy,Block Limit Registers,block,128,,,,,
0,50916,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(65536, 1, 1)",0,7.5,Occupancy,Block Limit Shared Mem,block,16,,,,,
0,50916,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(65536, 1, 1)",0,7.5,Occupancy,Block Limit Warps,block,32,,,,,
0,50916,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(65536, 1, 1)",0,7.5,Occupancy,Theoretical Active Warps per SM,warp,16,,,,,
0,50916,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(65536, 1, 1)",0,7.5,Occupancy,Theoretical Occupancy,%,50,,,,,
0,50916,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(65536, 1, 1)",0,7.5,Occupancy,Achieved Occupancy,%,32.31,,,,,
0,50916,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(65536, 1, 1)",0,7.5,Occupancy,Achieved Active Warps Per SM,warp,10.34,,,,,
0,50916,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(65536, 1, 1)",0,7.5,Occupancy,,,,AchievedOccupancy,OPT,The difference between calculated theoretical (50.0%) and measured achieved occupancy (32.3%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy.,global,35.37
0,50916,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(65536, 1, 1)",0,7.5,Occupancy,,,,TheoreticalOccupancy,OPT,The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared memory.,global,50.0
0,50916,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(65536, 1, 1)",0,7.5,Source Counters,Branch Instructions Ratio,%,0.08,,,,,
0,50916,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(65536, 1, 1)",0,7.5,Source Counters,Branch Instructions,inst,"65,536",,,,,
0,50916,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(65536, 1, 1)",0,7.5,Source Counters,Branch Efficiency,%,0,,,,,
0,50916,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(65536, 1, 1)",0,7.5,Source Counters,Avg. Divergent Branches,,0,,,,,
0,51002,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(32768, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Frequency,cycle/second,"6,047,691,527.14",,,,,
0,51002,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(32768, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Frequency,cycle/second,"1,388,746,194.82",,,,,
0,51002,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(32768, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Elapsed Cycles,cycle,"175,572",,,,,
0,51002,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(32768, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Memory Throughput,%,10.69,,,,,
0,51002,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(32768, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Throughput,%,2.15,,,,,
0,51002,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(32768, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Duration,nsecond,"126,144",,,,,
0,51002,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(32768, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L1/TEX Cache Throughput,%,16.56,,,,,
0,51002,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(32768, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L2 Cache Throughput,%,9.02,,,,,
0,51002,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(32768, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Active Cycles,cycle,"113,094.79",,,,,
0,51002,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(32768, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Compute (SM) Throughput,%,10.69,,,,,
0,51002,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(32768, 1, 1)",0,7.5,SpeedOfLight,,,,SOLBottleneck,OPT,This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.,,
0,51002,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(32768, 1, 1)",0,7.5,SpeedOfLight_RooflineChart,,,,SOLFPRoofline,INF,The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved  close to 0% of this device's fp32 peak performance and 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.,,
0,51002,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(32768, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Active,inst/cycle,0.27,,,,,
0,51002,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(32768, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Elapsed,inst/cycle,0.17,,,,,
0,51002,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(32768, 1, 1)",0,7.5,Compute Workload Analysis,Issue Slots Busy,%,6.74,,,,,
0,51002,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(32768, 1, 1)",0,7.5,Compute Workload Analysis,Issued Ipc Active,inst/cycle,0.27,,,,,
0,51002,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(32768, 1, 1)",0,7.5,Compute Workload Analysis,SM Busy,%,6.90,,,,,
0,51002,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(32768, 1, 1)",0,7.5,ComputeWorkloadAnalysis,,,,HighPipeUtilization,OPT,All compute pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.,local,94.83
0,51002,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(32768, 1, 1)",0,7.5,Memory Workload Analysis,Memory Throughput,byte/second,"4,158,041,603.25",,,,,
0,51002,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(32768, 1, 1)",0,7.5,Memory Workload Analysis,Mem Busy,%,7.27,,,,,
0,51002,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(32768, 1, 1)",0,7.5,Memory Workload Analysis,Max Bandwidth,%,10.69,,,,,
0,51002,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(32768, 1, 1)",0,7.5,Memory Workload Analysis,L1/TEX Hit Rate,%,9.48,,,,,
0,51002,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(32768, 1, 1)",0,7.5,Memory Workload Analysis,L2 Hit Rate,%,91.77,,,,,
0,51002,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(32768, 1, 1)",0,7.5,Memory Workload Analysis,Mem Pipes Busy,%,10.69,,,,,
0,51002,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(32768, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Chart,,,,MemoryL2Compression,WRN,The optional metric lts__average_gcomp_input_sector_success_rate.pct could not be found. Collecting it as an additional metric could enable the rule to provide more guidance.,,
0,51002,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(32768, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for loads from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced loads and try to minimize how many cache lines need to be accessed per memory request.",global,3.613
0,51002,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(32768, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for stores from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.3 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced stores and try to minimize how many cache lines need to be accessed per memory request.",global,1.658
0,51002,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(32768, 1, 1)",0,7.5,Scheduler Statistics,One or More Eligible,%,7.46,,,,,
0,51002,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(32768, 1, 1)",0,7.5,Scheduler Statistics,Issued Warp Per Scheduler,,0.07,,,,,
0,51002,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(32768, 1, 1)",0,7.5,Scheduler Statistics,No Eligible,%,92.54,,,,,
0,51002,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(32768, 1, 1)",0,7.5,Scheduler Statistics,Active Warps Per Scheduler,warp,2.82,,,,,
0,51002,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(32768, 1, 1)",0,7.5,Scheduler Statistics,Eligible Warps Per Scheduler,warp,0.08,,,,,
0,51002,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(32768, 1, 1)",0,7.5,SchedulerStats,,,,IssueSlotUtilization,OPT,"Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 13.4 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of 2.82 active warps per scheduler, but only an average of 0.08 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections.",local,89.31
0,51002,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(32768, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Issued Instruction,cycle,37.85,,,,,
0,51002,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(32768, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Executed Instruction,cycle,37.92,,,,,
0,51002,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(32768, 1, 1)",0,7.5,Warp State Statistics,Avg. Active Threads Per Warp,,2,,,,,
0,51002,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(32768, 1, 1)",0,7.5,Warp State Statistics,Avg. Not Predicated Off Threads Per Warp,,2,,,,,
0,51002,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(32768, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,OPT,"On average, each warp of this kernel spends 29.6 cycles being stalled waiting for a scoreboard dependency on a L1TEX (local, global, surface, texture) operation. Find the instruction producing the data being waited upon to identify the culprit. To reduce the number of cycles waiting on L1TEX data accesses verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit rates by increasing data locality (coalescing), or by changing the cache configuration. Consider moving frequently used data to shared memory. This stall type represents about 78.2% of the total average of 37.9 cycles between issuing two instructions.",global,78.19
0,51002,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(32768, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,INF,Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.,,
0,51002,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(32768, 1, 1)",0,7.5,WarpStateStats,,,,ThreadDivergence,OPT,"Instructions are executed in warps, which are groups of 32 threads. Optimal instruction throughput is achieved if all 32 threads of a warp execute the same instruction. The chosen launch configuration, early thread completion, and divergent flow control can significantly lower the number of active threads in a warp per cycle. This kernel achieves an average of 2.0 threads being active per cycle.",global,10.02
0,51002,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(32768, 1, 1)",0,7.5,Instruction Statistics,Avg. Executed Instructions Per Scheduler,inst,"7,606.86",,,,,
0,51002,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(32768, 1, 1)",0,7.5,Instruction Statistics,Executed Instructions,inst,"425,984",,,,,
0,51002,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(32768, 1, 1)",0,7.5,Instruction Statistics,Avg. Issued Instructions Per Scheduler,inst,"7,620.50",,,,,
0,51002,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(32768, 1, 1)",0,7.5,Instruction Statistics,Issued Instructions,inst,"426,748",,,,,
0,51002,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(32768, 1, 1)",0,7.5,InstructionStats,,,,FPInstructions,OPT,"This kernel executes 0 fused and 32768 non-fused FP32 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP32 performance could be increased by up to 50% (relative to its current performance). Check the Source page to identify where this kernel executes FP32 instructions.",global,2.587
0,51002,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(32768, 1, 1)",0,7.5,Launch Statistics,Block Size,,2,,,,,
0,51002,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(32768, 1, 1)",0,7.5,Launch Statistics,Function Cache Configuration,,CachePreferNone,,,,,
0,51002,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(32768, 1, 1)",0,7.5,Launch Statistics,Grid Size,,"32,768",,,,,
0,51002,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(32768, 1, 1)",0,7.5,Launch Statistics,Registers Per Thread,register/thread,16,,,,,
0,51002,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(32768, 1, 1)",0,7.5,Launch Statistics,Shared Memory Configuration Size,byte,"32,768",,,,,
0,51002,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(32768, 1, 1)",0,7.5,Launch Statistics,Driver Shared Memory Per Block,byte/block,0,,,,,
0,51002,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(32768, 1, 1)",0,7.5,Launch Statistics,Dynamic Shared Memory Per Block,byte/block,0,,,,,
0,51002,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(32768, 1, 1)",0,7.5,Launch Statistics,Static Shared Memory Per Block,byte/block,0,,,,,
0,51002,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(32768, 1, 1)",0,7.5,Launch Statistics,Threads,thread,"65,536",,,,,
0,51002,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(32768, 1, 1)",0,7.5,Launch Statistics,Waves Per SM,,146.29,,,,,
0,51002,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(32768, 1, 1)",0,7.5,LaunchStats,,,,LaunchConfiguration,OPT,"Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 2 threads per block. Consequently, some threads in a warp are masked off and those hardware resources are unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256 threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to kernels that frequently call __syncthreads(). See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations.",global,93.75
0,51002,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(32768, 1, 1)",0,7.5,Occupancy,Block Limit SM,block,16,,,,,
0,51002,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(32768, 1, 1)",0,7.5,Occupancy,Block Limit Registers,block,128,,,,,
0,51002,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(32768, 1, 1)",0,7.5,Occupancy,Block Limit Shared Mem,block,16,,,,,
0,51002,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(32768, 1, 1)",0,7.5,Occupancy,Block Limit Warps,block,32,,,,,
0,51002,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(32768, 1, 1)",0,7.5,Occupancy,Theoretical Active Warps per SM,warp,16,,,,,
0,51002,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(32768, 1, 1)",0,7.5,Occupancy,Theoretical Occupancy,%,50,,,,,
0,51002,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(32768, 1, 1)",0,7.5,Occupancy,Achieved Occupancy,%,32.91,,,,,
0,51002,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(32768, 1, 1)",0,7.5,Occupancy,Achieved Active Warps Per SM,warp,10.53,,,,,
0,51002,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(32768, 1, 1)",0,7.5,Occupancy,,,,AchievedOccupancy,OPT,The difference between calculated theoretical (50.0%) and measured achieved occupancy (32.9%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy.,global,34.18
0,51002,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(32768, 1, 1)",0,7.5,Occupancy,,,,TheoreticalOccupancy,OPT,The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared memory.,global,50.0
0,51002,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(32768, 1, 1)",0,7.5,Source Counters,Branch Instructions Ratio,%,0.08,,,,,
0,51002,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(32768, 1, 1)",0,7.5,Source Counters,Branch Instructions,inst,"32,768",,,,,
0,51002,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(32768, 1, 1)",0,7.5,Source Counters,Branch Efficiency,%,0,,,,,
0,51002,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(32768, 1, 1)",0,7.5,Source Counters,Avg. Divergent Branches,,0,,,,,
0,51079,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(16384, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Frequency,cycle/second,"5,983,935,742.97",,,,,
0,51079,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(16384, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Frequency,cycle/second,"1,374,074,422.69",,,,,
0,51079,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(16384, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Elapsed Cycles,cycle,"87,733",,,,,
0,51079,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(16384, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Memory Throughput,%,10.69,,,,,
0,51079,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(16384, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Throughput,%,4.30,,,,,
0,51079,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(16384, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Duration,nsecond,"63,744",,,,,
0,51079,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(16384, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L1/TEX Cache Throughput,%,16.74,,,,,
0,51079,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(16384, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L2 Cache Throughput,%,9.53,,,,,
0,51079,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(16384, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Active Cycles,cycle,"55,941.93",,,,,
0,51079,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(16384, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Compute (SM) Throughput,%,10.69,,,,,
0,51079,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(16384, 1, 1)",0,7.5,SpeedOfLight,,,,SOLBottleneck,OPT,This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.,,
0,51079,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(16384, 1, 1)",0,7.5,SpeedOfLight_RooflineChart,,,,SOLFPRoofline,INF,The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved  close to 0% of this device's fp32 peak performance and 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.,,
0,51079,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(16384, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Active,inst/cycle,0.27,,,,,
0,51079,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(16384, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Elapsed,inst/cycle,0.17,,,,,
0,51079,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(16384, 1, 1)",0,7.5,Compute Workload Analysis,Issue Slots Busy,%,6.82,,,,,
0,51079,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(16384, 1, 1)",0,7.5,Compute Workload Analysis,Issued Ipc Active,inst/cycle,0.27,,,,,
0,51079,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(16384, 1, 1)",0,7.5,Compute Workload Analysis,SM Busy,%,6.97,,,,,
0,51079,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(16384, 1, 1)",0,7.5,ComputeWorkloadAnalysis,,,,HighPipeUtilization,OPT,All compute pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.,local,94.77
0,51079,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(16384, 1, 1)",0,7.5,Memory Workload Analysis,Memory Throughput,byte/second,"8,228,413,654.62",,,,,
0,51079,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(16384, 1, 1)",0,7.5,Memory Workload Analysis,Mem Busy,%,7.31,,,,,
0,51079,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(16384, 1, 1)",0,7.5,Memory Workload Analysis,Max Bandwidth,%,10.69,,,,,
0,51079,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(16384, 1, 1)",0,7.5,Memory Workload Analysis,L1/TEX Hit Rate,%,2.69,,,,,
0,51079,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(16384, 1, 1)",0,7.5,Memory Workload Analysis,L2 Hit Rate,%,83.77,,,,,
0,51079,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(16384, 1, 1)",0,7.5,Memory Workload Analysis,Mem Pipes Busy,%,10.69,,,,,
0,51079,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(16384, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Chart,,,,MemoryL2Compression,WRN,The optional metric lts__average_gcomp_input_sector_success_rate.pct could not be found. Collecting it as an additional metric could enable the rule to provide more guidance.,,
0,51079,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(16384, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for loads from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced loads and try to minimize how many cache lines need to be accessed per memory request.",global,3.631
0,51079,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(16384, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for stores from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.1 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced stores and try to minimize how many cache lines need to be accessed per memory request.",global,1.788
0,51079,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(16384, 1, 1)",0,7.5,Scheduler Statistics,One or More Eligible,%,7.52,,,,,
0,51079,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(16384, 1, 1)",0,7.5,Scheduler Statistics,Issued Warp Per Scheduler,,0.08,,,,,
0,51079,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(16384, 1, 1)",0,7.5,Scheduler Statistics,No Eligible,%,92.48,,,,,
0,51079,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(16384, 1, 1)",0,7.5,Scheduler Statistics,Active Warps Per Scheduler,warp,2.78,,,,,
0,51079,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(16384, 1, 1)",0,7.5,Scheduler Statistics,Eligible Warps Per Scheduler,warp,0.08,,,,,
0,51079,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(16384, 1, 1)",0,7.5,SchedulerStats,,,,IssueSlotUtilization,OPT,"Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 13.3 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of 2.78 active warps per scheduler, but only an average of 0.08 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections.",local,89.31
0,51079,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(16384, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Issued Instruction,cycle,37.00,,,,,
0,51079,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(16384, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Executed Instruction,cycle,37.14,,,,,
0,51079,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(16384, 1, 1)",0,7.5,Warp State Statistics,Avg. Active Threads Per Warp,,4,,,,,
0,51079,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(16384, 1, 1)",0,7.5,Warp State Statistics,Avg. Not Predicated Off Threads Per Warp,,4,,,,,
0,51079,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(16384, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,OPT,"On average, each warp of this kernel spends 28.8 cycles being stalled waiting for a scoreboard dependency on a L1TEX (local, global, surface, texture) operation. Find the instruction producing the data being waited upon to identify the culprit. To reduce the number of cycles waiting on L1TEX data accesses verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit rates by increasing data locality (coalescing), or by changing the cache configuration. Consider moving frequently used data to shared memory. This stall type represents about 77.7% of the total average of 37.0 cycles between issuing two instructions.",global,77.72
0,51079,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(16384, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,INF,Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.,,
0,51079,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(16384, 1, 1)",0,7.5,WarpStateStats,,,,ThreadDivergence,OPT,"Instructions are executed in warps, which are groups of 32 threads. Optimal instruction throughput is achieved if all 32 threads of a warp execute the same instruction. The chosen launch configuration, early thread completion, and divergent flow control can significantly lower the number of active threads in a warp per cycle. This kernel achieves an average of 4.0 threads being active per cycle.",global,9.351
0,51079,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(16384, 1, 1)",0,7.5,Instruction Statistics,Avg. Executed Instructions Per Scheduler,inst,"3,803.43",,,,,
0,51079,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(16384, 1, 1)",0,7.5,Instruction Statistics,Executed Instructions,inst,"212,992",,,,,
0,51079,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(16384, 1, 1)",0,7.5,Instruction Statistics,Avg. Issued Instructions Per Scheduler,inst,"3,817.07",,,,,
0,51079,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(16384, 1, 1)",0,7.5,Instruction Statistics,Issued Instructions,inst,"213,756",,,,,
0,51079,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(16384, 1, 1)",0,7.5,InstructionStats,,,,FPInstructions,OPT,"This kernel executes 0 fused and 16384 non-fused FP32 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP32 performance could be increased by up to 50% (relative to its current performance). Check the Source page to identify where this kernel executes FP32 instructions.",global,2.615
0,51079,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(16384, 1, 1)",0,7.5,Launch Statistics,Block Size,,4,,,,,
0,51079,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(16384, 1, 1)",0,7.5,Launch Statistics,Function Cache Configuration,,CachePreferNone,,,,,
0,51079,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(16384, 1, 1)",0,7.5,Launch Statistics,Grid Size,,"16,384",,,,,
0,51079,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(16384, 1, 1)",0,7.5,Launch Statistics,Registers Per Thread,register/thread,16,,,,,
0,51079,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(16384, 1, 1)",0,7.5,Launch Statistics,Shared Memory Configuration Size,byte,"32,768",,,,,
0,51079,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(16384, 1, 1)",0,7.5,Launch Statistics,Driver Shared Memory Per Block,byte/block,0,,,,,
0,51079,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(16384, 1, 1)",0,7.5,Launch Statistics,Dynamic Shared Memory Per Block,byte/block,0,,,,,
0,51079,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(16384, 1, 1)",0,7.5,Launch Statistics,Static Shared Memory Per Block,byte/block,0,,,,,
0,51079,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(16384, 1, 1)",0,7.5,Launch Statistics,Threads,thread,"65,536",,,,,
0,51079,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(16384, 1, 1)",0,7.5,Launch Statistics,Waves Per SM,,73.14,,,,,
0,51079,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(16384, 1, 1)",0,7.5,LaunchStats,,,,LaunchConfiguration,OPT,"Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 4 threads per block. Consequently, some threads in a warp are masked off and those hardware resources are unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256 threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to kernels that frequently call __syncthreads(). See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations.",global,87.5
0,51079,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(16384, 1, 1)",0,7.5,Occupancy,Block Limit SM,block,16,,,,,
0,51079,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(16384, 1, 1)",0,7.5,Occupancy,Block Limit Registers,block,128,,,,,
0,51079,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(16384, 1, 1)",0,7.5,Occupancy,Block Limit Shared Mem,block,16,,,,,
0,51079,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(16384, 1, 1)",0,7.5,Occupancy,Block Limit Warps,block,32,,,,,
0,51079,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(16384, 1, 1)",0,7.5,Occupancy,Theoretical Active Warps per SM,warp,16,,,,,
0,51079,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(16384, 1, 1)",0,7.5,Occupancy,Theoretical Occupancy,%,50,,,,,
0,51079,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(16384, 1, 1)",0,7.5,Occupancy,Achieved Occupancy,%,33.03,,,,,
0,51079,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(16384, 1, 1)",0,7.5,Occupancy,Achieved Active Warps Per SM,warp,10.57,,,,,
0,51079,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(16384, 1, 1)",0,7.5,Occupancy,,,,AchievedOccupancy,OPT,The difference between calculated theoretical (50.0%) and measured achieved occupancy (33.0%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy.,global,33.95
0,51079,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(16384, 1, 1)",0,7.5,Occupancy,,,,TheoreticalOccupancy,OPT,The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared memory.,global,50.0
0,51079,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(16384, 1, 1)",0,7.5,Source Counters,Branch Instructions Ratio,%,0.08,,,,,
0,51079,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(16384, 1, 1)",0,7.5,Source Counters,Branch Instructions,inst,"16,384",,,,,
0,51079,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(16384, 1, 1)",0,7.5,Source Counters,Branch Efficiency,%,0,,,,,
0,51079,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(16384, 1, 1)",0,7.5,Source Counters,Avg. Divergent Branches,,0,,,,,
0,51164,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(8192, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Frequency,cycle/second,"6,035,502,958.58",,,,,
0,51164,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(8192, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Frequency,cycle/second,"1,386,418,269.23",,,,,
0,51164,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(8192, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Elapsed Cycles,cycle,"45,128",,,,,
0,51164,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(8192, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Memory Throughput,%,10.40,,,,,
0,51164,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(8192, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Throughput,%,8.37,,,,,
0,51164,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(8192, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Duration,nsecond,"32,448",,,,,
0,51164,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(8192, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L1/TEX Cache Throughput,%,16.63,,,,,
0,51164,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(8192, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L2 Cache Throughput,%,7.19,,,,,
0,51164,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(8192, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Active Cycles,cycle,"28,140.36",,,,,
0,51164,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(8192, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Compute (SM) Throughput,%,10.40,,,,,
0,51164,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(8192, 1, 1)",0,7.5,SpeedOfLight,,,,SOLBottleneck,OPT,This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.,,
0,51164,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(8192, 1, 1)",0,7.5,SpeedOfLight_RooflineChart,,,,SOLFPRoofline,INF,The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved  close to 0% of this device's fp32 peak performance and 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.,,
0,51164,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(8192, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Active,inst/cycle,0.27,,,,,
0,51164,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(8192, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Elapsed,inst/cycle,0.17,,,,,
0,51164,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(8192, 1, 1)",0,7.5,Compute Workload Analysis,Issue Slots Busy,%,6.81,,,,,
0,51164,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(8192, 1, 1)",0,7.5,Compute Workload Analysis,Issued Ipc Active,inst/cycle,0.27,,,,,
0,51164,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(8192, 1, 1)",0,7.5,Compute Workload Analysis,SM Busy,%,6.93,,,,,
0,51164,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(8192, 1, 1)",0,7.5,ComputeWorkloadAnalysis,,,,HighPipeUtilization,OPT,All compute pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.,local,94.8
0,51164,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(8192, 1, 1)",0,7.5,Memory Workload Analysis,Memory Throughput,byte/second,"16,164,694,280.08",,,,,
0,51164,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(8192, 1, 1)",0,7.5,Memory Workload Analysis,Mem Busy,%,7.19,,,,,
0,51164,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(8192, 1, 1)",0,7.5,Memory Workload Analysis,Max Bandwidth,%,10.40,,,,,
0,51164,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(8192, 1, 1)",0,7.5,Memory Workload Analysis,L1/TEX Hit Rate,%,0.57,,,,,
0,51164,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(8192, 1, 1)",0,7.5,Memory Workload Analysis,L2 Hit Rate,%,66.86,,,,,
0,51164,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(8192, 1, 1)",0,7.5,Memory Workload Analysis,Mem Pipes Busy,%,10.40,,,,,
0,51164,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(8192, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Chart,,,,MemoryL2Compression,WRN,The optional metric lts__average_gcomp_input_sector_success_rate.pct could not be found. Collecting it as an additional metric could enable the rule to provide more guidance.,,
0,51164,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(8192, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for loads from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced loads and try to minimize how many cache lines need to be accessed per memory request.",global,3.555
0,51164,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(8192, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for stores from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced stores and try to minimize how many cache lines need to be accessed per memory request.",global,1.768
0,51164,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(8192, 1, 1)",0,7.5,Scheduler Statistics,One or More Eligible,%,7.50,,,,,
0,51164,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(8192, 1, 1)",0,7.5,Scheduler Statistics,Issued Warp Per Scheduler,,0.08,,,,,
0,51164,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(8192, 1, 1)",0,7.5,Scheduler Statistics,No Eligible,%,92.50,,,,,
0,51164,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(8192, 1, 1)",0,7.5,Scheduler Statistics,Active Warps Per Scheduler,warp,2.91,,,,,
0,51164,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(8192, 1, 1)",0,7.5,Scheduler Statistics,Eligible Warps Per Scheduler,warp,0.08,,,,,
0,51164,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(8192, 1, 1)",0,7.5,SchedulerStats,,,,IssueSlotUtilization,OPT,"Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 13.3 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of 2.91 active warps per scheduler, but only an average of 0.08 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections.",local,89.6
0,51164,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(8192, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Issued Instruction,cycle,38.75,,,,,
0,51164,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(8192, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Executed Instruction,cycle,39.02,,,,,
0,51164,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(8192, 1, 1)",0,7.5,Warp State Statistics,Avg. Active Threads Per Warp,,8,,,,,
0,51164,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(8192, 1, 1)",0,7.5,Warp State Statistics,Avg. Not Predicated Off Threads Per Warp,,8,,,,,
0,51164,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(8192, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,OPT,"On average, each warp of this kernel spends 29.1 cycles being stalled waiting for a scoreboard dependency on a L1TEX (local, global, surface, texture) operation. Find the instruction producing the data being waited upon to identify the culprit. To reduce the number of cycles waiting on L1TEX data accesses verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit rates by increasing data locality (coalescing), or by changing the cache configuration. Consider moving frequently used data to shared memory. This stall type represents about 75.1% of the total average of 38.7 cycles between issuing two instructions.",global,75.08
0,51164,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(8192, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,INF,Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.,,
0,51164,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(8192, 1, 1)",0,7.5,WarpStateStats,,,,ThreadDivergence,OPT,"Instructions are executed in warps, which are groups of 32 threads. Optimal instruction throughput is achieved if all 32 threads of a warp execute the same instruction. The chosen launch configuration, early thread completion, and divergent flow control can significantly lower the number of active threads in a warp per cycle. This kernel achieves an average of 8.0 threads being active per cycle.",global,7.801
0,51164,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(8192, 1, 1)",0,7.5,Instruction Statistics,Avg. Executed Instructions Per Scheduler,inst,"1,901.71",,,,,
0,51164,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(8192, 1, 1)",0,7.5,Instruction Statistics,Executed Instructions,inst,"106,496",,,,,
0,51164,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(8192, 1, 1)",0,7.5,Instruction Statistics,Avg. Issued Instructions Per Scheduler,inst,"1,915.36",,,,,
0,51164,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(8192, 1, 1)",0,7.5,Instruction Statistics,Issued Instructions,inst,"107,260",,,,,
0,51164,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(8192, 1, 1)",0,7.5,InstructionStats,,,,FPInstructions,OPT,"This kernel executes 0 fused and 8192 non-fused FP32 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP32 performance could be increased by up to 50% (relative to its current performance). Check the Source page to identify where this kernel executes FP32 instructions.",global,2.599
0,51164,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(8192, 1, 1)",0,7.5,Launch Statistics,Block Size,,8,,,,,
0,51164,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(8192, 1, 1)",0,7.5,Launch Statistics,Function Cache Configuration,,CachePreferNone,,,,,
0,51164,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(8192, 1, 1)",0,7.5,Launch Statistics,Grid Size,,"8,192",,,,,
0,51164,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(8192, 1, 1)",0,7.5,Launch Statistics,Registers Per Thread,register/thread,16,,,,,
0,51164,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(8192, 1, 1)",0,7.5,Launch Statistics,Shared Memory Configuration Size,byte,"32,768",,,,,
0,51164,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(8192, 1, 1)",0,7.5,Launch Statistics,Driver Shared Memory Per Block,byte/block,0,,,,,
0,51164,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(8192, 1, 1)",0,7.5,Launch Statistics,Dynamic Shared Memory Per Block,byte/block,0,,,,,
0,51164,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(8192, 1, 1)",0,7.5,Launch Statistics,Static Shared Memory Per Block,byte/block,0,,,,,
0,51164,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(8192, 1, 1)",0,7.5,Launch Statistics,Threads,thread,"65,536",,,,,
0,51164,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(8192, 1, 1)",0,7.5,Launch Statistics,Waves Per SM,,36.57,,,,,
0,51164,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(8192, 1, 1)",0,7.5,LaunchStats,,,,LaunchConfiguration,OPT,"Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 8 threads per block. Consequently, some threads in a warp are masked off and those hardware resources are unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256 threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to kernels that frequently call __syncthreads(). See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations.",global,75.0
0,51164,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(8192, 1, 1)",0,7.5,Occupancy,Block Limit SM,block,16,,,,,
0,51164,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(8192, 1, 1)",0,7.5,Occupancy,Block Limit Registers,block,128,,,,,
0,51164,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(8192, 1, 1)",0,7.5,Occupancy,Block Limit Shared Mem,block,16,,,,,
0,51164,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(8192, 1, 1)",0,7.5,Occupancy,Block Limit Warps,block,32,,,,,
0,51164,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(8192, 1, 1)",0,7.5,Occupancy,Theoretical Active Warps per SM,warp,16,,,,,
0,51164,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(8192, 1, 1)",0,7.5,Occupancy,Theoretical Occupancy,%,50,,,,,
0,51164,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(8192, 1, 1)",0,7.5,Occupancy,Achieved Occupancy,%,33.79,,,,,
0,51164,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(8192, 1, 1)",0,7.5,Occupancy,Achieved Active Warps Per SM,warp,10.81,,,,,
0,51164,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(8192, 1, 1)",0,7.5,Occupancy,,,,AchievedOccupancy,OPT,The difference between calculated theoretical (50.0%) and measured achieved occupancy (33.8%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy.,global,32.42
0,51164,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(8192, 1, 1)",0,7.5,Occupancy,,,,TheoreticalOccupancy,OPT,The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared memory.,global,50.0
0,51164,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(8192, 1, 1)",0,7.5,Source Counters,Branch Instructions Ratio,%,0.08,,,,,
0,51164,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(8192, 1, 1)",0,7.5,Source Counters,Branch Instructions,inst,"8,192",,,,,
0,51164,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(8192, 1, 1)",0,7.5,Source Counters,Branch Efficiency,%,0,,,,,
0,51164,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(8192, 1, 1)",0,7.5,Source Counters,Avg. Divergent Branches,,0,,,,,
0,51249,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(4096, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Frequency,cycle/second,"5,776,991,150.44",,,,,
0,51249,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(4096, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Frequency,cycle/second,"1,329,341,814.16",,,,,
0,51249,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(4096, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Elapsed Cycles,cycle,"24,075",,,,,
0,51249,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(4096, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Memory Throughput,%,15.72,,,,,
0,51249,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(4096, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Throughput,%,15.72,,,,,
0,51249,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(4096, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Duration,nsecond,"18,080",,,,,
0,51249,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(4096, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L1/TEX Cache Throughput,%,15.18,,,,,
0,51249,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(4096, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L2 Cache Throughput,%,13.44,,,,,
0,51249,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(4096, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Active Cycles,cycle,"15,421.43",,,,,
0,51249,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(4096, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Compute (SM) Throughput,%,9.74,,,,,
0,51249,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(4096, 1, 1)",0,7.5,SpeedOfLight,,,,SOLBottleneck,OPT,This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.,,
0,51249,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(4096, 1, 1)",0,7.5,SpeedOfLight_RooflineChart,,,,SOLFPRoofline,INF,The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved  close to 0% of this device's fp32 peak performance and 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.,,
0,51249,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(4096, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Active,inst/cycle,0.25,,,,,
0,51249,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(4096, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Elapsed,inst/cycle,0.16,,,,,
0,51249,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(4096, 1, 1)",0,7.5,Compute Workload Analysis,Issue Slots Busy,%,6.25,,,,,
0,51249,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(4096, 1, 1)",0,7.5,Compute Workload Analysis,Issued Ipc Active,inst/cycle,0.25,,,,,
0,51249,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(4096, 1, 1)",0,7.5,Compute Workload Analysis,SM Busy,%,6.32,,,,,
0,51249,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(4096, 1, 1)",0,7.5,ComputeWorkloadAnalysis,,,,HighPipeUtilization,OPT,All compute pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.,local,95.26
0,51249,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(4096, 1, 1)",0,7.5,Memory Workload Analysis,Memory Throughput,byte/second,"29,067,256,637.17",,,,,
0,51249,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(4096, 1, 1)",0,7.5,Memory Workload Analysis,Mem Busy,%,13.44,,,,,
0,51249,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(4096, 1, 1)",0,7.5,Memory Workload Analysis,Max Bandwidth,%,15.72,,,,,
0,51249,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(4096, 1, 1)",0,7.5,Memory Workload Analysis,L1/TEX Hit Rate,%,1.10,,,,,
0,51249,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(4096, 1, 1)",0,7.5,Memory Workload Analysis,L2 Hit Rate,%,34.09,,,,,
0,51249,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(4096, 1, 1)",0,7.5,Memory Workload Analysis,Mem Pipes Busy,%,9.74,,,,,
0,51249,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(4096, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Chart,,,,MemoryL2Compression,WRN,The optional metric lts__average_gcomp_input_sector_success_rate.pct could not be found. Collecting it as an additional metric could enable the rule to provide more guidance.,,
0,51249,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(4096, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for loads from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 2.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced loads and try to minimize how many cache lines need to be accessed per memory request.",global,4.361
0,51249,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(4096, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for stores from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 2.1 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced stores and try to minimize how many cache lines need to be accessed per memory request.",global,2.138
0,51249,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(4096, 1, 1)",0,7.5,Scheduler Statistics,One or More Eligible,%,6.90,,,,,
0,51249,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(4096, 1, 1)",0,7.5,Scheduler Statistics,Issued Warp Per Scheduler,,0.07,,,,,
0,51249,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(4096, 1, 1)",0,7.5,Scheduler Statistics,No Eligible,%,93.10,,,,,
0,51249,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(4096, 1, 1)",0,7.5,Scheduler Statistics,Active Warps Per Scheduler,warp,2.89,,,,,
0,51249,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(4096, 1, 1)",0,7.5,Scheduler Statistics,Eligible Warps Per Scheduler,warp,0.07,,,,,
0,51249,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(4096, 1, 1)",0,7.5,SchedulerStats,,,,IssueSlotUtilization,OPT,"Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 14.5 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of 2.89 active warps per scheduler, but only an average of 0.07 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections.",local,84.28
0,51249,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(4096, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Issued Instruction,cycle,41.89,,,,,
0,51249,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(4096, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Executed Instruction,cycle,42.49,,,,,
0,51249,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(4096, 1, 1)",0,7.5,Warp State Statistics,Avg. Active Threads Per Warp,,16,,,,,
0,51249,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(4096, 1, 1)",0,7.5,Warp State Statistics,Avg. Not Predicated Off Threads Per Warp,,16,,,,,
0,51249,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(4096, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,OPT,"On average, each warp of this kernel spends 30.7 cycles being stalled waiting for a scoreboard dependency on a L1TEX (local, global, surface, texture) operation. Find the instruction producing the data being waited upon to identify the culprit. To reduce the number of cycles waiting on L1TEX data accesses verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit rates by increasing data locality (coalescing), or by changing the cache configuration. Consider moving frequently used data to shared memory. This stall type represents about 73.4% of the total average of 41.9 cycles between issuing two instructions.",global,73.41
0,51249,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(4096, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,INF,Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.,,
0,51249,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(4096, 1, 1)",0,7.5,WarpStateStats,,,,ThreadDivergence,OPT,"Instructions are executed in warps, which are groups of 32 threads. Optimal instruction throughput is achieved if all 32 threads of a warp execute the same instruction. The chosen launch configuration, early thread completion, and divergent flow control can significantly lower the number of active threads in a warp per cycle. This kernel achieves an average of 16.0 threads being active per cycle.",global,4.868
0,51249,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(4096, 1, 1)",0,7.5,Instruction Statistics,Avg. Executed Instructions Per Scheduler,inst,950.86,,,,,
0,51249,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(4096, 1, 1)",0,7.5,Instruction Statistics,Executed Instructions,inst,"53,248",,,,,
0,51249,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(4096, 1, 1)",0,7.5,Instruction Statistics,Avg. Issued Instructions Per Scheduler,inst,964.50,,,,,
0,51249,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(4096, 1, 1)",0,7.5,Instruction Statistics,Issued Instructions,inst,"54,012",,,,,
0,51249,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(4096, 1, 1)",0,7.5,InstructionStats,,,,FPInstructions,OPT,"This kernel executes 0 fused and 4096 non-fused FP32 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP32 performance could be increased by up to 50% (relative to its current performance). Check the Source page to identify where this kernel executes FP32 instructions.",global,2.371
0,51249,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(4096, 1, 1)",0,7.5,Launch Statistics,Block Size,,16,,,,,
0,51249,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(4096, 1, 1)",0,7.5,Launch Statistics,Function Cache Configuration,,CachePreferNone,,,,,
0,51249,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(4096, 1, 1)",0,7.5,Launch Statistics,Grid Size,,"4,096",,,,,
0,51249,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(4096, 1, 1)",0,7.5,Launch Statistics,Registers Per Thread,register/thread,16,,,,,
0,51249,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(4096, 1, 1)",0,7.5,Launch Statistics,Shared Memory Configuration Size,byte,"32,768",,,,,
0,51249,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(4096, 1, 1)",0,7.5,Launch Statistics,Driver Shared Memory Per Block,byte/block,0,,,,,
0,51249,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(4096, 1, 1)",0,7.5,Launch Statistics,Dynamic Shared Memory Per Block,byte/block,0,,,,,
0,51249,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(4096, 1, 1)",0,7.5,Launch Statistics,Static Shared Memory Per Block,byte/block,0,,,,,
0,51249,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(4096, 1, 1)",0,7.5,Launch Statistics,Threads,thread,"65,536",,,,,
0,51249,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(4096, 1, 1)",0,7.5,Launch Statistics,Waves Per SM,,18.29,,,,,
0,51249,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(4096, 1, 1)",0,7.5,LaunchStats,,,,LaunchConfiguration,OPT,"Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 16 threads per block. Consequently, some threads in a warp are masked off and those hardware resources are unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256 threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to kernels that frequently call __syncthreads(). See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations.",global,50.0
0,51249,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(4096, 1, 1)",0,7.5,Occupancy,Block Limit SM,block,16,,,,,
0,51249,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(4096, 1, 1)",0,7.5,Occupancy,Block Limit Registers,block,128,,,,,
0,51249,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(4096, 1, 1)",0,7.5,Occupancy,Block Limit Shared Mem,block,16,,,,,
0,51249,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(4096, 1, 1)",0,7.5,Occupancy,Block Limit Warps,block,32,,,,,
0,51249,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(4096, 1, 1)",0,7.5,Occupancy,Theoretical Active Warps per SM,warp,16,,,,,
0,51249,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(4096, 1, 1)",0,7.5,Occupancy,Theoretical Occupancy,%,50,,,,,
0,51249,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(4096, 1, 1)",0,7.5,Occupancy,Achieved Occupancy,%,33.68,,,,,
0,51249,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(4096, 1, 1)",0,7.5,Occupancy,Achieved Active Warps Per SM,warp,10.78,,,,,
0,51249,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(4096, 1, 1)",0,7.5,Occupancy,,,,AchievedOccupancy,OPT,The difference between calculated theoretical (50.0%) and measured achieved occupancy (33.7%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy.,global,32.64
0,51249,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(4096, 1, 1)",0,7.5,Occupancy,,,,TheoreticalOccupancy,OPT,The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared memory.,global,50.0
0,51249,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(4096, 1, 1)",0,7.5,Source Counters,Branch Instructions Ratio,%,0.08,,,,,
0,51249,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(4096, 1, 1)",0,7.5,Source Counters,Branch Instructions,inst,"4,096",,,,,
0,51249,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(4096, 1, 1)",0,7.5,Source Counters,Branch Efficiency,%,0,,,,,
0,51249,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(4096, 1, 1)",0,7.5,Source Counters,Avg. Divergent Branches,,0,,,,,
0,51326,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(2048, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Frequency,cycle/second,"5,248,554,913.29",,,,,
0,51326,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(2048, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Frequency,cycle/second,"1,202,808,887.28",,,,,
0,51326,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(2048, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Elapsed Cycles,cycle,"13,339",,,,,
0,51326,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(2048, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Memory Throughput,%,28.20,,,,,
0,51326,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(2048, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Throughput,%,28.20,,,,,
0,51326,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(2048, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Duration,nsecond,"11,072",,,,,
0,51326,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(2048, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L1/TEX Cache Throughput,%,12.96,,,,,
0,51326,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(2048, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L2 Cache Throughput,%,24.22,,,,,
0,51326,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(2048, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Active Cycles,cycle,"9,173.86",,,,,
0,51326,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(2048, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Compute (SM) Throughput,%,8.79,,,,,
0,51326,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(2048, 1, 1)",0,7.5,SpeedOfLight,,,,SOLBottleneck,OPT,This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.,,
0,51326,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(2048, 1, 1)",0,7.5,SpeedOfLight_RooflineChart,,,,SOLFPRoofline,INF,The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved  close to 0% of this device's fp32 peak performance and 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.,,
0,51326,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(2048, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Active,inst/cycle,0.21,,,,,
0,51326,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(2048, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Elapsed,inst/cycle,0.14,,,,,
0,51326,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(2048, 1, 1)",0,7.5,Compute Workload Analysis,Issue Slots Busy,%,5.33,,,,,
0,51326,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(2048, 1, 1)",0,7.5,Compute Workload Analysis,Issued Ipc Active,inst/cycle,0.21,,,,,
0,51326,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(2048, 1, 1)",0,7.5,Compute Workload Analysis,SM Busy,%,5.33,,,,,
0,51326,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(2048, 1, 1)",0,7.5,ComputeWorkloadAnalysis,,,,HighPipeUtilization,OPT,All compute pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.,local,96.01
0,51326,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(2048, 1, 1)",0,7.5,Memory Workload Analysis,Memory Throughput,byte/second,"47,367,052,023.12",,,,,
0,51326,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(2048, 1, 1)",0,7.5,Memory Workload Analysis,Mem Busy,%,24.22,,,,,
0,51326,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(2048, 1, 1)",0,7.5,Memory Workload Analysis,Max Bandwidth,%,28.20,,,,,
0,51326,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(2048, 1, 1)",0,7.5,Memory Workload Analysis,L1/TEX Hit Rate,%,0,,,,,
0,51326,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(2048, 1, 1)",0,7.5,Memory Workload Analysis,L2 Hit Rate,%,33.80,,,,,
0,51326,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(2048, 1, 1)",0,7.5,Memory Workload Analysis,Mem Pipes Busy,%,8.79,,,,,
0,51326,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(2048, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Chart,,,,MemoryL2Compression,WRN,The optional metric lts__average_gcomp_input_sector_success_rate.pct could not be found. Collecting it as an additional metric could enable the rule to provide more guidance.,,
0,51326,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(2048, 1, 1)",0,7.5,Scheduler Statistics,One or More Eligible,%,6.11,,,,,
0,51326,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(2048, 1, 1)",0,7.5,Scheduler Statistics,Issued Warp Per Scheduler,,0.06,,,,,
0,51326,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(2048, 1, 1)",0,7.5,Scheduler Statistics,No Eligible,%,93.89,,,,,
0,51326,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(2048, 1, 1)",0,7.5,Scheduler Statistics,Active Warps Per Scheduler,warp,2.90,,,,,
0,51326,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(2048, 1, 1)",0,7.5,Scheduler Statistics,Eligible Warps Per Scheduler,warp,0.06,,,,,
0,51326,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(2048, 1, 1)",0,7.5,SchedulerStats,,,,IssueSlotUtilization,OPT,"Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 16.4 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of 2.90 active warps per scheduler, but only an average of 0.06 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections.",local,71.8
0,51326,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(2048, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Issued Instruction,cycle,47.45,,,,,
0,51326,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(2048, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Executed Instruction,cycle,48.81,,,,,
0,51326,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(2048, 1, 1)",0,7.5,Warp State Statistics,Avg. Active Threads Per Warp,,32,,,,,
0,51326,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(2048, 1, 1)",0,7.5,Warp State Statistics,Avg. Not Predicated Off Threads Per Warp,,32,,,,,
0,51326,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(2048, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,OPT,"On average, each warp of this kernel spends 37.6 cycles being stalled waiting for a scoreboard dependency on a L1TEX (local, global, surface, texture) operation. Find the instruction producing the data being waited upon to identify the culprit. To reduce the number of cycles waiting on L1TEX data accesses verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit rates by increasing data locality (coalescing), or by changing the cache configuration. Consider moving frequently used data to shared memory. This stall type represents about 79.2% of the total average of 47.5 cycles between issuing two instructions.",global,71.8
0,51326,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(2048, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,INF,Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.,,
0,51326,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(2048, 1, 1)",0,7.5,Instruction Statistics,Avg. Executed Instructions Per Scheduler,inst,475.43,,,,,
0,51326,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(2048, 1, 1)",0,7.5,Instruction Statistics,Executed Instructions,inst,"26,624",,,,,
0,51326,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(2048, 1, 1)",0,7.5,Instruction Statistics,Avg. Issued Instructions Per Scheduler,inst,489.07,,,,,
0,51326,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(2048, 1, 1)",0,7.5,Instruction Statistics,Issued Instructions,inst,"27,388",,,,,
0,51326,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(2048, 1, 1)",0,7.5,InstructionStats,,,,FPInstructions,OPT,"This kernel executes 0 fused and 2048 non-fused FP32 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP32 performance could be increased by up to 50% (relative to its current performance). Check the Source page to identify where this kernel executes FP32 instructions.",global,1.993
0,51326,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(2048, 1, 1)",0,7.5,Launch Statistics,Block Size,,32,,,,,
0,51326,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(2048, 1, 1)",0,7.5,Launch Statistics,Function Cache Configuration,,CachePreferNone,,,,,
0,51326,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(2048, 1, 1)",0,7.5,Launch Statistics,Grid Size,,"2,048",,,,,
0,51326,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(2048, 1, 1)",0,7.5,Launch Statistics,Registers Per Thread,register/thread,16,,,,,
0,51326,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(2048, 1, 1)",0,7.5,Launch Statistics,Shared Memory Configuration Size,byte,"32,768",,,,,
0,51326,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(2048, 1, 1)",0,7.5,Launch Statistics,Driver Shared Memory Per Block,byte/block,0,,,,,
0,51326,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(2048, 1, 1)",0,7.5,Launch Statistics,Dynamic Shared Memory Per Block,byte/block,0,,,,,
0,51326,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(2048, 1, 1)",0,7.5,Launch Statistics,Static Shared Memory Per Block,byte/block,0,,,,,
0,51326,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(2048, 1, 1)",0,7.5,Launch Statistics,Threads,thread,"65,536",,,,,
0,51326,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(2048, 1, 1)",0,7.5,Launch Statistics,Waves Per SM,,9.14,,,,,
0,51326,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(2048, 1, 1)",0,7.5,Occupancy,Block Limit SM,block,16,,,,,
0,51326,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(2048, 1, 1)",0,7.5,Occupancy,Block Limit Registers,block,128,,,,,
0,51326,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(2048, 1, 1)",0,7.5,Occupancy,Block Limit Shared Mem,block,16,,,,,
0,51326,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(2048, 1, 1)",0,7.5,Occupancy,Block Limit Warps,block,32,,,,,
0,51326,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(2048, 1, 1)",0,7.5,Occupancy,Theoretical Active Warps per SM,warp,16,,,,,
0,51326,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(2048, 1, 1)",0,7.5,Occupancy,Theoretical Occupancy,%,50,,,,,
0,51326,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(2048, 1, 1)",0,7.5,Occupancy,Achieved Occupancy,%,33.00,,,,,
0,51326,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(2048, 1, 1)",0,7.5,Occupancy,Achieved Active Warps Per SM,warp,10.56,,,,,
0,51326,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(2048, 1, 1)",0,7.5,Occupancy,,,,AchievedOccupancy,OPT,The difference between calculated theoretical (50.0%) and measured achieved occupancy (33.0%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy.,global,34.0
0,51326,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(2048, 1, 1)",0,7.5,Occupancy,,,,TheoreticalOccupancy,OPT,The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared memory.,global,50.0
0,51326,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(2048, 1, 1)",0,7.5,Source Counters,Branch Instructions Ratio,%,0.08,,,,,
0,51326,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(2048, 1, 1)",0,7.5,Source Counters,Branch Instructions,inst,"2,048",,,,,
0,51326,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(2048, 1, 1)",0,7.5,Source Counters,Branch Efficiency,%,0,,,,,
0,51326,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(2048, 1, 1)",0,7.5,Source Counters,Avg. Divergent Branches,,0,,,,,
0,51412,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(1024, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Frequency,cycle/second,"5,026,178,010.47",,,,,
0,51412,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(1024, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Frequency,cycle/second,"1,145,124,345.55",,,,,
0,51412,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(1024, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Elapsed Cycles,cycle,"7,027",,,,,
0,51412,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(1024, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Memory Throughput,%,53.36,,,,,
0,51412,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(1024, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Throughput,%,53.36,,,,,
0,51412,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(1024, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Duration,nsecond,"6,112",,,,,
0,51412,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(1024, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L1/TEX Cache Throughput,%,22.77,,,,,
0,51412,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(1024, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L2 Cache Throughput,%,46.15,,,,,
0,51412,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(1024, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Active Cycles,cycle,"5,320.29",,,,,
0,51412,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(1024, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Compute (SM) Throughput,%,16.71,,,,,
0,51412,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(1024, 1, 1)",0,7.5,SpeedOfLight,,,,SOLBottleneck,OPT,This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.,,
0,51412,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(1024, 1, 1)",0,7.5,SpeedOfLight_RooflineChart,,,,SOLFPRoofline,INF,The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved  close to 1% of this device's fp32 peak performance and 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.,,
0,51412,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(1024, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Active,inst/cycle,0.36,,,,,
0,51412,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(1024, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Elapsed,inst/cycle,0.27,,,,,
0,51412,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(1024, 1, 1)",0,7.5,Compute Workload Analysis,Issue Slots Busy,%,9.41,,,,,
0,51412,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(1024, 1, 1)",0,7.5,Compute Workload Analysis,Issued Ipc Active,inst/cycle,0.38,,,,,
0,51412,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(1024, 1, 1)",0,7.5,Compute Workload Analysis,SM Busy,%,9.41,,,,,
0,51412,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(1024, 1, 1)",0,7.5,ComputeWorkloadAnalysis,,,,HighPipeUtilization,OPT,All compute pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.,local,93.13
0,51412,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(1024, 1, 1)",0,7.5,Memory Workload Analysis,Memory Throughput,byte/second,"85,816,753,926.70",,,,,
0,51412,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(1024, 1, 1)",0,7.5,Memory Workload Analysis,Mem Busy,%,46.15,,,,,
0,51412,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(1024, 1, 1)",0,7.5,Memory Workload Analysis,Max Bandwidth,%,53.36,,,,,
0,51412,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(1024, 1, 1)",0,7.5,Memory Workload Analysis,L1/TEX Hit Rate,%,0,,,,,
0,51412,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(1024, 1, 1)",0,7.5,Memory Workload Analysis,L2 Hit Rate,%,33.78,,,,,
0,51412,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(1024, 1, 1)",0,7.5,Memory Workload Analysis,Mem Pipes Busy,%,16.71,,,,,
0,51412,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(1024, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Chart,,,,MemoryL2Compression,WRN,The optional metric lts__average_gcomp_input_sector_success_rate.pct could not be found. Collecting it as an additional metric could enable the rule to provide more guidance.,,
0,51412,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(1024, 1, 1)",0,7.5,Scheduler Statistics,One or More Eligible,%,9.60,,,,,
0,51412,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(1024, 1, 1)",0,7.5,Scheduler Statistics,Issued Warp Per Scheduler,,0.10,,,,,
0,51412,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(1024, 1, 1)",0,7.5,Scheduler Statistics,No Eligible,%,90.40,,,,,
0,51412,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(1024, 1, 1)",0,7.5,Scheduler Statistics,Active Warps Per Scheduler,warp,5.73,,,,,
0,51412,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(1024, 1, 1)",0,7.5,Scheduler Statistics,Eligible Warps Per Scheduler,warp,0.12,,,,,
0,51412,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(1024, 1, 1)",0,7.5,SchedulerStats,,,,IssueSlotUtilization,OPT,"Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 10.4 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of 5.73 active warps per scheduler, but only an average of 0.12 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections.",local,46.64
0,51412,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(1024, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Issued Instruction,cycle,59.71,,,,,
0,51412,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(1024, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Executed Instruction,cycle,62.88,,,,,
0,51412,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(1024, 1, 1)",0,7.5,Warp State Statistics,Avg. Active Threads Per Warp,,32,,,,,
0,51412,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(1024, 1, 1)",0,7.5,Warp State Statistics,Avg. Not Predicated Off Threads Per Warp,,32,,,,,
0,51412,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(1024, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,OPT,"On average, each warp of this kernel spends 42.2 cycles being stalled waiting for a scoreboard dependency on a L1TEX (local, global, surface, texture) operation. Find the instruction producing the data being waited upon to identify the culprit. To reduce the number of cycles waiting on L1TEX data accesses verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit rates by increasing data locality (coalescing), or by changing the cache configuration. Consider moving frequently used data to shared memory. This stall type represents about 70.7% of the total average of 59.7 cycles between issuing two instructions.",global,46.64
0,51412,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(1024, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,INF,Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.,,
0,51412,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(1024, 1, 1)",0,7.5,Instruction Statistics,Avg. Executed Instructions Per Scheduler,inst,475.43,,,,,
0,51412,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(1024, 1, 1)",0,7.5,Instruction Statistics,Executed Instructions,inst,"26,624",,,,,
0,51412,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(1024, 1, 1)",0,7.5,Instruction Statistics,Avg. Issued Instructions Per Scheduler,inst,500.68,,,,,
0,51412,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(1024, 1, 1)",0,7.5,Instruction Statistics,Issued Instructions,inst,"28,038",,,,,
0,51412,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(1024, 1, 1)",0,7.5,InstructionStats,,,,FPInstructions,OPT,"This kernel executes 0 fused and 2048 non-fused FP32 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP32 performance could be increased by up to 50% (relative to its current performance). Check the Source page to identify where this kernel executes FP32 instructions.",global,3.437
0,51412,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(1024, 1, 1)",0,7.5,Launch Statistics,Block Size,,64,,,,,
0,51412,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(1024, 1, 1)",0,7.5,Launch Statistics,Function Cache Configuration,,CachePreferNone,,,,,
0,51412,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(1024, 1, 1)",0,7.5,Launch Statistics,Grid Size,,"1,024",,,,,
0,51412,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(1024, 1, 1)",0,7.5,Launch Statistics,Registers Per Thread,register/thread,16,,,,,
0,51412,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(1024, 1, 1)",0,7.5,Launch Statistics,Shared Memory Configuration Size,byte,"32,768",,,,,
0,51412,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(1024, 1, 1)",0,7.5,Launch Statistics,Driver Shared Memory Per Block,byte/block,0,,,,,
0,51412,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(1024, 1, 1)",0,7.5,Launch Statistics,Dynamic Shared Memory Per Block,byte/block,0,,,,,
0,51412,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(1024, 1, 1)",0,7.5,Launch Statistics,Static Shared Memory Per Block,byte/block,0,,,,,
0,51412,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(1024, 1, 1)",0,7.5,Launch Statistics,Threads,thread,"65,536",,,,,
0,51412,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(1024, 1, 1)",0,7.5,Launch Statistics,Waves Per SM,,4.57,,,,,
0,51412,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(1024, 1, 1)",0,7.5,LaunchStats,,,,LaunchConfiguration,OPT,"A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical occupancy of the kernel. This kernel launch results in 4 full waves and a partial wave of 127 thread blocks. Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for up to 20.0% of the total kernel runtime with a lower occupancy of 28.5%. Try launching a grid with no partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for a grid. See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations.",global,20.0
0,51412,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(1024, 1, 1)",0,7.5,Occupancy,Block Limit SM,block,16,,,,,
0,51412,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(1024, 1, 1)",0,7.5,Occupancy,Block Limit Registers,block,64,,,,,
0,51412,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(1024, 1, 1)",0,7.5,Occupancy,Block Limit Shared Mem,block,16,,,,,
0,51412,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(1024, 1, 1)",0,7.5,Occupancy,Block Limit Warps,block,16,,,,,
0,51412,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(1024, 1, 1)",0,7.5,Occupancy,Theoretical Active Warps per SM,warp,32,,,,,
0,51412,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(1024, 1, 1)",0,7.5,Occupancy,Theoretical Occupancy,%,100,,,,,
0,51412,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(1024, 1, 1)",0,7.5,Occupancy,Achieved Occupancy,%,71.48,,,,,
0,51412,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(1024, 1, 1)",0,7.5,Occupancy,Achieved Active Warps Per SM,warp,22.87,,,,,
0,51412,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(1024, 1, 1)",0,7.5,Occupancy,,,,AchievedOccupancy,OPT,The difference between calculated theoretical (100.0%) and measured achieved occupancy (71.5%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy.,global,28.52
0,51412,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(1024, 1, 1)",0,7.5,Source Counters,Branch Instructions Ratio,%,0.08,,,,,
0,51412,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(1024, 1, 1)",0,7.5,Source Counters,Branch Instructions,inst,"2,048",,,,,
0,51412,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(1024, 1, 1)",0,7.5,Source Counters,Branch Efficiency,%,0,,,,,
0,51412,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(1024, 1, 1)",0,7.5,Source Counters,Avg. Divergent Branches,,0,,,,,
0,51489,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(512, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Frequency,cycle/second,"4,529,100,529.10",,,,,
0,51489,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(512, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Frequency,cycle/second,"1,021,329,365.08",,,,,
0,51489,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(512, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Elapsed Cycles,cycle,"6,192",,,,,
0,51489,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(512, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Memory Throughput,%,59.84,,,,,
0,51489,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(512, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Throughput,%,59.84,,,,,
0,51489,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(512, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Duration,nsecond,"6,048",,,,,
0,51489,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(512, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L1/TEX Cache Throughput,%,25.10,,,,,
0,51489,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(512, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L2 Cache Throughput,%,52.35,,,,,
0,51489,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(512, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Active Cycles,cycle,"4,861.86",,,,,
0,51489,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(512, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Compute (SM) Throughput,%,18.94,,,,,
0,51489,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(512, 1, 1)",0,7.5,SpeedOfLight,,,,SOLBottleneck,OPT,This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.,,
0,51489,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(512, 1, 1)",0,7.5,SpeedOfLight_RooflineChart,,,,SOLFPRoofline,INF,The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved  close to 1% of this device's fp32 peak performance and 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.,,
0,51489,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(512, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Active,inst/cycle,0.39,,,,,
0,51489,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(512, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Elapsed,inst/cycle,0.31,,,,,
0,51489,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(512, 1, 1)",0,7.5,Compute Workload Analysis,Issue Slots Busy,%,10.44,,,,,
0,51489,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(512, 1, 1)",0,7.5,Compute Workload Analysis,Issued Ipc Active,inst/cycle,0.42,,,,,
0,51489,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(512, 1, 1)",0,7.5,Compute Workload Analysis,SM Busy,%,10.44,,,,,
0,51489,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(512, 1, 1)",0,7.5,ComputeWorkloadAnalysis,,,,HighPipeUtilization,OPT,All compute pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.,local,92.48
0,51489,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(512, 1, 1)",0,7.5,Memory Workload Analysis,Memory Throughput,byte/second,"86,724,867,724.87",,,,,
0,51489,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(512, 1, 1)",0,7.5,Memory Workload Analysis,Mem Busy,%,52.35,,,,,
0,51489,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(512, 1, 1)",0,7.5,Memory Workload Analysis,Max Bandwidth,%,59.84,,,,,
0,51489,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(512, 1, 1)",0,7.5,Memory Workload Analysis,L1/TEX Hit Rate,%,0,,,,,
0,51489,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(512, 1, 1)",0,7.5,Memory Workload Analysis,L2 Hit Rate,%,33.80,,,,,
0,51489,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(512, 1, 1)",0,7.5,Memory Workload Analysis,Mem Pipes Busy,%,18.94,,,,,
0,51489,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(512, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Chart,,,,MemoryL2Compression,WRN,The optional metric lts__average_gcomp_input_sector_success_rate.pct could not be found. Collecting it as an additional metric could enable the rule to provide more guidance.,,
0,51489,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(512, 1, 1)",0,7.5,Scheduler Statistics,One or More Eligible,%,10.48,,,,,
0,51489,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(512, 1, 1)",0,7.5,Scheduler Statistics,Issued Warp Per Scheduler,,0.10,,,,,
0,51489,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(512, 1, 1)",0,7.5,Scheduler Statistics,No Eligible,%,89.52,,,,,
0,51489,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(512, 1, 1)",0,7.5,Scheduler Statistics,Active Warps Per Scheduler,warp,6.30,,,,,
0,51489,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(512, 1, 1)",0,7.5,Scheduler Statistics,Eligible Warps Per Scheduler,warp,0.13,,,,,
0,51489,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(512, 1, 1)",0,7.5,SchedulerStats,,,,IssueSlotUtilization,OPT,"Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 9.5 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of 6.30 active warps per scheduler, but only an average of 0.13 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections.",local,40.16
0,51489,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(512, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Issued Instruction,cycle,60.15,,,,,
0,51489,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(512, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Executed Instruction,cycle,64.20,,,,,
0,51489,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(512, 1, 1)",0,7.5,Warp State Statistics,Avg. Active Threads Per Warp,,32,,,,,
0,51489,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(512, 1, 1)",0,7.5,Warp State Statistics,Avg. Not Predicated Off Threads Per Warp,,32,,,,,
0,51489,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(512, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,OPT,"On average, each warp of this kernel spends 45.9 cycles being stalled waiting for a scoreboard dependency on a L1TEX (local, global, surface, texture) operation. Find the instruction producing the data being waited upon to identify the culprit. To reduce the number of cycles waiting on L1TEX data accesses verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit rates by increasing data locality (coalescing), or by changing the cache configuration. Consider moving frequently used data to shared memory. This stall type represents about 76.3% of the total average of 60.1 cycles between issuing two instructions.",global,40.16
0,51489,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(512, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,INF,Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.,,
0,51489,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(512, 1, 1)",0,7.5,Instruction Statistics,Avg. Executed Instructions Per Scheduler,inst,475.43,,,,,
0,51489,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(512, 1, 1)",0,7.5,Instruction Statistics,Executed Instructions,inst,"26,624",,,,,
0,51489,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(512, 1, 1)",0,7.5,Instruction Statistics,Avg. Issued Instructions Per Scheduler,inst,507.43,,,,,
0,51489,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(512, 1, 1)",0,7.5,Instruction Statistics,Issued Instructions,inst,"28,416",,,,,
0,51489,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(512, 1, 1)",0,7.5,InstructionStats,,,,FPInstructions,OPT,"This kernel executes 0 fused and 2048 non-fused FP32 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP32 performance could be increased by up to 50% (relative to its current performance). Check the Source page to identify where this kernel executes FP32 instructions.",global,3.761
0,51489,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(512, 1, 1)",0,7.5,Launch Statistics,Block Size,,128,,,,,
0,51489,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(512, 1, 1)",0,7.5,Launch Statistics,Function Cache Configuration,,CachePreferNone,,,,,
0,51489,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(512, 1, 1)",0,7.5,Launch Statistics,Grid Size,,512,,,,,
0,51489,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(512, 1, 1)",0,7.5,Launch Statistics,Registers Per Thread,register/thread,16,,,,,
0,51489,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(512, 1, 1)",0,7.5,Launch Statistics,Shared Memory Configuration Size,byte,"32,768",,,,,
0,51489,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(512, 1, 1)",0,7.5,Launch Statistics,Driver Shared Memory Per Block,byte/block,0,,,,,
0,51489,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(512, 1, 1)",0,7.5,Launch Statistics,Dynamic Shared Memory Per Block,byte/block,0,,,,,
0,51489,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(512, 1, 1)",0,7.5,Launch Statistics,Static Shared Memory Per Block,byte/block,0,,,,,
0,51489,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(512, 1, 1)",0,7.5,Launch Statistics,Threads,thread,"65,536",,,,,
0,51489,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(512, 1, 1)",0,7.5,Launch Statistics,Waves Per SM,,4.57,,,,,
0,51489,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(512, 1, 1)",0,7.5,LaunchStats,,,,LaunchConfiguration,OPT,"A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical occupancy of the kernel. This kernel launch results in 4 full waves and a partial wave of 63 thread blocks. Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for up to 20.0% of the total kernel runtime with a lower occupancy of 20.3%. Try launching a grid with no partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for a grid. See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations.",global,20.0
0,51489,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(512, 1, 1)",0,7.5,Occupancy,Block Limit SM,block,16,,,,,
0,51489,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(512, 1, 1)",0,7.5,Occupancy,Block Limit Registers,block,32,,,,,
0,51489,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(512, 1, 1)",0,7.5,Occupancy,Block Limit Shared Mem,block,16,,,,,
0,51489,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(512, 1, 1)",0,7.5,Occupancy,Block Limit Warps,block,8,,,,,
0,51489,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(512, 1, 1)",0,7.5,Occupancy,Theoretical Active Warps per SM,warp,32,,,,,
0,51489,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(512, 1, 1)",0,7.5,Occupancy,Theoretical Occupancy,%,100,,,,,
0,51489,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(512, 1, 1)",0,7.5,Occupancy,Achieved Occupancy,%,79.67,,,,,
0,51489,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(512, 1, 1)",0,7.5,Occupancy,Achieved Active Warps Per SM,warp,25.49,,,,,
0,51489,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(512, 1, 1)",0,7.5,Occupancy,,,,AchievedOccupancy,OPT,The difference between calculated theoretical (100.0%) and measured achieved occupancy (79.7%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy.,global,20.33
0,51489,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(512, 1, 1)",0,7.5,Source Counters,Branch Instructions Ratio,%,0.08,,,,,
0,51489,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(512, 1, 1)",0,7.5,Source Counters,Branch Instructions,inst,"2,048",,,,,
0,51489,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(512, 1, 1)",0,7.5,Source Counters,Branch Efficiency,%,0,,,,,
0,51489,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(512, 1, 1)",0,7.5,Source Counters,Avg. Divergent Branches,,0,,,,,
0,51575,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(256, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Frequency,cycle/second,"4,843,243,243.24",,,,,
0,51575,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(256, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Frequency,cycle/second,"1,102,195,945.95",,,,,
0,51575,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(256, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Elapsed Cycles,cycle,"6,554",,,,,
0,51575,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(256, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Memory Throughput,%,57.17,,,,,
0,51575,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(256, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Throughput,%,57.17,,,,,
0,51575,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(256, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Duration,nsecond,"5,920",,,,,
0,51575,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(256, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L1/TEX Cache Throughput,%,23.48,,,,,
0,51575,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(256, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L2 Cache Throughput,%,49.48,,,,,
0,51575,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(256, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Active Cycles,cycle,"5,010.79",,,,,
0,51575,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(256, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Compute (SM) Throughput,%,17.92,,,,,
0,51575,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(256, 1, 1)",0,7.5,SpeedOfLight,,,,SOLBottleneck,OPT,This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.,,
0,51575,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(256, 1, 1)",0,7.5,SpeedOfLight_RooflineChart,,,,SOLFPRoofline,INF,The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved  close to 1% of this device's fp32 peak performance and 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.,,
0,51575,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(256, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Active,inst/cycle,0.38,,,,,
0,51575,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(256, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Elapsed,inst/cycle,0.29,,,,,
0,51575,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(256, 1, 1)",0,7.5,Compute Workload Analysis,Issue Slots Busy,%,10.12,,,,,
0,51575,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(256, 1, 1)",0,7.5,Compute Workload Analysis,Issued Ipc Active,inst/cycle,0.40,,,,,
0,51575,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(256, 1, 1)",0,7.5,Compute Workload Analysis,SM Busy,%,10.12,,,,,
0,51575,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(256, 1, 1)",0,7.5,ComputeWorkloadAnalysis,,,,HighPipeUtilization,OPT,All compute pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.,local,92.7
0,51575,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(256, 1, 1)",0,7.5,Memory Workload Analysis,Memory Throughput,byte/second,"88,600,000,000",,,,,
0,51575,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(256, 1, 1)",0,7.5,Memory Workload Analysis,Mem Busy,%,49.48,,,,,
0,51575,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(256, 1, 1)",0,7.5,Memory Workload Analysis,Max Bandwidth,%,57.17,,,,,
0,51575,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(256, 1, 1)",0,7.5,Memory Workload Analysis,L1/TEX Hit Rate,%,0,,,,,
0,51575,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(256, 1, 1)",0,7.5,Memory Workload Analysis,L2 Hit Rate,%,33.92,,,,,
0,51575,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(256, 1, 1)",0,7.5,Memory Workload Analysis,Mem Pipes Busy,%,17.92,,,,,
0,51575,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(256, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Chart,,,,MemoryL2Compression,WRN,The optional metric lts__average_gcomp_input_sector_success_rate.pct could not be found. Collecting it as an additional metric could enable the rule to provide more guidance.,,
0,51575,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(256, 1, 1)",0,7.5,Scheduler Statistics,One or More Eligible,%,10.20,,,,,
0,51575,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(256, 1, 1)",0,7.5,Scheduler Statistics,Issued Warp Per Scheduler,,0.10,,,,,
0,51575,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(256, 1, 1)",0,7.5,Scheduler Statistics,No Eligible,%,89.80,,,,,
0,51575,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(256, 1, 1)",0,7.5,Scheduler Statistics,Active Warps Per Scheduler,warp,6.53,,,,,
0,51575,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(256, 1, 1)",0,7.5,Scheduler Statistics,Eligible Warps Per Scheduler,warp,0.14,,,,,
0,51575,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(256, 1, 1)",0,7.5,SchedulerStats,,,,IssueSlotUtilization,OPT,"Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 9.8 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of 6.53 active warps per scheduler, but only an average of 0.14 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, avoid possible load imbalances due to highly different execution durations per warp. Reducing stalls indicated on the Warp State Statistics and Source Counters sections can help, too.",local,42.83
0,51575,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(256, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Issued Instruction,cycle,63.95,,,,,
0,51575,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(256, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Executed Instruction,cycle,68.19,,,,,
0,51575,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(256, 1, 1)",0,7.5,Warp State Statistics,Avg. Active Threads Per Warp,,32,,,,,
0,51575,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(256, 1, 1)",0,7.5,Warp State Statistics,Avg. Not Predicated Off Threads Per Warp,,32,,,,,
0,51575,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(256, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,OPT,"On average, each warp of this kernel spends 40.9 cycles being stalled waiting for a scoreboard dependency on a L1TEX (local, global, surface, texture) operation. Find the instruction producing the data being waited upon to identify the culprit. To reduce the number of cycles waiting on L1TEX data accesses verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit rates by increasing data locality (coalescing), or by changing the cache configuration. Consider moving frequently used data to shared memory. This stall type represents about 63.9% of the total average of 64.0 cycles between issuing two instructions.",global,42.83
0,51575,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(256, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,INF,Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.,,
0,51575,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(256, 1, 1)",0,7.5,Instruction Statistics,Avg. Executed Instructions Per Scheduler,inst,475.43,,,,,
0,51575,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(256, 1, 1)",0,7.5,Instruction Statistics,Executed Instructions,inst,"26,624",,,,,
0,51575,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(256, 1, 1)",0,7.5,Instruction Statistics,Avg. Issued Instructions Per Scheduler,inst,506.93,,,,,
0,51575,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(256, 1, 1)",0,7.5,Instruction Statistics,Issued Instructions,inst,"28,388",,,,,
0,51575,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(256, 1, 1)",0,7.5,InstructionStats,,,,FPInstructions,OPT,"This kernel executes 0 fused and 2048 non-fused FP32 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP32 performance could be increased by up to 50% (relative to its current performance). Check the Source page to identify where this kernel executes FP32 instructions.",global,3.649
0,51575,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(256, 1, 1)",0,7.5,Launch Statistics,Block Size,,256,,,,,
0,51575,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(256, 1, 1)",0,7.5,Launch Statistics,Function Cache Configuration,,CachePreferNone,,,,,
0,51575,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(256, 1, 1)",0,7.5,Launch Statistics,Grid Size,,256,,,,,
0,51575,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(256, 1, 1)",0,7.5,Launch Statistics,Registers Per Thread,register/thread,16,,,,,
0,51575,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(256, 1, 1)",0,7.5,Launch Statistics,Shared Memory Configuration Size,byte,"32,768",,,,,
0,51575,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(256, 1, 1)",0,7.5,Launch Statistics,Driver Shared Memory Per Block,byte/block,0,,,,,
0,51575,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(256, 1, 1)",0,7.5,Launch Statistics,Dynamic Shared Memory Per Block,byte/block,0,,,,,
0,51575,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(256, 1, 1)",0,7.5,Launch Statistics,Static Shared Memory Per Block,byte/block,0,,,,,
0,51575,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(256, 1, 1)",0,7.5,Launch Statistics,Threads,thread,"65,536",,,,,
0,51575,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(256, 1, 1)",0,7.5,Launch Statistics,Waves Per SM,,4.57,,,,,
0,51575,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(256, 1, 1)",0,7.5,Occupancy,Block Limit SM,block,16,,,,,
0,51575,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(256, 1, 1)",0,7.5,Occupancy,Block Limit Registers,block,16,,,,,
0,51575,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(256, 1, 1)",0,7.5,Occupancy,Block Limit Shared Mem,block,16,,,,,
0,51575,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(256, 1, 1)",0,7.5,Occupancy,Block Limit Warps,block,4,,,,,
0,51575,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(256, 1, 1)",0,7.5,Occupancy,Theoretical Active Warps per SM,warp,32,,,,,
0,51575,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(256, 1, 1)",0,7.5,Occupancy,Theoretical Occupancy,%,100,,,,,
0,51575,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(256, 1, 1)",0,7.5,Occupancy,Achieved Occupancy,%,80.05,,,,,
0,51575,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(256, 1, 1)",0,7.5,Occupancy,Achieved Active Warps Per SM,warp,25.62,,,,,
0,51575,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(256, 1, 1)",0,7.5,Occupancy,,,,AchievedOccupancy,OPT,The difference between calculated theoretical (100.0%) and measured achieved occupancy (80.0%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy.,global,19.95
0,51575,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(256, 1, 1)",0,7.5,Source Counters,Branch Instructions Ratio,%,0.08,,,,,
0,51575,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(256, 1, 1)",0,7.5,Source Counters,Branch Instructions,inst,"2,048",,,,,
0,51575,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(256, 1, 1)",0,7.5,Source Counters,Branch Efficiency,%,0,,,,,
0,51575,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(256, 1, 1)",0,7.5,Source Counters,Avg. Divergent Branches,,0,,,,,
0,51668,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(128, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Frequency,cycle/second,"4,882,051,282.05",,,,,
0,51668,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(128, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Frequency,cycle/second,"1,104,006,410.26",,,,,
0,51668,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(128, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Elapsed Cycles,cycle,"6,924",,,,,
0,51668,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(128, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Memory Throughput,%,53.80,,,,,
0,51668,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(128, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Throughput,%,53.80,,,,,
0,51668,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(128, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Duration,nsecond,"6,240",,,,,
0,51668,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(128, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L1/TEX Cache Throughput,%,22.42,,,,,
0,51668,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(128, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L2 Cache Throughput,%,46.75,,,,,
0,51668,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(128, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Active Cycles,cycle,"5,219.21",,,,,
0,51668,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(128, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Compute (SM) Throughput,%,16.98,,,,,
0,51668,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(128, 1, 1)",0,7.5,SpeedOfLight,,,,SOLBottleneck,OPT,This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.,,
0,51668,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(128, 1, 1)",0,7.5,SpeedOfLight_RooflineChart,,,,SOLFPRoofline,INF,The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved  close to 1% of this device's fp32 peak performance and 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.,,
0,51668,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(128, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Active,inst/cycle,0.36,,,,,
0,51668,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(128, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Elapsed,inst/cycle,0.28,,,,,
0,51668,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(128, 1, 1)",0,7.5,Compute Workload Analysis,Issue Slots Busy,%,9.72,,,,,
0,51668,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(128, 1, 1)",0,7.5,Compute Workload Analysis,Issued Ipc Active,inst/cycle,0.39,,,,,
0,51668,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(128, 1, 1)",0,7.5,Compute Workload Analysis,SM Busy,%,9.72,,,,,
0,51668,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(128, 1, 1)",0,7.5,ComputeWorkloadAnalysis,,,,HighPipeUtilization,OPT,All compute pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.,local,92.99
0,51668,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(128, 1, 1)",0,7.5,Memory Workload Analysis,Memory Throughput,byte/second,"84,046,153,846.15",,,,,
0,51668,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(128, 1, 1)",0,7.5,Memory Workload Analysis,Mem Busy,%,46.75,,,,,
0,51668,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(128, 1, 1)",0,7.5,Memory Workload Analysis,Max Bandwidth,%,53.80,,,,,
0,51668,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(128, 1, 1)",0,7.5,Memory Workload Analysis,L1/TEX Hit Rate,%,0,,,,,
0,51668,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(128, 1, 1)",0,7.5,Memory Workload Analysis,L2 Hit Rate,%,33.80,,,,,
0,51668,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(128, 1, 1)",0,7.5,Memory Workload Analysis,Mem Pipes Busy,%,16.98,,,,,
0,51668,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(128, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Chart,,,,MemoryL2Compression,WRN,The optional metric lts__average_gcomp_input_sector_success_rate.pct could not be found. Collecting it as an additional metric could enable the rule to provide more guidance.,,
0,51668,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(128, 1, 1)",0,7.5,Scheduler Statistics,One or More Eligible,%,9.88,,,,,
0,51668,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(128, 1, 1)",0,7.5,Scheduler Statistics,Issued Warp Per Scheduler,,0.10,,,,,
0,51668,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(128, 1, 1)",0,7.5,Scheduler Statistics,No Eligible,%,90.12,,,,,
0,51668,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(128, 1, 1)",0,7.5,Scheduler Statistics,Active Warps Per Scheduler,warp,6.33,,,,,
0,51668,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(128, 1, 1)",0,7.5,Scheduler Statistics,Eligible Warps Per Scheduler,warp,0.14,,,,,
0,51668,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(128, 1, 1)",0,7.5,SchedulerStats,,,,IssueSlotUtilization,OPT,"Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 10.1 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of 6.33 active warps per scheduler, but only an average of 0.14 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections.",local,46.2
0,51668,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(128, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Issued Instruction,cycle,64.08,,,,,
0,51668,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(128, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Executed Instruction,cycle,68.40,,,,,
0,51668,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(128, 1, 1)",0,7.5,Warp State Statistics,Avg. Active Threads Per Warp,,32,,,,,
0,51668,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(128, 1, 1)",0,7.5,Warp State Statistics,Avg. Not Predicated Off Threads Per Warp,,32,,,,,
0,51668,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(128, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,OPT,"On average, each warp of this kernel spends 46.5 cycles being stalled waiting for a scoreboard dependency on a L1TEX (local, global, surface, texture) operation. Find the instruction producing the data being waited upon to identify the culprit. To reduce the number of cycles waiting on L1TEX data accesses verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit rates by increasing data locality (coalescing), or by changing the cache configuration. Consider moving frequently used data to shared memory. This stall type represents about 72.6% of the total average of 64.1 cycles between issuing two instructions.",global,46.2
0,51668,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(128, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,INF,Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.,,
0,51668,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(128, 1, 1)",0,7.5,Instruction Statistics,Avg. Executed Instructions Per Scheduler,inst,475.43,,,,,
0,51668,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(128, 1, 1)",0,7.5,Instruction Statistics,Executed Instructions,inst,"26,624",,,,,
0,51668,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(128, 1, 1)",0,7.5,Instruction Statistics,Avg. Issued Instructions Per Scheduler,inst,507.43,,,,,
0,51668,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(128, 1, 1)",0,7.5,Instruction Statistics,Issued Instructions,inst,"28,416",,,,,
0,51668,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(128, 1, 1)",0,7.5,InstructionStats,,,,FPInstructions,OPT,"This kernel executes 0 fused and 2048 non-fused FP32 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP32 performance could be increased by up to 50% (relative to its current performance). Check the Source page to identify where this kernel executes FP32 instructions.",global,3.504
0,51668,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(128, 1, 1)",0,7.5,Launch Statistics,Block Size,,512,,,,,
0,51668,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(128, 1, 1)",0,7.5,Launch Statistics,Function Cache Configuration,,CachePreferNone,,,,,
0,51668,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(128, 1, 1)",0,7.5,Launch Statistics,Grid Size,,128,,,,,
0,51668,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(128, 1, 1)",0,7.5,Launch Statistics,Registers Per Thread,register/thread,16,,,,,
0,51668,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(128, 1, 1)",0,7.5,Launch Statistics,Shared Memory Configuration Size,byte,"32,768",,,,,
0,51668,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(128, 1, 1)",0,7.5,Launch Statistics,Driver Shared Memory Per Block,byte/block,0,,,,,
0,51668,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(128, 1, 1)",0,7.5,Launch Statistics,Dynamic Shared Memory Per Block,byte/block,0,,,,,
0,51668,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(128, 1, 1)",0,7.5,Launch Statistics,Static Shared Memory Per Block,byte/block,0,,,,,
0,51668,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(128, 1, 1)",0,7.5,Launch Statistics,Threads,thread,"65,536",,,,,
0,51668,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(128, 1, 1)",0,7.5,Launch Statistics,Waves Per SM,,4.57,,,,,
0,51668,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(128, 1, 1)",0,7.5,Occupancy,Block Limit SM,block,16,,,,,
0,51668,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(128, 1, 1)",0,7.5,Occupancy,Block Limit Registers,block,8,,,,,
0,51668,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(128, 1, 1)",0,7.5,Occupancy,Block Limit Shared Mem,block,16,,,,,
0,51668,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(128, 1, 1)",0,7.5,Occupancy,Block Limit Warps,block,2,,,,,
0,51668,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(128, 1, 1)",0,7.5,Occupancy,Theoretical Active Warps per SM,warp,32,,,,,
0,51668,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(128, 1, 1)",0,7.5,Occupancy,Theoretical Occupancy,%,100,,,,,
0,51668,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(128, 1, 1)",0,7.5,Occupancy,Achieved Occupancy,%,80.40,,,,,
0,51668,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(128, 1, 1)",0,7.5,Occupancy,Achieved Active Warps Per SM,warp,25.73,,,,,
0,51668,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(128, 1, 1)",0,7.5,Occupancy,,,,AchievedOccupancy,OPT,The difference between calculated theoretical (100.0%) and measured achieved occupancy (80.4%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy.,global,19.6
0,51668,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(128, 1, 1)",0,7.5,Source Counters,Branch Instructions Ratio,%,0.08,,,,,
0,51668,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(128, 1, 1)",0,7.5,Source Counters,Branch Instructions,inst,"2,048",,,,,
0,51668,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(128, 1, 1)",0,7.5,Source Counters,Branch Efficiency,%,0,,,,,
0,51668,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(128, 1, 1)",0,7.5,Source Counters,Avg. Divergent Branches,,0,,,,,
0,51745,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(64, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Frequency,cycle/second,"5,137,254,901.96",,,,,
0,51745,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(64, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Frequency,cycle/second,"1,177,159,926.47",,,,,
0,51745,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(64, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Elapsed Cycles,cycle,"7,716",,,,,
0,51745,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(64, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Memory Throughput,%,48.88,,,,,
0,51745,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(64, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Throughput,%,48.88,,,,,
0,51745,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(64, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Duration,nsecond,"6,528",,,,,
0,51745,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(64, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L1/TEX Cache Throughput,%,21.93,,,,,
0,51745,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(64, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L2 Cache Throughput,%,42.03,,,,,
0,51745,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(64, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Active Cycles,cycle,"5,336",,,,,
0,51745,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(64, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Compute (SM) Throughput,%,15.22,,,,,
0,51745,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(64, 1, 1)",0,7.5,SpeedOfLight,,,,SOLBottleneck,OPT,This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.,,
0,51745,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(64, 1, 1)",0,7.5,SpeedOfLight_RooflineChart,,,,SOLFPRoofline,INF,The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved  close to 0% of this device's fp32 peak performance and 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.,,
0,51745,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(64, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Active,inst/cycle,0.36,,,,,
0,51745,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(64, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Elapsed,inst/cycle,0.25,,,,,
0,51745,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(64, 1, 1)",0,7.5,Compute Workload Analysis,Issue Slots Busy,%,9.51,,,,,
0,51745,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(64, 1, 1)",0,7.5,Compute Workload Analysis,Issued Ipc Active,inst/cycle,0.38,,,,,
0,51745,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(64, 1, 1)",0,7.5,Compute Workload Analysis,SM Busy,%,9.51,,,,,
0,51745,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(64, 1, 1)",0,7.5,ComputeWorkloadAnalysis,,,,HighPipeUtilization,OPT,All compute pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.,local,93.15
0,51745,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(64, 1, 1)",0,7.5,Memory Workload Analysis,Memory Throughput,byte/second,"80,348,039,215.69",,,,,
0,51745,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(64, 1, 1)",0,7.5,Memory Workload Analysis,Mem Busy,%,42.03,,,,,
0,51745,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(64, 1, 1)",0,7.5,Memory Workload Analysis,Max Bandwidth,%,48.88,,,,,
0,51745,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(64, 1, 1)",0,7.5,Memory Workload Analysis,L1/TEX Hit Rate,%,0,,,,,
0,51745,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(64, 1, 1)",0,7.5,Memory Workload Analysis,L2 Hit Rate,%,33.78,,,,,
0,51745,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(64, 1, 1)",0,7.5,Memory Workload Analysis,Mem Pipes Busy,%,15.22,,,,,
0,51745,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(64, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Chart,,,,MemoryL2Compression,WRN,The optional metric lts__average_gcomp_input_sector_success_rate.pct could not be found. Collecting it as an additional metric could enable the rule to provide more guidance.,,
0,51745,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(64, 1, 1)",0,7.5,Scheduler Statistics,One or More Eligible,%,9.89,,,,,
0,51745,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(64, 1, 1)",0,7.5,Scheduler Statistics,Issued Warp Per Scheduler,,0.10,,,,,
0,51745,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(64, 1, 1)",0,7.5,Scheduler Statistics,No Eligible,%,90.11,,,,,
0,51745,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(64, 1, 1)",0,7.5,Scheduler Statistics,Active Warps Per Scheduler,warp,7.32,,,,,
0,51745,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(64, 1, 1)",0,7.5,Scheduler Statistics,Eligible Warps Per Scheduler,warp,0.22,,,,,
0,51745,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(64, 1, 1)",0,7.5,SchedulerStats,,,,IssueSlotUtilization,OPT,"Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 10.1 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of 7.32 active warps per scheduler, but only an average of 0.22 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, avoid possible load imbalances due to highly different execution durations per warp. Reducing stalls indicated on the Warp State Statistics and Source Counters sections can help, too.",local,51.12
0,51745,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(64, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Issued Instruction,cycle,74.07,,,,,
0,51745,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(64, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Executed Instruction,cycle,79.06,,,,,
0,51745,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(64, 1, 1)",0,7.5,Warp State Statistics,Avg. Active Threads Per Warp,,32,,,,,
0,51745,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(64, 1, 1)",0,7.5,Warp State Statistics,Avg. Not Predicated Off Threads Per Warp,,32,,,,,
0,51745,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(64, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,OPT,"On average, each warp of this kernel spends 49.2 cycles being stalled waiting for a scoreboard dependency on a L1TEX (local, global, surface, texture) operation. Find the instruction producing the data being waited upon to identify the culprit. To reduce the number of cycles waiting on L1TEX data accesses verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit rates by increasing data locality (coalescing), or by changing the cache configuration. Consider moving frequently used data to shared memory. This stall type represents about 66.4% of the total average of 74.1 cycles between issuing two instructions.",global,51.12
0,51745,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(64, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,INF,Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.,,
0,51745,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(64, 1, 1)",0,7.5,Instruction Statistics,Avg. Executed Instructions Per Scheduler,inst,475.43,,,,,
0,51745,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(64, 1, 1)",0,7.5,Instruction Statistics,Executed Instructions,inst,"26,624",,,,,
0,51745,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(64, 1, 1)",0,7.5,Instruction Statistics,Avg. Issued Instructions Per Scheduler,inst,507.43,,,,,
0,51745,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(64, 1, 1)",0,7.5,Instruction Statistics,Issued Instructions,inst,"28,416",,,,,
0,51745,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(64, 1, 1)",0,7.5,InstructionStats,,,,FPInstructions,OPT,"This kernel executes 0 fused and 2048 non-fused FP32 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP32 performance could be increased by up to 50% (relative to its current performance). Check the Source page to identify where this kernel executes FP32 instructions.",global,3.427
0,51745,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(64, 1, 1)",0,7.5,Launch Statistics,Block Size,,"1,024",,,,,
0,51745,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(64, 1, 1)",0,7.5,Launch Statistics,Function Cache Configuration,,CachePreferNone,,,,,
0,51745,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(64, 1, 1)",0,7.5,Launch Statistics,Grid Size,,64,,,,,
0,51745,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(64, 1, 1)",0,7.5,Launch Statistics,Registers Per Thread,register/thread,16,,,,,
0,51745,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(64, 1, 1)",0,7.5,Launch Statistics,Shared Memory Configuration Size,byte,"32,768",,,,,
0,51745,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(64, 1, 1)",0,7.5,Launch Statistics,Driver Shared Memory Per Block,byte/block,0,,,,,
0,51745,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(64, 1, 1)",0,7.5,Launch Statistics,Dynamic Shared Memory Per Block,byte/block,0,,,,,
0,51745,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(64, 1, 1)",0,7.5,Launch Statistics,Static Shared Memory Per Block,byte/block,0,,,,,
0,51745,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(64, 1, 1)",0,7.5,Launch Statistics,Threads,thread,"65,536",,,,,
0,51745,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(64, 1, 1)",0,7.5,Launch Statistics,Waves Per SM,,4.57,,,,,
0,51745,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(64, 1, 1)",0,7.5,Occupancy,Block Limit SM,block,16,,,,,
0,51745,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(64, 1, 1)",0,7.5,Occupancy,Block Limit Registers,block,4,,,,,
0,51745,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(64, 1, 1)",0,7.5,Occupancy,Block Limit Shared Mem,block,16,,,,,
0,51745,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(64, 1, 1)",0,7.5,Occupancy,Block Limit Warps,block,1,,,,,
0,51745,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(64, 1, 1)",0,7.5,Occupancy,Theoretical Active Warps per SM,warp,32,,,,,
0,51745,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(64, 1, 1)",0,7.5,Occupancy,Theoretical Occupancy,%,100,,,,,
0,51745,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(64, 1, 1)",0,7.5,Occupancy,Achieved Occupancy,%,86.75,,,,,
0,51745,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(64, 1, 1)",0,7.5,Occupancy,Achieved Active Warps Per SM,warp,27.76,,,,,
0,51745,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(64, 1, 1)",0,7.5,Occupancy,,,,AchievedOccupancy,OPT,The difference between calculated theoretical (100.0%) and measured achieved occupancy (86.7%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy.,global,13.25
0,51745,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(64, 1, 1)",0,7.5,Source Counters,Branch Instructions Ratio,%,0.08,,,,,
0,51745,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(64, 1, 1)",0,7.5,Source Counters,Branch Instructions,inst,"2,048",,,,,
0,51745,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(64, 1, 1)",0,7.5,Source Counters,Branch Efficiency,%,0,,,,,
0,51745,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(64, 1, 1)",0,7.5,Source Counters,Avg. Divergent Branches,,0,,,,,
0,51837,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(131072, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Frequency,cycle/second,"6,060,322,412.90",,,,,
0,51837,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(131072, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Frequency,cycle/second,"1,393,522,694.03",,,,,
0,51837,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(131072, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Elapsed Cycles,cycle,"686,765",,,,,
0,51837,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(131072, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Memory Throughput,%,10.92,,,,,
0,51837,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(131072, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Throughput,%,1.35,,,,,
0,51837,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(131072, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Duration,nsecond,"492,288",,,,,
0,51837,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(131072, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L1/TEX Cache Throughput,%,15.39,,,,,
0,51837,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(131072, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L2 Cache Throughput,%,8.43,,,,,
0,51837,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(131072, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Active Cycles,cycle,"486,567.14",,,,,
0,51837,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(131072, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Compute (SM) Throughput,%,10.92,,,,,
0,51837,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(131072, 1, 1)",0,7.5,SpeedOfLight,,,,SOLBottleneck,OPT,This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.,,
0,51837,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(131072, 1, 1)",0,7.5,SpeedOfLight_RooflineChart,,,,SOLFPRoofline,INF,The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved  close to 0% of this device's fp32 peak performance and 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.,,
0,51837,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(131072, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Active,inst/cycle,0.25,,,,,
0,51837,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(131072, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Elapsed,inst/cycle,0.18,,,,,
0,51837,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(131072, 1, 1)",0,7.5,Compute Workload Analysis,Issue Slots Busy,%,6.26,,,,,
0,51837,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(131072, 1, 1)",0,7.5,Compute Workload Analysis,Issued Ipc Active,inst/cycle,0.25,,,,,
0,51837,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(131072, 1, 1)",0,7.5,Compute Workload Analysis,SM Busy,%,6.41,,,,,
0,51837,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(131072, 1, 1)",0,7.5,ComputeWorkloadAnalysis,,,,HighPipeUtilization,OPT,All compute pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.,local,95.19
0,51837,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(131072, 1, 1)",0,7.5,Memory Workload Analysis,Memory Throughput,byte/second,"2,614,794,591.78",,,,,
0,51837,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(131072, 1, 1)",0,7.5,Memory Workload Analysis,Mem Busy,%,7.02,,,,,
0,51837,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(131072, 1, 1)",0,7.5,Memory Workload Analysis,Max Bandwidth,%,10.92,,,,,
0,51837,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(131072, 1, 1)",0,7.5,Memory Workload Analysis,L1/TEX Hit Rate,%,23.67,,,,,
0,51837,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(131072, 1, 1)",0,7.5,Memory Workload Analysis,L2 Hit Rate,%,95.41,,,,,
0,51837,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(131072, 1, 1)",0,7.5,Memory Workload Analysis,Mem Pipes Busy,%,10.92,,,,,
0,51837,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(131072, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Chart,,,,MemoryL2Compression,WRN,The optional metric lts__average_gcomp_input_sector_success_rate.pct could not be found. Collecting it as an additional metric could enable the rule to provide more guidance.,,
0,51837,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(131072, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for loads from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced loads and try to minimize how many cache lines need to be accessed per memory request.",global,3.491
0,51837,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(131072, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for stores from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.5 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced stores and try to minimize how many cache lines need to be accessed per memory request.",global,1.455
0,51837,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(131072, 1, 1)",0,7.5,Scheduler Statistics,One or More Eligible,%,7.02,,,,,
0,51837,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(131072, 1, 1)",0,7.5,Scheduler Statistics,Issued Warp Per Scheduler,,0.07,,,,,
0,51837,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(131072, 1, 1)",0,7.5,Scheduler Statistics,No Eligible,%,92.98,,,,,
0,51837,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(131072, 1, 1)",0,7.5,Scheduler Statistics,Active Warps Per Scheduler,warp,2.78,,,,,
0,51837,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(131072, 1, 1)",0,7.5,Scheduler Statistics,Eligible Warps Per Scheduler,warp,0.07,,,,,
0,51837,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(131072, 1, 1)",0,7.5,SchedulerStats,,,,IssueSlotUtilization,OPT,"Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 14.2 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of 2.78 active warps per scheduler, but only an average of 0.07 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections.",local,89.08
0,51837,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(131072, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Issued Instruction,cycle,39.58,,,,,
0,51837,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(131072, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Executed Instruction,cycle,39.60,,,,,
0,51837,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(131072, 1, 1)",0,7.5,Warp State Statistics,Avg. Active Threads Per Warp,,1,,,,,
0,51837,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(131072, 1, 1)",0,7.5,Warp State Statistics,Avg. Not Predicated Off Threads Per Warp,,1,,,,,
0,51837,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(131072, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,OPT,"On average, each warp of this kernel spends 31.7 cycles being stalled waiting for a scoreboard dependency on a L1TEX (local, global, surface, texture) operation. Find the instruction producing the data being waited upon to identify the culprit. To reduce the number of cycles waiting on L1TEX data accesses verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit rates by increasing data locality (coalescing), or by changing the cache configuration. Consider moving frequently used data to shared memory. This stall type represents about 80.0% of the total average of 39.6 cycles between issuing two instructions.",global,79.97
0,51837,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(131072, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,INF,Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.,,
0,51837,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(131072, 1, 1)",0,7.5,WarpStateStats,,,,ThreadDivergence,OPT,"Instructions are executed in warps, which are groups of 32 threads. Optimal instruction throughput is achieved if all 32 threads of a warp execute the same instruction. The chosen launch configuration, early thread completion, and divergent flow control can significantly lower the number of active threads in a warp per cycle. This kernel achieves an average of 1.0 threads being active per cycle.",global,10.58
0,51837,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(131072, 1, 1)",0,7.5,Instruction Statistics,Avg. Executed Instructions Per Scheduler,inst,"30,427.43",,,,,
0,51837,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(131072, 1, 1)",0,7.5,Instruction Statistics,Executed Instructions,inst,"1,703,936",,,,,
0,51837,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(131072, 1, 1)",0,7.5,Instruction Statistics,Avg. Issued Instructions Per Scheduler,inst,"30,441.07",,,,,
0,51837,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(131072, 1, 1)",0,7.5,Instruction Statistics,Issued Instructions,inst,"1,704,700",,,,,
0,51837,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(131072, 1, 1)",0,7.5,InstructionStats,,,,FPInstructions,OPT,"This kernel executes 0 fused and 131072 non-fused FP32 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP32 performance could be increased by up to 50% (relative to its current performance). Check the Source page to identify where this kernel executes FP32 instructions.",global,2.405
0,51837,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(131072, 1, 1)",0,7.5,Launch Statistics,Block Size,,1,,,,,
0,51837,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(131072, 1, 1)",0,7.5,Launch Statistics,Function Cache Configuration,,CachePreferNone,,,,,
0,51837,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(131072, 1, 1)",0,7.5,Launch Statistics,Grid Size,,"131,072",,,,,
0,51837,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(131072, 1, 1)",0,7.5,Launch Statistics,Registers Per Thread,register/thread,16,,,,,
0,51837,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(131072, 1, 1)",0,7.5,Launch Statistics,Shared Memory Configuration Size,byte,"32,768",,,,,
0,51837,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(131072, 1, 1)",0,7.5,Launch Statistics,Driver Shared Memory Per Block,byte/block,0,,,,,
0,51837,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(131072, 1, 1)",0,7.5,Launch Statistics,Dynamic Shared Memory Per Block,byte/block,0,,,,,
0,51837,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(131072, 1, 1)",0,7.5,Launch Statistics,Static Shared Memory Per Block,byte/block,0,,,,,
0,51837,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(131072, 1, 1)",0,7.5,Launch Statistics,Threads,thread,"131,072",,,,,
0,51837,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(131072, 1, 1)",0,7.5,Launch Statistics,Waves Per SM,,585.14,,,,,
0,51837,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(131072, 1, 1)",0,7.5,LaunchStats,,,,LaunchConfiguration,OPT,"Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 1 threads per block. Consequently, some threads in a warp are masked off and those hardware resources are unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256 threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to kernels that frequently call __syncthreads(). See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations.",global,96.88
0,51837,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(131072, 1, 1)",0,7.5,Occupancy,Block Limit SM,block,16,,,,,
0,51837,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(131072, 1, 1)",0,7.5,Occupancy,Block Limit Registers,block,128,,,,,
0,51837,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(131072, 1, 1)",0,7.5,Occupancy,Block Limit Shared Mem,block,16,,,,,
0,51837,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(131072, 1, 1)",0,7.5,Occupancy,Block Limit Warps,block,32,,,,,
0,51837,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(131072, 1, 1)",0,7.5,Occupancy,Theoretical Active Warps per SM,warp,16,,,,,
0,51837,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(131072, 1, 1)",0,7.5,Occupancy,Theoretical Occupancy,%,50,,,,,
0,51837,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(131072, 1, 1)",0,7.5,Occupancy,Achieved Occupancy,%,32.04,,,,,
0,51837,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(131072, 1, 1)",0,7.5,Occupancy,Achieved Active Warps Per SM,warp,10.25,,,,,
0,51837,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(131072, 1, 1)",0,7.5,Occupancy,,,,AchievedOccupancy,OPT,The difference between calculated theoretical (50.0%) and measured achieved occupancy (32.0%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy.,global,35.93
0,51837,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(131072, 1, 1)",0,7.5,Occupancy,,,,TheoreticalOccupancy,OPT,The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared memory.,global,50.0
0,51837,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(131072, 1, 1)",0,7.5,Source Counters,Branch Instructions Ratio,%,0.08,,,,,
0,51837,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(131072, 1, 1)",0,7.5,Source Counters,Branch Instructions,inst,"131,072",,,,,
0,51837,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(131072, 1, 1)",0,7.5,Source Counters,Branch Efficiency,%,0,,,,,
0,51837,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(131072, 1, 1)",0,7.5,Source Counters,Avg. Divergent Branches,,0,,,,,
0,51923,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(65536, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Frequency,cycle/second,"6,128,691,983.12",,,,,
0,51923,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(65536, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Frequency,cycle/second,"1,409,152,904.14",,,,,
0,51923,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(65536, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Elapsed Cycles,cycle,"342,769",,,,,
0,51923,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(65536, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Memory Throughput,%,10.95,,,,,
0,51923,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(65536, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Throughput,%,2.69,,,,,
0,51923,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(65536, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Duration,nsecond,"242,688",,,,,
0,51923,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(65536, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L1/TEX Cache Throughput,%,16.16,,,,,
0,51923,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(65536, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L2 Cache Throughput,%,9.33,,,,,
0,51923,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(65536, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Active Cycles,cycle,"231,759.21",,,,,
0,51923,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(65536, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Compute (SM) Throughput,%,10.95,,,,,
0,51923,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(65536, 1, 1)",0,7.5,SpeedOfLight,,,,SOLBottleneck,OPT,This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.,,
0,51923,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(65536, 1, 1)",0,7.5,SpeedOfLight_RooflineChart,,,,SOLFPRoofline,INF,The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved  close to 0% of this device's fp32 peak performance and 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.,,
0,51923,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(65536, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Active,inst/cycle,0.26,,,,,
0,51923,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(65536, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Elapsed,inst/cycle,0.18,,,,,
0,51923,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(65536, 1, 1)",0,7.5,Compute Workload Analysis,Issue Slots Busy,%,6.57,,,,,
0,51923,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(65536, 1, 1)",0,7.5,Compute Workload Analysis,Issued Ipc Active,inst/cycle,0.26,,,,,
0,51923,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(65536, 1, 1)",0,7.5,Compute Workload Analysis,SM Busy,%,6.73,,,,,
0,51923,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(65536, 1, 1)",0,7.5,ComputeWorkloadAnalysis,,,,HighPipeUtilization,OPT,All compute pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.,local,94.95
0,51923,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(65536, 1, 1)",0,7.5,Memory Workload Analysis,Memory Throughput,byte/second,"5,282,832,278.48",,,,,
0,51923,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(65536, 1, 1)",0,7.5,Memory Workload Analysis,Mem Busy,%,7.45,,,,,
0,51923,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(65536, 1, 1)",0,7.5,Memory Workload Analysis,Max Bandwidth,%,10.95,,,,,
0,51923,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(65536, 1, 1)",0,7.5,Memory Workload Analysis,L1/TEX Hit Rate,%,9.57,,,,,
0,51923,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(65536, 1, 1)",0,7.5,Memory Workload Analysis,L2 Hit Rate,%,91.96,,,,,
0,51923,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(65536, 1, 1)",0,7.5,Memory Workload Analysis,Mem Pipes Busy,%,10.95,,,,,
0,51923,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(65536, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Chart,,,,MemoryL2Compression,WRN,The optional metric lts__average_gcomp_input_sector_success_rate.pct could not be found. Collecting it as an additional metric could enable the rule to provide more guidance.,,
0,51923,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(65536, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for loads from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced loads and try to minimize how many cache lines need to be accessed per memory request.",global,3.704
0,51923,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(65536, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for stores from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.3 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced stores and try to minimize how many cache lines need to be accessed per memory request.",global,1.698
0,51923,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(65536, 1, 1)",0,7.5,Scheduler Statistics,One or More Eligible,%,7.36,,,,,
0,51923,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(65536, 1, 1)",0,7.5,Scheduler Statistics,Issued Warp Per Scheduler,,0.07,,,,,
0,51923,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(65536, 1, 1)",0,7.5,Scheduler Statistics,No Eligible,%,92.64,,,,,
0,51923,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(65536, 1, 1)",0,7.5,Scheduler Statistics,Active Warps Per Scheduler,warp,2.78,,,,,
0,51923,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(65536, 1, 1)",0,7.5,Scheduler Statistics,Eligible Warps Per Scheduler,warp,0.07,,,,,
0,51923,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(65536, 1, 1)",0,7.5,SchedulerStats,,,,IssueSlotUtilization,OPT,"Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 13.6 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of 2.78 active warps per scheduler, but only an average of 0.07 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections.",local,89.05
0,51923,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(65536, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Issued Instruction,cycle,37.82,,,,,
0,51923,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(65536, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Executed Instruction,cycle,37.86,,,,,
0,51923,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(65536, 1, 1)",0,7.5,Warp State Statistics,Avg. Active Threads Per Warp,,2,,,,,
0,51923,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(65536, 1, 1)",0,7.5,Warp State Statistics,Avg. Not Predicated Off Threads Per Warp,,2,,,,,
0,51923,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(65536, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,OPT,"On average, each warp of this kernel spends 29.9 cycles being stalled waiting for a scoreboard dependency on a L1TEX (local, global, surface, texture) operation. Find the instruction producing the data being waited upon to identify the culprit. To reduce the number of cycles waiting on L1TEX data accesses verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit rates by increasing data locality (coalescing), or by changing the cache configuration. Consider moving frequently used data to shared memory. This stall type represents about 79.0% of the total average of 37.8 cycles between issuing two instructions.",global,78.95
0,51923,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(65536, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,INF,Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.,,
0,51923,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(65536, 1, 1)",0,7.5,WarpStateStats,,,,ThreadDivergence,OPT,"Instructions are executed in warps, which are groups of 32 threads. Optimal instruction throughput is achieved if all 32 threads of a warp execute the same instruction. The chosen launch configuration, early thread completion, and divergent flow control can significantly lower the number of active threads in a warp per cycle. This kernel achieves an average of 2.0 threads being active per cycle.",global,10.26
0,51923,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(65536, 1, 1)",0,7.5,Instruction Statistics,Avg. Executed Instructions Per Scheduler,inst,"15,213.71",,,,,
0,51923,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(65536, 1, 1)",0,7.5,Instruction Statistics,Executed Instructions,inst,"851,968",,,,,
0,51923,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(65536, 1, 1)",0,7.5,Instruction Statistics,Avg. Issued Instructions Per Scheduler,inst,"15,227.36",,,,,
0,51923,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(65536, 1, 1)",0,7.5,Instruction Statistics,Issued Instructions,inst,"852,732",,,,,
0,51923,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(65536, 1, 1)",0,7.5,InstructionStats,,,,FPInstructions,OPT,"This kernel executes 0 fused and 65536 non-fused FP32 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP32 performance could be increased by up to 50% (relative to its current performance). Check the Source page to identify where this kernel executes FP32 instructions.",global,2.525
0,51923,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(65536, 1, 1)",0,7.5,Launch Statistics,Block Size,,2,,,,,
0,51923,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(65536, 1, 1)",0,7.5,Launch Statistics,Function Cache Configuration,,CachePreferNone,,,,,
0,51923,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(65536, 1, 1)",0,7.5,Launch Statistics,Grid Size,,"65,536",,,,,
0,51923,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(65536, 1, 1)",0,7.5,Launch Statistics,Registers Per Thread,register/thread,16,,,,,
0,51923,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(65536, 1, 1)",0,7.5,Launch Statistics,Shared Memory Configuration Size,byte,"32,768",,,,,
0,51923,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(65536, 1, 1)",0,7.5,Launch Statistics,Driver Shared Memory Per Block,byte/block,0,,,,,
0,51923,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(65536, 1, 1)",0,7.5,Launch Statistics,Dynamic Shared Memory Per Block,byte/block,0,,,,,
0,51923,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(65536, 1, 1)",0,7.5,Launch Statistics,Static Shared Memory Per Block,byte/block,0,,,,,
0,51923,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(65536, 1, 1)",0,7.5,Launch Statistics,Threads,thread,"131,072",,,,,
0,51923,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(65536, 1, 1)",0,7.5,Launch Statistics,Waves Per SM,,292.57,,,,,
0,51923,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(65536, 1, 1)",0,7.5,LaunchStats,,,,LaunchConfiguration,OPT,"Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 2 threads per block. Consequently, some threads in a warp are masked off and those hardware resources are unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256 threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to kernels that frequently call __syncthreads(). See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations.",global,93.75
0,51923,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(65536, 1, 1)",0,7.5,Occupancy,Block Limit SM,block,16,,,,,
0,51923,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(65536, 1, 1)",0,7.5,Occupancy,Block Limit Registers,block,128,,,,,
0,51923,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(65536, 1, 1)",0,7.5,Occupancy,Block Limit Shared Mem,block,16,,,,,
0,51923,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(65536, 1, 1)",0,7.5,Occupancy,Block Limit Warps,block,32,,,,,
0,51923,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(65536, 1, 1)",0,7.5,Occupancy,Theoretical Active Warps per SM,warp,16,,,,,
0,51923,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(65536, 1, 1)",0,7.5,Occupancy,Theoretical Occupancy,%,50,,,,,
0,51923,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(65536, 1, 1)",0,7.5,Occupancy,Achieved Occupancy,%,32.37,,,,,
0,51923,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(65536, 1, 1)",0,7.5,Occupancy,Achieved Active Warps Per SM,warp,10.36,,,,,
0,51923,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(65536, 1, 1)",0,7.5,Occupancy,,,,AchievedOccupancy,OPT,The difference between calculated theoretical (50.0%) and measured achieved occupancy (32.4%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy.,global,35.25
0,51923,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(65536, 1, 1)",0,7.5,Occupancy,,,,TheoreticalOccupancy,OPT,The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared memory.,global,50.0
0,51923,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(65536, 1, 1)",0,7.5,Source Counters,Branch Instructions Ratio,%,0.08,,,,,
0,51923,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(65536, 1, 1)",0,7.5,Source Counters,Branch Instructions,inst,"65,536",,,,,
0,51923,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(65536, 1, 1)",0,7.5,Source Counters,Branch Efficiency,%,0,,,,,
0,51923,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(65536, 1, 1)",0,7.5,Source Counters,Avg. Divergent Branches,,0,,,,,
0,52009,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(32768, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Frequency,cycle/second,"6,011,428,571.43",,,,,
0,52009,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(32768, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Frequency,cycle/second,"1,382,045,454.55",,,,,
0,52009,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(32768, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Elapsed Cycles,cycle,"170,457",,,,,
0,52009,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(32768, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Memory Throughput,%,11.00,,,,,
0,52009,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(32768, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Throughput,%,5.40,,,,,
0,52009,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(32768, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Duration,nsecond,"123,200",,,,,
0,52009,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(32768, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L1/TEX Cache Throughput,%,16.56,,,,,
0,52009,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(32768, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L2 Cache Throughput,%,9.82,,,,,
0,52009,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(32768, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Active Cycles,cycle,"113,062.86",,,,,
0,52009,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(32768, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Compute (SM) Throughput,%,11.00,,,,,
0,52009,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(32768, 1, 1)",0,7.5,SpeedOfLight,,,,SOLBottleneck,OPT,This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.,,
0,52009,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(32768, 1, 1)",0,7.5,SpeedOfLight_RooflineChart,,,,SOLFPRoofline,INF,The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved  close to 0% of this device's fp32 peak performance and 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.,,
0,52009,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(32768, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Active,inst/cycle,0.27,,,,,
0,52009,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(32768, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Elapsed,inst/cycle,0.18,,,,,
0,52009,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(32768, 1, 1)",0,7.5,Compute Workload Analysis,Issue Slots Busy,%,6.74,,,,,
0,52009,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(32768, 1, 1)",0,7.5,Compute Workload Analysis,Issued Ipc Active,inst/cycle,0.27,,,,,
0,52009,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(32768, 1, 1)",0,7.5,Compute Workload Analysis,SM Busy,%,6.90,,,,,
0,52009,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(32768, 1, 1)",0,7.5,ComputeWorkloadAnalysis,,,,HighPipeUtilization,OPT,All compute pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.,local,94.82
0,52009,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(32768, 1, 1)",0,7.5,Memory Workload Analysis,Memory Throughput,byte/second,"10,385,974,025.97",,,,,
0,52009,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(32768, 1, 1)",0,7.5,Memory Workload Analysis,Mem Busy,%,7.53,,,,,
0,52009,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(32768, 1, 1)",0,7.5,Memory Workload Analysis,Max Bandwidth,%,11.00,,,,,
0,52009,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(32768, 1, 1)",0,7.5,Memory Workload Analysis,L1/TEX Hit Rate,%,2.79,,,,,
0,52009,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(32768, 1, 1)",0,7.5,Memory Workload Analysis,L2 Hit Rate,%,83.54,,,,,
0,52009,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(32768, 1, 1)",0,7.5,Memory Workload Analysis,Mem Pipes Busy,%,11.00,,,,,
0,52009,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(32768, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Chart,,,,MemoryL2Compression,WRN,The optional metric lts__average_gcomp_input_sector_success_rate.pct could not be found. Collecting it as an additional metric could enable the rule to provide more guidance.,,
0,52009,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(32768, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for loads from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced loads and try to minimize how many cache lines need to be accessed per memory request.",global,3.748
0,52009,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(32768, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for stores from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.1 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced stores and try to minimize how many cache lines need to be accessed per memory request.",global,1.836
0,52009,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(32768, 1, 1)",0,7.5,Scheduler Statistics,One or More Eligible,%,7.48,,,,,
0,52009,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(32768, 1, 1)",0,7.5,Scheduler Statistics,Issued Warp Per Scheduler,,0.07,,,,,
0,52009,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(32768, 1, 1)",0,7.5,Scheduler Statistics,No Eligible,%,92.52,,,,,
0,52009,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(32768, 1, 1)",0,7.5,Scheduler Statistics,Active Warps Per Scheduler,warp,2.81,,,,,
0,52009,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(32768, 1, 1)",0,7.5,Scheduler Statistics,Eligible Warps Per Scheduler,warp,0.08,,,,,
0,52009,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(32768, 1, 1)",0,7.5,SchedulerStats,,,,IssueSlotUtilization,OPT,"Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 13.4 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of 2.81 active warps per scheduler, but only an average of 0.08 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections.",local,89.0
0,52009,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(32768, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Issued Instruction,cycle,37.53,,,,,
0,52009,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(32768, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Executed Instruction,cycle,37.59,,,,,
0,52009,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(32768, 1, 1)",0,7.5,Warp State Statistics,Avg. Active Threads Per Warp,,4,,,,,
0,52009,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(32768, 1, 1)",0,7.5,Warp State Statistics,Avg. Not Predicated Off Threads Per Warp,,4,,,,,
0,52009,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(32768, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,OPT,"On average, each warp of this kernel spends 29.2 cycles being stalled waiting for a scoreboard dependency on a L1TEX (local, global, surface, texture) operation. Find the instruction producing the data being waited upon to identify the culprit. To reduce the number of cycles waiting on L1TEX data accesses verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit rates by increasing data locality (coalescing), or by changing the cache configuration. Consider moving frequently used data to shared memory. This stall type represents about 77.8% of the total average of 37.5 cycles between issuing two instructions.",global,77.79
0,52009,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(32768, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,INF,Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.,,
0,52009,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(32768, 1, 1)",0,7.5,WarpStateStats,,,,ThreadDivergence,OPT,"Instructions are executed in warps, which are groups of 32 threads. Optimal instruction throughput is achieved if all 32 threads of a warp execute the same instruction. The chosen launch configuration, early thread completion, and divergent flow control can significantly lower the number of active threads in a warp per cycle. This kernel achieves an average of 4.0 threads being active per cycle.",global,9.621
0,52009,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(32768, 1, 1)",0,7.5,Instruction Statistics,Avg. Executed Instructions Per Scheduler,inst,"7,606.86",,,,,
0,52009,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(32768, 1, 1)",0,7.5,Instruction Statistics,Executed Instructions,inst,"425,984",,,,,
0,52009,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(32768, 1, 1)",0,7.5,Instruction Statistics,Avg. Issued Instructions Per Scheduler,inst,"7,620.50",,,,,
0,52009,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(32768, 1, 1)",0,7.5,Instruction Statistics,Issued Instructions,inst,"426,748",,,,,
0,52009,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(32768, 1, 1)",0,7.5,InstructionStats,,,,FPInstructions,OPT,"This kernel executes 0 fused and 32768 non-fused FP32 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP32 performance could be increased by up to 50% (relative to its current performance). Check the Source page to identify where this kernel executes FP32 instructions.",global,2.588
0,52009,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(32768, 1, 1)",0,7.5,Launch Statistics,Block Size,,4,,,,,
0,52009,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(32768, 1, 1)",0,7.5,Launch Statistics,Function Cache Configuration,,CachePreferNone,,,,,
0,52009,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(32768, 1, 1)",0,7.5,Launch Statistics,Grid Size,,"32,768",,,,,
0,52009,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(32768, 1, 1)",0,7.5,Launch Statistics,Registers Per Thread,register/thread,16,,,,,
0,52009,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(32768, 1, 1)",0,7.5,Launch Statistics,Shared Memory Configuration Size,byte,"32,768",,,,,
0,52009,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(32768, 1, 1)",0,7.5,Launch Statistics,Driver Shared Memory Per Block,byte/block,0,,,,,
0,52009,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(32768, 1, 1)",0,7.5,Launch Statistics,Dynamic Shared Memory Per Block,byte/block,0,,,,,
0,52009,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(32768, 1, 1)",0,7.5,Launch Statistics,Static Shared Memory Per Block,byte/block,0,,,,,
0,52009,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(32768, 1, 1)",0,7.5,Launch Statistics,Threads,thread,"131,072",,,,,
0,52009,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(32768, 1, 1)",0,7.5,Launch Statistics,Waves Per SM,,146.29,,,,,
0,52009,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(32768, 1, 1)",0,7.5,LaunchStats,,,,LaunchConfiguration,OPT,"Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 4 threads per block. Consequently, some threads in a warp are masked off and those hardware resources are unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256 threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to kernels that frequently call __syncthreads(). See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations.",global,87.5
0,52009,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(32768, 1, 1)",0,7.5,Occupancy,Block Limit SM,block,16,,,,,
0,52009,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(32768, 1, 1)",0,7.5,Occupancy,Block Limit Registers,block,128,,,,,
0,52009,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(32768, 1, 1)",0,7.5,Occupancy,Block Limit Shared Mem,block,16,,,,,
0,52009,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(32768, 1, 1)",0,7.5,Occupancy,Block Limit Warps,block,32,,,,,
0,52009,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(32768, 1, 1)",0,7.5,Occupancy,Theoretical Active Warps per SM,warp,16,,,,,
0,52009,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(32768, 1, 1)",0,7.5,Occupancy,Theoretical Occupancy,%,50,,,,,
0,52009,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(32768, 1, 1)",0,7.5,Occupancy,Achieved Occupancy,%,32.81,,,,,
0,52009,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(32768, 1, 1)",0,7.5,Occupancy,Achieved Active Warps Per SM,warp,10.50,,,,,
0,52009,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(32768, 1, 1)",0,7.5,Occupancy,,,,AchievedOccupancy,OPT,The difference between calculated theoretical (50.0%) and measured achieved occupancy (32.8%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy.,global,34.37
0,52009,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(32768, 1, 1)",0,7.5,Occupancy,,,,TheoreticalOccupancy,OPT,The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared memory.,global,50.0
0,52009,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(32768, 1, 1)",0,7.5,Source Counters,Branch Instructions Ratio,%,0.08,,,,,
0,52009,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(32768, 1, 1)",0,7.5,Source Counters,Branch Instructions,inst,"32,768",,,,,
0,52009,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(32768, 1, 1)",0,7.5,Source Counters,Branch Efficiency,%,0,,,,,
0,52009,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(32768, 1, 1)",0,7.5,Source Counters,Avg. Divergent Branches,,0,,,,,
0,52086,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(16384, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Frequency,cycle/second,"5,866,396,761.13",,,,,
0,52086,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(16384, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Frequency,cycle/second,"1,347,134,362.35",,,,,
0,52086,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(16384, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Elapsed Cycles,cycle,"85,392",,,,,
0,52086,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(16384, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Memory Throughput,%,10.99,,,,,
0,52086,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(16384, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Throughput,%,10.78,,,,,
0,52086,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(16384, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Duration,nsecond,"63,232",,,,,
0,52086,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(16384, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L1/TEX Cache Throughput,%,15.40,,,,,
0,52086,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(16384, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L2 Cache Throughput,%,7.57,,,,,
0,52086,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(16384, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Active Cycles,cycle,"60,790.64",,,,,
0,52086,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(16384, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Compute (SM) Throughput,%,10.99,,,,,
0,52086,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(16384, 1, 1)",0,7.5,SpeedOfLight,,,,SOLBottleneck,OPT,This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.,,
0,52086,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(16384, 1, 1)",0,7.5,SpeedOfLight_RooflineChart,,,,SOLFPRoofline,INF,The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved  close to 0% of this device's fp32 peak performance and 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.,,
0,52086,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(16384, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Active,inst/cycle,0.25,,,,,
0,52086,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(16384, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Elapsed,inst/cycle,0.18,,,,,
0,52086,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(16384, 1, 1)",0,7.5,Compute Workload Analysis,Issue Slots Busy,%,6.28,,,,,
0,52086,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(16384, 1, 1)",0,7.5,Compute Workload Analysis,Issued Ipc Active,inst/cycle,0.25,,,,,
0,52086,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(16384, 1, 1)",0,7.5,Compute Workload Analysis,SM Busy,%,6.42,,,,,
0,52086,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(16384, 1, 1)",0,7.5,ComputeWorkloadAnalysis,,,,HighPipeUtilization,OPT,All compute pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.,local,95.19
0,52086,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(16384, 1, 1)",0,7.5,Memory Workload Analysis,Memory Throughput,byte/second,"20,235,829,959.51",,,,,
0,52086,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(16384, 1, 1)",0,7.5,Memory Workload Analysis,Mem Busy,%,7.57,,,,,
0,52086,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(16384, 1, 1)",0,7.5,Memory Workload Analysis,Max Bandwidth,%,10.99,,,,,
0,52086,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(16384, 1, 1)",0,7.5,Memory Workload Analysis,L1/TEX Hit Rate,%,0.72,,,,,
0,52086,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(16384, 1, 1)",0,7.5,Memory Workload Analysis,L2 Hit Rate,%,66.43,,,,,
0,52086,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(16384, 1, 1)",0,7.5,Memory Workload Analysis,Mem Pipes Busy,%,10.99,,,,,
0,52086,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(16384, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Chart,,,,MemoryL2Compression,WRN,The optional metric lts__average_gcomp_input_sector_success_rate.pct could not be found. Collecting it as an additional metric could enable the rule to provide more guidance.,,
0,52086,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(16384, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for loads from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced loads and try to minimize how many cache lines need to be accessed per memory request.",global,3.768
0,52086,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(16384, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for stores from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced stores and try to minimize how many cache lines need to be accessed per memory request.",global,1.864
0,52086,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(16384, 1, 1)",0,7.5,Scheduler Statistics,One or More Eligible,%,7.15,,,,,
0,52086,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(16384, 1, 1)",0,7.5,Scheduler Statistics,Issued Warp Per Scheduler,,0.07,,,,,
0,52086,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(16384, 1, 1)",0,7.5,Scheduler Statistics,No Eligible,%,92.85,,,,,
0,52086,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(16384, 1, 1)",0,7.5,Scheduler Statistics,Active Warps Per Scheduler,warp,2.82,,,,,
0,52086,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(16384, 1, 1)",0,7.5,Scheduler Statistics,Eligible Warps Per Scheduler,warp,0.07,,,,,
0,52086,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(16384, 1, 1)",0,7.5,SchedulerStats,,,,IssueSlotUtilization,OPT,"Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 14.0 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of 2.82 active warps per scheduler, but only an average of 0.07 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections.",local,89.01
0,52086,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(16384, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Issued Instruction,cycle,39.49,,,,,
0,52086,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(16384, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Executed Instruction,cycle,39.64,,,,,
0,52086,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(16384, 1, 1)",0,7.5,Warp State Statistics,Avg. Active Threads Per Warp,,8,,,,,
0,52086,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(16384, 1, 1)",0,7.5,Warp State Statistics,Avg. Not Predicated Off Threads Per Warp,,8,,,,,
0,52086,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(16384, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,OPT,"On average, each warp of this kernel spends 30.6 cycles being stalled waiting for a scoreboard dependency on a L1TEX (local, global, surface, texture) operation. Find the instruction producing the data being waited upon to identify the culprit. To reduce the number of cycles waiting on L1TEX data accesses verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit rates by increasing data locality (coalescing), or by changing the cache configuration. Consider moving frequently used data to shared memory. This stall type represents about 77.4% of the total average of 39.5 cycles between issuing two instructions.",global,77.42
0,52086,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(16384, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,INF,Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.,,
0,52086,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(16384, 1, 1)",0,7.5,WarpStateStats,,,,ThreadDivergence,OPT,"Instructions are executed in warps, which are groups of 32 threads. Optimal instruction throughput is achieved if all 32 threads of a warp execute the same instruction. The chosen launch configuration, early thread completion, and divergent flow control can significantly lower the number of active threads in a warp per cycle. This kernel achieves an average of 8.0 threads being active per cycle.",global,8.24
0,52086,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(16384, 1, 1)",0,7.5,Instruction Statistics,Avg. Executed Instructions Per Scheduler,inst,"3,803.43",,,,,
0,52086,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(16384, 1, 1)",0,7.5,Instruction Statistics,Executed Instructions,inst,"212,992",,,,,
0,52086,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(16384, 1, 1)",0,7.5,Instruction Statistics,Avg. Issued Instructions Per Scheduler,inst,"3,817.12",,,,,
0,52086,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(16384, 1, 1)",0,7.5,Instruction Statistics,Issued Instructions,inst,"213,759",,,,,
0,52086,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(16384, 1, 1)",0,7.5,InstructionStats,,,,FPInstructions,OPT,"This kernel executes 0 fused and 16384 non-fused FP32 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP32 performance could be increased by up to 50% (relative to its current performance). Check the Source page to identify where this kernel executes FP32 instructions.",global,2.406
0,52086,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(16384, 1, 1)",0,7.5,Launch Statistics,Block Size,,8,,,,,
0,52086,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(16384, 1, 1)",0,7.5,Launch Statistics,Function Cache Configuration,,CachePreferNone,,,,,
0,52086,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(16384, 1, 1)",0,7.5,Launch Statistics,Grid Size,,"16,384",,,,,
0,52086,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(16384, 1, 1)",0,7.5,Launch Statistics,Registers Per Thread,register/thread,16,,,,,
0,52086,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(16384, 1, 1)",0,7.5,Launch Statistics,Shared Memory Configuration Size,byte,"32,768",,,,,
0,52086,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(16384, 1, 1)",0,7.5,Launch Statistics,Driver Shared Memory Per Block,byte/block,0,,,,,
0,52086,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(16384, 1, 1)",0,7.5,Launch Statistics,Dynamic Shared Memory Per Block,byte/block,0,,,,,
0,52086,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(16384, 1, 1)",0,7.5,Launch Statistics,Static Shared Memory Per Block,byte/block,0,,,,,
0,52086,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(16384, 1, 1)",0,7.5,Launch Statistics,Threads,thread,"131,072",,,,,
0,52086,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(16384, 1, 1)",0,7.5,Launch Statistics,Waves Per SM,,73.14,,,,,
0,52086,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(16384, 1, 1)",0,7.5,LaunchStats,,,,LaunchConfiguration,OPT,"Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 8 threads per block. Consequently, some threads in a warp are masked off and those hardware resources are unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256 threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to kernels that frequently call __syncthreads(). See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations.",global,75.0
0,52086,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(16384, 1, 1)",0,7.5,Occupancy,Block Limit SM,block,16,,,,,
0,52086,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(16384, 1, 1)",0,7.5,Occupancy,Block Limit Registers,block,128,,,,,
0,52086,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(16384, 1, 1)",0,7.5,Occupancy,Block Limit Shared Mem,block,16,,,,,
0,52086,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(16384, 1, 1)",0,7.5,Occupancy,Block Limit Warps,block,32,,,,,
0,52086,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(16384, 1, 1)",0,7.5,Occupancy,Theoretical Active Warps per SM,warp,16,,,,,
0,52086,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(16384, 1, 1)",0,7.5,Occupancy,Theoretical Occupancy,%,50,,,,,
0,52086,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(16384, 1, 1)",0,7.5,Occupancy,Achieved Occupancy,%,32.13,,,,,
0,52086,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(16384, 1, 1)",0,7.5,Occupancy,Achieved Active Warps Per SM,warp,10.28,,,,,
0,52086,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(16384, 1, 1)",0,7.5,Occupancy,,,,AchievedOccupancy,OPT,The difference between calculated theoretical (50.0%) and measured achieved occupancy (32.1%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy.,global,35.74
0,52086,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(16384, 1, 1)",0,7.5,Occupancy,,,,TheoreticalOccupancy,OPT,The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared memory.,global,50.0
0,52086,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(16384, 1, 1)",0,7.5,Source Counters,Branch Instructions Ratio,%,0.08,,,,,
0,52086,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(16384, 1, 1)",0,7.5,Source Counters,Branch Instructions,inst,"16,384",,,,,
0,52086,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(16384, 1, 1)",0,7.5,Source Counters,Branch Efficiency,%,0,,,,,
0,52086,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(16384, 1, 1)",0,7.5,Source Counters,Avg. Divergent Branches,,0,,,,,
0,52170,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(8192, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Frequency,cycle/second,"5,732,225,300.09",,,,,
0,52170,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(8192, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Frequency,cycle/second,"1,315,472,068.33",,,,,
0,52170,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(8192, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Elapsed Cycles,cycle,"45,715",,,,,
0,52170,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(8192, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Memory Throughput,%,20.15,,,,,
0,52170,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(8192, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Throughput,%,20.15,,,,,
0,52170,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(8192, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Duration,nsecond,"34,656",,,,,
0,52170,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(8192, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L1/TEX Cache Throughput,%,14.61,,,,,
0,52170,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(8192, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L2 Cache Throughput,%,14.14,,,,,
0,52170,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(8192, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Active Cycles,cycle,"32,051.43",,,,,
0,52170,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(8192, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Compute (SM) Throughput,%,10.26,,,,,
0,52170,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(8192, 1, 1)",0,7.5,SpeedOfLight,,,,SOLBottleneck,OPT,This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.,,
0,52170,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(8192, 1, 1)",0,7.5,SpeedOfLight_RooflineChart,,,,SOLFPRoofline,INF,The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved  close to 0% of this device's fp32 peak performance and 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.,,
0,52170,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(8192, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Active,inst/cycle,0.24,,,,,
0,52170,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(8192, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Elapsed,inst/cycle,0.17,,,,,
0,52170,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(8192, 1, 1)",0,7.5,Compute Workload Analysis,Issue Slots Busy,%,5.98,,,,,
0,52170,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(8192, 1, 1)",0,7.5,Compute Workload Analysis,Issued Ipc Active,inst/cycle,0.24,,,,,
0,52170,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(8192, 1, 1)",0,7.5,Compute Workload Analysis,SM Busy,%,6.09,,,,,
0,52170,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(8192, 1, 1)",0,7.5,ComputeWorkloadAnalysis,,,,HighPipeUtilization,OPT,All compute pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.,local,95.44
0,52170,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(8192, 1, 1)",0,7.5,Memory Workload Analysis,Memory Throughput,byte/second,"36,958,448,753.46",,,,,
0,52170,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(8192, 1, 1)",0,7.5,Memory Workload Analysis,Mem Busy,%,14.14,,,,,
0,52170,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(8192, 1, 1)",0,7.5,Memory Workload Analysis,Max Bandwidth,%,20.15,,,,,
0,52170,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(8192, 1, 1)",0,7.5,Memory Workload Analysis,L1/TEX Hit Rate,%,0.49,,,,,
0,52170,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(8192, 1, 1)",0,7.5,Memory Workload Analysis,L2 Hit Rate,%,33.54,,,,,
0,52170,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(8192, 1, 1)",0,7.5,Memory Workload Analysis,Mem Pipes Busy,%,10.26,,,,,
0,52170,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(8192, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Chart,,,,MemoryL2Compression,WRN,The optional metric lts__average_gcomp_input_sector_success_rate.pct could not be found. Collecting it as an additional metric could enable the rule to provide more guidance.,,
0,52170,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(8192, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for loads from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 2.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced loads and try to minimize how many cache lines need to be accessed per memory request.",global,4.639
0,52170,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(8192, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for stores from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 2.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced stores and try to minimize how many cache lines need to be accessed per memory request.",global,2.308
0,52170,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(8192, 1, 1)",0,7.5,Scheduler Statistics,One or More Eligible,%,6.66,,,,,
0,52170,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(8192, 1, 1)",0,7.5,Scheduler Statistics,Issued Warp Per Scheduler,,0.07,,,,,
0,52170,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(8192, 1, 1)",0,7.5,Scheduler Statistics,No Eligible,%,93.34,,,,,
0,52170,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(8192, 1, 1)",0,7.5,Scheduler Statistics,Active Warps Per Scheduler,warp,2.91,,,,,
0,52170,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(8192, 1, 1)",0,7.5,Scheduler Statistics,Eligible Warps Per Scheduler,warp,0.07,,,,,
0,52170,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(8192, 1, 1)",0,7.5,SchedulerStats,,,,IssueSlotUtilization,OPT,"Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 15.0 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of 2.91 active warps per scheduler, but only an average of 0.07 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections.",local,79.85
0,52170,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(8192, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Issued Instruction,cycle,43.72,,,,,
0,52170,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(8192, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Executed Instruction,cycle,44.03,,,,,
0,52170,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(8192, 1, 1)",0,7.5,Warp State Statistics,Avg. Active Threads Per Warp,,16,,,,,
0,52170,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(8192, 1, 1)",0,7.5,Warp State Statistics,Avg. Not Predicated Off Threads Per Warp,,16,,,,,
0,52170,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(8192, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,OPT,"On average, each warp of this kernel spends 34.0 cycles being stalled waiting for a scoreboard dependency on a L1TEX (local, global, surface, texture) operation. Find the instruction producing the data being waited upon to identify the culprit. To reduce the number of cycles waiting on L1TEX data accesses verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit rates by increasing data locality (coalescing), or by changing the cache configuration. Consider moving frequently used data to shared memory. This stall type represents about 77.8% of the total average of 43.7 cycles between issuing two instructions.",global,77.75
0,52170,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(8192, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,INF,Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.,,
0,52170,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(8192, 1, 1)",0,7.5,WarpStateStats,,,,ThreadDivergence,OPT,"Instructions are executed in warps, which are groups of 32 threads. Optimal instruction throughput is achieved if all 32 threads of a warp execute the same instruction. The chosen launch configuration, early thread completion, and divergent flow control can significantly lower the number of active threads in a warp per cycle. This kernel achieves an average of 16.0 threads being active per cycle.",global,5.132
0,52170,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(8192, 1, 1)",0,7.5,Instruction Statistics,Avg. Executed Instructions Per Scheduler,inst,"1,901.71",,,,,
0,52170,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(8192, 1, 1)",0,7.5,Instruction Statistics,Executed Instructions,inst,"106,496",,,,,
0,52170,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(8192, 1, 1)",0,7.5,Instruction Statistics,Avg. Issued Instructions Per Scheduler,inst,"1,915.36",,,,,
0,52170,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(8192, 1, 1)",0,7.5,Instruction Statistics,Issued Instructions,inst,"107,260",,,,,
0,52170,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(8192, 1, 1)",0,7.5,InstructionStats,,,,FPInstructions,OPT,"This kernel executes 0 fused and 8192 non-fused FP32 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP32 performance could be increased by up to 50% (relative to its current performance). Check the Source page to identify where this kernel executes FP32 instructions.",global,2.282
0,52170,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(8192, 1, 1)",0,7.5,Launch Statistics,Block Size,,16,,,,,
0,52170,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(8192, 1, 1)",0,7.5,Launch Statistics,Function Cache Configuration,,CachePreferNone,,,,,
0,52170,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(8192, 1, 1)",0,7.5,Launch Statistics,Grid Size,,"8,192",,,,,
0,52170,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(8192, 1, 1)",0,7.5,Launch Statistics,Registers Per Thread,register/thread,16,,,,,
0,52170,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(8192, 1, 1)",0,7.5,Launch Statistics,Shared Memory Configuration Size,byte,"32,768",,,,,
0,52170,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(8192, 1, 1)",0,7.5,Launch Statistics,Driver Shared Memory Per Block,byte/block,0,,,,,
0,52170,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(8192, 1, 1)",0,7.5,Launch Statistics,Dynamic Shared Memory Per Block,byte/block,0,,,,,
0,52170,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(8192, 1, 1)",0,7.5,Launch Statistics,Static Shared Memory Per Block,byte/block,0,,,,,
0,52170,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(8192, 1, 1)",0,7.5,Launch Statistics,Threads,thread,"131,072",,,,,
0,52170,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(8192, 1, 1)",0,7.5,Launch Statistics,Waves Per SM,,36.57,,,,,
0,52170,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(8192, 1, 1)",0,7.5,LaunchStats,,,,LaunchConfiguration,OPT,"Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 16 threads per block. Consequently, some threads in a warp are masked off and those hardware resources are unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256 threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to kernels that frequently call __syncthreads(). See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations.",global,50.0
0,52170,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(8192, 1, 1)",0,7.5,Occupancy,Block Limit SM,block,16,,,,,
0,52170,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(8192, 1, 1)",0,7.5,Occupancy,Block Limit Registers,block,128,,,,,
0,52170,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(8192, 1, 1)",0,7.5,Occupancy,Block Limit Shared Mem,block,16,,,,,
0,52170,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(8192, 1, 1)",0,7.5,Occupancy,Block Limit Warps,block,32,,,,,
0,52170,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(8192, 1, 1)",0,7.5,Occupancy,Theoretical Active Warps per SM,warp,16,,,,,
0,52170,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(8192, 1, 1)",0,7.5,Occupancy,Theoretical Occupancy,%,50,,,,,
0,52170,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(8192, 1, 1)",0,7.5,Occupancy,Achieved Occupancy,%,33.17,,,,,
0,52170,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(8192, 1, 1)",0,7.5,Occupancy,Achieved Active Warps Per SM,warp,10.61,,,,,
0,52170,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(8192, 1, 1)",0,7.5,Occupancy,,,,AchievedOccupancy,OPT,The difference between calculated theoretical (50.0%) and measured achieved occupancy (33.2%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy.,global,33.67
0,52170,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(8192, 1, 1)",0,7.5,Occupancy,,,,TheoreticalOccupancy,OPT,The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared memory.,global,50.0
0,52170,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(8192, 1, 1)",0,7.5,Source Counters,Branch Instructions Ratio,%,0.08,,,,,
0,52170,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(8192, 1, 1)",0,7.5,Source Counters,Branch Instructions,inst,"8,192",,,,,
0,52170,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(8192, 1, 1)",0,7.5,Source Counters,Branch Efficiency,%,0,,,,,
0,52170,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(8192, 1, 1)",0,7.5,Source Counters,Avg. Divergent Branches,,0,,,,,
0,52247,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(4096, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Frequency,cycle/second,"5,456,342,668.86",,,,,
0,52247,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(4096, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Frequency,cycle/second,"1,253,500,823.72",,,,,
0,52247,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(4096, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Elapsed Cycles,cycle,"24,423",,,,,
0,52247,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(4096, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Memory Throughput,%,36.76,,,,,
0,52247,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(4096, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Throughput,%,36.76,,,,,
0,52247,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(4096, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Duration,nsecond,"19,424",,,,,
0,52247,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(4096, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L1/TEX Cache Throughput,%,14.30,,,,,
0,52247,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(4096, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L2 Cache Throughput,%,26.49,,,,,
0,52247,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(4096, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Active Cycles,cycle,"18,129.71",,,,,
0,52247,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(4096, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Compute (SM) Throughput,%,9.61,,,,,
0,52247,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(4096, 1, 1)",0,7.5,SpeedOfLight,,,,SOLBottleneck,OPT,This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.,,
0,52247,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(4096, 1, 1)",0,7.5,SpeedOfLight_RooflineChart,,,,SOLFPRoofline,INF,The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved  close to 0% of this device's fp32 peak performance and 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.,,
0,52247,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(4096, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Active,inst/cycle,0.21,,,,,
0,52247,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(4096, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Elapsed,inst/cycle,0.16,,,,,
0,52247,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(4096, 1, 1)",0,7.5,Compute Workload Analysis,Issue Slots Busy,%,5.32,,,,,
0,52247,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(4096, 1, 1)",0,7.5,Compute Workload Analysis,Issued Ipc Active,inst/cycle,0.21,,,,,
0,52247,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(4096, 1, 1)",0,7.5,Compute Workload Analysis,SM Busy,%,5.38,,,,,
0,52247,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(4096, 1, 1)",0,7.5,ComputeWorkloadAnalysis,,,,HighPipeUtilization,OPT,All compute pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.,local,95.97
0,52247,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(4096, 1, 1)",0,7.5,Memory Workload Analysis,Memory Throughput,byte/second,"64,181,219,110.38",,,,,
0,52247,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(4096, 1, 1)",0,7.5,Memory Workload Analysis,Mem Busy,%,26.49,,,,,
0,52247,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(4096, 1, 1)",0,7.5,Memory Workload Analysis,Max Bandwidth,%,36.76,,,,,
0,52247,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(4096, 1, 1)",0,7.5,Memory Workload Analysis,L1/TEX Hit Rate,%,0,,,,,
0,52247,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(4096, 1, 1)",0,7.5,Memory Workload Analysis,L2 Hit Rate,%,33.70,,,,,
0,52247,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(4096, 1, 1)",0,7.5,Memory Workload Analysis,Mem Pipes Busy,%,9.61,,,,,
0,52247,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(4096, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Chart,,,,MemoryL2Compression,WRN,The optional metric lts__average_gcomp_input_sector_success_rate.pct could not be found. Collecting it as an additional metric could enable the rule to provide more guidance.,,
0,52247,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(4096, 1, 1)",0,7.5,Scheduler Statistics,One or More Eligible,%,5.89,,,,,
0,52247,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(4096, 1, 1)",0,7.5,Scheduler Statistics,Issued Warp Per Scheduler,,0.06,,,,,
0,52247,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(4096, 1, 1)",0,7.5,Scheduler Statistics,No Eligible,%,94.11,,,,,
0,52247,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(4096, 1, 1)",0,7.5,Scheduler Statistics,Active Warps Per Scheduler,warp,2.86,,,,,
0,52247,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(4096, 1, 1)",0,7.5,Scheduler Statistics,Eligible Warps Per Scheduler,warp,0.06,,,,,
0,52247,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(4096, 1, 1)",0,7.5,SchedulerStats,,,,IssueSlotUtilization,OPT,"Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 17.0 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of 2.86 active warps per scheduler, but only an average of 0.06 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections.",local,63.24
0,52247,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(4096, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Issued Instruction,cycle,48.62,,,,,
0,52247,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(4096, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Executed Instruction,cycle,49.32,,,,,
0,52247,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(4096, 1, 1)",0,7.5,Warp State Statistics,Avg. Active Threads Per Warp,,32,,,,,
0,52247,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(4096, 1, 1)",0,7.5,Warp State Statistics,Avg. Not Predicated Off Threads Per Warp,,32,,,,,
0,52247,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(4096, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,OPT,"On average, each warp of this kernel spends 38.7 cycles being stalled waiting for a scoreboard dependency on a L1TEX (local, global, surface, texture) operation. Find the instruction producing the data being waited upon to identify the culprit. To reduce the number of cycles waiting on L1TEX data accesses verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit rates by increasing data locality (coalescing), or by changing the cache configuration. Consider moving frequently used data to shared memory. This stall type represents about 79.5% of the total average of 48.6 cycles between issuing two instructions.",global,63.24
0,52247,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(4096, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,INF,Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.,,
0,52247,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(4096, 1, 1)",0,7.5,Instruction Statistics,Avg. Executed Instructions Per Scheduler,inst,950.86,,,,,
0,52247,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(4096, 1, 1)",0,7.5,Instruction Statistics,Executed Instructions,inst,"53,248",,,,,
0,52247,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(4096, 1, 1)",0,7.5,Instruction Statistics,Avg. Issued Instructions Per Scheduler,inst,964.50,,,,,
0,52247,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(4096, 1, 1)",0,7.5,Instruction Statistics,Issued Instructions,inst,"54,012",,,,,
0,52247,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(4096, 1, 1)",0,7.5,InstructionStats,,,,FPInstructions,OPT,"This kernel executes 0 fused and 4096 non-fused FP32 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP32 performance could be increased by up to 50% (relative to its current performance). Check the Source page to identify where this kernel executes FP32 instructions.",global,2.017
0,52247,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(4096, 1, 1)",0,7.5,Launch Statistics,Block Size,,32,,,,,
0,52247,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(4096, 1, 1)",0,7.5,Launch Statistics,Function Cache Configuration,,CachePreferNone,,,,,
0,52247,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(4096, 1, 1)",0,7.5,Launch Statistics,Grid Size,,"4,096",,,,,
0,52247,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(4096, 1, 1)",0,7.5,Launch Statistics,Registers Per Thread,register/thread,16,,,,,
0,52247,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(4096, 1, 1)",0,7.5,Launch Statistics,Shared Memory Configuration Size,byte,"32,768",,,,,
0,52247,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(4096, 1, 1)",0,7.5,Launch Statistics,Driver Shared Memory Per Block,byte/block,0,,,,,
0,52247,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(4096, 1, 1)",0,7.5,Launch Statistics,Dynamic Shared Memory Per Block,byte/block,0,,,,,
0,52247,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(4096, 1, 1)",0,7.5,Launch Statistics,Static Shared Memory Per Block,byte/block,0,,,,,
0,52247,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(4096, 1, 1)",0,7.5,Launch Statistics,Threads,thread,"131,072",,,,,
0,52247,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(4096, 1, 1)",0,7.5,Launch Statistics,Waves Per SM,,18.29,,,,,
0,52247,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(4096, 1, 1)",0,7.5,Occupancy,Block Limit SM,block,16,,,,,
0,52247,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(4096, 1, 1)",0,7.5,Occupancy,Block Limit Registers,block,128,,,,,
0,52247,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(4096, 1, 1)",0,7.5,Occupancy,Block Limit Shared Mem,block,16,,,,,
0,52247,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(4096, 1, 1)",0,7.5,Occupancy,Block Limit Warps,block,32,,,,,
0,52247,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(4096, 1, 1)",0,7.5,Occupancy,Theoretical Active Warps per SM,warp,16,,,,,
0,52247,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(4096, 1, 1)",0,7.5,Occupancy,Theoretical Occupancy,%,50,,,,,
0,52247,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(4096, 1, 1)",0,7.5,Occupancy,Achieved Occupancy,%,33.31,,,,,
0,52247,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(4096, 1, 1)",0,7.5,Occupancy,Achieved Active Warps Per SM,warp,10.66,,,,,
0,52247,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(4096, 1, 1)",0,7.5,Occupancy,,,,AchievedOccupancy,OPT,The difference between calculated theoretical (50.0%) and measured achieved occupancy (33.3%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy.,global,33.37
0,52247,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(4096, 1, 1)",0,7.5,Occupancy,,,,TheoreticalOccupancy,OPT,The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared memory.,global,50.0
0,52247,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(4096, 1, 1)",0,7.5,Source Counters,Branch Instructions Ratio,%,0.08,,,,,
0,52247,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(4096, 1, 1)",0,7.5,Source Counters,Branch Instructions,inst,"4,096",,,,,
0,52247,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(4096, 1, 1)",0,7.5,Source Counters,Branch Efficiency,%,0,,,,,
0,52247,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(4096, 1, 1)",0,7.5,Source Counters,Avg. Divergent Branches,,0,,,,,
0,52333,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(2048, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Frequency,cycle/second,"5,027,190,332.33",,,,,
0,52333,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(2048, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Frequency,cycle/second,"1,145,817,598.19",,,,,
0,52333,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(2048, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Elapsed Cycles,cycle,"12,175",,,,,
0,52333,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(2048, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Memory Throughput,%,70.62,,,,,
0,52333,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(2048, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Throughput,%,70.62,,,,,
0,52333,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(2048, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Duration,nsecond,"10,592",,,,,
0,52333,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(2048, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L1/TEX Cache Throughput,%,26.25,,,,,
0,52333,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(2048, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L2 Cache Throughput,%,53.04,,,,,
0,52333,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(2048, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Active Cycles,cycle,"10,709.29",,,,,
0,52333,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(2048, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Compute (SM) Throughput,%,19.28,,,,,
0,52333,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(2048, 1, 1)",0,7.5,SpeedOfLight,,,,SOLBottleneck,OPT,Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or whether there are values you can (re)compute.,,
0,52333,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(2048, 1, 1)",0,7.5,SpeedOfLight_RooflineChart,,,,SOLFPRoofline,INF,The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved  close to 1% of this device's fp32 peak performance and 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.,,
0,52333,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(2048, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Active,inst/cycle,0.36,,,,,
0,52333,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(2048, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Elapsed,inst/cycle,0.31,,,,,
0,52333,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(2048, 1, 1)",0,7.5,Compute Workload Analysis,Issue Slots Busy,%,9.11,,,,,
0,52333,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(2048, 1, 1)",0,7.5,Compute Workload Analysis,Issued Ipc Active,inst/cycle,0.36,,,,,
0,52333,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(2048, 1, 1)",0,7.5,Compute Workload Analysis,SM Busy,%,9.11,,,,,
0,52333,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(2048, 1, 1)",0,7.5,ComputeWorkloadAnalysis,,,,HighPipeUtilization,OPT,All compute pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.,local,93.17
0,52333,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(2048, 1, 1)",0,7.5,Memory Workload Analysis,Memory Throughput,byte/second,"113,601,208,459.21",,,,,
0,52333,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(2048, 1, 1)",0,7.5,Memory Workload Analysis,Mem Busy,%,53.04,,,,,
0,52333,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(2048, 1, 1)",0,7.5,Memory Workload Analysis,Max Bandwidth,%,70.62,,,,,
0,52333,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(2048, 1, 1)",0,7.5,Memory Workload Analysis,L1/TEX Hit Rate,%,0,,,,,
0,52333,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(2048, 1, 1)",0,7.5,Memory Workload Analysis,L2 Hit Rate,%,33.72,,,,,
0,52333,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(2048, 1, 1)",0,7.5,Memory Workload Analysis,Mem Pipes Busy,%,19.28,,,,,
0,52333,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(2048, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Chart,,,,MemoryL2Compression,WRN,The optional metric lts__average_gcomp_input_sector_success_rate.pct could not be found. Collecting it as an additional metric could enable the rule to provide more guidance.,,
0,52333,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(2048, 1, 1)",0,7.5,Scheduler Statistics,One or More Eligible,%,9.67,,,,,
0,52333,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(2048, 1, 1)",0,7.5,Scheduler Statistics,Issued Warp Per Scheduler,,0.10,,,,,
0,52333,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(2048, 1, 1)",0,7.5,Scheduler Statistics,No Eligible,%,90.33,,,,,
0,52333,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(2048, 1, 1)",0,7.5,Scheduler Statistics,Active Warps Per Scheduler,warp,5.94,,,,,
0,52333,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(2048, 1, 1)",0,7.5,Scheduler Statistics,Eligible Warps Per Scheduler,warp,0.11,,,,,
0,52333,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(2048, 1, 1)",0,7.5,SchedulerStats,,,,IssueSlotUtilization,OPT,"Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 10.3 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of 5.94 active warps per scheduler, but only an average of 0.11 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections.",local,29.38
0,52333,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(2048, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Issued Instruction,cycle,61.46,,,,,
0,52333,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(2048, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Executed Instruction,cycle,63.09,,,,,
0,52333,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(2048, 1, 1)",0,7.5,Warp State Statistics,Avg. Active Threads Per Warp,,32,,,,,
0,52333,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(2048, 1, 1)",0,7.5,Warp State Statistics,Avg. Not Predicated Off Threads Per Warp,,32,,,,,
0,52333,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(2048, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,OPT,"On average, each warp of this kernel spends 46.6 cycles being stalled waiting for a scoreboard dependency on a L1TEX (local, global, surface, texture) operation. Find the instruction producing the data being waited upon to identify the culprit. To reduce the number of cycles waiting on L1TEX data accesses verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit rates by increasing data locality (coalescing), or by changing the cache configuration. Consider moving frequently used data to shared memory. This stall type represents about 75.8% of the total average of 61.5 cycles between issuing two instructions.",global,29.38
0,52333,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(2048, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,INF,Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.,,
0,52333,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(2048, 1, 1)",0,7.5,Instruction Statistics,Avg. Executed Instructions Per Scheduler,inst,950.86,,,,,
0,52333,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(2048, 1, 1)",0,7.5,Instruction Statistics,Executed Instructions,inst,"53,248",,,,,
0,52333,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(2048, 1, 1)",0,7.5,Instruction Statistics,Avg. Issued Instructions Per Scheduler,inst,976.05,,,,,
0,52333,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(2048, 1, 1)",0,7.5,Instruction Statistics,Issued Instructions,inst,"54,659",,,,,
0,52333,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(2048, 1, 1)",0,7.5,InstructionStats,,,,FPInstructions,OPT,"This kernel executes 0 fused and 4096 non-fused FP32 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP32 performance could be increased by up to 50% (relative to its current performance). Check the Source page to identify where this kernel executes FP32 instructions.",global,3.415
0,52333,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(2048, 1, 1)",0,7.5,Launch Statistics,Block Size,,64,,,,,
0,52333,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(2048, 1, 1)",0,7.5,Launch Statistics,Function Cache Configuration,,CachePreferNone,,,,,
0,52333,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(2048, 1, 1)",0,7.5,Launch Statistics,Grid Size,,"2,048",,,,,
0,52333,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(2048, 1, 1)",0,7.5,Launch Statistics,Registers Per Thread,register/thread,16,,,,,
0,52333,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(2048, 1, 1)",0,7.5,Launch Statistics,Shared Memory Configuration Size,byte,"32,768",,,,,
0,52333,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(2048, 1, 1)",0,7.5,Launch Statistics,Driver Shared Memory Per Block,byte/block,0,,,,,
0,52333,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(2048, 1, 1)",0,7.5,Launch Statistics,Dynamic Shared Memory Per Block,byte/block,0,,,,,
0,52333,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(2048, 1, 1)",0,7.5,Launch Statistics,Static Shared Memory Per Block,byte/block,0,,,,,
0,52333,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(2048, 1, 1)",0,7.5,Launch Statistics,Threads,thread,"131,072",,,,,
0,52333,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(2048, 1, 1)",0,7.5,Launch Statistics,Waves Per SM,,9.14,,,,,
0,52333,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(2048, 1, 1)",0,7.5,Occupancy,Block Limit SM,block,16,,,,,
0,52333,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(2048, 1, 1)",0,7.5,Occupancy,Block Limit Registers,block,64,,,,,
0,52333,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(2048, 1, 1)",0,7.5,Occupancy,Block Limit Shared Mem,block,16,,,,,
0,52333,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(2048, 1, 1)",0,7.5,Occupancy,Block Limit Warps,block,16,,,,,
0,52333,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(2048, 1, 1)",0,7.5,Occupancy,Theoretical Active Warps per SM,warp,32,,,,,
0,52333,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(2048, 1, 1)",0,7.5,Occupancy,Theoretical Occupancy,%,100,,,,,
0,52333,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(2048, 1, 1)",0,7.5,Occupancy,Achieved Occupancy,%,71.69,,,,,
0,52333,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(2048, 1, 1)",0,7.5,Occupancy,Achieved Active Warps Per SM,warp,22.94,,,,,
0,52333,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(2048, 1, 1)",0,7.5,Occupancy,,,,AchievedOccupancy,OPT,The difference between calculated theoretical (100.0%) and measured achieved occupancy (71.7%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy.,global,28.31
0,52333,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(2048, 1, 1)",0,7.5,Source Counters,Branch Instructions Ratio,%,0.08,,,,,
0,52333,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(2048, 1, 1)",0,7.5,Source Counters,Branch Instructions,inst,"4,096",,,,,
0,52333,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(2048, 1, 1)",0,7.5,Source Counters,Branch Efficiency,%,0,,,,,
0,52333,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(2048, 1, 1)",0,7.5,Source Counters,Avg. Divergent Branches,,0,,,,,
0,52410,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(1024, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Frequency,cycle/second,"4,731,707,317.07",,,,,
0,52410,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(1024, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Frequency,cycle/second,"1,075,552,591.46",,,,,
0,52410,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(1024, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Elapsed Cycles,cycle,"11,341",,,,,
0,52410,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(1024, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Memory Throughput,%,75.20,,,,,
0,52410,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(1024, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Throughput,%,75.20,,,,,
0,52410,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(1024, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Duration,nsecond,"10,496",,,,,
0,52410,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(1024, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L1/TEX Cache Throughput,%,27.47,,,,,
0,52410,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(1024, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L2 Cache Throughput,%,57.08,,,,,
0,52410,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(1024, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Active Cycles,cycle,"9,703.50",,,,,
0,52410,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(1024, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Compute (SM) Throughput,%,20.72,,,,,
0,52410,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(1024, 1, 1)",0,7.5,SpeedOfLight,,,,SOLBottleneck,OPT,Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or whether there are values you can (re)compute.,,
0,52410,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(1024, 1, 1)",0,7.5,SpeedOfLight_RooflineChart,,,,SOLFPRoofline,INF,The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved  close to 1% of this device's fp32 peak performance and 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.,,
0,52410,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(1024, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Active,inst/cycle,0.39,,,,,
0,52410,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(1024, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Elapsed,inst/cycle,0.34,,,,,
0,52410,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(1024, 1, 1)",0,7.5,Compute Workload Analysis,Issue Slots Busy,%,10.13,,,,,
0,52410,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(1024, 1, 1)",0,7.5,Compute Workload Analysis,Issued Ipc Active,inst/cycle,0.41,,,,,
0,52410,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(1024, 1, 1)",0,7.5,Compute Workload Analysis,SM Busy,%,10.13,,,,,
0,52410,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(1024, 1, 1)",0,7.5,ComputeWorkloadAnalysis,,,,HighPipeUtilization,OPT,All compute pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.,local,92.46
0,52410,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(1024, 1, 1)",0,7.5,Memory Workload Analysis,Memory Throughput,byte/second,"113,865,853,658.54",,,,,
0,52410,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(1024, 1, 1)",0,7.5,Memory Workload Analysis,Mem Busy,%,57.08,,,,,
0,52410,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(1024, 1, 1)",0,7.5,Memory Workload Analysis,Max Bandwidth,%,75.20,,,,,
0,52410,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(1024, 1, 1)",0,7.5,Memory Workload Analysis,L1/TEX Hit Rate,%,0,,,,,
0,52410,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(1024, 1, 1)",0,7.5,Memory Workload Analysis,L2 Hit Rate,%,33.72,,,,,
0,52410,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(1024, 1, 1)",0,7.5,Memory Workload Analysis,Mem Pipes Busy,%,20.72,,,,,
0,52410,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(1024, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Chart,,,,MemoryL2Compression,WRN,The optional metric lts__average_gcomp_input_sector_success_rate.pct could not be found. Collecting it as an additional metric could enable the rule to provide more guidance.,,
0,52410,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(1024, 1, 1)",0,7.5,Scheduler Statistics,One or More Eligible,%,10.13,,,,,
0,52410,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(1024, 1, 1)",0,7.5,Scheduler Statistics,Issued Warp Per Scheduler,,0.10,,,,,
0,52410,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(1024, 1, 1)",0,7.5,Scheduler Statistics,No Eligible,%,89.87,,,,,
0,52410,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(1024, 1, 1)",0,7.5,Scheduler Statistics,Active Warps Per Scheduler,warp,6.49,,,,,
0,52410,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(1024, 1, 1)",0,7.5,Scheduler Statistics,Eligible Warps Per Scheduler,warp,0.12,,,,,
0,52410,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(1024, 1, 1)",0,7.5,SchedulerStats,,,,IssueSlotUtilization,OPT,"Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 9.9 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of 6.49 active warps per scheduler, but only an average of 0.12 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, avoid possible load imbalances due to highly different execution durations per warp. Reducing stalls indicated on the Warp State Statistics and Source Counters sections can help, too.",local,24.8
0,52410,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(1024, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Issued Instruction,cycle,64.08,,,,,
0,52410,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(1024, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Executed Instruction,cycle,66.23,,,,,
0,52410,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(1024, 1, 1)",0,7.5,Warp State Statistics,Avg. Active Threads Per Warp,,32,,,,,
0,52410,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(1024, 1, 1)",0,7.5,Warp State Statistics,Avg. Not Predicated Off Threads Per Warp,,32,,,,,
0,52410,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(1024, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,OPT,"On average, each warp of this kernel spends 48.5 cycles being stalled waiting for a scoreboard dependency on a L1TEX (local, global, surface, texture) operation. Find the instruction producing the data being waited upon to identify the culprit. To reduce the number of cycles waiting on L1TEX data accesses verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit rates by increasing data locality (coalescing), or by changing the cache configuration. Consider moving frequently used data to shared memory. This stall type represents about 75.8% of the total average of 64.1 cycles between issuing two instructions.",global,24.8
0,52410,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(1024, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,INF,Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.,,
0,52410,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(1024, 1, 1)",0,7.5,Instruction Statistics,Avg. Executed Instructions Per Scheduler,inst,950.86,,,,,
0,52410,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(1024, 1, 1)",0,7.5,Instruction Statistics,Executed Instructions,inst,"53,248",,,,,
0,52410,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(1024, 1, 1)",0,7.5,Instruction Statistics,Avg. Issued Instructions Per Scheduler,inst,982.86,,,,,
0,52410,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(1024, 1, 1)",0,7.5,Instruction Statistics,Issued Instructions,inst,"55,040",,,,,
0,52410,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(1024, 1, 1)",0,7.5,InstructionStats,,,,FPInstructions,OPT,"This kernel executes 0 fused and 4096 non-fused FP32 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP32 performance could be increased by up to 50% (relative to its current performance). Check the Source page to identify where this kernel executes FP32 instructions.",global,3.769
0,52410,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(1024, 1, 1)",0,7.5,Launch Statistics,Block Size,,128,,,,,
0,52410,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(1024, 1, 1)",0,7.5,Launch Statistics,Function Cache Configuration,,CachePreferNone,,,,,
0,52410,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(1024, 1, 1)",0,7.5,Launch Statistics,Grid Size,,"1,024",,,,,
0,52410,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(1024, 1, 1)",0,7.5,Launch Statistics,Registers Per Thread,register/thread,16,,,,,
0,52410,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(1024, 1, 1)",0,7.5,Launch Statistics,Shared Memory Configuration Size,byte,"32,768",,,,,
0,52410,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(1024, 1, 1)",0,7.5,Launch Statistics,Driver Shared Memory Per Block,byte/block,0,,,,,
0,52410,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(1024, 1, 1)",0,7.5,Launch Statistics,Dynamic Shared Memory Per Block,byte/block,0,,,,,
0,52410,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(1024, 1, 1)",0,7.5,Launch Statistics,Static Shared Memory Per Block,byte/block,0,,,,,
0,52410,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(1024, 1, 1)",0,7.5,Launch Statistics,Threads,thread,"131,072",,,,,
0,52410,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(1024, 1, 1)",0,7.5,Launch Statistics,Waves Per SM,,9.14,,,,,
0,52410,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(1024, 1, 1)",0,7.5,Occupancy,Block Limit SM,block,16,,,,,
0,52410,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(1024, 1, 1)",0,7.5,Occupancy,Block Limit Registers,block,32,,,,,
0,52410,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(1024, 1, 1)",0,7.5,Occupancy,Block Limit Shared Mem,block,16,,,,,
0,52410,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(1024, 1, 1)",0,7.5,Occupancy,Block Limit Warps,block,8,,,,,
0,52410,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(1024, 1, 1)",0,7.5,Occupancy,Theoretical Active Warps per SM,warp,32,,,,,
0,52410,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(1024, 1, 1)",0,7.5,Occupancy,Theoretical Occupancy,%,100,,,,,
0,52410,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(1024, 1, 1)",0,7.5,Occupancy,Achieved Occupancy,%,81.91,,,,,
0,52410,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(1024, 1, 1)",0,7.5,Occupancy,Achieved Active Warps Per SM,warp,26.21,,,,,
0,52410,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(1024, 1, 1)",0,7.5,Occupancy,,,,AchievedOccupancy,OPT,The difference between calculated theoretical (100.0%) and measured achieved occupancy (81.9%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy.,global,18.09
0,52410,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(1024, 1, 1)",0,7.5,Source Counters,Branch Instructions Ratio,%,0.08,,,,,
0,52410,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(1024, 1, 1)",0,7.5,Source Counters,Branch Instructions,inst,"4,096",,,,,
0,52410,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(1024, 1, 1)",0,7.5,Source Counters,Branch Efficiency,%,0,,,,,
0,52410,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(1024, 1, 1)",0,7.5,Source Counters,Avg. Divergent Branches,,0,,,,,
0,52496,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(512, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Frequency,cycle/second,"4,740,740,740.74",,,,,
0,52496,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(512, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Frequency,cycle/second,"1,080,970,293.21",,,,,
0,52496,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(512, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Elapsed Cycles,cycle,"11,243",,,,,
0,52496,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(512, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Memory Throughput,%,75.86,,,,,
0,52496,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(512, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Throughput,%,75.86,,,,,
0,52496,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(512, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Duration,nsecond,"10,368",,,,,
0,52496,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(512, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L1/TEX Cache Throughput,%,27.24,,,,,
0,52496,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(512, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L2 Cache Throughput,%,57.51,,,,,
0,52496,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(512, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Active Cycles,cycle,"9,761.07",,,,,
0,52496,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(512, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Compute (SM) Throughput,%,20.87,,,,,
0,52496,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(512, 1, 1)",0,7.5,SpeedOfLight,,,,SOLBottleneck,OPT,Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or whether there are values you can (re)compute.,,
0,52496,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(512, 1, 1)",0,7.5,SpeedOfLight_RooflineChart,,,,SOLFPRoofline,INF,The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved  close to 1% of this device's fp32 peak performance and 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.,,
0,52496,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(512, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Active,inst/cycle,0.39,,,,,
0,52496,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(512, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Elapsed,inst/cycle,0.34,,,,,
0,52496,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(512, 1, 1)",0,7.5,Compute Workload Analysis,Issue Slots Busy,%,10.06,,,,,
0,52496,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(512, 1, 1)",0,7.5,Compute Workload Analysis,Issued Ipc Active,inst/cycle,0.40,,,,,
0,52496,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(512, 1, 1)",0,7.5,Compute Workload Analysis,SM Busy,%,10.06,,,,,
0,52496,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(512, 1, 1)",0,7.5,ComputeWorkloadAnalysis,,,,HighPipeUtilization,OPT,All compute pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.,local,92.51
0,52496,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(512, 1, 1)",0,7.5,Memory Workload Analysis,Memory Throughput,byte/second,"115,080,246,913.58",,,,,
0,52496,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(512, 1, 1)",0,7.5,Memory Workload Analysis,Mem Busy,%,57.51,,,,,
0,52496,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(512, 1, 1)",0,7.5,Memory Workload Analysis,Max Bandwidth,%,75.86,,,,,
0,52496,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(512, 1, 1)",0,7.5,Memory Workload Analysis,L1/TEX Hit Rate,%,0,,,,,
0,52496,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(512, 1, 1)",0,7.5,Memory Workload Analysis,L2 Hit Rate,%,33.56,,,,,
0,52496,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(512, 1, 1)",0,7.5,Memory Workload Analysis,Mem Pipes Busy,%,20.87,,,,,
0,52496,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(512, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Chart,,,,MemoryL2Compression,WRN,The optional metric lts__average_gcomp_input_sector_success_rate.pct could not be found. Collecting it as an additional metric could enable the rule to provide more guidance.,,
0,52496,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(512, 1, 1)",0,7.5,Scheduler Statistics,One or More Eligible,%,9.97,,,,,
0,52496,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(512, 1, 1)",0,7.5,Scheduler Statistics,Issued Warp Per Scheduler,,0.10,,,,,
0,52496,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(512, 1, 1)",0,7.5,Scheduler Statistics,No Eligible,%,90.03,,,,,
0,52496,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(512, 1, 1)",0,7.5,Scheduler Statistics,Active Warps Per Scheduler,warp,6.40,,,,,
0,52496,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(512, 1, 1)",0,7.5,Scheduler Statistics,Eligible Warps Per Scheduler,warp,0.12,,,,,
0,52496,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(512, 1, 1)",0,7.5,SchedulerStats,,,,IssueSlotUtilization,OPT,"Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 10.0 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of 6.40 active warps per scheduler, but only an average of 0.12 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, avoid possible load imbalances due to highly different execution durations per warp. Reducing stalls indicated on the Warp State Statistics and Source Counters sections can help, too.",local,24.14
0,52496,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(512, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Issued Instruction,cycle,64.19,,,,,
0,52496,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(512, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Executed Instruction,cycle,66.31,,,,,
0,52496,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(512, 1, 1)",0,7.5,Warp State Statistics,Avg. Active Threads Per Warp,,32,,,,,
0,52496,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(512, 1, 1)",0,7.5,Warp State Statistics,Avg. Not Predicated Off Threads Per Warp,,32,,,,,
0,52496,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(512, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,OPT,"On average, each warp of this kernel spends 48.7 cycles being stalled waiting for a scoreboard dependency on a L1TEX (local, global, surface, texture) operation. Find the instruction producing the data being waited upon to identify the culprit. To reduce the number of cycles waiting on L1TEX data accesses verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit rates by increasing data locality (coalescing), or by changing the cache configuration. Consider moving frequently used data to shared memory. This stall type represents about 75.9% of the total average of 64.2 cycles between issuing two instructions.",global,24.14
0,52496,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(512, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,INF,Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.,,
0,52496,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(512, 1, 1)",0,7.5,Instruction Statistics,Avg. Executed Instructions Per Scheduler,inst,950.86,,,,,
0,52496,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(512, 1, 1)",0,7.5,Instruction Statistics,Executed Instructions,inst,"53,248",,,,,
0,52496,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(512, 1, 1)",0,7.5,Instruction Statistics,Avg. Issued Instructions Per Scheduler,inst,982.36,,,,,
0,52496,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(512, 1, 1)",0,7.5,Instruction Statistics,Issued Instructions,inst,"55,012",,,,,
0,52496,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(512, 1, 1)",0,7.5,InstructionStats,,,,FPInstructions,OPT,"This kernel executes 0 fused and 4096 non-fused FP32 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP32 performance could be increased by up to 50% (relative to its current performance). Check the Source page to identify where this kernel executes FP32 instructions.",global,3.747
0,52496,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(512, 1, 1)",0,7.5,Launch Statistics,Block Size,,256,,,,,
0,52496,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(512, 1, 1)",0,7.5,Launch Statistics,Function Cache Configuration,,CachePreferNone,,,,,
0,52496,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(512, 1, 1)",0,7.5,Launch Statistics,Grid Size,,512,,,,,
0,52496,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(512, 1, 1)",0,7.5,Launch Statistics,Registers Per Thread,register/thread,16,,,,,
0,52496,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(512, 1, 1)",0,7.5,Launch Statistics,Shared Memory Configuration Size,byte,"32,768",,,,,
0,52496,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(512, 1, 1)",0,7.5,Launch Statistics,Driver Shared Memory Per Block,byte/block,0,,,,,
0,52496,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(512, 1, 1)",0,7.5,Launch Statistics,Dynamic Shared Memory Per Block,byte/block,0,,,,,
0,52496,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(512, 1, 1)",0,7.5,Launch Statistics,Static Shared Memory Per Block,byte/block,0,,,,,
0,52496,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(512, 1, 1)",0,7.5,Launch Statistics,Threads,thread,"131,072",,,,,
0,52496,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(512, 1, 1)",0,7.5,Launch Statistics,Waves Per SM,,9.14,,,,,
0,52496,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(512, 1, 1)",0,7.5,Occupancy,Block Limit SM,block,16,,,,,
0,52496,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(512, 1, 1)",0,7.5,Occupancy,Block Limit Registers,block,16,,,,,
0,52496,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(512, 1, 1)",0,7.5,Occupancy,Block Limit Shared Mem,block,16,,,,,
0,52496,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(512, 1, 1)",0,7.5,Occupancy,Block Limit Warps,block,4,,,,,
0,52496,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(512, 1, 1)",0,7.5,Occupancy,Theoretical Active Warps per SM,warp,32,,,,,
0,52496,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(512, 1, 1)",0,7.5,Occupancy,Theoretical Occupancy,%,100,,,,,
0,52496,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(512, 1, 1)",0,7.5,Occupancy,Achieved Occupancy,%,81.23,,,,,
0,52496,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(512, 1, 1)",0,7.5,Occupancy,Achieved Active Warps Per SM,warp,25.99,,,,,
0,52496,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(512, 1, 1)",0,7.5,Occupancy,,,,AchievedOccupancy,OPT,The difference between calculated theoretical (100.0%) and measured achieved occupancy (81.2%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy.,global,18.77
0,52496,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(512, 1, 1)",0,7.5,Source Counters,Branch Instructions Ratio,%,0.08,,,,,
0,52496,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(512, 1, 1)",0,7.5,Source Counters,Branch Instructions,inst,"4,096",,,,,
0,52496,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(512, 1, 1)",0,7.5,Source Counters,Branch Efficiency,%,0,,,,,
0,52496,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(512, 1, 1)",0,7.5,Source Counters,Avg. Divergent Branches,,0,,,,,
0,52582,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(256, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Frequency,cycle/second,"4,814,589,665.65",,,,,
0,52582,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(256, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Frequency,cycle/second,"1,096,884,498.48",,,,,
0,52582,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(256, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Elapsed Cycles,cycle,"11,588",,,,,
0,52582,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(256, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Memory Throughput,%,73.79,,,,,
0,52582,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(256, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Throughput,%,73.79,,,,,
0,52582,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(256, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Duration,nsecond,"10,528",,,,,
0,52582,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(256, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L1/TEX Cache Throughput,%,26.17,,,,,
0,52582,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(256, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L2 Cache Throughput,%,55.76,,,,,
0,52582,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(256, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Active Cycles,cycle,"9,997.43",,,,,
0,52582,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(256, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Compute (SM) Throughput,%,20.26,,,,,
0,52582,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(256, 1, 1)",0,7.5,SpeedOfLight,,,,SOLBottleneck,OPT,Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or whether there are values you can (re)compute.,,
0,52582,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(256, 1, 1)",0,7.5,SpeedOfLight_RooflineChart,,,,SOLFPRoofline,INF,The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved  close to 1% of this device's fp32 peak performance and 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.,,
0,52582,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(256, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Active,inst/cycle,0.38,,,,,
0,52582,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(256, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Elapsed,inst/cycle,0.33,,,,,
0,52582,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(256, 1, 1)",0,7.5,Compute Workload Analysis,Issue Slots Busy,%,9.83,,,,,
0,52582,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(256, 1, 1)",0,7.5,Compute Workload Analysis,Issued Ipc Active,inst/cycle,0.39,,,,,
0,52582,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(256, 1, 1)",0,7.5,Compute Workload Analysis,SM Busy,%,9.83,,,,,
0,52582,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(256, 1, 1)",0,7.5,ComputeWorkloadAnalysis,,,,HighPipeUtilization,OPT,All compute pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.,local,92.68
0,52582,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(256, 1, 1)",0,7.5,Memory Workload Analysis,Memory Throughput,byte/second,"113,683,890,577.51",,,,,
0,52582,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(256, 1, 1)",0,7.5,Memory Workload Analysis,Mem Busy,%,55.76,,,,,
0,52582,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(256, 1, 1)",0,7.5,Memory Workload Analysis,Max Bandwidth,%,73.79,,,,,
0,52582,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(256, 1, 1)",0,7.5,Memory Workload Analysis,L1/TEX Hit Rate,%,0,,,,,
0,52582,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(256, 1, 1)",0,7.5,Memory Workload Analysis,L2 Hit Rate,%,33.72,,,,,
0,52582,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(256, 1, 1)",0,7.5,Memory Workload Analysis,Mem Pipes Busy,%,20.26,,,,,
0,52582,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(256, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Chart,,,,MemoryL2Compression,WRN,The optional metric lts__average_gcomp_input_sector_success_rate.pct could not be found. Collecting it as an additional metric could enable the rule to provide more guidance.,,
0,52582,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(256, 1, 1)",0,7.5,Scheduler Statistics,One or More Eligible,%,9.82,,,,,
0,52582,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(256, 1, 1)",0,7.5,Scheduler Statistics,Issued Warp Per Scheduler,,0.10,,,,,
0,52582,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(256, 1, 1)",0,7.5,Scheduler Statistics,No Eligible,%,90.18,,,,,
0,52582,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(256, 1, 1)",0,7.5,Scheduler Statistics,Active Warps Per Scheduler,warp,6.37,,,,,
0,52582,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(256, 1, 1)",0,7.5,Scheduler Statistics,Eligible Warps Per Scheduler,warp,0.14,,,,,
0,52582,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(256, 1, 1)",0,7.5,SchedulerStats,,,,IssueSlotUtilization,OPT,"Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 10.2 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of 6.37 active warps per scheduler, but only an average of 0.14 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections.",local,26.21
0,52582,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(256, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Issued Instruction,cycle,64.87,,,,,
0,52582,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(256, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Executed Instruction,cycle,67.05,,,,,
0,52582,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(256, 1, 1)",0,7.5,Warp State Statistics,Avg. Active Threads Per Warp,,32,,,,,
0,52582,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(256, 1, 1)",0,7.5,Warp State Statistics,Avg. Not Predicated Off Threads Per Warp,,32,,,,,
0,52582,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(256, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,OPT,"On average, each warp of this kernel spends 49.5 cycles being stalled waiting for a scoreboard dependency on a L1TEX (local, global, surface, texture) operation. Find the instruction producing the data being waited upon to identify the culprit. To reduce the number of cycles waiting on L1TEX data accesses verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit rates by increasing data locality (coalescing), or by changing the cache configuration. Consider moving frequently used data to shared memory. This stall type represents about 76.3% of the total average of 64.9 cycles between issuing two instructions.",global,26.21
0,52582,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(256, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,INF,Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.,,
0,52582,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(256, 1, 1)",0,7.5,Instruction Statistics,Avg. Executed Instructions Per Scheduler,inst,950.86,,,,,
0,52582,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(256, 1, 1)",0,7.5,Instruction Statistics,Executed Instructions,inst,"53,248",,,,,
0,52582,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(256, 1, 1)",0,7.5,Instruction Statistics,Avg. Issued Instructions Per Scheduler,inst,982.86,,,,,
0,52582,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(256, 1, 1)",0,7.5,Instruction Statistics,Issued Instructions,inst,"55,040",,,,,
0,52582,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(256, 1, 1)",0,7.5,InstructionStats,,,,FPInstructions,OPT,"This kernel executes 0 fused and 4096 non-fused FP32 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP32 performance could be increased by up to 50% (relative to its current performance). Check the Source page to identify where this kernel executes FP32 instructions.",global,3.658
0,52582,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(256, 1, 1)",0,7.5,Launch Statistics,Block Size,,512,,,,,
0,52582,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(256, 1, 1)",0,7.5,Launch Statistics,Function Cache Configuration,,CachePreferNone,,,,,
0,52582,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(256, 1, 1)",0,7.5,Launch Statistics,Grid Size,,256,,,,,
0,52582,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(256, 1, 1)",0,7.5,Launch Statistics,Registers Per Thread,register/thread,16,,,,,
0,52582,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(256, 1, 1)",0,7.5,Launch Statistics,Shared Memory Configuration Size,byte,"32,768",,,,,
0,52582,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(256, 1, 1)",0,7.5,Launch Statistics,Driver Shared Memory Per Block,byte/block,0,,,,,
0,52582,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(256, 1, 1)",0,7.5,Launch Statistics,Dynamic Shared Memory Per Block,byte/block,0,,,,,
0,52582,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(256, 1, 1)",0,7.5,Launch Statistics,Static Shared Memory Per Block,byte/block,0,,,,,
0,52582,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(256, 1, 1)",0,7.5,Launch Statistics,Threads,thread,"131,072",,,,,
0,52582,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(256, 1, 1)",0,7.5,Launch Statistics,Waves Per SM,,9.14,,,,,
0,52582,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(256, 1, 1)",0,7.5,Occupancy,Block Limit SM,block,16,,,,,
0,52582,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(256, 1, 1)",0,7.5,Occupancy,Block Limit Registers,block,8,,,,,
0,52582,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(256, 1, 1)",0,7.5,Occupancy,Block Limit Shared Mem,block,16,,,,,
0,52582,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(256, 1, 1)",0,7.5,Occupancy,Block Limit Warps,block,2,,,,,
0,52582,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(256, 1, 1)",0,7.5,Occupancy,Theoretical Active Warps per SM,warp,32,,,,,
0,52582,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(256, 1, 1)",0,7.5,Occupancy,Theoretical Occupancy,%,100,,,,,
0,52582,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(256, 1, 1)",0,7.5,Occupancy,Achieved Occupancy,%,80.62,,,,,
0,52582,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(256, 1, 1)",0,7.5,Occupancy,Achieved Active Warps Per SM,warp,25.80,,,,,
0,52582,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(256, 1, 1)",0,7.5,Occupancy,,,,AchievedOccupancy,OPT,The difference between calculated theoretical (100.0%) and measured achieved occupancy (80.6%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy.,global,19.38
0,52582,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(256, 1, 1)",0,7.5,Source Counters,Branch Instructions Ratio,%,0.08,,,,,
0,52582,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(256, 1, 1)",0,7.5,Source Counters,Branch Instructions,inst,"4,096",,,,,
0,52582,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(256, 1, 1)",0,7.5,Source Counters,Branch Efficiency,%,0,,,,,
0,52582,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(256, 1, 1)",0,7.5,Source Counters,Avg. Divergent Branches,,0,,,,,
0,52678,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(128, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Frequency,cycle/second,"5,162,790,697.67",,,,,
0,52678,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(128, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Frequency,cycle/second,"1,176,825,944.77",,,,,
0,52678,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(128, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Elapsed Cycles,cycle,"12,966",,,,,
0,52678,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(128, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Memory Throughput,%,66.47,,,,,
0,52678,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(128, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Throughput,%,66.47,,,,,
0,52678,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(128, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Duration,nsecond,"11,008",,,,,
0,52678,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(128, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L1/TEX Cache Throughput,%,23.52,,,,,
0,52678,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(128, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L2 Cache Throughput,%,49.66,,,,,
0,52678,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(128, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Active Cycles,cycle,"9,953.29",,,,,
0,52678,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(128, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Compute (SM) Throughput,%,18.07,,,,,
0,52678,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(128, 1, 1)",0,7.5,SpeedOfLight,,,,SOLBottleneck,OPT,Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or whether there are values you can (re)compute.,,
0,52678,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(128, 1, 1)",0,7.5,SpeedOfLight_RooflineChart,,,,SOLFPRoofline,INF,The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved  close to 1% of this device's fp32 peak performance and 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.,,
0,52678,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(128, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Active,inst/cycle,0.38,,,,,
0,52678,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(128, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Elapsed,inst/cycle,0.29,,,,,
0,52678,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(128, 1, 1)",0,7.5,Compute Workload Analysis,Issue Slots Busy,%,9.87,,,,,
0,52678,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(128, 1, 1)",0,7.5,Compute Workload Analysis,Issued Ipc Active,inst/cycle,0.39,,,,,
0,52678,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(128, 1, 1)",0,7.5,Compute Workload Analysis,SM Busy,%,9.87,,,,,
0,52678,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(128, 1, 1)",0,7.5,ComputeWorkloadAnalysis,,,,HighPipeUtilization,OPT,All compute pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.,local,92.65
0,52678,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(128, 1, 1)",0,7.5,Memory Workload Analysis,Memory Throughput,byte/second,"109,813,953,488.37",,,,,
0,52678,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(128, 1, 1)",0,7.5,Memory Workload Analysis,Mem Busy,%,49.66,,,,,
0,52678,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(128, 1, 1)",0,7.5,Memory Workload Analysis,Max Bandwidth,%,66.47,,,,,
0,52678,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(128, 1, 1)",0,7.5,Memory Workload Analysis,L1/TEX Hit Rate,%,0,,,,,
0,52678,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(128, 1, 1)",0,7.5,Memory Workload Analysis,L2 Hit Rate,%,33.58,,,,,
0,52678,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(128, 1, 1)",0,7.5,Memory Workload Analysis,Mem Pipes Busy,%,18.07,,,,,
0,52678,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(128, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Chart,,,,MemoryL2Compression,WRN,The optional metric lts__average_gcomp_input_sector_success_rate.pct could not be found. Collecting it as an additional metric could enable the rule to provide more guidance.,,
0,52678,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(128, 1, 1)",0,7.5,Scheduler Statistics,One or More Eligible,%,10.18,,,,,
0,52678,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(128, 1, 1)",0,7.5,Scheduler Statistics,Issued Warp Per Scheduler,,0.10,,,,,
0,52678,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(128, 1, 1)",0,7.5,Scheduler Statistics,No Eligible,%,89.82,,,,,
0,52678,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(128, 1, 1)",0,7.5,Scheduler Statistics,Active Warps Per Scheduler,warp,7.24,,,,,
0,52678,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(128, 1, 1)",0,7.5,Scheduler Statistics,Eligible Warps Per Scheduler,warp,0.23,,,,,
0,52678,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(128, 1, 1)",0,7.5,SchedulerStats,,,,IssueSlotUtilization,OPT,"Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 9.8 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of 7.24 active warps per scheduler, but only an average of 0.23 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, avoid possible load imbalances due to highly different execution durations per warp. Reducing stalls indicated on the Warp State Statistics and Source Counters sections can help, too.",local,33.53
0,52678,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(128, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Issued Instruction,cycle,71.16,,,,,
0,52678,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(128, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Executed Instruction,cycle,73.55,,,,,
0,52678,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(128, 1, 1)",0,7.5,Warp State Statistics,Avg. Active Threads Per Warp,,32,,,,,
0,52678,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(128, 1, 1)",0,7.5,Warp State Statistics,Avg. Not Predicated Off Threads Per Warp,,32,,,,,
0,52678,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(128, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,OPT,"On average, each warp of this kernel spends 52.8 cycles being stalled waiting for a scoreboard dependency on a L1TEX (local, global, surface, texture) operation. Find the instruction producing the data being waited upon to identify the culprit. To reduce the number of cycles waiting on L1TEX data accesses verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit rates by increasing data locality (coalescing), or by changing the cache configuration. Consider moving frequently used data to shared memory. This stall type represents about 74.2% of the total average of 71.2 cycles between issuing two instructions.",global,33.53
0,52678,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(128, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,INF,Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.,,
0,52678,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(128, 1, 1)",0,7.5,Instruction Statistics,Avg. Executed Instructions Per Scheduler,inst,950.86,,,,,
0,52678,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(128, 1, 1)",0,7.5,Instruction Statistics,Executed Instructions,inst,"53,248",,,,,
0,52678,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(128, 1, 1)",0,7.5,Instruction Statistics,Avg. Issued Instructions Per Scheduler,inst,982.86,,,,,
0,52678,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(128, 1, 1)",0,7.5,Instruction Statistics,Issued Instructions,inst,"55,040",,,,,
0,52678,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(128, 1, 1)",0,7.5,InstructionStats,,,,FPInstructions,OPT,"This kernel executes 0 fused and 4096 non-fused FP32 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP32 performance could be increased by up to 50% (relative to its current performance). Check the Source page to identify where this kernel executes FP32 instructions.",global,3.674
0,52678,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(128, 1, 1)",0,7.5,Launch Statistics,Block Size,,"1,024",,,,,
0,52678,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(128, 1, 1)",0,7.5,Launch Statistics,Function Cache Configuration,,CachePreferNone,,,,,
0,52678,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(128, 1, 1)",0,7.5,Launch Statistics,Grid Size,,128,,,,,
0,52678,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(128, 1, 1)",0,7.5,Launch Statistics,Registers Per Thread,register/thread,16,,,,,
0,52678,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(128, 1, 1)",0,7.5,Launch Statistics,Shared Memory Configuration Size,byte,"32,768",,,,,
0,52678,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(128, 1, 1)",0,7.5,Launch Statistics,Driver Shared Memory Per Block,byte/block,0,,,,,
0,52678,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(128, 1, 1)",0,7.5,Launch Statistics,Dynamic Shared Memory Per Block,byte/block,0,,,,,
0,52678,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(128, 1, 1)",0,7.5,Launch Statistics,Static Shared Memory Per Block,byte/block,0,,,,,
0,52678,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(128, 1, 1)",0,7.5,Launch Statistics,Threads,thread,"131,072",,,,,
0,52678,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(128, 1, 1)",0,7.5,Launch Statistics,Waves Per SM,,9.14,,,,,
0,52678,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(128, 1, 1)",0,7.5,Occupancy,Block Limit SM,block,16,,,,,
0,52678,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(128, 1, 1)",0,7.5,Occupancy,Block Limit Registers,block,4,,,,,
0,52678,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(128, 1, 1)",0,7.5,Occupancy,Block Limit Shared Mem,block,16,,,,,
0,52678,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(128, 1, 1)",0,7.5,Occupancy,Block Limit Warps,block,1,,,,,
0,52678,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(128, 1, 1)",0,7.5,Occupancy,Theoretical Active Warps per SM,warp,32,,,,,
0,52678,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(128, 1, 1)",0,7.5,Occupancy,Theoretical Occupancy,%,100,,,,,
0,52678,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(128, 1, 1)",0,7.5,Occupancy,Achieved Occupancy,%,86.80,,,,,
0,52678,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(128, 1, 1)",0,7.5,Occupancy,Achieved Active Warps Per SM,warp,27.78,,,,,
0,52678,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(128, 1, 1)",0,7.5,Occupancy,,,,AchievedOccupancy,OPT,The difference between calculated theoretical (100.0%) and measured achieved occupancy (86.8%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy.,global,13.2
0,52678,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(128, 1, 1)",0,7.5,Source Counters,Branch Instructions Ratio,%,0.08,,,,,
0,52678,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(128, 1, 1)",0,7.5,Source Counters,Branch Instructions,inst,"4,096",,,,,
0,52678,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(128, 1, 1)",0,7.5,Source Counters,Branch Efficiency,%,0,,,,,
0,52678,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(128, 1, 1)",0,7.5,Source Counters,Avg. Divergent Branches,,0,,,,,
0,52755,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(262144, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Frequency,cycle/second,"6,018,216,368.52",,,,,
0,52755,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(262144, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Frequency,cycle/second,"1,384,102,553.08",,,,,
0,52755,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(262144, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Elapsed Cycles,cycle,"1,353,895",,,,,
0,52755,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(262144, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Memory Throughput,%,11.08,,,,,
0,52755,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(262144, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Throughput,%,1.52,,,,,
0,52755,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(262144, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Duration,nsecond,"976,704",,,,,
0,52755,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(262144, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L1/TEX Cache Throughput,%,14.92,,,,,
0,52755,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(262144, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L2 Cache Throughput,%,8.63,,,,,
0,52755,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(262144, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Active Cycles,cycle,"1,003,849.36",,,,,
0,52755,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(262144, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Compute (SM) Throughput,%,11.08,,,,,
0,52755,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(262144, 1, 1)",0,7.5,SpeedOfLight,,,,SOLBottleneck,OPT,This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.,,
0,52755,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(262144, 1, 1)",0,7.5,SpeedOfLight_RooflineChart,,,,SOLFPRoofline,INF,The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved  close to 0% of this device's fp32 peak performance and 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.,,
0,52755,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(262144, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Active,inst/cycle,0.24,,,,,
0,52755,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(262144, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Elapsed,inst/cycle,0.18,,,,,
0,52755,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(262144, 1, 1)",0,7.5,Compute Workload Analysis,Issue Slots Busy,%,6.06,,,,,
0,52755,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(262144, 1, 1)",0,7.5,Compute Workload Analysis,Issued Ipc Active,inst/cycle,0.24,,,,,
0,52755,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(262144, 1, 1)",0,7.5,Compute Workload Analysis,SM Busy,%,6.22,,,,,
0,52755,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(262144, 1, 1)",0,7.5,ComputeWorkloadAnalysis,,,,HighPipeUtilization,OPT,All compute pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.,local,95.34
0,52755,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(262144, 1, 1)",0,7.5,Memory Workload Analysis,Memory Throughput,byte/second,"2,920,450,822.36",,,,,
0,52755,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(262144, 1, 1)",0,7.5,Memory Workload Analysis,Mem Busy,%,7.13,,,,,
0,52755,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(262144, 1, 1)",0,7.5,Memory Workload Analysis,Max Bandwidth,%,11.08,,,,,
0,52755,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(262144, 1, 1)",0,7.5,Memory Workload Analysis,L1/TEX Hit Rate,%,23.11,,,,,
0,52755,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(262144, 1, 1)",0,7.5,Memory Workload Analysis,L2 Hit Rate,%,95.80,,,,,
0,52755,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(262144, 1, 1)",0,7.5,Memory Workload Analysis,Mem Pipes Busy,%,11.08,,,,,
0,52755,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(262144, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Chart,,,,MemoryL2Compression,WRN,The optional metric lts__average_gcomp_input_sector_success_rate.pct could not be found. Collecting it as an additional metric could enable the rule to provide more guidance.,,
0,52755,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(262144, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for loads from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced loads and try to minimize how many cache lines need to be accessed per memory request.",global,3.544
0,52755,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(262144, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for stores from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.5 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced stores and try to minimize how many cache lines need to be accessed per memory request.",global,1.485
0,52755,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(262144, 1, 1)",0,7.5,Scheduler Statistics,One or More Eligible,%,6.86,,,,,
0,52755,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(262144, 1, 1)",0,7.5,Scheduler Statistics,Issued Warp Per Scheduler,,0.07,,,,,
0,52755,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(262144, 1, 1)",0,7.5,Scheduler Statistics,No Eligible,%,93.14,,,,,
0,52755,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(262144, 1, 1)",0,7.5,Scheduler Statistics,Active Warps Per Scheduler,warp,2.71,,,,,
0,52755,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(262144, 1, 1)",0,7.5,Scheduler Statistics,Eligible Warps Per Scheduler,warp,0.07,,,,,
0,52755,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(262144, 1, 1)",0,7.5,SchedulerStats,,,,IssueSlotUtilization,OPT,"Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 14.6 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of 2.71 active warps per scheduler, but only an average of 0.07 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections.",local,88.92
0,52755,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(262144, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Issued Instruction,cycle,39.55,,,,,
0,52755,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(262144, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Executed Instruction,cycle,39.55,,,,,
0,52755,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(262144, 1, 1)",0,7.5,Warp State Statistics,Avg. Active Threads Per Warp,,1,,,,,
0,52755,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(262144, 1, 1)",0,7.5,Warp State Statistics,Avg. Not Predicated Off Threads Per Warp,,1,,,,,
0,52755,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(262144, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,OPT,"On average, each warp of this kernel spends 31.6 cycles being stalled waiting for a scoreboard dependency on a L1TEX (local, global, surface, texture) operation. Find the instruction producing the data being waited upon to identify the culprit. To reduce the number of cycles waiting on L1TEX data accesses verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit rates by increasing data locality (coalescing), or by changing the cache configuration. Consider moving frequently used data to shared memory. This stall type represents about 79.9% of the total average of 39.5 cycles between issuing two instructions.",global,79.93
0,52755,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(262144, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,INF,Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.,,
0,52755,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(262144, 1, 1)",0,7.5,WarpStateStats,,,,ThreadDivergence,OPT,"Instructions are executed in warps, which are groups of 32 threads. Optimal instruction throughput is achieved if all 32 threads of a warp execute the same instruction. The chosen launch configuration, early thread completion, and divergent flow control can significantly lower the number of active threads in a warp per cycle. This kernel achieves an average of 1.0 threads being active per cycle.",global,10.73
0,52755,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(262144, 1, 1)",0,7.5,Instruction Statistics,Avg. Executed Instructions Per Scheduler,inst,"60,854.86",,,,,
0,52755,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(262144, 1, 1)",0,7.5,Instruction Statistics,Executed Instructions,inst,"3,407,872",,,,,
0,52755,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(262144, 1, 1)",0,7.5,Instruction Statistics,Avg. Issued Instructions Per Scheduler,inst,"60,868.50",,,,,
0,52755,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(262144, 1, 1)",0,7.5,Instruction Statistics,Issued Instructions,inst,"3,408,636",,,,,
0,52755,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(262144, 1, 1)",0,7.5,InstructionStats,,,,FPInstructions,OPT,"This kernel executes 0 fused and 262144 non-fused FP32 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP32 performance could be increased by up to 50% (relative to its current performance). Check the Source page to identify where this kernel executes FP32 instructions.",global,2.332
0,52755,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(262144, 1, 1)",0,7.5,Launch Statistics,Block Size,,1,,,,,
0,52755,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(262144, 1, 1)",0,7.5,Launch Statistics,Function Cache Configuration,,CachePreferNone,,,,,
0,52755,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(262144, 1, 1)",0,7.5,Launch Statistics,Grid Size,,"262,144",,,,,
0,52755,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(262144, 1, 1)",0,7.5,Launch Statistics,Registers Per Thread,register/thread,16,,,,,
0,52755,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(262144, 1, 1)",0,7.5,Launch Statistics,Shared Memory Configuration Size,byte,"32,768",,,,,
0,52755,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(262144, 1, 1)",0,7.5,Launch Statistics,Driver Shared Memory Per Block,byte/block,0,,,,,
0,52755,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(262144, 1, 1)",0,7.5,Launch Statistics,Dynamic Shared Memory Per Block,byte/block,0,,,,,
0,52755,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(262144, 1, 1)",0,7.5,Launch Statistics,Static Shared Memory Per Block,byte/block,0,,,,,
0,52755,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(262144, 1, 1)",0,7.5,Launch Statistics,Threads,thread,"262,144",,,,,
0,52755,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(262144, 1, 1)",0,7.5,Launch Statistics,Waves Per SM,,"1,170.29",,,,,
0,52755,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(262144, 1, 1)",0,7.5,LaunchStats,,,,LaunchConfiguration,OPT,"Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 1 threads per block. Consequently, some threads in a warp are masked off and those hardware resources are unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256 threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to kernels that frequently call __syncthreads(). See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations.",global,96.88
0,52755,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(262144, 1, 1)",0,7.5,Occupancy,Block Limit SM,block,16,,,,,
0,52755,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(262144, 1, 1)",0,7.5,Occupancy,Block Limit Registers,block,128,,,,,
0,52755,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(262144, 1, 1)",0,7.5,Occupancy,Block Limit Shared Mem,block,16,,,,,
0,52755,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(262144, 1, 1)",0,7.5,Occupancy,Block Limit Warps,block,32,,,,,
0,52755,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(262144, 1, 1)",0,7.5,Occupancy,Theoretical Active Warps per SM,warp,16,,,,,
0,52755,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(262144, 1, 1)",0,7.5,Occupancy,Theoretical Occupancy,%,50,,,,,
0,52755,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(262144, 1, 1)",0,7.5,Occupancy,Achieved Occupancy,%,31.16,,,,,
0,52755,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(262144, 1, 1)",0,7.5,Occupancy,Achieved Active Warps Per SM,warp,9.97,,,,,
0,52755,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(262144, 1, 1)",0,7.5,Occupancy,,,,AchievedOccupancy,OPT,The difference between calculated theoretical (50.0%) and measured achieved occupancy (31.2%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy.,global,37.69
0,52755,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(262144, 1, 1)",0,7.5,Occupancy,,,,TheoreticalOccupancy,OPT,The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared memory.,global,50.0
0,52755,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(262144, 1, 1)",0,7.5,Source Counters,Branch Instructions Ratio,%,0.08,,,,,
0,52755,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(262144, 1, 1)",0,7.5,Source Counters,Branch Instructions,inst,"262,144",,,,,
0,52755,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(262144, 1, 1)",0,7.5,Source Counters,Branch Efficiency,%,0,,,,,
0,52755,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(262144, 1, 1)",0,7.5,Source Counters,Avg. Divergent Branches,,0,,,,,
0,52840,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(131072, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Frequency,cycle/second,"5,980,117,190.07",,,,,
0,52840,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(131072, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Frequency,cycle/second,"1,374,872,440.58",,,,,
0,52840,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(131072, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Elapsed Cycles,cycle,"668,876",,,,,
0,52840,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(131072, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Memory Throughput,%,11.21,,,,,
0,52840,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(131072, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Throughput,%,3.08,,,,,
0,52840,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(131072, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Duration,nsecond,"486,048",,,,,
0,52840,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(131072, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L1/TEX Cache Throughput,%,15.41,,,,,
0,52840,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(131072, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L2 Cache Throughput,%,9.57,,,,,
0,52840,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(131072, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Active Cycles,cycle,"486,019",,,,,
0,52840,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(131072, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Compute (SM) Throughput,%,11.21,,,,,
0,52840,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(131072, 1, 1)",0,7.5,SpeedOfLight,,,,SOLBottleneck,OPT,This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.,,
0,52840,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(131072, 1, 1)",0,7.5,SpeedOfLight_RooflineChart,,,,SOLFPRoofline,INF,The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved  close to 0% of this device's fp32 peak performance and 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.,,
0,52840,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(131072, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Active,inst/cycle,0.25,,,,,
0,52840,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(131072, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Elapsed,inst/cycle,0.18,,,,,
0,52840,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(131072, 1, 1)",0,7.5,Compute Workload Analysis,Issue Slots Busy,%,6.26,,,,,
0,52840,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(131072, 1, 1)",0,7.5,Compute Workload Analysis,Issued Ipc Active,inst/cycle,0.25,,,,,
0,52840,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(131072, 1, 1)",0,7.5,Compute Workload Analysis,SM Busy,%,6.42,,,,,
0,52840,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(131072, 1, 1)",0,7.5,ComputeWorkloadAnalysis,,,,HighPipeUtilization,OPT,All compute pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.,local,95.18
0,52840,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(131072, 1, 1)",0,7.5,Memory Workload Analysis,Memory Throughput,byte/second,"5,895,977,352.03",,,,,
0,52840,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(131072, 1, 1)",0,7.5,Memory Workload Analysis,Mem Busy,%,7.64,,,,,
0,52840,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(131072, 1, 1)",0,7.5,Memory Workload Analysis,Max Bandwidth,%,11.21,,,,,
0,52840,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(131072, 1, 1)",0,7.5,Memory Workload Analysis,L1/TEX Hit Rate,%,9.30,,,,,
0,52840,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(131072, 1, 1)",0,7.5,Memory Workload Analysis,L2 Hit Rate,%,91.42,,,,,
0,52840,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(131072, 1, 1)",0,7.5,Memory Workload Analysis,Mem Pipes Busy,%,11.21,,,,,
0,52840,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(131072, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Chart,,,,MemoryL2Compression,WRN,The optional metric lts__average_gcomp_input_sector_success_rate.pct could not be found. Collecting it as an additional metric could enable the rule to provide more guidance.,,
0,52840,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(131072, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for loads from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced loads and try to minimize how many cache lines need to be accessed per memory request.",global,3.804
0,52840,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(131072, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for stores from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.3 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced stores and try to minimize how many cache lines need to be accessed per memory request.",global,1.745
0,52840,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(131072, 1, 1)",0,7.5,Scheduler Statistics,One or More Eligible,%,7.06,,,,,
0,52840,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(131072, 1, 1)",0,7.5,Scheduler Statistics,Issued Warp Per Scheduler,,0.07,,,,,
0,52840,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(131072, 1, 1)",0,7.5,Scheduler Statistics,No Eligible,%,92.94,,,,,
0,52840,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(131072, 1, 1)",0,7.5,Scheduler Statistics,Active Warps Per Scheduler,warp,2.72,,,,,
0,52840,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(131072, 1, 1)",0,7.5,Scheduler Statistics,Eligible Warps Per Scheduler,warp,0.07,,,,,
0,52840,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(131072, 1, 1)",0,7.5,SchedulerStats,,,,IssueSlotUtilization,OPT,"Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 14.2 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of 2.72 active warps per scheduler, but only an average of 0.07 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections.",local,88.79
0,52840,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(131072, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Issued Instruction,cycle,38.54,,,,,
0,52840,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(131072, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Executed Instruction,cycle,38.55,,,,,
0,52840,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(131072, 1, 1)",0,7.5,Warp State Statistics,Avg. Active Threads Per Warp,,2,,,,,
0,52840,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(131072, 1, 1)",0,7.5,Warp State Statistics,Avg. Not Predicated Off Threads Per Warp,,2,,,,,
0,52840,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(131072, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,OPT,"On average, each warp of this kernel spends 30.3 cycles being stalled waiting for a scoreboard dependency on a L1TEX (local, global, surface, texture) operation. Find the instruction producing the data being waited upon to identify the culprit. To reduce the number of cycles waiting on L1TEX data accesses verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit rates by increasing data locality (coalescing), or by changing the cache configuration. Consider moving frequently used data to shared memory. This stall type represents about 78.7% of the total average of 38.5 cycles between issuing two instructions.",global,78.7
0,52840,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(131072, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,INF,Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.,,
0,52840,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(131072, 1, 1)",0,7.5,WarpStateStats,,,,ThreadDivergence,OPT,"Instructions are executed in warps, which are groups of 32 threads. Optimal instruction throughput is achieved if all 32 threads of a warp execute the same instruction. The chosen launch configuration, early thread completion, and divergent flow control can significantly lower the number of active threads in a warp per cycle. This kernel achieves an average of 2.0 threads being active per cycle.",global,10.51
0,52840,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(131072, 1, 1)",0,7.5,Instruction Statistics,Avg. Executed Instructions Per Scheduler,inst,"30,427.43",,,,,
0,52840,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(131072, 1, 1)",0,7.5,Instruction Statistics,Executed Instructions,inst,"1,703,936",,,,,
0,52840,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(131072, 1, 1)",0,7.5,Instruction Statistics,Avg. Issued Instructions Per Scheduler,inst,"30,441.07",,,,,
0,52840,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(131072, 1, 1)",0,7.5,Instruction Statistics,Issued Instructions,inst,"1,704,700",,,,,
0,52840,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(131072, 1, 1)",0,7.5,InstructionStats,,,,FPInstructions,OPT,"This kernel executes 0 fused and 131072 non-fused FP32 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP32 performance could be increased by up to 50% (relative to its current performance). Check the Source page to identify where this kernel executes FP32 instructions.",global,2.408
0,52840,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(131072, 1, 1)",0,7.5,Launch Statistics,Block Size,,2,,,,,
0,52840,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(131072, 1, 1)",0,7.5,Launch Statistics,Function Cache Configuration,,CachePreferNone,,,,,
0,52840,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(131072, 1, 1)",0,7.5,Launch Statistics,Grid Size,,"131,072",,,,,
0,52840,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(131072, 1, 1)",0,7.5,Launch Statistics,Registers Per Thread,register/thread,16,,,,,
0,52840,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(131072, 1, 1)",0,7.5,Launch Statistics,Shared Memory Configuration Size,byte,"32,768",,,,,
0,52840,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(131072, 1, 1)",0,7.5,Launch Statistics,Driver Shared Memory Per Block,byte/block,0,,,,,
0,52840,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(131072, 1, 1)",0,7.5,Launch Statistics,Dynamic Shared Memory Per Block,byte/block,0,,,,,
0,52840,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(131072, 1, 1)",0,7.5,Launch Statistics,Static Shared Memory Per Block,byte/block,0,,,,,
0,52840,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(131072, 1, 1)",0,7.5,Launch Statistics,Threads,thread,"262,144",,,,,
0,52840,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(131072, 1, 1)",0,7.5,Launch Statistics,Waves Per SM,,585.14,,,,,
0,52840,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(131072, 1, 1)",0,7.5,LaunchStats,,,,LaunchConfiguration,OPT,"Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 2 threads per block. Consequently, some threads in a warp are masked off and those hardware resources are unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256 threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to kernels that frequently call __syncthreads(). See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations.",global,93.75
0,52840,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(131072, 1, 1)",0,7.5,Occupancy,Block Limit SM,block,16,,,,,
0,52840,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(131072, 1, 1)",0,7.5,Occupancy,Block Limit Registers,block,128,,,,,
0,52840,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(131072, 1, 1)",0,7.5,Occupancy,Block Limit Shared Mem,block,16,,,,,
0,52840,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(131072, 1, 1)",0,7.5,Occupancy,Block Limit Warps,block,32,,,,,
0,52840,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(131072, 1, 1)",0,7.5,Occupancy,Theoretical Active Warps per SM,warp,16,,,,,
0,52840,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(131072, 1, 1)",0,7.5,Occupancy,Theoretical Occupancy,%,50,,,,,
0,52840,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(131072, 1, 1)",0,7.5,Occupancy,Achieved Occupancy,%,31.04,,,,,
0,52840,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(131072, 1, 1)",0,7.5,Occupancy,Achieved Active Warps Per SM,warp,9.93,,,,,
0,52840,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(131072, 1, 1)",0,7.5,Occupancy,,,,AchievedOccupancy,OPT,The difference between calculated theoretical (50.0%) and measured achieved occupancy (31.0%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy.,global,37.92
0,52840,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(131072, 1, 1)",0,7.5,Occupancy,,,,TheoreticalOccupancy,OPT,The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared memory.,global,50.0
0,52840,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(131072, 1, 1)",0,7.5,Source Counters,Branch Instructions Ratio,%,0.08,,,,,
0,52840,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(131072, 1, 1)",0,7.5,Source Counters,Branch Instructions,inst,"131,072",,,,,
0,52840,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(131072, 1, 1)",0,7.5,Source Counters,Branch Efficiency,%,0,,,,,
0,52840,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(131072, 1, 1)",0,7.5,Source Counters,Avg. Divergent Branches,,0,,,,,
0,52917,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(65536, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Frequency,cycle/second,"5,983,621,474.07",,,,,
0,52917,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(65536, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Frequency,cycle/second,"1,376,027,720.01",,,,,
0,52917,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(65536, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Elapsed Cycles,cycle,"339,186",,,,,
0,52917,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(65536, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Memory Throughput,%,11.05,,,,,
0,52917,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(65536, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Throughput,%,6.05,,,,,
0,52917,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(65536, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Duration,nsecond,"246,176",,,,,
0,52917,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(65536, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L1/TEX Cache Throughput,%,15.22,,,,,
0,52917,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(65536, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L2 Cache Throughput,%,9.83,,,,,
0,52917,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(65536, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Active Cycles,cycle,"246,023.21",,,,,
0,52917,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(65536, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Compute (SM) Throughput,%,11.05,,,,,
0,52917,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(65536, 1, 1)",0,7.5,SpeedOfLight,,,,SOLBottleneck,OPT,This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.,,
0,52917,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(65536, 1, 1)",0,7.5,SpeedOfLight_RooflineChart,,,,SOLFPRoofline,INF,The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved  close to 0% of this device's fp32 peak performance and 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.,,
0,52917,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(65536, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Active,inst/cycle,0.25,,,,,
0,52917,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(65536, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Elapsed,inst/cycle,0.18,,,,,
0,52917,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(65536, 1, 1)",0,7.5,Compute Workload Analysis,Issue Slots Busy,%,6.19,,,,,
0,52917,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(65536, 1, 1)",0,7.5,Compute Workload Analysis,Issued Ipc Active,inst/cycle,0.25,,,,,
0,52917,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(65536, 1, 1)",0,7.5,Compute Workload Analysis,SM Busy,%,6.34,,,,,
0,52917,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(65536, 1, 1)",0,7.5,ComputeWorkloadAnalysis,,,,HighPipeUtilization,OPT,All compute pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.,local,95.24
0,52917,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(65536, 1, 1)",0,7.5,Memory Workload Analysis,Memory Throughput,byte/second,"11,587,287,144.16",,,,,
0,52917,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(65536, 1, 1)",0,7.5,Memory Workload Analysis,Mem Busy,%,7.56,,,,,
0,52917,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(65536, 1, 1)",0,7.5,Memory Workload Analysis,Max Bandwidth,%,11.05,,,,,
0,52917,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(65536, 1, 1)",0,7.5,Memory Workload Analysis,L1/TEX Hit Rate,%,2.93,,,,,
0,52917,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(65536, 1, 1)",0,7.5,Memory Workload Analysis,L2 Hit Rate,%,83.41,,,,,
0,52917,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(65536, 1, 1)",0,7.5,Memory Workload Analysis,Mem Pipes Busy,%,11.05,,,,,
0,52917,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(65536, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Chart,,,,MemoryL2Compression,WRN,The optional metric lts__average_gcomp_input_sector_success_rate.pct could not be found. Collecting it as an additional metric could enable the rule to provide more guidance.,,
0,52917,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(65536, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for loads from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced loads and try to minimize how many cache lines need to be accessed per memory request.",global,3.765
0,52917,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(65536, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for stores from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.1 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced stores and try to minimize how many cache lines need to be accessed per memory request.",global,1.847
0,52917,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(65536, 1, 1)",0,7.5,Scheduler Statistics,One or More Eligible,%,7.00,,,,,
0,52917,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(65536, 1, 1)",0,7.5,Scheduler Statistics,Issued Warp Per Scheduler,,0.07,,,,,
0,52917,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(65536, 1, 1)",0,7.5,Scheduler Statistics,No Eligible,%,93.00,,,,,
0,52917,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(65536, 1, 1)",0,7.5,Scheduler Statistics,Active Warps Per Scheduler,warp,2.71,,,,,
0,52917,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(65536, 1, 1)",0,7.5,Scheduler Statistics,Eligible Warps Per Scheduler,warp,0.07,,,,,
0,52917,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(65536, 1, 1)",0,7.5,SchedulerStats,,,,IssueSlotUtilization,OPT,"Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 14.3 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of 2.71 active warps per scheduler, but only an average of 0.07 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections.",local,88.95
0,52917,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(65536, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Issued Instruction,cycle,38.67,,,,,
0,52917,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(65536, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Executed Instruction,cycle,38.70,,,,,
0,52917,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(65536, 1, 1)",0,7.5,Warp State Statistics,Avg. Active Threads Per Warp,,4,,,,,
0,52917,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(65536, 1, 1)",0,7.5,Warp State Statistics,Avg. Not Predicated Off Threads Per Warp,,4,,,,,
0,52917,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(65536, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,OPT,"On average, each warp of this kernel spends 30.3 cycles being stalled waiting for a scoreboard dependency on a L1TEX (local, global, surface, texture) operation. Find the instruction producing the data being waited upon to identify the culprit. To reduce the number of cycles waiting on L1TEX data accesses verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit rates by increasing data locality (coalescing), or by changing the cache configuration. Consider moving frequently used data to shared memory. This stall type represents about 78.3% of the total average of 38.7 cycles between issuing two instructions.",global,78.28
0,52917,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(65536, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,INF,Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.,,
0,52917,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(65536, 1, 1)",0,7.5,WarpStateStats,,,,ThreadDivergence,OPT,"Instructions are executed in warps, which are groups of 32 threads. Optimal instruction throughput is achieved if all 32 threads of a warp execute the same instruction. The chosen launch configuration, early thread completion, and divergent flow control can significantly lower the number of active threads in a warp per cycle. This kernel achieves an average of 4.0 threads being active per cycle.",global,9.672
0,52917,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(65536, 1, 1)",0,7.5,Instruction Statistics,Avg. Executed Instructions Per Scheduler,inst,"15,213.71",,,,,
0,52917,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(65536, 1, 1)",0,7.5,Instruction Statistics,Executed Instructions,inst,"851,968",,,,,
0,52917,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(65536, 1, 1)",0,7.5,Instruction Statistics,Avg. Issued Instructions Per Scheduler,inst,"15,227.36",,,,,
0,52917,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(65536, 1, 1)",0,7.5,Instruction Statistics,Issued Instructions,inst,"852,732",,,,,
0,52917,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(65536, 1, 1)",0,7.5,InstructionStats,,,,FPInstructions,OPT,"This kernel executes 0 fused and 65536 non-fused FP32 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP32 performance could be increased by up to 50% (relative to its current performance). Check the Source page to identify where this kernel executes FP32 instructions.",global,2.378
0,52917,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(65536, 1, 1)",0,7.5,Launch Statistics,Block Size,,4,,,,,
0,52917,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(65536, 1, 1)",0,7.5,Launch Statistics,Function Cache Configuration,,CachePreferNone,,,,,
0,52917,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(65536, 1, 1)",0,7.5,Launch Statistics,Grid Size,,"65,536",,,,,
0,52917,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(65536, 1, 1)",0,7.5,Launch Statistics,Registers Per Thread,register/thread,16,,,,,
0,52917,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(65536, 1, 1)",0,7.5,Launch Statistics,Shared Memory Configuration Size,byte,"32,768",,,,,
0,52917,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(65536, 1, 1)",0,7.5,Launch Statistics,Driver Shared Memory Per Block,byte/block,0,,,,,
0,52917,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(65536, 1, 1)",0,7.5,Launch Statistics,Dynamic Shared Memory Per Block,byte/block,0,,,,,
0,52917,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(65536, 1, 1)",0,7.5,Launch Statistics,Static Shared Memory Per Block,byte/block,0,,,,,
0,52917,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(65536, 1, 1)",0,7.5,Launch Statistics,Threads,thread,"262,144",,,,,
0,52917,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(65536, 1, 1)",0,7.5,Launch Statistics,Waves Per SM,,292.57,,,,,
0,52917,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(65536, 1, 1)",0,7.5,LaunchStats,,,,LaunchConfiguration,OPT,"Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 4 threads per block. Consequently, some threads in a warp are masked off and those hardware resources are unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256 threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to kernels that frequently call __syncthreads(). See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations.",global,87.5
0,52917,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(65536, 1, 1)",0,7.5,Occupancy,Block Limit SM,block,16,,,,,
0,52917,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(65536, 1, 1)",0,7.5,Occupancy,Block Limit Registers,block,128,,,,,
0,52917,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(65536, 1, 1)",0,7.5,Occupancy,Block Limit Shared Mem,block,16,,,,,
0,52917,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(65536, 1, 1)",0,7.5,Occupancy,Block Limit Warps,block,32,,,,,
0,52917,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(65536, 1, 1)",0,7.5,Occupancy,Theoretical Active Warps per SM,warp,16,,,,,
0,52917,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(65536, 1, 1)",0,7.5,Occupancy,Theoretical Occupancy,%,50,,,,,
0,52917,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(65536, 1, 1)",0,7.5,Occupancy,Achieved Occupancy,%,30.95,,,,,
0,52917,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(65536, 1, 1)",0,7.5,Occupancy,Achieved Active Warps Per SM,warp,9.91,,,,,
0,52917,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(65536, 1, 1)",0,7.5,Occupancy,,,,AchievedOccupancy,OPT,The difference between calculated theoretical (50.0%) and measured achieved occupancy (31.0%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy.,global,38.09
0,52917,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(65536, 1, 1)",0,7.5,Occupancy,,,,TheoreticalOccupancy,OPT,The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared memory.,global,50.0
0,52917,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(65536, 1, 1)",0,7.5,Source Counters,Branch Instructions Ratio,%,0.08,,,,,
0,52917,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(65536, 1, 1)",0,7.5,Source Counters,Branch Instructions,inst,"65,536",,,,,
0,52917,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(65536, 1, 1)",0,7.5,Source Counters,Branch Efficiency,%,0,,,,,
0,52917,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(65536, 1, 1)",0,7.5,Source Counters,Avg. Divergent Branches,,0,,,,,
0,53003,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(32768, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Frequency,cycle/second,"6,087,414,428.65",,,,,
0,53003,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(32768, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Frequency,cycle/second,"1,399,716,956.29",,,,,
0,53003,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(32768, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Elapsed Cycles,cycle,"170,221",,,,,
0,53003,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(32768, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Memory Throughput,%,12.05,,,,,
0,53003,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(32768, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Throughput,%,12.05,,,,,
0,53003,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(32768, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Duration,nsecond,"121,536",,,,,
0,53003,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(32768, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L1/TEX Cache Throughput,%,14.21,,,,,
0,53003,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(32768, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L2 Cache Throughput,%,7.56,,,,,
0,53003,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(32768, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Active Cycles,cycle,"131,810.29",,,,,
0,53003,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(32768, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Compute (SM) Throughput,%,11.01,,,,,
0,53003,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(32768, 1, 1)",0,7.5,SpeedOfLight,,,,SOLBottleneck,OPT,This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.,,
0,53003,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(32768, 1, 1)",0,7.5,SpeedOfLight_RooflineChart,,,,SOLFPRoofline,INF,The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved  close to 0% of this device's fp32 peak performance and 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.,,
0,53003,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(32768, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Active,inst/cycle,0.23,,,,,
0,53003,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(32768, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Elapsed,inst/cycle,0.18,,,,,
0,53003,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(32768, 1, 1)",0,7.5,Compute Workload Analysis,Issue Slots Busy,%,5.78,,,,,
0,53003,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(32768, 1, 1)",0,7.5,Compute Workload Analysis,Issued Ipc Active,inst/cycle,0.23,,,,,
0,53003,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(32768, 1, 1)",0,7.5,Compute Workload Analysis,SM Busy,%,5.92,,,,,
0,53003,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(32768, 1, 1)",0,7.5,ComputeWorkloadAnalysis,,,,HighPipeUtilization,OPT,All compute pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.,local,95.56
0,53003,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(32768, 1, 1)",0,7.5,Memory Workload Analysis,Memory Throughput,byte/second,"23,470,774,091.63",,,,,
0,53003,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(32768, 1, 1)",0,7.5,Memory Workload Analysis,Mem Busy,%,7.56,,,,,
0,53003,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(32768, 1, 1)",0,7.5,Memory Workload Analysis,Max Bandwidth,%,12.05,,,,,
0,53003,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(32768, 1, 1)",0,7.5,Memory Workload Analysis,L1/TEX Hit Rate,%,1.44,,,,,
0,53003,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(32768, 1, 1)",0,7.5,Memory Workload Analysis,L2 Hit Rate,%,66.75,,,,,
0,53003,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(32768, 1, 1)",0,7.5,Memory Workload Analysis,Mem Pipes Busy,%,11.01,,,,,
0,53003,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(32768, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Chart,,,,MemoryL2Compression,WRN,The optional metric lts__average_gcomp_input_sector_success_rate.pct could not be found. Collecting it as an additional metric could enable the rule to provide more guidance.,,
0,53003,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(32768, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for loads from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced loads and try to minimize how many cache lines need to be accessed per memory request.",global,3.767
0,53003,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(32768, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for stores from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced stores and try to minimize how many cache lines need to be accessed per memory request.",global,1.863
0,53003,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(32768, 1, 1)",0,7.5,Scheduler Statistics,One or More Eligible,%,6.51,,,,,
0,53003,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(32768, 1, 1)",0,7.5,Scheduler Statistics,Issued Warp Per Scheduler,,0.07,,,,,
0,53003,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(32768, 1, 1)",0,7.5,Scheduler Statistics,No Eligible,%,93.49,,,,,
0,53003,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(32768, 1, 1)",0,7.5,Scheduler Statistics,Active Warps Per Scheduler,warp,2.69,,,,,
0,53003,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(32768, 1, 1)",0,7.5,Scheduler Statistics,Eligible Warps Per Scheduler,warp,0.07,,,,,
0,53003,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(32768, 1, 1)",0,7.5,SchedulerStats,,,,IssueSlotUtilization,OPT,"Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 15.4 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of 2.69 active warps per scheduler, but only an average of 0.07 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections.",local,87.95
0,53003,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(32768, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Issued Instruction,cycle,41.25,,,,,
0,53003,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(32768, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Executed Instruction,cycle,41.33,,,,,
0,53003,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(32768, 1, 1)",0,7.5,Warp State Statistics,Avg. Active Threads Per Warp,,8,,,,,
0,53003,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(32768, 1, 1)",0,7.5,Warp State Statistics,Avg. Not Predicated Off Threads Per Warp,,8,,,,,
0,53003,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(32768, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,OPT,"On average, each warp of this kernel spends 32.7 cycles being stalled waiting for a scoreboard dependency on a L1TEX (local, global, surface, texture) operation. Find the instruction producing the data being waited upon to identify the culprit. To reduce the number of cycles waiting on L1TEX data accesses verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit rates by increasing data locality (coalescing), or by changing the cache configuration. Consider moving frequently used data to shared memory. This stall type represents about 79.2% of the total average of 41.3 cycles between issuing two instructions.",global,79.22
0,53003,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(32768, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,INF,Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.,,
0,53003,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(32768, 1, 1)",0,7.5,WarpStateStats,,,,ThreadDivergence,OPT,"Instructions are executed in warps, which are groups of 32 threads. Optimal instruction throughput is achieved if all 32 threads of a warp execute the same instruction. The chosen launch configuration, early thread completion, and divergent flow control can significantly lower the number of active threads in a warp per cycle. This kernel achieves an average of 8.0 threads being active per cycle.",global,8.254
0,53003,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(32768, 1, 1)",0,7.5,Instruction Statistics,Avg. Executed Instructions Per Scheduler,inst,"7,606.86",,,,,
0,53003,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(32768, 1, 1)",0,7.5,Instruction Statistics,Executed Instructions,inst,"425,984",,,,,
0,53003,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(32768, 1, 1)",0,7.5,Instruction Statistics,Avg. Issued Instructions Per Scheduler,inst,"7,620.50",,,,,
0,53003,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(32768, 1, 1)",0,7.5,Instruction Statistics,Issued Instructions,inst,"426,748",,,,,
0,53003,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(32768, 1, 1)",0,7.5,InstructionStats,,,,FPInstructions,OPT,"This kernel executes 0 fused and 32768 non-fused FP32 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP32 performance could be increased by up to 50% (relative to its current performance). Check the Source page to identify where this kernel executes FP32 instructions.",global,2.22
0,53003,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(32768, 1, 1)",0,7.5,Launch Statistics,Block Size,,8,,,,,
0,53003,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(32768, 1, 1)",0,7.5,Launch Statistics,Function Cache Configuration,,CachePreferNone,,,,,
0,53003,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(32768, 1, 1)",0,7.5,Launch Statistics,Grid Size,,"32,768",,,,,
0,53003,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(32768, 1, 1)",0,7.5,Launch Statistics,Registers Per Thread,register/thread,16,,,,,
0,53003,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(32768, 1, 1)",0,7.5,Launch Statistics,Shared Memory Configuration Size,byte,"32,768",,,,,
0,53003,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(32768, 1, 1)",0,7.5,Launch Statistics,Driver Shared Memory Per Block,byte/block,0,,,,,
0,53003,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(32768, 1, 1)",0,7.5,Launch Statistics,Dynamic Shared Memory Per Block,byte/block,0,,,,,
0,53003,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(32768, 1, 1)",0,7.5,Launch Statistics,Static Shared Memory Per Block,byte/block,0,,,,,
0,53003,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(32768, 1, 1)",0,7.5,Launch Statistics,Threads,thread,"262,144",,,,,
0,53003,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(32768, 1, 1)",0,7.5,Launch Statistics,Waves Per SM,,146.29,,,,,
0,53003,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(32768, 1, 1)",0,7.5,LaunchStats,,,,LaunchConfiguration,OPT,"Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 8 threads per block. Consequently, some threads in a warp are masked off and those hardware resources are unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256 threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to kernels that frequently call __syncthreads(). See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations.",global,75.0
0,53003,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(32768, 1, 1)",0,7.5,Occupancy,Block Limit SM,block,16,,,,,
0,53003,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(32768, 1, 1)",0,7.5,Occupancy,Block Limit Registers,block,128,,,,,
0,53003,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(32768, 1, 1)",0,7.5,Occupancy,Block Limit Shared Mem,block,16,,,,,
0,53003,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(32768, 1, 1)",0,7.5,Occupancy,Block Limit Warps,block,32,,,,,
0,53003,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(32768, 1, 1)",0,7.5,Occupancy,Theoretical Active Warps per SM,warp,16,,,,,
0,53003,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(32768, 1, 1)",0,7.5,Occupancy,Theoretical Occupancy,%,50,,,,,
0,53003,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(32768, 1, 1)",0,7.5,Occupancy,Achieved Occupancy,%,30.75,,,,,
0,53003,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(32768, 1, 1)",0,7.5,Occupancy,Achieved Active Warps Per SM,warp,9.84,,,,,
0,53003,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(32768, 1, 1)",0,7.5,Occupancy,,,,AchievedOccupancy,OPT,The difference between calculated theoretical (50.0%) and measured achieved occupancy (30.8%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy.,global,38.49
0,53003,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(32768, 1, 1)",0,7.5,Occupancy,,,,TheoreticalOccupancy,OPT,The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared memory.,global,50.0
0,53003,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(32768, 1, 1)",0,7.5,Source Counters,Branch Instructions Ratio,%,0.08,,,,,
0,53003,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(32768, 1, 1)",0,7.5,Source Counters,Branch Instructions,inst,"32,768",,,,,
0,53003,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(32768, 1, 1)",0,7.5,Source Counters,Branch Efficiency,%,0,,,,,
0,53003,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(32768, 1, 1)",0,7.5,Source Counters,Avg. Divergent Branches,,0,,,,,
0,53080,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(16384, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Frequency,cycle/second,"5,910,188,314.82",,,,,
0,53080,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(16384, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Frequency,cycle/second,"1,357,443,565.91",,,,,
0,53080,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(16384, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Elapsed Cycles,cycle,"90,071",,,,,
0,53080,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(16384, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Memory Throughput,%,22.80,,,,,
0,53080,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(16384, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Throughput,%,22.80,,,,,
0,53080,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(16384, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Duration,nsecond,"66,272",,,,,
0,53080,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(16384, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L1/TEX Cache Throughput,%,13.37,,,,,
0,53080,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(16384, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L2 Cache Throughput,%,14.33,,,,,
0,53080,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(16384, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Active Cycles,cycle,"70,037.29",,,,,
0,53080,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(16384, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Compute (SM) Throughput,%,10.41,,,,,
0,53080,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(16384, 1, 1)",0,7.5,SpeedOfLight,,,,SOLBottleneck,OPT,This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.,,
0,53080,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(16384, 1, 1)",0,7.5,SpeedOfLight_RooflineChart,,,,SOLFPRoofline,INF,The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved  close to 0% of this device's fp32 peak performance and 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.,,
0,53080,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(16384, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Active,inst/cycle,0.22,,,,,
0,53080,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(16384, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Elapsed,inst/cycle,0.17,,,,,
0,53080,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(16384, 1, 1)",0,7.5,Compute Workload Analysis,Issue Slots Busy,%,5.45,,,,,
0,53080,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(16384, 1, 1)",0,7.5,Compute Workload Analysis,Issued Ipc Active,inst/cycle,0.22,,,,,
0,53080,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(16384, 1, 1)",0,7.5,Compute Workload Analysis,SM Busy,%,5.57,,,,,
0,53080,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(16384, 1, 1)",0,7.5,ComputeWorkloadAnalysis,,,,HighPipeUtilization,OPT,All compute pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.,local,95.82
0,53080,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(16384, 1, 1)",0,7.5,Memory Workload Analysis,Memory Throughput,byte/second,"43,127,957,508.45",,,,,
0,53080,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(16384, 1, 1)",0,7.5,Memory Workload Analysis,Mem Busy,%,14.33,,,,,
0,53080,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(16384, 1, 1)",0,7.5,Memory Workload Analysis,Max Bandwidth,%,22.80,,,,,
0,53080,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(16384, 1, 1)",0,7.5,Memory Workload Analysis,L1/TEX Hit Rate,%,0.43,,,,,
0,53080,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(16384, 1, 1)",0,7.5,Memory Workload Analysis,L2 Hit Rate,%,33.49,,,,,
0,53080,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(16384, 1, 1)",0,7.5,Memory Workload Analysis,Mem Pipes Busy,%,10.41,,,,,
0,53080,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(16384, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Chart,,,,MemoryL2Compression,WRN,The optional metric lts__average_gcomp_input_sector_success_rate.pct could not be found. Collecting it as an additional metric could enable the rule to provide more guidance.,,
0,53080,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(16384, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for loads from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 2.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced loads and try to minimize how many cache lines need to be accessed per memory request.",global,4.74
0,53080,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(16384, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for stores from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 2.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced stores and try to minimize how many cache lines need to be accessed per memory request.",global,2.346
0,53080,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(16384, 1, 1)",0,7.5,Scheduler Statistics,One or More Eligible,%,6.14,,,,,
0,53080,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(16384, 1, 1)",0,7.5,Scheduler Statistics,Issued Warp Per Scheduler,,0.06,,,,,
0,53080,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(16384, 1, 1)",0,7.5,Scheduler Statistics,No Eligible,%,93.86,,,,,
0,53080,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(16384, 1, 1)",0,7.5,Scheduler Statistics,Active Warps Per Scheduler,warp,2.82,,,,,
0,53080,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(16384, 1, 1)",0,7.5,Scheduler Statistics,Eligible Warps Per Scheduler,warp,0.06,,,,,
0,53080,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(16384, 1, 1)",0,7.5,SchedulerStats,,,,IssueSlotUtilization,OPT,"Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 16.3 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of 2.82 active warps per scheduler, but only an average of 0.06 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections.",local,77.2
0,53080,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(16384, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Issued Instruction,cycle,45.91,,,,,
0,53080,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(16384, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Executed Instruction,cycle,46.08,,,,,
0,53080,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(16384, 1, 1)",0,7.5,Warp State Statistics,Avg. Active Threads Per Warp,,16,,,,,
0,53080,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(16384, 1, 1)",0,7.5,Warp State Statistics,Avg. Not Predicated Off Threads Per Warp,,16,,,,,
0,53080,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(16384, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,OPT,"On average, each warp of this kernel spends 37.1 cycles being stalled waiting for a scoreboard dependency on a L1TEX (local, global, surface, texture) operation. Find the instruction producing the data being waited upon to identify the culprit. To reduce the number of cycles waiting on L1TEX data accesses verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit rates by increasing data locality (coalescing), or by changing the cache configuration. Consider moving frequently used data to shared memory. This stall type represents about 80.9% of the total average of 45.9 cycles between issuing two instructions.",global,77.2
0,53080,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(16384, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,INF,Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.,,
0,53080,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(16384, 1, 1)",0,7.5,WarpStateStats,,,,ThreadDivergence,OPT,"Instructions are executed in warps, which are groups of 32 threads. Optimal instruction throughput is achieved if all 32 threads of a warp execute the same instruction. The chosen launch configuration, early thread completion, and divergent flow control can significantly lower the number of active threads in a warp per cycle. This kernel achieves an average of 16.0 threads being active per cycle.",global,5.203
0,53080,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(16384, 1, 1)",0,7.5,Instruction Statistics,Avg. Executed Instructions Per Scheduler,inst,"3,803.43",,,,,
0,53080,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(16384, 1, 1)",0,7.5,Instruction Statistics,Executed Instructions,inst,"212,992",,,,,
0,53080,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(16384, 1, 1)",0,7.5,Instruction Statistics,Avg. Issued Instructions Per Scheduler,inst,"3,817.07",,,,,
0,53080,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(16384, 1, 1)",0,7.5,Instruction Statistics,Issued Instructions,inst,"213,756",,,,,
0,53080,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(16384, 1, 1)",0,7.5,InstructionStats,,,,FPInstructions,OPT,"This kernel executes 0 fused and 16384 non-fused FP32 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP32 performance could be increased by up to 50% (relative to its current performance). Check the Source page to identify where this kernel executes FP32 instructions.",global,2.089
0,53080,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(16384, 1, 1)",0,7.5,Launch Statistics,Block Size,,16,,,,,
0,53080,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(16384, 1, 1)",0,7.5,Launch Statistics,Function Cache Configuration,,CachePreferNone,,,,,
0,53080,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(16384, 1, 1)",0,7.5,Launch Statistics,Grid Size,,"16,384",,,,,
0,53080,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(16384, 1, 1)",0,7.5,Launch Statistics,Registers Per Thread,register/thread,16,,,,,
0,53080,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(16384, 1, 1)",0,7.5,Launch Statistics,Shared Memory Configuration Size,byte,"32,768",,,,,
0,53080,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(16384, 1, 1)",0,7.5,Launch Statistics,Driver Shared Memory Per Block,byte/block,0,,,,,
0,53080,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(16384, 1, 1)",0,7.5,Launch Statistics,Dynamic Shared Memory Per Block,byte/block,0,,,,,
0,53080,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(16384, 1, 1)",0,7.5,Launch Statistics,Static Shared Memory Per Block,byte/block,0,,,,,
0,53080,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(16384, 1, 1)",0,7.5,Launch Statistics,Threads,thread,"262,144",,,,,
0,53080,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(16384, 1, 1)",0,7.5,Launch Statistics,Waves Per SM,,73.14,,,,,
0,53080,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(16384, 1, 1)",0,7.5,LaunchStats,,,,LaunchConfiguration,OPT,"Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 16 threads per block. Consequently, some threads in a warp are masked off and those hardware resources are unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256 threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to kernels that frequently call __syncthreads(). See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations.",global,50.0
0,53080,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(16384, 1, 1)",0,7.5,Occupancy,Block Limit SM,block,16,,,,,
0,53080,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(16384, 1, 1)",0,7.5,Occupancy,Block Limit Registers,block,128,,,,,
0,53080,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(16384, 1, 1)",0,7.5,Occupancy,Block Limit Shared Mem,block,16,,,,,
0,53080,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(16384, 1, 1)",0,7.5,Occupancy,Block Limit Warps,block,32,,,,,
0,53080,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(16384, 1, 1)",0,7.5,Occupancy,Theoretical Active Warps per SM,warp,16,,,,,
0,53080,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(16384, 1, 1)",0,7.5,Occupancy,Theoretical Occupancy,%,50,,,,,
0,53080,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(16384, 1, 1)",0,7.5,Occupancy,Achieved Occupancy,%,32.09,,,,,
0,53080,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(16384, 1, 1)",0,7.5,Occupancy,Achieved Active Warps Per SM,warp,10.27,,,,,
0,53080,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(16384, 1, 1)",0,7.5,Occupancy,,,,AchievedOccupancy,OPT,The difference between calculated theoretical (50.0%) and measured achieved occupancy (32.1%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy.,global,35.81
0,53080,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(16384, 1, 1)",0,7.5,Occupancy,,,,TheoreticalOccupancy,OPT,The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared memory.,global,50.0
0,53080,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(16384, 1, 1)",0,7.5,Source Counters,Branch Instructions Ratio,%,0.08,,,,,
0,53080,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(16384, 1, 1)",0,7.5,Source Counters,Branch Instructions,inst,"16,384",,,,,
0,53080,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(16384, 1, 1)",0,7.5,Source Counters,Branch Efficiency,%,0,,,,,
0,53080,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(16384, 1, 1)",0,7.5,Source Counters,Avg. Divergent Branches,,0,,,,,
0,53166,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(8192, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Frequency,cycle/second,"5,962,466,487.94",,,,,
0,53166,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(8192, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Frequency,cycle/second,"1,371,718,610.37",,,,,
0,53166,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(8192, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Elapsed Cycles,cycle,"49,225",,,,,
0,53166,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(8192, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Memory Throughput,%,41.28,,,,,
0,53166,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(8192, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Throughput,%,41.28,,,,,
0,53166,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(8192, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Duration,nsecond,"35,808",,,,,
0,53166,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(8192, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L1/TEX Cache Throughput,%,14.17,,,,,
0,53166,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(8192, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L2 Cache Throughput,%,26.19,,,,,
0,53166,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(8192, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Active Cycles,cycle,"39,322.93",,,,,
0,53166,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(8192, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Compute (SM) Throughput,%,9.53,,,,,
0,53166,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(8192, 1, 1)",0,7.5,SpeedOfLight,,,,SOLBottleneck,OPT,This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.,,
0,53166,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(8192, 1, 1)",0,7.5,SpeedOfLight_RooflineChart,,,,SOLFPRoofline,INF,The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved  close to 0% of this device's fp32 peak performance and 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.,,
0,53166,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(8192, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Active,inst/cycle,0.19,,,,,
0,53166,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(8192, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Elapsed,inst/cycle,0.15,,,,,
0,53166,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(8192, 1, 1)",0,7.5,Compute Workload Analysis,Issue Slots Busy,%,4.87,,,,,
0,53166,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(8192, 1, 1)",0,7.5,Compute Workload Analysis,Issued Ipc Active,inst/cycle,0.19,,,,,
0,53166,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(8192, 1, 1)",0,7.5,Compute Workload Analysis,SM Busy,%,4.96,,,,,
0,53166,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(8192, 1, 1)",0,7.5,ComputeWorkloadAnalysis,,,,HighPipeUtilization,OPT,All compute pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.,local,96.28
0,53166,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(8192, 1, 1)",0,7.5,Memory Workload Analysis,Memory Throughput,byte/second,"78,757,819,481.68",,,,,
0,53166,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(8192, 1, 1)",0,7.5,Memory Workload Analysis,Mem Busy,%,26.19,,,,,
0,53166,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(8192, 1, 1)",0,7.5,Memory Workload Analysis,Max Bandwidth,%,41.28,,,,,
0,53166,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(8192, 1, 1)",0,7.5,Memory Workload Analysis,L1/TEX Hit Rate,%,0,,,,,
0,53166,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(8192, 1, 1)",0,7.5,Memory Workload Analysis,L2 Hit Rate,%,33.42,,,,,
0,53166,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(8192, 1, 1)",0,7.5,Memory Workload Analysis,Mem Pipes Busy,%,9.53,,,,,
0,53166,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(8192, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Chart,,,,MemoryL2Compression,WRN,The optional metric lts__average_gcomp_input_sector_success_rate.pct could not be found. Collecting it as an additional metric could enable the rule to provide more guidance.,,
0,53166,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(8192, 1, 1)",0,7.5,Scheduler Statistics,One or More Eligible,%,5.56,,,,,
0,53166,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(8192, 1, 1)",0,7.5,Scheduler Statistics,Issued Warp Per Scheduler,,0.06,,,,,
0,53166,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(8192, 1, 1)",0,7.5,Scheduler Statistics,No Eligible,%,94.44,,,,,
0,53166,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(8192, 1, 1)",0,7.5,Scheduler Statistics,Active Warps Per Scheduler,warp,2.91,,,,,
0,53166,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(8192, 1, 1)",0,7.5,Scheduler Statistics,Eligible Warps Per Scheduler,warp,0.06,,,,,
0,53166,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(8192, 1, 1)",0,7.5,SchedulerStats,,,,IssueSlotUtilization,OPT,"Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 18.0 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of 2.91 active warps per scheduler, but only an average of 0.06 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections.",local,58.72
0,53166,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(8192, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Issued Instruction,cycle,52.31,,,,,
0,53166,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(8192, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Executed Instruction,cycle,52.69,,,,,
0,53166,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(8192, 1, 1)",0,7.5,Warp State Statistics,Avg. Active Threads Per Warp,,32,,,,,
0,53166,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(8192, 1, 1)",0,7.5,Warp State Statistics,Avg. Not Predicated Off Threads Per Warp,,32,,,,,
0,53166,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(8192, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,OPT,"On average, each warp of this kernel spends 43.6 cycles being stalled waiting for a scoreboard dependency on a L1TEX (local, global, surface, texture) operation. Find the instruction producing the data being waited upon to identify the culprit. To reduce the number of cycles waiting on L1TEX data accesses verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit rates by increasing data locality (coalescing), or by changing the cache configuration. Consider moving frequently used data to shared memory. This stall type represents about 83.4% of the total average of 52.3 cycles between issuing two instructions.",global,58.72
0,53166,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(8192, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,INF,Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.,,
0,53166,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(8192, 1, 1)",0,7.5,Instruction Statistics,Avg. Executed Instructions Per Scheduler,inst,"1,901.71",,,,,
0,53166,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(8192, 1, 1)",0,7.5,Instruction Statistics,Executed Instructions,inst,"106,496",,,,,
0,53166,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(8192, 1, 1)",0,7.5,Instruction Statistics,Avg. Issued Instructions Per Scheduler,inst,"1,915.36",,,,,
0,53166,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(8192, 1, 1)",0,7.5,Instruction Statistics,Issued Instructions,inst,"107,260",,,,,
0,53166,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(8192, 1, 1)",0,7.5,InstructionStats,,,,FPInstructions,OPT,"This kernel executes 0 fused and 8192 non-fused FP32 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP32 performance could be increased by up to 50% (relative to its current performance). Check the Source page to identify where this kernel executes FP32 instructions.",global,1.86
0,53166,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(8192, 1, 1)",0,7.5,Launch Statistics,Block Size,,32,,,,,
0,53166,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(8192, 1, 1)",0,7.5,Launch Statistics,Function Cache Configuration,,CachePreferNone,,,,,
0,53166,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(8192, 1, 1)",0,7.5,Launch Statistics,Grid Size,,"8,192",,,,,
0,53166,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(8192, 1, 1)",0,7.5,Launch Statistics,Registers Per Thread,register/thread,16,,,,,
0,53166,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(8192, 1, 1)",0,7.5,Launch Statistics,Shared Memory Configuration Size,byte,"32,768",,,,,
0,53166,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(8192, 1, 1)",0,7.5,Launch Statistics,Driver Shared Memory Per Block,byte/block,0,,,,,
0,53166,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(8192, 1, 1)",0,7.5,Launch Statistics,Dynamic Shared Memory Per Block,byte/block,0,,,,,
0,53166,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(8192, 1, 1)",0,7.5,Launch Statistics,Static Shared Memory Per Block,byte/block,0,,,,,
0,53166,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(8192, 1, 1)",0,7.5,Launch Statistics,Threads,thread,"262,144",,,,,
0,53166,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(8192, 1, 1)",0,7.5,Launch Statistics,Waves Per SM,,36.57,,,,,
0,53166,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(8192, 1, 1)",0,7.5,Occupancy,Block Limit SM,block,16,,,,,
0,53166,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(8192, 1, 1)",0,7.5,Occupancy,Block Limit Registers,block,128,,,,,
0,53166,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(8192, 1, 1)",0,7.5,Occupancy,Block Limit Shared Mem,block,16,,,,,
0,53166,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(8192, 1, 1)",0,7.5,Occupancy,Block Limit Warps,block,32,,,,,
0,53166,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(8192, 1, 1)",0,7.5,Occupancy,Theoretical Active Warps per SM,warp,16,,,,,
0,53166,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(8192, 1, 1)",0,7.5,Occupancy,Theoretical Occupancy,%,50,,,,,
0,53166,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(8192, 1, 1)",0,7.5,Occupancy,Achieved Occupancy,%,33.51,,,,,
0,53166,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(8192, 1, 1)",0,7.5,Occupancy,Achieved Active Warps Per SM,warp,10.72,,,,,
0,53166,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(8192, 1, 1)",0,7.5,Occupancy,,,,AchievedOccupancy,OPT,The difference between calculated theoretical (50.0%) and measured achieved occupancy (33.5%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy.,global,32.98
0,53166,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(8192, 1, 1)",0,7.5,Occupancy,,,,TheoreticalOccupancy,OPT,The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared memory.,global,50.0
0,53166,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(8192, 1, 1)",0,7.5,Source Counters,Branch Instructions Ratio,%,0.08,,,,,
0,53166,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(8192, 1, 1)",0,7.5,Source Counters,Branch Instructions,inst,"8,192",,,,,
0,53166,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(8192, 1, 1)",0,7.5,Source Counters,Branch Efficiency,%,0,,,,,
0,53166,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(8192, 1, 1)",0,7.5,Source Counters,Avg. Divergent Branches,,0,,,,,
0,53252,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(4096, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Frequency,cycle/second,"5,433,715,220.95",,,,,
0,53252,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(4096, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Frequency,cycle/second,"1,246,164,075.29",,,,,
0,53252,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(4096, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Elapsed Cycles,cycle,"24,461",,,,,
0,53252,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(4096, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Memory Throughput,%,80.58,,,,,
0,53252,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(4096, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Throughput,%,80.58,,,,,
0,53252,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(4096, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Duration,nsecond,"19,552",,,,,
0,53252,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(4096, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L1/TEX Cache Throughput,%,25.76,,,,,
0,53252,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(4096, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L2 Cache Throughput,%,52.79,,,,,
0,53252,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(4096, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Active Cycles,cycle,"22,205.57",,,,,
0,53252,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(4096, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Compute (SM) Throughput,%,19.20,,,,,
0,53252,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(4096, 1, 1)",0,7.5,SpeedOfLight,,,,SOLBottleneck,INF,"The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To further improve performance, work will likely need to be shifted from the most utilized to another unit. Start by analyzing DRAM in the Memory Workload Analysis section.",,
0,53252,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(4096, 1, 1)",0,7.5,SpeedOfLight_RooflineChart,,,,SOLFPRoofline,INF,The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved  close to 1% of this device's fp32 peak performance and 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.,,
0,53252,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(4096, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Active,inst/cycle,0.34,,,,,
0,53252,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(4096, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Elapsed,inst/cycle,0.31,,,,,
0,53252,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(4096, 1, 1)",0,7.5,Compute Workload Analysis,Issue Slots Busy,%,8.68,,,,,
0,53252,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(4096, 1, 1)",0,7.5,Compute Workload Analysis,Issued Ipc Active,inst/cycle,0.35,,,,,
0,53252,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(4096, 1, 1)",0,7.5,Compute Workload Analysis,SM Busy,%,8.78,,,,,
0,53252,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(4096, 1, 1)",0,7.5,ComputeWorkloadAnalysis,,,,HighPipeUtilization,OPT,All compute pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.,local,93.41
0,53252,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(4096, 1, 1)",0,7.5,Memory Workload Analysis,Memory Throughput,byte/second,"140,108,019,639.93",,,,,
0,53252,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(4096, 1, 1)",0,7.5,Memory Workload Analysis,Mem Busy,%,52.79,,,,,
0,53252,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(4096, 1, 1)",0,7.5,Memory Workload Analysis,Max Bandwidth,%,80.58,,,,,
0,53252,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(4096, 1, 1)",0,7.5,Memory Workload Analysis,L1/TEX Hit Rate,%,0,,,,,
0,53252,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(4096, 1, 1)",0,7.5,Memory Workload Analysis,L2 Hit Rate,%,33.45,,,,,
0,53252,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(4096, 1, 1)",0,7.5,Memory Workload Analysis,Mem Pipes Busy,%,19.20,,,,,
0,53252,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(4096, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Chart,,,,MemoryL2Compression,WRN,The optional metric lts__average_gcomp_input_sector_success_rate.pct could not be found. Collecting it as an additional metric could enable the rule to provide more guidance.,,
0,53252,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(4096, 1, 1)",0,7.5,Scheduler Statistics,One or More Eligible,%,8.70,,,,,
0,53252,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(4096, 1, 1)",0,7.5,Scheduler Statistics,Issued Warp Per Scheduler,,0.09,,,,,
0,53252,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(4096, 1, 1)",0,7.5,Scheduler Statistics,No Eligible,%,91.30,,,,,
0,53252,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(4096, 1, 1)",0,7.5,Scheduler Statistics,Active Warps Per Scheduler,warp,6.24,,,,,
0,53252,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(4096, 1, 1)",0,7.5,Scheduler Statistics,Eligible Warps Per Scheduler,warp,0.10,,,,,
0,53252,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(4096, 1, 1)",0,7.5,SchedulerStats,,,,IssueSlotUtilization,OPT,"Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 11.5 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of 6.24 active warps per scheduler, but only an average of 0.10 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections.",local,19.42
0,53252,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(4096, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Issued Instruction,cycle,71.67,,,,,
0,53252,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(4096, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Executed Instruction,cycle,72.62,,,,,
0,53252,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(4096, 1, 1)",0,7.5,Warp State Statistics,Avg. Active Threads Per Warp,,32,,,,,
0,53252,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(4096, 1, 1)",0,7.5,Warp State Statistics,Avg. Not Predicated Off Threads Per Warp,,32,,,,,
0,53252,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(4096, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,OPT,"On average, each warp of this kernel spends 59.5 cycles being stalled waiting for a scoreboard dependency on a L1TEX (local, global, surface, texture) operation. Find the instruction producing the data being waited upon to identify the culprit. To reduce the number of cycles waiting on L1TEX data accesses verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit rates by increasing data locality (coalescing), or by changing the cache configuration. Consider moving frequently used data to shared memory. This stall type represents about 83.1% of the total average of 71.7 cycles between issuing two instructions.",global,19.42
0,53252,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(4096, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,INF,Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.,,
0,53252,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(4096, 1, 1)",0,7.5,Instruction Statistics,Avg. Executed Instructions Per Scheduler,inst,"1,901.71",,,,,
0,53252,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(4096, 1, 1)",0,7.5,Instruction Statistics,Executed Instructions,inst,"106,496",,,,,
0,53252,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(4096, 1, 1)",0,7.5,Instruction Statistics,Avg. Issued Instructions Per Scheduler,inst,"1,926.75",,,,,
0,53252,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(4096, 1, 1)",0,7.5,Instruction Statistics,Issued Instructions,inst,"107,898",,,,,
0,53252,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(4096, 1, 1)",0,7.5,InstructionStats,,,,FPInstructions,OPT,"This kernel executes 0 fused and 8192 non-fused FP32 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP32 performance could be increased by up to 50% (relative to its current performance). Check the Source page to identify where this kernel executes FP32 instructions.",global,3.294
0,53252,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(4096, 1, 1)",0,7.5,Launch Statistics,Block Size,,64,,,,,
0,53252,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(4096, 1, 1)",0,7.5,Launch Statistics,Function Cache Configuration,,CachePreferNone,,,,,
0,53252,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(4096, 1, 1)",0,7.5,Launch Statistics,Grid Size,,"4,096",,,,,
0,53252,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(4096, 1, 1)",0,7.5,Launch Statistics,Registers Per Thread,register/thread,16,,,,,
0,53252,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(4096, 1, 1)",0,7.5,Launch Statistics,Shared Memory Configuration Size,byte,"32,768",,,,,
0,53252,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(4096, 1, 1)",0,7.5,Launch Statistics,Driver Shared Memory Per Block,byte/block,0,,,,,
0,53252,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(4096, 1, 1)",0,7.5,Launch Statistics,Dynamic Shared Memory Per Block,byte/block,0,,,,,
0,53252,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(4096, 1, 1)",0,7.5,Launch Statistics,Static Shared Memory Per Block,byte/block,0,,,,,
0,53252,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(4096, 1, 1)",0,7.5,Launch Statistics,Threads,thread,"262,144",,,,,
0,53252,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(4096, 1, 1)",0,7.5,Launch Statistics,Waves Per SM,,18.29,,,,,
0,53252,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(4096, 1, 1)",0,7.5,Occupancy,Block Limit SM,block,16,,,,,
0,53252,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(4096, 1, 1)",0,7.5,Occupancy,Block Limit Registers,block,64,,,,,
0,53252,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(4096, 1, 1)",0,7.5,Occupancy,Block Limit Shared Mem,block,16,,,,,
0,53252,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(4096, 1, 1)",0,7.5,Occupancy,Block Limit Warps,block,16,,,,,
0,53252,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(4096, 1, 1)",0,7.5,Occupancy,Theoretical Active Warps per SM,warp,32,,,,,
0,53252,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(4096, 1, 1)",0,7.5,Occupancy,Theoretical Occupancy,%,100,,,,,
0,53252,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(4096, 1, 1)",0,7.5,Occupancy,Achieved Occupancy,%,76.93,,,,,
0,53252,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(4096, 1, 1)",0,7.5,Occupancy,Achieved Active Warps Per SM,warp,24.62,,,,,
0,53252,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(4096, 1, 1)",0,7.5,Occupancy,,,,AchievedOccupancy,OPT,The difference between calculated theoretical (100.0%) and measured achieved occupancy (76.9%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy.,global,19.42
0,53252,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(4096, 1, 1)",0,7.5,Source Counters,Branch Instructions Ratio,%,0.08,,,,,
0,53252,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(4096, 1, 1)",0,7.5,Source Counters,Branch Instructions,inst,"8,192",,,,,
0,53252,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(4096, 1, 1)",0,7.5,Source Counters,Branch Efficiency,%,0,,,,,
0,53252,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(4096, 1, 1)",0,7.5,Source Counters,Avg. Divergent Branches,,0,,,,,
0,53329,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(2048, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Frequency,cycle/second,"5,193,442,622.95",,,,,
0,53329,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(2048, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Frequency,cycle/second,"1,191,265,368.85",,,,,
0,53329,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(2048, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Elapsed Cycles,cycle,"23,313",,,,,
0,53329,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(2048, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Memory Throughput,%,83.65,,,,,
0,53329,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(2048, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Throughput,%,83.65,,,,,
0,53329,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(2048, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Duration,nsecond,"19,520",,,,,
0,53329,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(2048, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L1/TEX Cache Throughput,%,26.64,,,,,
0,53329,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(2048, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L2 Cache Throughput,%,55.37,,,,,
0,53329,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(2048, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Active Cycles,cycle,"21,700.21",,,,,
0,53329,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(2048, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Compute (SM) Throughput,%,20.12,,,,,
0,53329,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(2048, 1, 1)",0,7.5,SpeedOfLight,,,,SOLBottleneck,INF,"The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To further improve performance, work will likely need to be shifted from the most utilized to another unit. Start by analyzing DRAM in the Memory Workload Analysis section.",,
0,53329,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(2048, 1, 1)",0,7.5,SpeedOfLight_RooflineChart,,,,SOLFPRoofline,INF,The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved  close to 1% of this device's fp32 peak performance and 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.,,
0,53329,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(2048, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Active,inst/cycle,0.35,,,,,
0,53329,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(2048, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Elapsed,inst/cycle,0.33,,,,,
0,53329,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(2048, 1, 1)",0,7.5,Compute Workload Analysis,Issue Slots Busy,%,8.91,,,,,
0,53329,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(2048, 1, 1)",0,7.5,Compute Workload Analysis,Issued Ipc Active,inst/cycle,0.36,,,,,
0,53329,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(2048, 1, 1)",0,7.5,Compute Workload Analysis,SM Busy,%,8.99,,,,,
0,53329,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(2048, 1, 1)",0,7.5,ComputeWorkloadAnalysis,,,,HighPipeUtilization,OPT,All compute pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.,local,93.26
0,53329,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(2048, 1, 1)",0,7.5,Memory Workload Analysis,Memory Throughput,byte/second,"139,026,229,508.20",,,,,
0,53329,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(2048, 1, 1)",0,7.5,Memory Workload Analysis,Mem Busy,%,55.37,,,,,
0,53329,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(2048, 1, 1)",0,7.5,Memory Workload Analysis,Max Bandwidth,%,83.65,,,,,
0,53329,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(2048, 1, 1)",0,7.5,Memory Workload Analysis,L1/TEX Hit Rate,%,0,,,,,
0,53329,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(2048, 1, 1)",0,7.5,Memory Workload Analysis,L2 Hit Rate,%,33.45,,,,,
0,53329,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(2048, 1, 1)",0,7.5,Memory Workload Analysis,Mem Pipes Busy,%,20.12,,,,,
0,53329,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(2048, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Chart,,,,MemoryL2Compression,WRN,The optional metric lts__average_gcomp_input_sector_success_rate.pct could not be found. Collecting it as an additional metric could enable the rule to provide more guidance.,,
0,53329,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(2048, 1, 1)",0,7.5,Scheduler Statistics,One or More Eligible,%,9.02,,,,,
0,53329,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(2048, 1, 1)",0,7.5,Scheduler Statistics,Issued Warp Per Scheduler,,0.09,,,,,
0,53329,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(2048, 1, 1)",0,7.5,Scheduler Statistics,No Eligible,%,90.98,,,,,
0,53329,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(2048, 1, 1)",0,7.5,Scheduler Statistics,Active Warps Per Scheduler,warp,6.66,,,,,
0,53329,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(2048, 1, 1)",0,7.5,Scheduler Statistics,Eligible Warps Per Scheduler,warp,0.10,,,,,
0,53329,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(2048, 1, 1)",0,7.5,SchedulerStats,,,,IssueSlotUtilization,OPT,"Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 11.1 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of 6.66 active warps per scheduler, but only an average of 0.10 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, avoid possible load imbalances due to highly different execution durations per warp. Reducing stalls indicated on the Warp State Statistics and Source Counters sections can help, too.",local,16.35
0,53329,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(2048, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Issued Instruction,cycle,73.82,,,,,
0,53329,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(2048, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Executed Instruction,cycle,75.07,,,,,
0,53329,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(2048, 1, 1)",0,7.5,Warp State Statistics,Avg. Active Threads Per Warp,,32,,,,,
0,53329,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(2048, 1, 1)",0,7.5,Warp State Statistics,Avg. Not Predicated Off Threads Per Warp,,32,,,,,
0,53329,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(2048, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,OPT,"On average, each warp of this kernel spends 63.1 cycles being stalled waiting for a scoreboard dependency on a L1TEX (local, global, surface, texture) operation. Find the instruction producing the data being waited upon to identify the culprit. To reduce the number of cycles waiting on L1TEX data accesses verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit rates by increasing data locality (coalescing), or by changing the cache configuration. Consider moving frequently used data to shared memory. This stall type represents about 85.4% of the total average of 73.8 cycles between issuing two instructions.",global,16.35
0,53329,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(2048, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,INF,Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.,,
0,53329,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(2048, 1, 1)",0,7.5,Instruction Statistics,Avg. Executed Instructions Per Scheduler,inst,"1,901.71",,,,,
0,53329,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(2048, 1, 1)",0,7.5,Instruction Statistics,Executed Instructions,inst,"106,496",,,,,
0,53329,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(2048, 1, 1)",0,7.5,Instruction Statistics,Avg. Issued Instructions Per Scheduler,inst,"1,933.71",,,,,
0,53329,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(2048, 1, 1)",0,7.5,Instruction Statistics,Issued Instructions,inst,"108,288",,,,,
0,53329,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(2048, 1, 1)",0,7.5,InstructionStats,,,,FPInstructions,OPT,"This kernel executes 0 fused and 8192 non-fused FP32 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP32 performance could be increased by up to 50% (relative to its current performance). Check the Source page to identify where this kernel executes FP32 instructions.",global,3.371
0,53329,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(2048, 1, 1)",0,7.5,Launch Statistics,Block Size,,128,,,,,
0,53329,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(2048, 1, 1)",0,7.5,Launch Statistics,Function Cache Configuration,,CachePreferNone,,,,,
0,53329,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(2048, 1, 1)",0,7.5,Launch Statistics,Grid Size,,"2,048",,,,,
0,53329,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(2048, 1, 1)",0,7.5,Launch Statistics,Registers Per Thread,register/thread,16,,,,,
0,53329,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(2048, 1, 1)",0,7.5,Launch Statistics,Shared Memory Configuration Size,byte,"32,768",,,,,
0,53329,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(2048, 1, 1)",0,7.5,Launch Statistics,Driver Shared Memory Per Block,byte/block,0,,,,,
0,53329,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(2048, 1, 1)",0,7.5,Launch Statistics,Dynamic Shared Memory Per Block,byte/block,0,,,,,
0,53329,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(2048, 1, 1)",0,7.5,Launch Statistics,Static Shared Memory Per Block,byte/block,0,,,,,
0,53329,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(2048, 1, 1)",0,7.5,Launch Statistics,Threads,thread,"262,144",,,,,
0,53329,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(2048, 1, 1)",0,7.5,Launch Statistics,Waves Per SM,,18.29,,,,,
0,53329,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(2048, 1, 1)",0,7.5,Occupancy,Block Limit SM,block,16,,,,,
0,53329,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(2048, 1, 1)",0,7.5,Occupancy,Block Limit Registers,block,32,,,,,
0,53329,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(2048, 1, 1)",0,7.5,Occupancy,Block Limit Shared Mem,block,16,,,,,
0,53329,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(2048, 1, 1)",0,7.5,Occupancy,Block Limit Warps,block,8,,,,,
0,53329,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(2048, 1, 1)",0,7.5,Occupancy,Theoretical Active Warps per SM,warp,32,,,,,
0,53329,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(2048, 1, 1)",0,7.5,Occupancy,Theoretical Occupancy,%,100,,,,,
0,53329,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(2048, 1, 1)",0,7.5,Occupancy,Achieved Occupancy,%,84.42,,,,,
0,53329,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(2048, 1, 1)",0,7.5,Occupancy,Achieved Active Warps Per SM,warp,27.01,,,,,
0,53329,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(2048, 1, 1)",0,7.5,Occupancy,,,,AchievedOccupancy,OPT,The difference between calculated theoretical (100.0%) and measured achieved occupancy (84.4%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy.,global,15.58
0,53329,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(2048, 1, 1)",0,7.5,Source Counters,Branch Instructions Ratio,%,0.08,,,,,
0,53329,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(2048, 1, 1)",0,7.5,Source Counters,Branch Instructions,inst,"8,192",,,,,
0,53329,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(2048, 1, 1)",0,7.5,Source Counters,Branch Efficiency,%,0,,,,,
0,53329,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(2048, 1, 1)",0,7.5,Source Counters,Avg. Divergent Branches,,0,,,,,
0,53415,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(1024, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Frequency,cycle/second,"5,342,148,760.33",,,,,
0,53415,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(1024, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Frequency,cycle/second,"1,223,915,289.26",,,,,
0,53415,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(1024, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Elapsed Cycles,cycle,"23,774",,,,,
0,53415,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(1024, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Memory Throughput,%,82.54,,,,,
0,53415,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(1024, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Throughput,%,82.54,,,,,
0,53415,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(1024, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Duration,nsecond,"19,360",,,,,
0,53415,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(1024, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L1/TEX Cache Throughput,%,25.84,,,,,
0,53415,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(1024, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L2 Cache Throughput,%,54.31,,,,,
0,53415,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(1024, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Active Cycles,cycle,"21,823.21",,,,,
0,53415,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(1024, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Compute (SM) Throughput,%,19.75,,,,,
0,53415,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(1024, 1, 1)",0,7.5,SpeedOfLight,,,,SOLBottleneck,INF,"The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To further improve performance, work will likely need to be shifted from the most utilized to another unit. Start by analyzing DRAM in the Memory Workload Analysis section.",,
0,53415,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(1024, 1, 1)",0,7.5,SpeedOfLight_RooflineChart,,,,SOLFPRoofline,INF,The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved  close to 1% of this device's fp32 peak performance and 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.,,
0,53415,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(1024, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Active,inst/cycle,0.35,,,,,
0,53415,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(1024, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Elapsed,inst/cycle,0.32,,,,,
0,53415,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(1024, 1, 1)",0,7.5,Compute Workload Analysis,Issue Slots Busy,%,8.86,,,,,
0,53415,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(1024, 1, 1)",0,7.5,Compute Workload Analysis,Issued Ipc Active,inst/cycle,0.35,,,,,
0,53415,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(1024, 1, 1)",0,7.5,Compute Workload Analysis,SM Busy,%,8.94,,,,,
0,53415,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(1024, 1, 1)",0,7.5,ComputeWorkloadAnalysis,,,,HighPipeUtilization,OPT,All compute pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.,local,93.3
0,53415,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(1024, 1, 1)",0,7.5,Memory Workload Analysis,Memory Throughput,byte/second,"141,102,479,338.84",,,,,
0,53415,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(1024, 1, 1)",0,7.5,Memory Workload Analysis,Mem Busy,%,54.31,,,,,
0,53415,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(1024, 1, 1)",0,7.5,Memory Workload Analysis,Max Bandwidth,%,82.54,,,,,
0,53415,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(1024, 1, 1)",0,7.5,Memory Workload Analysis,L1/TEX Hit Rate,%,0,,,,,
0,53415,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(1024, 1, 1)",0,7.5,Memory Workload Analysis,L2 Hit Rate,%,33.52,,,,,
0,53415,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(1024, 1, 1)",0,7.5,Memory Workload Analysis,Mem Pipes Busy,%,19.75,,,,,
0,53415,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(1024, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Chart,,,,MemoryL2Compression,WRN,The optional metric lts__average_gcomp_input_sector_success_rate.pct could not be found. Collecting it as an additional metric could enable the rule to provide more guidance.,,
0,53415,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(1024, 1, 1)",0,7.5,Scheduler Statistics,One or More Eligible,%,8.85,,,,,
0,53415,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(1024, 1, 1)",0,7.5,Scheduler Statistics,Issued Warp Per Scheduler,,0.09,,,,,
0,53415,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(1024, 1, 1)",0,7.5,Scheduler Statistics,No Eligible,%,91.15,,,,,
0,53415,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(1024, 1, 1)",0,7.5,Scheduler Statistics,Active Warps Per Scheduler,warp,6.46,,,,,
0,53415,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(1024, 1, 1)",0,7.5,Scheduler Statistics,Eligible Warps Per Scheduler,warp,0.11,,,,,
0,53415,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(1024, 1, 1)",0,7.5,SchedulerStats,,,,IssueSlotUtilization,OPT,"Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 11.3 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of 6.46 active warps per scheduler, but only an average of 0.11 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, avoid possible load imbalances due to highly different execution durations per warp. Reducing stalls indicated on the Warp State Statistics and Source Counters sections can help, too.",local,17.46
0,53415,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(1024, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Issued Instruction,cycle,73.04,,,,,
0,53415,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(1024, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Executed Instruction,cycle,74.25,,,,,
0,53415,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(1024, 1, 1)",0,7.5,Warp State Statistics,Avg. Active Threads Per Warp,,32,,,,,
0,53415,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(1024, 1, 1)",0,7.5,Warp State Statistics,Avg. Not Predicated Off Threads Per Warp,,32,,,,,
0,53415,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(1024, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,OPT,"On average, each warp of this kernel spends 61.3 cycles being stalled waiting for a scoreboard dependency on a L1TEX (local, global, surface, texture) operation. Find the instruction producing the data being waited upon to identify the culprit. To reduce the number of cycles waiting on L1TEX data accesses verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit rates by increasing data locality (coalescing), or by changing the cache configuration. Consider moving frequently used data to shared memory. This stall type represents about 83.9% of the total average of 73.0 cycles between issuing two instructions.",global,17.46
0,53415,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(1024, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,INF,Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.,,
0,53415,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(1024, 1, 1)",0,7.5,Instruction Statistics,Avg. Executed Instructions Per Scheduler,inst,"1,901.71",,,,,
0,53415,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(1024, 1, 1)",0,7.5,Instruction Statistics,Executed Instructions,inst,"106,496",,,,,
0,53415,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(1024, 1, 1)",0,7.5,Instruction Statistics,Avg. Issued Instructions Per Scheduler,inst,"1,933.21",,,,,
0,53415,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(1024, 1, 1)",0,7.5,Instruction Statistics,Issued Instructions,inst,"108,260",,,,,
0,53415,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(1024, 1, 1)",0,7.5,InstructionStats,,,,FPInstructions,OPT,"This kernel executes 0 fused and 8192 non-fused FP32 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP32 performance could be increased by up to 50% (relative to its current performance). Check the Source page to identify where this kernel executes FP32 instructions.",global,3.352
0,53415,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(1024, 1, 1)",0,7.5,Launch Statistics,Block Size,,256,,,,,
0,53415,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(1024, 1, 1)",0,7.5,Launch Statistics,Function Cache Configuration,,CachePreferNone,,,,,
0,53415,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(1024, 1, 1)",0,7.5,Launch Statistics,Grid Size,,"1,024",,,,,
0,53415,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(1024, 1, 1)",0,7.5,Launch Statistics,Registers Per Thread,register/thread,16,,,,,
0,53415,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(1024, 1, 1)",0,7.5,Launch Statistics,Shared Memory Configuration Size,byte,"32,768",,,,,
0,53415,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(1024, 1, 1)",0,7.5,Launch Statistics,Driver Shared Memory Per Block,byte/block,0,,,,,
0,53415,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(1024, 1, 1)",0,7.5,Launch Statistics,Dynamic Shared Memory Per Block,byte/block,0,,,,,
0,53415,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(1024, 1, 1)",0,7.5,Launch Statistics,Static Shared Memory Per Block,byte/block,0,,,,,
0,53415,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(1024, 1, 1)",0,7.5,Launch Statistics,Threads,thread,"262,144",,,,,
0,53415,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(1024, 1, 1)",0,7.5,Launch Statistics,Waves Per SM,,18.29,,,,,
0,53415,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(1024, 1, 1)",0,7.5,Occupancy,Block Limit SM,block,16,,,,,
0,53415,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(1024, 1, 1)",0,7.5,Occupancy,Block Limit Registers,block,16,,,,,
0,53415,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(1024, 1, 1)",0,7.5,Occupancy,Block Limit Shared Mem,block,16,,,,,
0,53415,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(1024, 1, 1)",0,7.5,Occupancy,Block Limit Warps,block,4,,,,,
0,53415,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(1024, 1, 1)",0,7.5,Occupancy,Theoretical Active Warps per SM,warp,32,,,,,
0,53415,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(1024, 1, 1)",0,7.5,Occupancy,Theoretical Occupancy,%,100,,,,,
0,53415,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(1024, 1, 1)",0,7.5,Occupancy,Achieved Occupancy,%,82.50,,,,,
0,53415,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(1024, 1, 1)",0,7.5,Occupancy,Achieved Active Warps Per SM,warp,26.40,,,,,
0,53415,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(1024, 1, 1)",0,7.5,Occupancy,,,,AchievedOccupancy,OPT,The difference between calculated theoretical (100.0%) and measured achieved occupancy (82.5%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy.,global,17.46
0,53415,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(1024, 1, 1)",0,7.5,Source Counters,Branch Instructions Ratio,%,0.08,,,,,
0,53415,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(1024, 1, 1)",0,7.5,Source Counters,Branch Instructions,inst,"8,192",,,,,
0,53415,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(1024, 1, 1)",0,7.5,Source Counters,Branch Efficiency,%,0,,,,,
0,53415,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(1024, 1, 1)",0,7.5,Source Counters,Avg. Divergent Branches,,0,,,,,
0,53509,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(512, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Frequency,cycle/second,"5,415,986,949.43",,,,,
0,53509,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(512, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Frequency,cycle/second,"1,242,659,053.83",,,,,
0,53509,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(512, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Elapsed Cycles,cycle,"24,484",,,,,
0,53509,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(512, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Memory Throughput,%,80.72,,,,,
0,53509,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(512, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Throughput,%,80.72,,,,,
0,53509,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(512, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Duration,nsecond,"19,616",,,,,
0,53509,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(512, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L1/TEX Cache Throughput,%,24.60,,,,,
0,53509,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(512, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L2 Cache Throughput,%,52.74,,,,,
0,53509,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(512, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Active Cycles,cycle,"22,269.57",,,,,
0,53509,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(512, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Compute (SM) Throughput,%,19.19,,,,,
0,53509,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(512, 1, 1)",0,7.5,SpeedOfLight,,,,SOLBottleneck,INF,"The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To further improve performance, work will likely need to be shifted from the most utilized to another unit. Start by analyzing DRAM in the Memory Workload Analysis section.",,
0,53509,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(512, 1, 1)",0,7.5,SpeedOfLight_RooflineChart,,,,SOLFPRoofline,INF,The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved  close to 1% of this device's fp32 peak performance and 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.,,
0,53509,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(512, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Active,inst/cycle,0.34,,,,,
0,53509,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(512, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Elapsed,inst/cycle,0.31,,,,,
0,53509,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(512, 1, 1)",0,7.5,Compute Workload Analysis,Issue Slots Busy,%,8.68,,,,,
0,53509,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(512, 1, 1)",0,7.5,Compute Workload Analysis,Issued Ipc Active,inst/cycle,0.35,,,,,
0,53509,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(512, 1, 1)",0,7.5,Compute Workload Analysis,SM Busy,%,8.76,,,,,
0,53509,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(512, 1, 1)",0,7.5,ComputeWorkloadAnalysis,,,,HighPipeUtilization,OPT,All compute pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.,local,93.43
0,53509,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(512, 1, 1)",0,7.5,Memory Workload Analysis,Memory Throughput,byte/second,"139,905,383,360.52",,,,,
0,53509,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(512, 1, 1)",0,7.5,Memory Workload Analysis,Mem Busy,%,52.74,,,,,
0,53509,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(512, 1, 1)",0,7.5,Memory Workload Analysis,Max Bandwidth,%,80.72,,,,,
0,53509,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(512, 1, 1)",0,7.5,Memory Workload Analysis,L1/TEX Hit Rate,%,0,,,,,
0,53509,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(512, 1, 1)",0,7.5,Memory Workload Analysis,L2 Hit Rate,%,33.42,,,,,
0,53509,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(512, 1, 1)",0,7.5,Memory Workload Analysis,Mem Pipes Busy,%,19.19,,,,,
0,53509,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(512, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Chart,,,,MemoryL2Compression,WRN,The optional metric lts__average_gcomp_input_sector_success_rate.pct could not be found. Collecting it as an additional metric could enable the rule to provide more guidance.,,
0,53509,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(512, 1, 1)",0,7.5,Scheduler Statistics,One or More Eligible,%,8.82,,,,,
0,53509,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(512, 1, 1)",0,7.5,Scheduler Statistics,Issued Warp Per Scheduler,,0.09,,,,,
0,53509,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(512, 1, 1)",0,7.5,Scheduler Statistics,No Eligible,%,91.18,,,,,
0,53509,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(512, 1, 1)",0,7.5,Scheduler Statistics,Active Warps Per Scheduler,warp,6.56,,,,,
0,53509,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(512, 1, 1)",0,7.5,Scheduler Statistics,Eligible Warps Per Scheduler,warp,0.12,,,,,
0,53509,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(512, 1, 1)",0,7.5,SchedulerStats,,,,IssueSlotUtilization,OPT,"Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 11.3 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of 6.56 active warps per scheduler, but only an average of 0.12 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, avoid possible load imbalances due to highly different execution durations per warp. Reducing stalls indicated on the Warp State Statistics and Source Counters sections can help, too.",local,19.28
0,53509,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(512, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Issued Instruction,cycle,74.38,,,,,
0,53509,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(512, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Executed Instruction,cycle,75.63,,,,,
0,53509,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(512, 1, 1)",0,7.5,Warp State Statistics,Avg. Active Threads Per Warp,,32,,,,,
0,53509,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(512, 1, 1)",0,7.5,Warp State Statistics,Avg. Not Predicated Off Threads Per Warp,,32,,,,,
0,53509,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(512, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,OPT,"On average, each warp of this kernel spends 60.6 cycles being stalled waiting for a scoreboard dependency on a L1TEX (local, global, surface, texture) operation. Find the instruction producing the data being waited upon to identify the culprit. To reduce the number of cycles waiting on L1TEX data accesses verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit rates by increasing data locality (coalescing), or by changing the cache configuration. Consider moving frequently used data to shared memory. This stall type represents about 81.4% of the total average of 74.4 cycles between issuing two instructions.",global,19.28
0,53509,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(512, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,INF,Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.,,
0,53509,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(512, 1, 1)",0,7.5,Instruction Statistics,Avg. Executed Instructions Per Scheduler,inst,"1,901.71",,,,,
0,53509,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(512, 1, 1)",0,7.5,Instruction Statistics,Executed Instructions,inst,"106,496",,,,,
0,53509,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(512, 1, 1)",0,7.5,Instruction Statistics,Avg. Issued Instructions Per Scheduler,inst,"1,933.71",,,,,
0,53509,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(512, 1, 1)",0,7.5,Instruction Statistics,Issued Instructions,inst,"108,288",,,,,
0,53509,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(512, 1, 1)",0,7.5,InstructionStats,,,,FPInstructions,OPT,"This kernel executes 0 fused and 8192 non-fused FP32 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP32 performance could be increased by up to 50% (relative to its current performance). Check the Source page to identify where this kernel executes FP32 instructions.",global,3.284
0,53509,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(512, 1, 1)",0,7.5,Launch Statistics,Block Size,,512,,,,,
0,53509,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(512, 1, 1)",0,7.5,Launch Statistics,Function Cache Configuration,,CachePreferNone,,,,,
0,53509,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(512, 1, 1)",0,7.5,Launch Statistics,Grid Size,,512,,,,,
0,53509,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(512, 1, 1)",0,7.5,Launch Statistics,Registers Per Thread,register/thread,16,,,,,
0,53509,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(512, 1, 1)",0,7.5,Launch Statistics,Shared Memory Configuration Size,byte,"32,768",,,,,
0,53509,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(512, 1, 1)",0,7.5,Launch Statistics,Driver Shared Memory Per Block,byte/block,0,,,,,
0,53509,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(512, 1, 1)",0,7.5,Launch Statistics,Dynamic Shared Memory Per Block,byte/block,0,,,,,
0,53509,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(512, 1, 1)",0,7.5,Launch Statistics,Static Shared Memory Per Block,byte/block,0,,,,,
0,53509,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(512, 1, 1)",0,7.5,Launch Statistics,Threads,thread,"262,144",,,,,
0,53509,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(512, 1, 1)",0,7.5,Launch Statistics,Waves Per SM,,18.29,,,,,
0,53509,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(512, 1, 1)",0,7.5,Occupancy,Block Limit SM,block,16,,,,,
0,53509,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(512, 1, 1)",0,7.5,Occupancy,Block Limit Registers,block,8,,,,,
0,53509,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(512, 1, 1)",0,7.5,Occupancy,Block Limit Shared Mem,block,16,,,,,
0,53509,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(512, 1, 1)",0,7.5,Occupancy,Block Limit Warps,block,2,,,,,
0,53509,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(512, 1, 1)",0,7.5,Occupancy,Theoretical Active Warps per SM,warp,32,,,,,
0,53509,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(512, 1, 1)",0,7.5,Occupancy,Theoretical Occupancy,%,100,,,,,
0,53509,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(512, 1, 1)",0,7.5,Occupancy,Achieved Occupancy,%,81.86,,,,,
0,53509,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(512, 1, 1)",0,7.5,Occupancy,Achieved Active Warps Per SM,warp,26.20,,,,,
0,53509,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(512, 1, 1)",0,7.5,Occupancy,,,,AchievedOccupancy,OPT,The difference between calculated theoretical (100.0%) and measured achieved occupancy (81.9%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy.,global,18.14
0,53509,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(512, 1, 1)",0,7.5,Source Counters,Branch Instructions Ratio,%,0.08,,,,,
0,53509,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(512, 1, 1)",0,7.5,Source Counters,Branch Instructions,inst,"8,192",,,,,
0,53509,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(512, 1, 1)",0,7.5,Source Counters,Branch Efficiency,%,0,,,,,
0,53509,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(512, 1, 1)",0,7.5,Source Counters,Avg. Divergent Branches,,0,,,,,
0,53586,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(256, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Frequency,cycle/second,"5,540,412,044.37",,,,,
0,53586,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(256, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Frequency,cycle/second,"1,268,794,572.11",,,,,
0,53586,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(256, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Elapsed Cycles,cycle,"25,705",,,,,
0,53586,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(256, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Memory Throughput,%,77.12,,,,,
0,53586,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(256, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Throughput,%,77.12,,,,,
0,53586,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(256, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Duration,nsecond,"20,192",,,,,
0,53586,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(256, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L1/TEX Cache Throughput,%,22.99,,,,,
0,53586,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(256, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L2 Cache Throughput,%,50.18,,,,,
0,53586,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(256, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Active Cycles,cycle,"21,584.86",,,,,
0,53586,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(256, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Compute (SM) Throughput,%,18.26,,,,,
0,53586,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(256, 1, 1)",0,7.5,SpeedOfLight,,,,SOLBottleneck,OPT,Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or whether there are values you can (re)compute.,,
0,53586,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(256, 1, 1)",0,7.5,SpeedOfLight_RooflineChart,,,,SOLFPRoofline,INF,The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved  close to 1% of this device's fp32 peak performance and 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.,,
0,53586,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(256, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Active,inst/cycle,0.35,,,,,
0,53586,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(256, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Elapsed,inst/cycle,0.30,,,,,
0,53586,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(256, 1, 1)",0,7.5,Compute Workload Analysis,Issue Slots Busy,%,8.96,,,,,
0,53586,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(256, 1, 1)",0,7.5,Compute Workload Analysis,Issued Ipc Active,inst/cycle,0.36,,,,,
0,53586,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(256, 1, 1)",0,7.5,Compute Workload Analysis,SM Busy,%,9.04,,,,,
0,53586,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(256, 1, 1)",0,7.5,ComputeWorkloadAnalysis,,,,HighPipeUtilization,OPT,All compute pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.,local,93.22
0,53586,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(256, 1, 1)",0,7.5,Memory Workload Analysis,Memory Throughput,byte/second,"136,722,662,440.57",,,,,
0,53586,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(256, 1, 1)",0,7.5,Memory Workload Analysis,Mem Busy,%,50.18,,,,,
0,53586,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(256, 1, 1)",0,7.5,Memory Workload Analysis,Max Bandwidth,%,77.12,,,,,
0,53586,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(256, 1, 1)",0,7.5,Memory Workload Analysis,L1/TEX Hit Rate,%,0,,,,,
0,53586,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(256, 1, 1)",0,7.5,Memory Workload Analysis,L2 Hit Rate,%,33.52,,,,,
0,53586,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(256, 1, 1)",0,7.5,Memory Workload Analysis,Mem Pipes Busy,%,18.26,,,,,
0,53586,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(256, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Chart,,,,MemoryL2Compression,WRN,The optional metric lts__average_gcomp_input_sector_success_rate.pct could not be found. Collecting it as an additional metric could enable the rule to provide more guidance.,,
0,53586,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(256, 1, 1)",0,7.5,Scheduler Statistics,One or More Eligible,%,9.23,,,,,
0,53586,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(256, 1, 1)",0,7.5,Scheduler Statistics,Issued Warp Per Scheduler,,0.09,,,,,
0,53586,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(256, 1, 1)",0,7.5,Scheduler Statistics,No Eligible,%,90.77,,,,,
0,53586,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(256, 1, 1)",0,7.5,Scheduler Statistics,Active Warps Per Scheduler,warp,7.17,,,,,
0,53586,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(256, 1, 1)",0,7.5,Scheduler Statistics,Eligible Warps Per Scheduler,warp,0.21,,,,,
0,53586,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(256, 1, 1)",0,7.5,SchedulerStats,,,,IssueSlotUtilization,OPT,"Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 10.8 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of 7.17 active warps per scheduler, but only an average of 0.21 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, avoid possible load imbalances due to highly different execution durations per warp. Reducing stalls indicated on the Warp State Statistics and Source Counters sections can help, too.",local,22.88
0,53586,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(256, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Issued Instruction,cycle,77.64,,,,,
0,53586,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(256, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Executed Instruction,cycle,78.94,,,,,
0,53586,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(256, 1, 1)",0,7.5,Warp State Statistics,Avg. Active Threads Per Warp,,32,,,,,
0,53586,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(256, 1, 1)",0,7.5,Warp State Statistics,Avg. Not Predicated Off Threads Per Warp,,32,,,,,
0,53586,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(256, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,OPT,"On average, each warp of this kernel spends 59.9 cycles being stalled waiting for a scoreboard dependency on a L1TEX (local, global, surface, texture) operation. Find the instruction producing the data being waited upon to identify the culprit. To reduce the number of cycles waiting on L1TEX data accesses verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit rates by increasing data locality (coalescing), or by changing the cache configuration. Consider moving frequently used data to shared memory. This stall type represents about 77.2% of the total average of 77.6 cycles between issuing two instructions.",global,22.88
0,53586,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(256, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,INF,Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.,,
0,53586,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(256, 1, 1)",0,7.5,Instruction Statistics,Avg. Executed Instructions Per Scheduler,inst,"1,901.71",,,,,
0,53586,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(256, 1, 1)",0,7.5,Instruction Statistics,Executed Instructions,inst,"106,496",,,,,
0,53586,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(256, 1, 1)",0,7.5,Instruction Statistics,Avg. Issued Instructions Per Scheduler,inst,"1,933.71",,,,,
0,53586,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(256, 1, 1)",0,7.5,Instruction Statistics,Issued Instructions,inst,"108,288",,,,,
0,53586,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(256, 1, 1)",0,7.5,InstructionStats,,,,FPInstructions,OPT,"This kernel executes 0 fused and 8192 non-fused FP32 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP32 performance could be increased by up to 50% (relative to its current performance). Check the Source page to identify where this kernel executes FP32 instructions.",global,3.389
0,53586,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(256, 1, 1)",0,7.5,Launch Statistics,Block Size,,"1,024",,,,,
0,53586,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(256, 1, 1)",0,7.5,Launch Statistics,Function Cache Configuration,,CachePreferNone,,,,,
0,53586,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(256, 1, 1)",0,7.5,Launch Statistics,Grid Size,,256,,,,,
0,53586,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(256, 1, 1)",0,7.5,Launch Statistics,Registers Per Thread,register/thread,16,,,,,
0,53586,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(256, 1, 1)",0,7.5,Launch Statistics,Shared Memory Configuration Size,byte,"32,768",,,,,
0,53586,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(256, 1, 1)",0,7.5,Launch Statistics,Driver Shared Memory Per Block,byte/block,0,,,,,
0,53586,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(256, 1, 1)",0,7.5,Launch Statistics,Dynamic Shared Memory Per Block,byte/block,0,,,,,
0,53586,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(256, 1, 1)",0,7.5,Launch Statistics,Static Shared Memory Per Block,byte/block,0,,,,,
0,53586,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(256, 1, 1)",0,7.5,Launch Statistics,Threads,thread,"262,144",,,,,
0,53586,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(256, 1, 1)",0,7.5,Launch Statistics,Waves Per SM,,18.29,,,,,
0,53586,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(256, 1, 1)",0,7.5,Occupancy,Block Limit SM,block,16,,,,,
0,53586,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(256, 1, 1)",0,7.5,Occupancy,Block Limit Registers,block,4,,,,,
0,53586,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(256, 1, 1)",0,7.5,Occupancy,Block Limit Shared Mem,block,16,,,,,
0,53586,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(256, 1, 1)",0,7.5,Occupancy,Block Limit Warps,block,1,,,,,
0,53586,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(256, 1, 1)",0,7.5,Occupancy,Theoretical Active Warps per SM,warp,32,,,,,
0,53586,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(256, 1, 1)",0,7.5,Occupancy,Theoretical Occupancy,%,100,,,,,
0,53586,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(256, 1, 1)",0,7.5,Occupancy,Achieved Occupancy,%,88.05,,,,,
0,53586,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(256, 1, 1)",0,7.5,Occupancy,Achieved Active Warps Per SM,warp,28.18,,,,,
0,53586,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(256, 1, 1)",0,7.5,Occupancy,,,,AchievedOccupancy,OPT,The difference between calculated theoretical (100.0%) and measured achieved occupancy (88.0%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy.,global,11.95
0,53586,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(256, 1, 1)",0,7.5,Source Counters,Branch Instructions Ratio,%,0.08,,,,,
0,53586,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(256, 1, 1)",0,7.5,Source Counters,Branch Instructions,inst,"8,192",,,,,
0,53586,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(256, 1, 1)",0,7.5,Source Counters,Branch Efficiency,%,0,,,,,
0,53586,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(256, 1, 1)",0,7.5,Source Counters,Avg. Divergent Branches,,0,,,,,
0,53671,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(524288, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Frequency,cycle/second,"5,960,417,722.14",,,,,
0,53671,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(524288, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Frequency,cycle/second,"1,371,025,633.69",,,,,
0,53671,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(524288, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Elapsed Cycles,cycle,"2,688,502",,,,,
0,53671,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(524288, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Memory Throughput,%,11.16,,,,,
0,53671,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(524288, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Throughput,%,1.61,,,,,
0,53671,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(524288, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Duration,nsecond,"1,958,048",,,,,
0,53671,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(524288, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L1/TEX Cache Throughput,%,15.10,,,,,
0,53671,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(524288, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L2 Cache Throughput,%,8.70,,,,,
0,53671,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(524288, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Active Cycles,cycle,"1,984,424",,,,,
0,53671,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(524288, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Compute (SM) Throughput,%,11.16,,,,,
0,53671,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(524288, 1, 1)",0,7.5,SpeedOfLight,,,,SOLBottleneck,OPT,This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.,,
0,53671,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(524288, 1, 1)",0,7.5,SpeedOfLight_RooflineChart,,,,SOLFPRoofline,INF,The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved  close to 0% of this device's fp32 peak performance and 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.,,
0,53671,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(524288, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Active,inst/cycle,0.25,,,,,
0,53671,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(524288, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Elapsed,inst/cycle,0.18,,,,,
0,53671,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(524288, 1, 1)",0,7.5,Compute Workload Analysis,Issue Slots Busy,%,6.13,,,,,
0,53671,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(524288, 1, 1)",0,7.5,Compute Workload Analysis,Issued Ipc Active,inst/cycle,0.25,,,,,
0,53671,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(524288, 1, 1)",0,7.5,Compute Workload Analysis,SM Busy,%,6.29,,,,,
0,53671,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(524288, 1, 1)",0,7.5,ComputeWorkloadAnalysis,,,,HighPipeUtilization,OPT,All compute pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.,local,95.28
0,53671,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(524288, 1, 1)",0,7.5,Memory Workload Analysis,Memory Throughput,byte/second,"3,063,393,747.24",,,,,
0,53671,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(524288, 1, 1)",0,7.5,Memory Workload Analysis,Mem Busy,%,7.18,,,,,
0,53671,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(524288, 1, 1)",0,7.5,Memory Workload Analysis,Max Bandwidth,%,11.16,,,,,
0,53671,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(524288, 1, 1)",0,7.5,Memory Workload Analysis,L1/TEX Hit Rate,%,23.19,,,,,
0,53671,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(524288, 1, 1)",0,7.5,Memory Workload Analysis,L2 Hit Rate,%,95.58,,,,,
0,53671,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(524288, 1, 1)",0,7.5,Memory Workload Analysis,Mem Pipes Busy,%,11.16,,,,,
0,53671,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(524288, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Chart,,,,MemoryL2Compression,WRN,The optional metric lts__average_gcomp_input_sector_success_rate.pct could not be found. Collecting it as an additional metric could enable the rule to provide more guidance.,,
0,53671,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(524288, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for loads from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced loads and try to minimize how many cache lines need to be accessed per memory request.",global,3.573
0,53671,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(524288, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for stores from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.5 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced stores and try to minimize how many cache lines need to be accessed per memory request.",global,1.503
0,53671,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(524288, 1, 1)",0,7.5,Scheduler Statistics,One or More Eligible,%,6.89,,,,,
0,53671,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(524288, 1, 1)",0,7.5,Scheduler Statistics,Issued Warp Per Scheduler,,0.07,,,,,
0,53671,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(524288, 1, 1)",0,7.5,Scheduler Statistics,No Eligible,%,93.11,,,,,
0,53671,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(524288, 1, 1)",0,7.5,Scheduler Statistics,Active Warps Per Scheduler,warp,2.71,,,,,
0,53671,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(524288, 1, 1)",0,7.5,Scheduler Statistics,Eligible Warps Per Scheduler,warp,0.07,,,,,
0,53671,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(524288, 1, 1)",0,7.5,SchedulerStats,,,,IssueSlotUtilization,OPT,"Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 14.5 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of 2.71 active warps per scheduler, but only an average of 0.07 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections.",local,88.84
0,53671,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(524288, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Issued Instruction,cycle,39.41,,,,,
0,53671,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(524288, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Executed Instruction,cycle,39.42,,,,,
0,53671,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(524288, 1, 1)",0,7.5,Warp State Statistics,Avg. Active Threads Per Warp,,1,,,,,
0,53671,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(524288, 1, 1)",0,7.5,Warp State Statistics,Avg. Not Predicated Off Threads Per Warp,,1,,,,,
0,53671,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(524288, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,OPT,"On average, each warp of this kernel spends 31.4 cycles being stalled waiting for a scoreboard dependency on a L1TEX (local, global, surface, texture) operation. Find the instruction producing the data being waited upon to identify the culprit. To reduce the number of cycles waiting on L1TEX data accesses verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit rates by increasing data locality (coalescing), or by changing the cache configuration. Consider moving frequently used data to shared memory. This stall type represents about 79.7% of the total average of 39.4 cycles between issuing two instructions.",global,79.74
0,53671,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(524288, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,INF,Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.,,
0,53671,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(524288, 1, 1)",0,7.5,WarpStateStats,,,,ThreadDivergence,OPT,"Instructions are executed in warps, which are groups of 32 threads. Optimal instruction throughput is achieved if all 32 threads of a warp execute the same instruction. The chosen launch configuration, early thread completion, and divergent flow control can significantly lower the number of active threads in a warp per cycle. This kernel achieves an average of 1.0 threads being active per cycle.",global,10.81
0,53671,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(524288, 1, 1)",0,7.5,Instruction Statistics,Avg. Executed Instructions Per Scheduler,inst,"121,709.71",,,,,
0,53671,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(524288, 1, 1)",0,7.5,Instruction Statistics,Executed Instructions,inst,"6,815,744",,,,,
0,53671,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(524288, 1, 1)",0,7.5,Instruction Statistics,Avg. Issued Instructions Per Scheduler,inst,"121,723.36",,,,,
0,53671,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(524288, 1, 1)",0,7.5,Instruction Statistics,Issued Instructions,inst,"6,816,508",,,,,
0,53671,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(524288, 1, 1)",0,7.5,InstructionStats,,,,FPInstructions,OPT,"This kernel executes 0 fused and 524288 non-fused FP32 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP32 performance could be increased by up to 50% (relative to its current performance). Check the Source page to identify where this kernel executes FP32 instructions.",global,2.359
0,53671,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(524288, 1, 1)",0,7.5,Launch Statistics,Block Size,,1,,,,,
0,53671,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(524288, 1, 1)",0,7.5,Launch Statistics,Function Cache Configuration,,CachePreferNone,,,,,
0,53671,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(524288, 1, 1)",0,7.5,Launch Statistics,Grid Size,,"524,288",,,,,
0,53671,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(524288, 1, 1)",0,7.5,Launch Statistics,Registers Per Thread,register/thread,16,,,,,
0,53671,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(524288, 1, 1)",0,7.5,Launch Statistics,Shared Memory Configuration Size,byte,"32,768",,,,,
0,53671,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(524288, 1, 1)",0,7.5,Launch Statistics,Driver Shared Memory Per Block,byte/block,0,,,,,
0,53671,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(524288, 1, 1)",0,7.5,Launch Statistics,Dynamic Shared Memory Per Block,byte/block,0,,,,,
0,53671,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(524288, 1, 1)",0,7.5,Launch Statistics,Static Shared Memory Per Block,byte/block,0,,,,,
0,53671,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(524288, 1, 1)",0,7.5,Launch Statistics,Threads,thread,"524,288",,,,,
0,53671,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(524288, 1, 1)",0,7.5,Launch Statistics,Waves Per SM,,"2,340.57",,,,,
0,53671,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(524288, 1, 1)",0,7.5,LaunchStats,,,,LaunchConfiguration,OPT,"Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 1 threads per block. Consequently, some threads in a warp are masked off and those hardware resources are unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256 threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to kernels that frequently call __syncthreads(). See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations.",global,96.88
0,53671,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(524288, 1, 1)",0,7.5,Occupancy,Block Limit SM,block,16,,,,,
0,53671,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(524288, 1, 1)",0,7.5,Occupancy,Block Limit Registers,block,128,,,,,
0,53671,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(524288, 1, 1)",0,7.5,Occupancy,Block Limit Shared Mem,block,16,,,,,
0,53671,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(524288, 1, 1)",0,7.5,Occupancy,Block Limit Warps,block,32,,,,,
0,53671,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(524288, 1, 1)",0,7.5,Occupancy,Theoretical Active Warps per SM,warp,16,,,,,
0,53671,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(524288, 1, 1)",0,7.5,Occupancy,Theoretical Occupancy,%,50,,,,,
0,53671,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(524288, 1, 1)",0,7.5,Occupancy,Achieved Occupancy,%,31.21,,,,,
0,53671,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(524288, 1, 1)",0,7.5,Occupancy,Achieved Active Warps Per SM,warp,9.99,,,,,
0,53671,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(524288, 1, 1)",0,7.5,Occupancy,,,,AchievedOccupancy,OPT,The difference between calculated theoretical (50.0%) and measured achieved occupancy (31.2%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy.,global,37.58
0,53671,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(524288, 1, 1)",0,7.5,Occupancy,,,,TheoreticalOccupancy,OPT,The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared memory.,global,50.0
0,53671,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(524288, 1, 1)",0,7.5,Source Counters,Branch Instructions Ratio,%,0.08,,,,,
0,53671,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(524288, 1, 1)",0,7.5,Source Counters,Branch Instructions,inst,"524,288",,,,,
0,53671,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(524288, 1, 1)",0,7.5,Source Counters,Branch Efficiency,%,0,,,,,
0,53671,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1, 1, 1)","(524288, 1, 1)",0,7.5,Source Counters,Avg. Divergent Branches,,0,,,,,
0,53748,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(262144, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Frequency,cycle/second,"6,011,987,815.66",,,,,
0,53748,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(262144, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Frequency,cycle/second,"1,382,165,872.39",,,,,
0,53748,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(262144, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Elapsed Cycles,cycle,"1,351,998",,,,,
0,53748,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(262144, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Memory Throughput,%,11.09,,,,,
0,53748,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(262144, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Throughput,%,3.19,,,,,
0,53748,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(262144, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Duration,nsecond,"976,992",,,,,
0,53748,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(262144, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L1/TEX Cache Throughput,%,15.66,,,,,
0,53748,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(262144, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L2 Cache Throughput,%,9.48,,,,,
0,53748,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(262144, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Active Cycles,cycle,"956,844",,,,,
0,53748,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(262144, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Compute (SM) Throughput,%,11.09,,,,,
0,53748,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(262144, 1, 1)",0,7.5,SpeedOfLight,,,,SOLBottleneck,OPT,This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.,,
0,53748,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(262144, 1, 1)",0,7.5,SpeedOfLight_RooflineChart,,,,SOLFPRoofline,INF,The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved  close to 0% of this device's fp32 peak performance and 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.,,
0,53748,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(262144, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Active,inst/cycle,0.25,,,,,
0,53748,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(262144, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Elapsed,inst/cycle,0.18,,,,,
0,53748,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(262144, 1, 1)",0,7.5,Compute Workload Analysis,Issue Slots Busy,%,6.36,,,,,
0,53748,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(262144, 1, 1)",0,7.5,Compute Workload Analysis,Issued Ipc Active,inst/cycle,0.25,,,,,
0,53748,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(262144, 1, 1)",0,7.5,Compute Workload Analysis,SM Busy,%,6.52,,,,,
0,53748,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(262144, 1, 1)",0,7.5,ComputeWorkloadAnalysis,,,,HighPipeUtilization,OPT,All compute pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.,local,95.11
0,53748,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(262144, 1, 1)",0,7.5,Memory Workload Analysis,Memory Throughput,byte/second,"6,141,495,529.13",,,,,
0,53748,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(262144, 1, 1)",0,7.5,Memory Workload Analysis,Mem Busy,%,7.56,,,,,
0,53748,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(262144, 1, 1)",0,7.5,Memory Workload Analysis,Max Bandwidth,%,11.09,,,,,
0,53748,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(262144, 1, 1)",0,7.5,Memory Workload Analysis,L1/TEX Hit Rate,%,9.40,,,,,
0,53748,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(262144, 1, 1)",0,7.5,Memory Workload Analysis,L2 Hit Rate,%,91.63,,,,,
0,53748,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(262144, 1, 1)",0,7.5,Memory Workload Analysis,Mem Pipes Busy,%,11.09,,,,,
0,53748,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(262144, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Chart,,,,MemoryL2Compression,WRN,The optional metric lts__average_gcomp_input_sector_success_rate.pct could not be found. Collecting it as an additional metric could enable the rule to provide more guidance.,,
0,53748,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(262144, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for loads from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced loads and try to minimize how many cache lines need to be accessed per memory request.",global,3.762
0,53748,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(262144, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for stores from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.3 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced stores and try to minimize how many cache lines need to be accessed per memory request.",global,1.725
0,53748,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(262144, 1, 1)",0,7.5,Scheduler Statistics,One or More Eligible,%,7.14,,,,,
0,53748,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(262144, 1, 1)",0,7.5,Scheduler Statistics,Issued Warp Per Scheduler,,0.07,,,,,
0,53748,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(262144, 1, 1)",0,7.5,Scheduler Statistics,No Eligible,%,92.86,,,,,
0,53748,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(262144, 1, 1)",0,7.5,Scheduler Statistics,Active Warps Per Scheduler,warp,2.72,,,,,
0,53748,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(262144, 1, 1)",0,7.5,Scheduler Statistics,Eligible Warps Per Scheduler,warp,0.07,,,,,
0,53748,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(262144, 1, 1)",0,7.5,SchedulerStats,,,,IssueSlotUtilization,OPT,"Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 14.0 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of 2.72 active warps per scheduler, but only an average of 0.07 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections.",local,88.91
0,53748,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(262144, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Issued Instruction,cycle,38.16,,,,,
0,53748,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(262144, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Executed Instruction,cycle,38.17,,,,,
0,53748,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(262144, 1, 1)",0,7.5,Warp State Statistics,Avg. Active Threads Per Warp,,2,,,,,
0,53748,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(262144, 1, 1)",0,7.5,Warp State Statistics,Avg. Not Predicated Off Threads Per Warp,,2,,,,,
0,53748,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(262144, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,OPT,"On average, each warp of this kernel spends 29.9 cycles being stalled waiting for a scoreboard dependency on a L1TEX (local, global, surface, texture) operation. Find the instruction producing the data being waited upon to identify the culprit. To reduce the number of cycles waiting on L1TEX data accesses verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit rates by increasing data locality (coalescing), or by changing the cache configuration. Consider moving frequently used data to shared memory. This stall type represents about 78.4% of the total average of 38.2 cycles between issuing two instructions.",global,78.44
0,53748,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(262144, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,INF,Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.,,
0,53748,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(262144, 1, 1)",0,7.5,WarpStateStats,,,,ThreadDivergence,OPT,"Instructions are executed in warps, which are groups of 32 threads. Optimal instruction throughput is achieved if all 32 threads of a warp execute the same instruction. The chosen launch configuration, early thread completion, and divergent flow control can significantly lower the number of active threads in a warp per cycle. This kernel achieves an average of 2.0 threads being active per cycle.",global,10.4
0,53748,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(262144, 1, 1)",0,7.5,Instruction Statistics,Avg. Executed Instructions Per Scheduler,inst,"60,854.86",,,,,
0,53748,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(262144, 1, 1)",0,7.5,Instruction Statistics,Executed Instructions,inst,"3,407,872",,,,,
0,53748,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(262144, 1, 1)",0,7.5,Instruction Statistics,Avg. Issued Instructions Per Scheduler,inst,"60,868.50",,,,,
0,53748,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(262144, 1, 1)",0,7.5,Instruction Statistics,Issued Instructions,inst,"3,408,636",,,,,
0,53748,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(262144, 1, 1)",0,7.5,InstructionStats,,,,FPInstructions,OPT,"This kernel executes 0 fused and 262144 non-fused FP32 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP32 performance could be increased by up to 50% (relative to its current performance). Check the Source page to identify where this kernel executes FP32 instructions.",global,2.446
0,53748,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(262144, 1, 1)",0,7.5,Launch Statistics,Block Size,,2,,,,,
0,53748,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(262144, 1, 1)",0,7.5,Launch Statistics,Function Cache Configuration,,CachePreferNone,,,,,
0,53748,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(262144, 1, 1)",0,7.5,Launch Statistics,Grid Size,,"262,144",,,,,
0,53748,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(262144, 1, 1)",0,7.5,Launch Statistics,Registers Per Thread,register/thread,16,,,,,
0,53748,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(262144, 1, 1)",0,7.5,Launch Statistics,Shared Memory Configuration Size,byte,"32,768",,,,,
0,53748,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(262144, 1, 1)",0,7.5,Launch Statistics,Driver Shared Memory Per Block,byte/block,0,,,,,
0,53748,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(262144, 1, 1)",0,7.5,Launch Statistics,Dynamic Shared Memory Per Block,byte/block,0,,,,,
0,53748,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(262144, 1, 1)",0,7.5,Launch Statistics,Static Shared Memory Per Block,byte/block,0,,,,,
0,53748,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(262144, 1, 1)",0,7.5,Launch Statistics,Threads,thread,"524,288",,,,,
0,53748,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(262144, 1, 1)",0,7.5,Launch Statistics,Waves Per SM,,"1,170.29",,,,,
0,53748,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(262144, 1, 1)",0,7.5,LaunchStats,,,,LaunchConfiguration,OPT,"Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 2 threads per block. Consequently, some threads in a warp are masked off and those hardware resources are unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256 threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to kernels that frequently call __syncthreads(). See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations.",global,93.75
0,53748,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(262144, 1, 1)",0,7.5,Occupancy,Block Limit SM,block,16,,,,,
0,53748,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(262144, 1, 1)",0,7.5,Occupancy,Block Limit Registers,block,128,,,,,
0,53748,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(262144, 1, 1)",0,7.5,Occupancy,Block Limit Shared Mem,block,16,,,,,
0,53748,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(262144, 1, 1)",0,7.5,Occupancy,Block Limit Warps,block,32,,,,,
0,53748,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(262144, 1, 1)",0,7.5,Occupancy,Theoretical Active Warps per SM,warp,16,,,,,
0,53748,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(262144, 1, 1)",0,7.5,Occupancy,Theoretical Occupancy,%,50,,,,,
0,53748,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(262144, 1, 1)",0,7.5,Occupancy,Achieved Occupancy,%,31.33,,,,,
0,53748,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(262144, 1, 1)",0,7.5,Occupancy,Achieved Active Warps Per SM,warp,10.03,,,,,
0,53748,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(262144, 1, 1)",0,7.5,Occupancy,,,,AchievedOccupancy,OPT,The difference between calculated theoretical (50.0%) and measured achieved occupancy (31.3%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy.,global,37.34
0,53748,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(262144, 1, 1)",0,7.5,Occupancy,,,,TheoreticalOccupancy,OPT,The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared memory.,global,50.0
0,53748,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(262144, 1, 1)",0,7.5,Source Counters,Branch Instructions Ratio,%,0.08,,,,,
0,53748,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(262144, 1, 1)",0,7.5,Source Counters,Branch Instructions,inst,"262,144",,,,,
0,53748,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(262144, 1, 1)",0,7.5,Source Counters,Branch Efficiency,%,0,,,,,
0,53748,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(2, 1, 1)","(262144, 1, 1)",0,7.5,Source Counters,Avg. Divergent Branches,,0,,,,,
0,53833,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(131072, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Frequency,cycle/second,"5,993,968,795.07",,,,,
0,53833,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(131072, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Frequency,cycle/second,"1,377,812,786.81",,,,,
0,53833,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(131072, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Elapsed Cycles,cycle,"673,404",,,,,
0,53833,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(131072, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Memory Throughput,%,11.13,,,,,
0,53833,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(131072, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Throughput,%,6.43,,,,,
0,53833,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(131072, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Duration,nsecond,"488,128",,,,,
0,53833,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(131072, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L1/TEX Cache Throughput,%,15.59,,,,,
0,53833,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(131072, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L2 Cache Throughput,%,9.93,,,,,
0,53833,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(131072, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Active Cycles,cycle,"480,305.93",,,,,
0,53833,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(131072, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Compute (SM) Throughput,%,11.13,,,,,
0,53833,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(131072, 1, 1)",0,7.5,SpeedOfLight,,,,SOLBottleneck,OPT,This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.,,
0,53833,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(131072, 1, 1)",0,7.5,SpeedOfLight_RooflineChart,,,,SOLFPRoofline,INF,The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved  close to 0% of this device's fp32 peak performance and 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.,,
0,53833,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(131072, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Active,inst/cycle,0.25,,,,,
0,53833,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(131072, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Elapsed,inst/cycle,0.18,,,,,
0,53833,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(131072, 1, 1)",0,7.5,Compute Workload Analysis,Issue Slots Busy,%,6.34,,,,,
0,53833,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(131072, 1, 1)",0,7.5,Compute Workload Analysis,Issued Ipc Active,inst/cycle,0.25,,,,,
0,53833,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(131072, 1, 1)",0,7.5,Compute Workload Analysis,SM Busy,%,6.50,,,,,
0,53833,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(131072, 1, 1)",0,7.5,ComputeWorkloadAnalysis,,,,HighPipeUtilization,OPT,All compute pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.,local,95.13
0,53833,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(131072, 1, 1)",0,7.5,Memory Workload Analysis,Memory Throughput,byte/second,"12,326,865,084.57",,,,,
0,53833,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(131072, 1, 1)",0,7.5,Memory Workload Analysis,Mem Busy,%,7.62,,,,,
0,53833,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(131072, 1, 1)",0,7.5,Memory Workload Analysis,Max Bandwidth,%,11.13,,,,,
0,53833,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(131072, 1, 1)",0,7.5,Memory Workload Analysis,L1/TEX Hit Rate,%,2.66,,,,,
0,53833,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(131072, 1, 1)",0,7.5,Memory Workload Analysis,L2 Hit Rate,%,83.31,,,,,
0,53833,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(131072, 1, 1)",0,7.5,Memory Workload Analysis,Mem Pipes Busy,%,11.13,,,,,
0,53833,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(131072, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Chart,,,,MemoryL2Compression,WRN,The optional metric lts__average_gcomp_input_sector_success_rate.pct could not be found. Collecting it as an additional metric could enable the rule to provide more guidance.,,
0,53833,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(131072, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for loads from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced loads and try to minimize how many cache lines need to be accessed per memory request.",global,3.798
0,53833,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(131072, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for stores from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.1 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced stores and try to minimize how many cache lines need to be accessed per memory request.",global,1.864
0,53833,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(131072, 1, 1)",0,7.5,Scheduler Statistics,One or More Eligible,%,7.16,,,,,
0,53833,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(131072, 1, 1)",0,7.5,Scheduler Statistics,Issued Warp Per Scheduler,,0.07,,,,,
0,53833,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(131072, 1, 1)",0,7.5,Scheduler Statistics,No Eligible,%,92.84,,,,,
0,53833,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(131072, 1, 1)",0,7.5,Scheduler Statistics,Active Warps Per Scheduler,warp,2.72,,,,,
0,53833,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(131072, 1, 1)",0,7.5,Scheduler Statistics,Eligible Warps Per Scheduler,warp,0.07,,,,,
0,53833,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(131072, 1, 1)",0,7.5,SchedulerStats,,,,IssueSlotUtilization,OPT,"Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 14.0 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of 2.72 active warps per scheduler, but only an average of 0.07 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections.",local,88.87
0,53833,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(131072, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Issued Instruction,cycle,38.04,,,,,
0,53833,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(131072, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Executed Instruction,cycle,38.06,,,,,
0,53833,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(131072, 1, 1)",0,7.5,Warp State Statistics,Avg. Active Threads Per Warp,,4,,,,,
0,53833,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(131072, 1, 1)",0,7.5,Warp State Statistics,Avg. Not Predicated Off Threads Per Warp,,4,,,,,
0,53833,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(131072, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,OPT,"On average, each warp of this kernel spends 30.1 cycles being stalled waiting for a scoreboard dependency on a L1TEX (local, global, surface, texture) operation. Find the instruction producing the data being waited upon to identify the culprit. To reduce the number of cycles waiting on L1TEX data accesses verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit rates by increasing data locality (coalescing), or by changing the cache configuration. Consider moving frequently used data to shared memory. This stall type represents about 79.0% of the total average of 38.0 cycles between issuing two instructions.",global,79.02
0,53833,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(131072, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,INF,Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.,,
0,53833,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(131072, 1, 1)",0,7.5,WarpStateStats,,,,ThreadDivergence,OPT,"Instructions are executed in warps, which are groups of 32 threads. Optimal instruction throughput is achieved if all 32 threads of a warp execute the same instruction. The chosen launch configuration, early thread completion, and divergent flow control can significantly lower the number of active threads in a warp per cycle. This kernel achieves an average of 4.0 threads being active per cycle.",global,9.743
0,53833,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(131072, 1, 1)",0,7.5,Instruction Statistics,Avg. Executed Instructions Per Scheduler,inst,"30,427.43",,,,,
0,53833,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(131072, 1, 1)",0,7.5,Instruction Statistics,Executed Instructions,inst,"1,703,936",,,,,
0,53833,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(131072, 1, 1)",0,7.5,Instruction Statistics,Avg. Issued Instructions Per Scheduler,inst,"30,441.07",,,,,
0,53833,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(131072, 1, 1)",0,7.5,Instruction Statistics,Issued Instructions,inst,"1,704,700",,,,,
0,53833,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(131072, 1, 1)",0,7.5,InstructionStats,,,,FPInstructions,OPT,"This kernel executes 0 fused and 131072 non-fused FP32 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP32 performance could be increased by up to 50% (relative to its current performance). Check the Source page to identify where this kernel executes FP32 instructions.",global,2.437
0,53833,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(131072, 1, 1)",0,7.5,Launch Statistics,Block Size,,4,,,,,
0,53833,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(131072, 1, 1)",0,7.5,Launch Statistics,Function Cache Configuration,,CachePreferNone,,,,,
0,53833,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(131072, 1, 1)",0,7.5,Launch Statistics,Grid Size,,"131,072",,,,,
0,53833,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(131072, 1, 1)",0,7.5,Launch Statistics,Registers Per Thread,register/thread,16,,,,,
0,53833,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(131072, 1, 1)",0,7.5,Launch Statistics,Shared Memory Configuration Size,byte,"32,768",,,,,
0,53833,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(131072, 1, 1)",0,7.5,Launch Statistics,Driver Shared Memory Per Block,byte/block,0,,,,,
0,53833,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(131072, 1, 1)",0,7.5,Launch Statistics,Dynamic Shared Memory Per Block,byte/block,0,,,,,
0,53833,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(131072, 1, 1)",0,7.5,Launch Statistics,Static Shared Memory Per Block,byte/block,0,,,,,
0,53833,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(131072, 1, 1)",0,7.5,Launch Statistics,Threads,thread,"524,288",,,,,
0,53833,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(131072, 1, 1)",0,7.5,Launch Statistics,Waves Per SM,,585.14,,,,,
0,53833,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(131072, 1, 1)",0,7.5,LaunchStats,,,,LaunchConfiguration,OPT,"Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 4 threads per block. Consequently, some threads in a warp are masked off and those hardware resources are unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256 threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to kernels that frequently call __syncthreads(). See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations.",global,87.5
0,53833,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(131072, 1, 1)",0,7.5,Occupancy,Block Limit SM,block,16,,,,,
0,53833,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(131072, 1, 1)",0,7.5,Occupancy,Block Limit Registers,block,128,,,,,
0,53833,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(131072, 1, 1)",0,7.5,Occupancy,Block Limit Shared Mem,block,16,,,,,
0,53833,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(131072, 1, 1)",0,7.5,Occupancy,Block Limit Warps,block,32,,,,,
0,53833,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(131072, 1, 1)",0,7.5,Occupancy,Theoretical Active Warps per SM,warp,16,,,,,
0,53833,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(131072, 1, 1)",0,7.5,Occupancy,Theoretical Occupancy,%,50,,,,,
0,53833,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(131072, 1, 1)",0,7.5,Occupancy,Achieved Occupancy,%,31.38,,,,,
0,53833,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(131072, 1, 1)",0,7.5,Occupancy,Achieved Active Warps Per SM,warp,10.04,,,,,
0,53833,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(131072, 1, 1)",0,7.5,Occupancy,,,,AchievedOccupancy,OPT,The difference between calculated theoretical (50.0%) and measured achieved occupancy (31.4%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy.,global,37.23
0,53833,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(131072, 1, 1)",0,7.5,Occupancy,,,,TheoreticalOccupancy,OPT,The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared memory.,global,50.0
0,53833,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(131072, 1, 1)",0,7.5,Source Counters,Branch Instructions Ratio,%,0.08,,,,,
0,53833,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(131072, 1, 1)",0,7.5,Source Counters,Branch Instructions,inst,"131,072",,,,,
0,53833,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(131072, 1, 1)",0,7.5,Source Counters,Branch Efficiency,%,0,,,,,
0,53833,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(4, 1, 1)","(131072, 1, 1)",0,7.5,Source Counters,Avg. Divergent Branches,,0,,,,,
0,53919,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(65536, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Frequency,cycle/second,"6,006,059,807.67",,,,,
0,53919,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(65536, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Frequency,cycle/second,"1,379,590,139.64",,,,,
0,53919,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(65536, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Elapsed Cycles,cycle,"335,675",,,,,
0,53919,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(65536, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Memory Throughput,%,12.92,,,,,
0,53919,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(65536, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Throughput,%,12.92,,,,,
0,53919,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(65536, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Duration,nsecond,"242,912",,,,,
0,53919,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(65536, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L1/TEX Cache Throughput,%,14.30,,,,,
0,53919,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(65536, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L2 Cache Throughput,%,7.66,,,,,
0,53919,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(65536, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Active Cycles,cycle,"261,942.14",,,,,
0,53919,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(65536, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Compute (SM) Throughput,%,11.17,,,,,
0,53919,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(65536, 1, 1)",0,7.5,SpeedOfLight,,,,SOLBottleneck,OPT,This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.,,
0,53919,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(65536, 1, 1)",0,7.5,SpeedOfLight_RooflineChart,,,,SOLFPRoofline,INF,The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved  close to 0% of this device's fp32 peak performance and 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.,,
0,53919,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(65536, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Active,inst/cycle,0.23,,,,,
0,53919,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(65536, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Elapsed,inst/cycle,0.18,,,,,
0,53919,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(65536, 1, 1)",0,7.5,Compute Workload Analysis,Issue Slots Busy,%,5.81,,,,,
0,53919,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(65536, 1, 1)",0,7.5,Compute Workload Analysis,Issued Ipc Active,inst/cycle,0.23,,,,,
0,53919,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(65536, 1, 1)",0,7.5,Compute Workload Analysis,SM Busy,%,5.96,,,,,
0,53919,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(65536, 1, 1)",0,7.5,ComputeWorkloadAnalysis,,,,HighPipeUtilization,OPT,All compute pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.,local,95.53
0,53919,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(65536, 1, 1)",0,7.5,Memory Workload Analysis,Memory Throughput,byte/second,"24,834,672,638.65",,,,,
0,53919,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(65536, 1, 1)",0,7.5,Memory Workload Analysis,Mem Busy,%,7.66,,,,,
0,53919,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(65536, 1, 1)",0,7.5,Memory Workload Analysis,Max Bandwidth,%,12.92,,,,,
0,53919,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(65536, 1, 1)",0,7.5,Memory Workload Analysis,L1/TEX Hit Rate,%,1.09,,,,,
0,53919,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(65536, 1, 1)",0,7.5,Memory Workload Analysis,L2 Hit Rate,%,66.72,,,,,
0,53919,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(65536, 1, 1)",0,7.5,Memory Workload Analysis,Mem Pipes Busy,%,11.17,,,,,
0,53919,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(65536, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Chart,,,,MemoryL2Compression,WRN,The optional metric lts__average_gcomp_input_sector_success_rate.pct could not be found. Collecting it as an additional metric could enable the rule to provide more guidance.,,
0,53919,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(65536, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for loads from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced loads and try to minimize how many cache lines need to be accessed per memory request.",global,3.821
0,53919,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(65536, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for stores from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced stores and try to minimize how many cache lines need to be accessed per memory request.",global,1.895
0,53919,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(65536, 1, 1)",0,7.5,Scheduler Statistics,One or More Eligible,%,6.50,,,,,
0,53919,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(65536, 1, 1)",0,7.5,Scheduler Statistics,Issued Warp Per Scheduler,,0.06,,,,,
0,53919,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(65536, 1, 1)",0,7.5,Scheduler Statistics,No Eligible,%,93.50,,,,,
0,53919,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(65536, 1, 1)",0,7.5,Scheduler Statistics,Active Warps Per Scheduler,warp,2.65,,,,,
0,53919,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(65536, 1, 1)",0,7.5,Scheduler Statistics,Eligible Warps Per Scheduler,warp,0.07,,,,,
0,53919,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(65536, 1, 1)",0,7.5,SchedulerStats,,,,IssueSlotUtilization,OPT,"Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 15.4 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of 2.65 active warps per scheduler, but only an average of 0.07 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections.",local,87.08
0,53919,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(65536, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Issued Instruction,cycle,40.79,,,,,
0,53919,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(65536, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Executed Instruction,cycle,40.83,,,,,
0,53919,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(65536, 1, 1)",0,7.5,Warp State Statistics,Avg. Active Threads Per Warp,,8,,,,,
0,53919,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(65536, 1, 1)",0,7.5,Warp State Statistics,Avg. Not Predicated Off Threads Per Warp,,8,,,,,
0,53919,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(65536, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,OPT,"On average, each warp of this kernel spends 32.5 cycles being stalled waiting for a scoreboard dependency on a L1TEX (local, global, surface, texture) operation. Find the instruction producing the data being waited upon to identify the culprit. To reduce the number of cycles waiting on L1TEX data accesses verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit rates by increasing data locality (coalescing), or by changing the cache configuration. Consider moving frequently used data to shared memory. This stall type represents about 79.7% of the total average of 40.8 cycles between issuing two instructions.",global,79.7
0,53919,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(65536, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,INF,Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.,,
0,53919,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(65536, 1, 1)",0,7.5,WarpStateStats,,,,ThreadDivergence,OPT,"Instructions are executed in warps, which are groups of 32 threads. Optimal instruction throughput is achieved if all 32 threads of a warp execute the same instruction. The chosen launch configuration, early thread completion, and divergent flow control can significantly lower the number of active threads in a warp per cycle. This kernel achieves an average of 8.0 threads being active per cycle.",global,8.379
0,53919,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(65536, 1, 1)",0,7.5,Instruction Statistics,Avg. Executed Instructions Per Scheduler,inst,"15,213.71",,,,,
0,53919,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(65536, 1, 1)",0,7.5,Instruction Statistics,Executed Instructions,inst,"851,968",,,,,
0,53919,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(65536, 1, 1)",0,7.5,Instruction Statistics,Avg. Issued Instructions Per Scheduler,inst,"15,227.36",,,,,
0,53919,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(65536, 1, 1)",0,7.5,Instruction Statistics,Issued Instructions,inst,"852,732",,,,,
0,53919,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(65536, 1, 1)",0,7.5,InstructionStats,,,,FPInstructions,OPT,"This kernel executes 0 fused and 65536 non-fused FP32 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP32 performance could be increased by up to 50% (relative to its current performance). Check the Source page to identify where this kernel executes FP32 instructions.",global,2.234
0,53919,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(65536, 1, 1)",0,7.5,Launch Statistics,Block Size,,8,,,,,
0,53919,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(65536, 1, 1)",0,7.5,Launch Statistics,Function Cache Configuration,,CachePreferNone,,,,,
0,53919,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(65536, 1, 1)",0,7.5,Launch Statistics,Grid Size,,"65,536",,,,,
0,53919,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(65536, 1, 1)",0,7.5,Launch Statistics,Registers Per Thread,register/thread,16,,,,,
0,53919,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(65536, 1, 1)",0,7.5,Launch Statistics,Shared Memory Configuration Size,byte,"32,768",,,,,
0,53919,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(65536, 1, 1)",0,7.5,Launch Statistics,Driver Shared Memory Per Block,byte/block,0,,,,,
0,53919,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(65536, 1, 1)",0,7.5,Launch Statistics,Dynamic Shared Memory Per Block,byte/block,0,,,,,
0,53919,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(65536, 1, 1)",0,7.5,Launch Statistics,Static Shared Memory Per Block,byte/block,0,,,,,
0,53919,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(65536, 1, 1)",0,7.5,Launch Statistics,Threads,thread,"524,288",,,,,
0,53919,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(65536, 1, 1)",0,7.5,Launch Statistics,Waves Per SM,,292.57,,,,,
0,53919,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(65536, 1, 1)",0,7.5,LaunchStats,,,,LaunchConfiguration,OPT,"Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 8 threads per block. Consequently, some threads in a warp are masked off and those hardware resources are unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256 threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to kernels that frequently call __syncthreads(). See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations.",global,75.0
0,53919,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(65536, 1, 1)",0,7.5,Occupancy,Block Limit SM,block,16,,,,,
0,53919,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(65536, 1, 1)",0,7.5,Occupancy,Block Limit Registers,block,128,,,,,
0,53919,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(65536, 1, 1)",0,7.5,Occupancy,Block Limit Shared Mem,block,16,,,,,
0,53919,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(65536, 1, 1)",0,7.5,Occupancy,Block Limit Warps,block,32,,,,,
0,53919,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(65536, 1, 1)",0,7.5,Occupancy,Theoretical Active Warps per SM,warp,16,,,,,
0,53919,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(65536, 1, 1)",0,7.5,Occupancy,Theoretical Occupancy,%,50,,,,,
0,53919,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(65536, 1, 1)",0,7.5,Occupancy,Achieved Occupancy,%,30.45,,,,,
0,53919,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(65536, 1, 1)",0,7.5,Occupancy,Achieved Active Warps Per SM,warp,9.74,,,,,
0,53919,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(65536, 1, 1)",0,7.5,Occupancy,,,,AchievedOccupancy,OPT,The difference between calculated theoretical (50.0%) and measured achieved occupancy (30.4%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy.,global,39.11
0,53919,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(65536, 1, 1)",0,7.5,Occupancy,,,,TheoreticalOccupancy,OPT,The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared memory.,global,50.0
0,53919,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(65536, 1, 1)",0,7.5,Source Counters,Branch Instructions Ratio,%,0.08,,,,,
0,53919,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(65536, 1, 1)",0,7.5,Source Counters,Branch Instructions,inst,"65,536",,,,,
0,53919,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(65536, 1, 1)",0,7.5,Source Counters,Branch Efficiency,%,0,,,,,
0,53919,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(8, 1, 1)","(65536, 1, 1)",0,7.5,Source Counters,Avg. Divergent Branches,,0,,,,,
0,53997,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(32768, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Frequency,cycle/second,"5,896,815,601.09",,,,,
0,53997,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(32768, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Frequency,cycle/second,"1,354,376,234.26",,,,,
0,53997,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(32768, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Elapsed Cycles,cycle,"175,924",,,,,
0,53997,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(32768, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Memory Throughput,%,24.52,,,,,
0,53997,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(32768, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Throughput,%,24.52,,,,,
0,53997,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(32768, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Duration,nsecond,"129,632",,,,,
0,53997,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(32768, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L1/TEX Cache Throughput,%,13.24,,,,,
0,53997,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(32768, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L2 Cache Throughput,%,14.66,,,,,
0,53997,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(32768, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Active Cycles,cycle,"141,391.57",,,,,
0,53997,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(32768, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Compute (SM) Throughput,%,10.66,,,,,
0,53997,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(32768, 1, 1)",0,7.5,SpeedOfLight,,,,SOLBottleneck,OPT,This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.,,
0,53997,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(32768, 1, 1)",0,7.5,SpeedOfLight_RooflineChart,,,,SOLFPRoofline,INF,The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved  close to 0% of this device's fp32 peak performance and 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.,,
0,53997,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(32768, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Active,inst/cycle,0.22,,,,,
0,53997,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(32768, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Elapsed,inst/cycle,0.17,,,,,
0,53997,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(32768, 1, 1)",0,7.5,Compute Workload Analysis,Issue Slots Busy,%,5.39,,,,,
0,53997,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(32768, 1, 1)",0,7.5,Compute Workload Analysis,Issued Ipc Active,inst/cycle,0.22,,,,,
0,53997,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(32768, 1, 1)",0,7.5,Compute Workload Analysis,SM Busy,%,5.52,,,,,
0,53997,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(32768, 1, 1)",0,7.5,ComputeWorkloadAnalysis,,,,HighPipeUtilization,OPT,All compute pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.,local,95.86
0,53997,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(32768, 1, 1)",0,7.5,Memory Workload Analysis,Memory Throughput,byte/second,"46,268,328,807.70",,,,,
0,53997,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(32768, 1, 1)",0,7.5,Memory Workload Analysis,Mem Busy,%,14.66,,,,,
0,53997,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(32768, 1, 1)",0,7.5,Memory Workload Analysis,Max Bandwidth,%,24.52,,,,,
0,53997,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(32768, 1, 1)",0,7.5,Memory Workload Analysis,L1/TEX Hit Rate,%,0.31,,,,,
0,53997,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(32768, 1, 1)",0,7.5,Memory Workload Analysis,L2 Hit Rate,%,33.35,,,,,
0,53997,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(32768, 1, 1)",0,7.5,Memory Workload Analysis,Mem Pipes Busy,%,10.66,,,,,
0,53997,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(32768, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Chart,,,,MemoryL2Compression,WRN,The optional metric lts__average_gcomp_input_sector_success_rate.pct could not be found. Collecting it as an additional metric could enable the rule to provide more guidance.,,
0,53997,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(32768, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for loads from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 2.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced loads and try to minimize how many cache lines need to be accessed per memory request.",global,4.869
0,53997,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(32768, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for stores from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 2.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced stores and try to minimize how many cache lines need to be accessed per memory request.",global,2.416
0,53997,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(32768, 1, 1)",0,7.5,Scheduler Statistics,One or More Eligible,%,6.10,,,,,
0,53997,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(32768, 1, 1)",0,7.5,Scheduler Statistics,Issued Warp Per Scheduler,,0.06,,,,,
0,53997,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(32768, 1, 1)",0,7.5,Scheduler Statistics,No Eligible,%,93.90,,,,,
0,53997,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(32768, 1, 1)",0,7.5,Scheduler Statistics,Active Warps Per Scheduler,warp,2.78,,,,,
0,53997,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(32768, 1, 1)",0,7.5,Scheduler Statistics,Eligible Warps Per Scheduler,warp,0.06,,,,,
0,53997,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(32768, 1, 1)",0,7.5,SchedulerStats,,,,IssueSlotUtilization,OPT,"Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 16.4 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of 2.78 active warps per scheduler, but only an average of 0.06 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections.",local,75.48
0,53997,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(32768, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Issued Instruction,cycle,45.59,,,,,
0,53997,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(32768, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Executed Instruction,cycle,45.67,,,,,
0,53997,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(32768, 1, 1)",0,7.5,Warp State Statistics,Avg. Active Threads Per Warp,,16,,,,,
0,53997,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(32768, 1, 1)",0,7.5,Warp State Statistics,Avg. Not Predicated Off Threads Per Warp,,16,,,,,
0,53997,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(32768, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,OPT,"On average, each warp of this kernel spends 37.1 cycles being stalled waiting for a scoreboard dependency on a L1TEX (local, global, surface, texture) operation. Find the instruction producing the data being waited upon to identify the culprit. To reduce the number of cycles waiting on L1TEX data accesses verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit rates by increasing data locality (coalescing), or by changing the cache configuration. Consider moving frequently used data to shared memory. This stall type represents about 81.4% of the total average of 45.6 cycles between issuing two instructions.",global,75.48
0,53997,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(32768, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,INF,Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.,,
0,53997,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(32768, 1, 1)",0,7.5,WarpStateStats,,,,ThreadDivergence,OPT,"Instructions are executed in warps, which are groups of 32 threads. Optimal instruction throughput is achieved if all 32 threads of a warp execute the same instruction. The chosen launch configuration, early thread completion, and divergent flow control can significantly lower the number of active threads in a warp per cycle. This kernel achieves an average of 16.0 threads being active per cycle.",global,5.331
0,53997,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(32768, 1, 1)",0,7.5,Instruction Statistics,Avg. Executed Instructions Per Scheduler,inst,"7,606.86",,,,,
0,53997,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(32768, 1, 1)",0,7.5,Instruction Statistics,Executed Instructions,inst,"425,984",,,,,
0,53997,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(32768, 1, 1)",0,7.5,Instruction Statistics,Avg. Issued Instructions Per Scheduler,inst,"7,620.55",,,,,
0,53997,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(32768, 1, 1)",0,7.5,Instruction Statistics,Issued Instructions,inst,"426,751",,,,,
0,53997,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(32768, 1, 1)",0,7.5,InstructionStats,,,,FPInstructions,OPT,"This kernel executes 0 fused and 32768 non-fused FP32 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP32 performance could be increased by up to 50% (relative to its current performance). Check the Source page to identify where this kernel executes FP32 instructions.",global,2.069
0,53997,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(32768, 1, 1)",0,7.5,Launch Statistics,Block Size,,16,,,,,
0,53997,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(32768, 1, 1)",0,7.5,Launch Statistics,Function Cache Configuration,,CachePreferNone,,,,,
0,53997,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(32768, 1, 1)",0,7.5,Launch Statistics,Grid Size,,"32,768",,,,,
0,53997,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(32768, 1, 1)",0,7.5,Launch Statistics,Registers Per Thread,register/thread,16,,,,,
0,53997,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(32768, 1, 1)",0,7.5,Launch Statistics,Shared Memory Configuration Size,byte,"32,768",,,,,
0,53997,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(32768, 1, 1)",0,7.5,Launch Statistics,Driver Shared Memory Per Block,byte/block,0,,,,,
0,53997,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(32768, 1, 1)",0,7.5,Launch Statistics,Dynamic Shared Memory Per Block,byte/block,0,,,,,
0,53997,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(32768, 1, 1)",0,7.5,Launch Statistics,Static Shared Memory Per Block,byte/block,0,,,,,
0,53997,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(32768, 1, 1)",0,7.5,Launch Statistics,Threads,thread,"524,288",,,,,
0,53997,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(32768, 1, 1)",0,7.5,Launch Statistics,Waves Per SM,,146.29,,,,,
0,53997,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(32768, 1, 1)",0,7.5,LaunchStats,,,,LaunchConfiguration,OPT,"Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 16 threads per block. Consequently, some threads in a warp are masked off and those hardware resources are unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256 threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to kernels that frequently call __syncthreads(). See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations.",global,50.0
0,53997,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(32768, 1, 1)",0,7.5,Occupancy,Block Limit SM,block,16,,,,,
0,53997,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(32768, 1, 1)",0,7.5,Occupancy,Block Limit Registers,block,128,,,,,
0,53997,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(32768, 1, 1)",0,7.5,Occupancy,Block Limit Shared Mem,block,16,,,,,
0,53997,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(32768, 1, 1)",0,7.5,Occupancy,Block Limit Warps,block,32,,,,,
0,53997,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(32768, 1, 1)",0,7.5,Occupancy,Theoretical Active Warps per SM,warp,16,,,,,
0,53997,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(32768, 1, 1)",0,7.5,Occupancy,Theoretical Occupancy,%,50,,,,,
0,53997,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(32768, 1, 1)",0,7.5,Occupancy,Achieved Occupancy,%,31.88,,,,,
0,53997,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(32768, 1, 1)",0,7.5,Occupancy,Achieved Active Warps Per SM,warp,10.20,,,,,
0,53997,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(32768, 1, 1)",0,7.5,Occupancy,,,,AchievedOccupancy,OPT,The difference between calculated theoretical (50.0%) and measured achieved occupancy (31.9%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy.,global,36.24
0,53997,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(32768, 1, 1)",0,7.5,Occupancy,,,,TheoreticalOccupancy,OPT,The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared memory.,global,50.0
0,53997,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(32768, 1, 1)",0,7.5,Source Counters,Branch Instructions Ratio,%,0.08,,,,,
0,53997,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(32768, 1, 1)",0,7.5,Source Counters,Branch Instructions,inst,"32,768",,,,,
0,53997,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(32768, 1, 1)",0,7.5,Source Counters,Branch Efficiency,%,0,,,,,
0,53997,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(16, 1, 1)","(32768, 1, 1)",0,7.5,Source Counters,Avg. Divergent Branches,,0,,,,,
0,54084,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(16384, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Frequency,cycle/second,"5,976,470,588.24",,,,,
0,54084,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(16384, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Frequency,cycle/second,"1,373,380,938.91",,,,,
0,54084,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(16384, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Elapsed Cycles,cycle,"97,282",,,,,
0,54084,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(16384, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Memory Throughput,%,44.11,,,,,
0,54084,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(16384, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Throughput,%,44.11,,,,,
0,54084,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(16384, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Duration,nsecond,"70,720",,,,,
0,54084,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(16384, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L1/TEX Cache Throughput,%,14.33,,,,,
0,54084,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(16384, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L2 Cache Throughput,%,26.47,,,,,
0,54084,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(16384, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Active Cycles,cycle,"78,807.21",,,,,
0,54084,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(16384, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Compute (SM) Throughput,%,9.64,,,,,
0,54084,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(16384, 1, 1)",0,7.5,SpeedOfLight,,,,SOLBottleneck,OPT,This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.,,
0,54084,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(16384, 1, 1)",0,7.5,SpeedOfLight_RooflineChart,,,,SOLFPRoofline,INF,The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved  close to 0% of this device's fp32 peak performance and 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.,,
0,54084,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(16384, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Active,inst/cycle,0.19,,,,,
0,54084,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(16384, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Elapsed,inst/cycle,0.16,,,,,
0,54084,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(16384, 1, 1)",0,7.5,Compute Workload Analysis,Issue Slots Busy,%,4.84,,,,,
0,54084,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(16384, 1, 1)",0,7.5,Compute Workload Analysis,Issued Ipc Active,inst/cycle,0.19,,,,,
0,54084,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(16384, 1, 1)",0,7.5,Compute Workload Analysis,SM Busy,%,4.95,,,,,
0,54084,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(16384, 1, 1)",0,7.5,ComputeWorkloadAnalysis,,,,HighPipeUtilization,OPT,All compute pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.,local,96.29
0,54084,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(16384, 1, 1)",0,7.5,Memory Workload Analysis,Memory Throughput,byte/second,"84,361,085,972.85",,,,,
0,54084,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(16384, 1, 1)",0,7.5,Memory Workload Analysis,Mem Busy,%,26.47,,,,,
0,54084,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(16384, 1, 1)",0,7.5,Memory Workload Analysis,Max Bandwidth,%,44.11,,,,,
0,54084,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(16384, 1, 1)",0,7.5,Memory Workload Analysis,L1/TEX Hit Rate,%,0,,,,,
0,54084,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(16384, 1, 1)",0,7.5,Memory Workload Analysis,L2 Hit Rate,%,33.42,,,,,
0,54084,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(16384, 1, 1)",0,7.5,Memory Workload Analysis,Mem Pipes Busy,%,9.64,,,,,
0,54084,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(16384, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Chart,,,,MemoryL2Compression,WRN,The optional metric lts__average_gcomp_input_sector_success_rate.pct could not be found. Collecting it as an additional metric could enable the rule to provide more guidance.,,
0,54084,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(16384, 1, 1)",0,7.5,Scheduler Statistics,One or More Eligible,%,5.42,,,,,
0,54084,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(16384, 1, 1)",0,7.5,Scheduler Statistics,Issued Warp Per Scheduler,,0.05,,,,,
0,54084,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(16384, 1, 1)",0,7.5,Scheduler Statistics,No Eligible,%,94.58,,,,,
0,54084,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(16384, 1, 1)",0,7.5,Scheduler Statistics,Active Warps Per Scheduler,warp,2.89,,,,,
0,54084,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(16384, 1, 1)",0,7.5,Scheduler Statistics,Eligible Warps Per Scheduler,warp,0.06,,,,,
0,54084,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(16384, 1, 1)",0,7.5,SchedulerStats,,,,IssueSlotUtilization,OPT,"Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 18.4 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of 2.89 active warps per scheduler, but only an average of 0.06 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections.",local,55.89
0,54084,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(16384, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Issued Instruction,cycle,53.32,,,,,
0,54084,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(16384, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Executed Instruction,cycle,53.51,,,,,
0,54084,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(16384, 1, 1)",0,7.5,Warp State Statistics,Avg. Active Threads Per Warp,,32,,,,,
0,54084,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(16384, 1, 1)",0,7.5,Warp State Statistics,Avg. Not Predicated Off Threads Per Warp,,32,,,,,
0,54084,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(16384, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,OPT,"On average, each warp of this kernel spends 45.3 cycles being stalled waiting for a scoreboard dependency on a L1TEX (local, global, surface, texture) operation. Find the instruction producing the data being waited upon to identify the culprit. To reduce the number of cycles waiting on L1TEX data accesses verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit rates by increasing data locality (coalescing), or by changing the cache configuration. Consider moving frequently used data to shared memory. This stall type represents about 84.9% of the total average of 53.3 cycles between issuing two instructions.",global,55.89
0,54084,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(16384, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,INF,Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.,,
0,54084,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(16384, 1, 1)",0,7.5,Instruction Statistics,Avg. Executed Instructions Per Scheduler,inst,"3,803.43",,,,,
0,54084,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(16384, 1, 1)",0,7.5,Instruction Statistics,Executed Instructions,inst,"212,992",,,,,
0,54084,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(16384, 1, 1)",0,7.5,Instruction Statistics,Avg. Issued Instructions Per Scheduler,inst,"3,817.07",,,,,
0,54084,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(16384, 1, 1)",0,7.5,Instruction Statistics,Issued Instructions,inst,"213,756",,,,,
0,54084,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(16384, 1, 1)",0,7.5,InstructionStats,,,,FPInstructions,OPT,"This kernel executes 0 fused and 16384 non-fused FP32 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP32 performance could be increased by up to 50% (relative to its current performance). Check the Source page to identify where this kernel executes FP32 instructions.",global,1.856
0,54084,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(16384, 1, 1)",0,7.5,Launch Statistics,Block Size,,32,,,,,
0,54084,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(16384, 1, 1)",0,7.5,Launch Statistics,Function Cache Configuration,,CachePreferNone,,,,,
0,54084,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(16384, 1, 1)",0,7.5,Launch Statistics,Grid Size,,"16,384",,,,,
0,54084,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(16384, 1, 1)",0,7.5,Launch Statistics,Registers Per Thread,register/thread,16,,,,,
0,54084,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(16384, 1, 1)",0,7.5,Launch Statistics,Shared Memory Configuration Size,byte,"32,768",,,,,
0,54084,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(16384, 1, 1)",0,7.5,Launch Statistics,Driver Shared Memory Per Block,byte/block,0,,,,,
0,54084,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(16384, 1, 1)",0,7.5,Launch Statistics,Dynamic Shared Memory Per Block,byte/block,0,,,,,
0,54084,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(16384, 1, 1)",0,7.5,Launch Statistics,Static Shared Memory Per Block,byte/block,0,,,,,
0,54084,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(16384, 1, 1)",0,7.5,Launch Statistics,Threads,thread,"524,288",,,,,
0,54084,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(16384, 1, 1)",0,7.5,Launch Statistics,Waves Per SM,,73.14,,,,,
0,54084,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(16384, 1, 1)",0,7.5,Occupancy,Block Limit SM,block,16,,,,,
0,54084,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(16384, 1, 1)",0,7.5,Occupancy,Block Limit Registers,block,128,,,,,
0,54084,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(16384, 1, 1)",0,7.5,Occupancy,Block Limit Shared Mem,block,16,,,,,
0,54084,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(16384, 1, 1)",0,7.5,Occupancy,Block Limit Warps,block,32,,,,,
0,54084,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(16384, 1, 1)",0,7.5,Occupancy,Theoretical Active Warps per SM,warp,16,,,,,
0,54084,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(16384, 1, 1)",0,7.5,Occupancy,Theoretical Occupancy,%,50,,,,,
0,54084,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(16384, 1, 1)",0,7.5,Occupancy,Achieved Occupancy,%,34.01,,,,,
0,54084,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(16384, 1, 1)",0,7.5,Occupancy,Achieved Active Warps Per SM,warp,10.88,,,,,
0,54084,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(16384, 1, 1)",0,7.5,Occupancy,,,,AchievedOccupancy,OPT,The difference between calculated theoretical (50.0%) and measured achieved occupancy (34.0%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy.,global,31.98
0,54084,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(16384, 1, 1)",0,7.5,Occupancy,,,,TheoreticalOccupancy,OPT,The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared memory.,global,50.0
0,54084,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(16384, 1, 1)",0,7.5,Source Counters,Branch Instructions Ratio,%,0.08,,,,,
0,54084,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(16384, 1, 1)",0,7.5,Source Counters,Branch Instructions,inst,"16,384",,,,,
0,54084,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(16384, 1, 1)",0,7.5,Source Counters,Branch Efficiency,%,0,,,,,
0,54084,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(32, 1, 1)","(16384, 1, 1)",0,7.5,Source Counters,Avg. Divergent Branches,,0,,,,,
0,54161,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(8192, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Frequency,cycle/second,"5,647,875,108.41",,,,,
0,54161,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(8192, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Frequency,cycle/second,"1,294,544,124.02",,,,,
0,54161,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(8192, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Elapsed Cycles,cycle,"47,878",,,,,
0,54161,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(8192, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Memory Throughput,%,87.35,,,,,
0,54161,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(8192, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Throughput,%,87.35,,,,,
0,54161,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(8192, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Duration,nsecond,"36,896",,,,,
0,54161,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(8192, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L1/TEX Cache Throughput,%,26.41,,,,,
0,54161,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(8192, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L2 Cache Throughput,%,53.77,,,,,
0,54161,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(8192, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Active Cycles,cycle,"46,192.79",,,,,
0,54161,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(8192, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Compute (SM) Throughput,%,19.59,,,,,
0,54161,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(8192, 1, 1)",0,7.5,SpeedOfLight,,,,SOLBottleneck,INF,"The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To further improve performance, work will likely need to be shifted from the most utilized to another unit. Start by analyzing DRAM in the Memory Workload Analysis section.",,
0,54161,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(8192, 1, 1)",0,7.5,SpeedOfLight_RooflineChart,,,,SOLFPRoofline,INF,The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved  close to 1% of this device's fp32 peak performance and 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.,,
0,54161,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(8192, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Active,inst/cycle,0.33,,,,,
0,54161,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(8192, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Elapsed,inst/cycle,0.32,,,,,
0,54161,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(8192, 1, 1)",0,7.5,Compute Workload Analysis,Issue Slots Busy,%,8.29,,,,,
0,54161,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(8192, 1, 1)",0,7.5,Compute Workload Analysis,Issued Ipc Active,inst/cycle,0.33,,,,,
0,54161,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(8192, 1, 1)",0,7.5,Compute Workload Analysis,SM Busy,%,8.44,,,,,
0,54161,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(8192, 1, 1)",0,7.5,ComputeWorkloadAnalysis,,,,HighPipeUtilization,OPT,All compute pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.,local,93.67
0,54161,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(8192, 1, 1)",0,7.5,Memory Workload Analysis,Memory Throughput,byte/second,"157,861,231,569.82",,,,,
0,54161,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(8192, 1, 1)",0,7.5,Memory Workload Analysis,Mem Busy,%,53.77,,,,,
0,54161,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(8192, 1, 1)",0,7.5,Memory Workload Analysis,Max Bandwidth,%,87.35,,,,,
0,54161,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(8192, 1, 1)",0,7.5,Memory Workload Analysis,L1/TEX Hit Rate,%,0,,,,,
0,54161,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(8192, 1, 1)",0,7.5,Memory Workload Analysis,L2 Hit Rate,%,33.42,,,,,
0,54161,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(8192, 1, 1)",0,7.5,Memory Workload Analysis,Mem Pipes Busy,%,19.59,,,,,
0,54161,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(8192, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Chart,,,,MemoryL2Compression,WRN,The optional metric lts__average_gcomp_input_sector_success_rate.pct could not be found. Collecting it as an additional metric could enable the rule to provide more guidance.,,
0,54161,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(8192, 1, 1)",0,7.5,Scheduler Statistics,One or More Eligible,%,8.33,,,,,
0,54161,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(8192, 1, 1)",0,7.5,Scheduler Statistics,Issued Warp Per Scheduler,,0.08,,,,,
0,54161,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(8192, 1, 1)",0,7.5,Scheduler Statistics,No Eligible,%,91.67,,,,,
0,54161,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(8192, 1, 1)",0,7.5,Scheduler Statistics,Active Warps Per Scheduler,warp,6.15,,,,,
0,54161,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(8192, 1, 1)",0,7.5,Scheduler Statistics,Eligible Warps Per Scheduler,warp,0.09,,,,,
0,54161,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(8192, 1, 1)",0,7.5,SchedulerStats,,,,IssueSlotUtilization,OPT,"Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 12.0 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of 6.15 active warps per scheduler, but only an average of 0.09 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections.",local,12.65
0,54161,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(8192, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Issued Instruction,cycle,73.86,,,,,
0,54161,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(8192, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Executed Instruction,cycle,74.35,,,,,
0,54161,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(8192, 1, 1)",0,7.5,Warp State Statistics,Avg. Active Threads Per Warp,,32,,,,,
0,54161,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(8192, 1, 1)",0,7.5,Warp State Statistics,Avg. Not Predicated Off Threads Per Warp,,32,,,,,
0,54161,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(8192, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,OPT,"On average, each warp of this kernel spends 65.0 cycles being stalled waiting for a scoreboard dependency on a L1TEX (local, global, surface, texture) operation. Find the instruction producing the data being waited upon to identify the culprit. To reduce the number of cycles waiting on L1TEX data accesses verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit rates by increasing data locality (coalescing), or by changing the cache configuration. Consider moving frequently used data to shared memory. This stall type represents about 88.1% of the total average of 73.9 cycles between issuing two instructions.",global,12.65
0,54161,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(8192, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,INF,Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.,,
0,54161,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(8192, 1, 1)",0,7.5,Instruction Statistics,Avg. Executed Instructions Per Scheduler,inst,"3,803.43",,,,,
0,54161,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(8192, 1, 1)",0,7.5,Instruction Statistics,Executed Instructions,inst,"212,992",,,,,
0,54161,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(8192, 1, 1)",0,7.5,Instruction Statistics,Avg. Issued Instructions Per Scheduler,inst,"3,828.57",,,,,
0,54161,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(8192, 1, 1)",0,7.5,Instruction Statistics,Issued Instructions,inst,"214,400",,,,,
0,54161,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(8192, 1, 1)",0,7.5,InstructionStats,,,,FPInstructions,OPT,"This kernel executes 0 fused and 16384 non-fused FP32 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP32 performance could be increased by up to 50% (relative to its current performance). Check the Source page to identify where this kernel executes FP32 instructions.",global,3.167
0,54161,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(8192, 1, 1)",0,7.5,Launch Statistics,Block Size,,64,,,,,
0,54161,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(8192, 1, 1)",0,7.5,Launch Statistics,Function Cache Configuration,,CachePreferNone,,,,,
0,54161,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(8192, 1, 1)",0,7.5,Launch Statistics,Grid Size,,"8,192",,,,,
0,54161,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(8192, 1, 1)",0,7.5,Launch Statistics,Registers Per Thread,register/thread,16,,,,,
0,54161,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(8192, 1, 1)",0,7.5,Launch Statistics,Shared Memory Configuration Size,byte,"32,768",,,,,
0,54161,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(8192, 1, 1)",0,7.5,Launch Statistics,Driver Shared Memory Per Block,byte/block,0,,,,,
0,54161,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(8192, 1, 1)",0,7.5,Launch Statistics,Dynamic Shared Memory Per Block,byte/block,0,,,,,
0,54161,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(8192, 1, 1)",0,7.5,Launch Statistics,Static Shared Memory Per Block,byte/block,0,,,,,
0,54161,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(8192, 1, 1)",0,7.5,Launch Statistics,Threads,thread,"524,288",,,,,
0,54161,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(8192, 1, 1)",0,7.5,Launch Statistics,Waves Per SM,,36.57,,,,,
0,54161,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(8192, 1, 1)",0,7.5,Occupancy,Block Limit SM,block,16,,,,,
0,54161,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(8192, 1, 1)",0,7.5,Occupancy,Block Limit Registers,block,64,,,,,
0,54161,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(8192, 1, 1)",0,7.5,Occupancy,Block Limit Shared Mem,block,16,,,,,
0,54161,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(8192, 1, 1)",0,7.5,Occupancy,Block Limit Warps,block,16,,,,,
0,54161,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(8192, 1, 1)",0,7.5,Occupancy,Theoretical Active Warps per SM,warp,32,,,,,
0,54161,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(8192, 1, 1)",0,7.5,Occupancy,Theoretical Occupancy,%,100,,,,,
0,54161,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(8192, 1, 1)",0,7.5,Occupancy,Achieved Occupancy,%,78.00,,,,,
0,54161,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(8192, 1, 1)",0,7.5,Occupancy,Achieved Active Warps Per SM,warp,24.96,,,,,
0,54161,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(8192, 1, 1)",0,7.5,Occupancy,,,,AchievedOccupancy,OPT,The difference between calculated theoretical (100.0%) and measured achieved occupancy (78.0%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy.,global,12.65
0,54161,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(8192, 1, 1)",0,7.5,Source Counters,Branch Instructions Ratio,%,0.08,,,,,
0,54161,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(8192, 1, 1)",0,7.5,Source Counters,Branch Instructions,inst,"16,384",,,,,
0,54161,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(8192, 1, 1)",0,7.5,Source Counters,Branch Efficiency,%,0,,,,,
0,54161,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(64, 1, 1)","(8192, 1, 1)",0,7.5,Source Counters,Avg. Divergent Branches,,0,,,,,
0,54245,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(4096, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Frequency,cycle/second,"5,545,927,209.71",,,,,
0,54245,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(4096, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Frequency,cycle/second,"1,270,038,994.80",,,,,
0,54245,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(4096, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Elapsed Cycles,cycle,"47,036",,,,,
0,54245,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(4096, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Memory Throughput,%,88.82,,,,,
0,54245,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(4096, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Throughput,%,88.82,,,,,
0,54245,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(4096, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Duration,nsecond,"36,928",,,,,
0,54245,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(4096, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L1/TEX Cache Throughput,%,26.46,,,,,
0,54245,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(4096, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L2 Cache Throughput,%,54.74,,,,,
0,54245,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(4096, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Active Cycles,cycle,"45,230",,,,,
0,54245,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(4096, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Compute (SM) Throughput,%,19.95,,,,,
0,54245,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(4096, 1, 1)",0,7.5,SpeedOfLight,,,,SOLBottleneck,INF,"The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To further improve performance, work will likely need to be shifted from the most utilized to another unit. Start by analyzing DRAM in the Memory Workload Analysis section.",,
0,54245,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(4096, 1, 1)",0,7.5,SpeedOfLight_RooflineChart,,,,SOLFPRoofline,INF,The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved  close to 1% of this device's fp32 peak performance and 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.,,
0,54245,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(4096, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Active,inst/cycle,0.34,,,,,
0,54245,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(4096, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Elapsed,inst/cycle,0.32,,,,,
0,54245,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(4096, 1, 1)",0,7.5,Compute Workload Analysis,Issue Slots Busy,%,8.48,,,,,
0,54245,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(4096, 1, 1)",0,7.5,Compute Workload Analysis,Issued Ipc Active,inst/cycle,0.34,,,,,
0,54245,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(4096, 1, 1)",0,7.5,Compute Workload Analysis,SM Busy,%,8.62,,,,,
0,54245,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(4096, 1, 1)",0,7.5,ComputeWorkloadAnalysis,,,,HighPipeUtilization,OPT,All compute pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.,local,93.53
0,54245,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(4096, 1, 1)",0,7.5,Memory Workload Analysis,Memory Throughput,byte/second,"157,623,916,811.09",,,,,
0,54245,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(4096, 1, 1)",0,7.5,Memory Workload Analysis,Mem Busy,%,54.74,,,,,
0,54245,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(4096, 1, 1)",0,7.5,Memory Workload Analysis,Max Bandwidth,%,88.82,,,,,
0,54245,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(4096, 1, 1)",0,7.5,Memory Workload Analysis,L1/TEX Hit Rate,%,0,,,,,
0,54245,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(4096, 1, 1)",0,7.5,Memory Workload Analysis,L2 Hit Rate,%,33.38,,,,,
0,54245,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(4096, 1, 1)",0,7.5,Memory Workload Analysis,Mem Pipes Busy,%,19.95,,,,,
0,54245,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(4096, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Chart,,,,MemoryL2Compression,WRN,The optional metric lts__average_gcomp_input_sector_success_rate.pct could not be found. Collecting it as an additional metric could enable the rule to provide more guidance.,,
0,54245,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(4096, 1, 1)",0,7.5,Scheduler Statistics,One or More Eligible,%,8.47,,,,,
0,54245,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(4096, 1, 1)",0,7.5,Scheduler Statistics,Issued Warp Per Scheduler,,0.08,,,,,
0,54245,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(4096, 1, 1)",0,7.5,Scheduler Statistics,No Eligible,%,91.53,,,,,
0,54245,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(4096, 1, 1)",0,7.5,Scheduler Statistics,Active Warps Per Scheduler,warp,6.72,,,,,
0,54245,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(4096, 1, 1)",0,7.5,Scheduler Statistics,Eligible Warps Per Scheduler,warp,0.09,,,,,
0,54245,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(4096, 1, 1)",0,7.5,SchedulerStats,,,,IssueSlotUtilization,OPT,"Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 11.8 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of 6.72 active warps per scheduler, but only an average of 0.09 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, avoid possible load imbalances due to highly different execution durations per warp. Reducing stalls indicated on the Warp State Statistics and Source Counters sections can help, too.",local,11.18
0,54245,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(4096, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Issued Instruction,cycle,79.33,,,,,
0,54245,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(4096, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Executed Instruction,cycle,79.99,,,,,
0,54245,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(4096, 1, 1)",0,7.5,Warp State Statistics,Avg. Active Threads Per Warp,,32,,,,,
0,54245,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(4096, 1, 1)",0,7.5,Warp State Statistics,Avg. Not Predicated Off Threads Per Warp,,32,,,,,
0,54245,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(4096, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,OPT,"On average, each warp of this kernel spends 69.0 cycles being stalled waiting for a scoreboard dependency on a L1TEX (local, global, surface, texture) operation. Find the instruction producing the data being waited upon to identify the culprit. To reduce the number of cycles waiting on L1TEX data accesses verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit rates by increasing data locality (coalescing), or by changing the cache configuration. Consider moving frequently used data to shared memory. This stall type represents about 86.9% of the total average of 79.3 cycles between issuing two instructions.",global,11.18
0,54245,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(4096, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,INF,Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.,,
0,54245,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(4096, 1, 1)",0,7.5,Instruction Statistics,Avg. Executed Instructions Per Scheduler,inst,"3,803.43",,,,,
0,54245,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(4096, 1, 1)",0,7.5,Instruction Statistics,Executed Instructions,inst,"212,992",,,,,
0,54245,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(4096, 1, 1)",0,7.5,Instruction Statistics,Avg. Issued Instructions Per Scheduler,inst,"3,835.43",,,,,
0,54245,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(4096, 1, 1)",0,7.5,Instruction Statistics,Issued Instructions,inst,"214,784",,,,,
0,54245,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(4096, 1, 1)",0,7.5,InstructionStats,,,,FPInstructions,OPT,"This kernel executes 0 fused and 16384 non-fused FP32 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP32 performance could be increased by up to 50% (relative to its current performance). Check the Source page to identify where this kernel executes FP32 instructions.",global,3.234
0,54245,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(4096, 1, 1)",0,7.5,Launch Statistics,Block Size,,128,,,,,
0,54245,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(4096, 1, 1)",0,7.5,Launch Statistics,Function Cache Configuration,,CachePreferNone,,,,,
0,54245,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(4096, 1, 1)",0,7.5,Launch Statistics,Grid Size,,"4,096",,,,,
0,54245,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(4096, 1, 1)",0,7.5,Launch Statistics,Registers Per Thread,register/thread,16,,,,,
0,54245,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(4096, 1, 1)",0,7.5,Launch Statistics,Shared Memory Configuration Size,byte,"32,768",,,,,
0,54245,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(4096, 1, 1)",0,7.5,Launch Statistics,Driver Shared Memory Per Block,byte/block,0,,,,,
0,54245,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(4096, 1, 1)",0,7.5,Launch Statistics,Dynamic Shared Memory Per Block,byte/block,0,,,,,
0,54245,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(4096, 1, 1)",0,7.5,Launch Statistics,Static Shared Memory Per Block,byte/block,0,,,,,
0,54245,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(4096, 1, 1)",0,7.5,Launch Statistics,Threads,thread,"524,288",,,,,
0,54245,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(4096, 1, 1)",0,7.5,Launch Statistics,Waves Per SM,,36.57,,,,,
0,54245,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(4096, 1, 1)",0,7.5,Occupancy,Block Limit SM,block,16,,,,,
0,54245,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(4096, 1, 1)",0,7.5,Occupancy,Block Limit Registers,block,32,,,,,
0,54245,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(4096, 1, 1)",0,7.5,Occupancy,Block Limit Shared Mem,block,16,,,,,
0,54245,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(4096, 1, 1)",0,7.5,Occupancy,Block Limit Warps,block,8,,,,,
0,54245,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(4096, 1, 1)",0,7.5,Occupancy,Theoretical Active Warps per SM,warp,32,,,,,
0,54245,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(4096, 1, 1)",0,7.5,Occupancy,Theoretical Occupancy,%,100,,,,,
0,54245,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(4096, 1, 1)",0,7.5,Occupancy,Achieved Occupancy,%,85.54,,,,,
0,54245,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(4096, 1, 1)",0,7.5,Occupancy,Achieved Active Warps Per SM,warp,27.37,,,,,
0,54245,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(4096, 1, 1)",0,7.5,Occupancy,,,,AchievedOccupancy,OPT,The difference between calculated theoretical (100.0%) and measured achieved occupancy (85.5%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy.,global,11.18
0,54245,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(4096, 1, 1)",0,7.5,Source Counters,Branch Instructions Ratio,%,0.08,,,,,
0,54245,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(4096, 1, 1)",0,7.5,Source Counters,Branch Instructions,inst,"16,384",,,,,
0,54245,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(4096, 1, 1)",0,7.5,Source Counters,Branch Efficiency,%,0,,,,,
0,54245,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(128, 1, 1)","(4096, 1, 1)",0,7.5,Source Counters,Avg. Divergent Branches,,0,,,,,
0,54322,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(2048, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Frequency,cycle/second,"5,555,555,555.56",,,,,
0,54322,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(2048, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Frequency,cycle/second,"1,275,349,934.90",,,,,
0,54322,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(2048, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Elapsed Cycles,cycle,"47,151",,,,,
0,54322,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(2048, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Memory Throughput,%,88.81,,,,,
0,54322,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(2048, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Throughput,%,88.81,,,,,
0,54322,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(2048, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Duration,nsecond,"36,864",,,,,
0,54322,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(2048, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L1/TEX Cache Throughput,%,26.09,,,,,
0,54322,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(2048, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L2 Cache Throughput,%,54.64,,,,,
0,54322,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(2048, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Active Cycles,cycle,"45,134.43",,,,,
0,54322,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(2048, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Compute (SM) Throughput,%,19.91,,,,,
0,54322,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(2048, 1, 1)",0,7.5,SpeedOfLight,,,,SOLBottleneck,INF,"The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To further improve performance, work will likely need to be shifted from the most utilized to another unit. Start by analyzing DRAM in the Memory Workload Analysis section.",,
0,54322,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(2048, 1, 1)",0,7.5,SpeedOfLight_RooflineChart,,,,SOLFPRoofline,INF,The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved  close to 1% of this device's fp32 peak performance and 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.,,
0,54322,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(2048, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Active,inst/cycle,0.34,,,,,
0,54322,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(2048, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Elapsed,inst/cycle,0.32,,,,,
0,54322,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(2048, 1, 1)",0,7.5,Compute Workload Analysis,Issue Slots Busy,%,8.50,,,,,
0,54322,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(2048, 1, 1)",0,7.5,Compute Workload Analysis,Issued Ipc Active,inst/cycle,0.34,,,,,
0,54322,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(2048, 1, 1)",0,7.5,Compute Workload Analysis,SM Busy,%,8.64,,,,,
0,54322,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(2048, 1, 1)",0,7.5,ComputeWorkloadAnalysis,,,,HighPipeUtilization,OPT,All compute pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.,local,93.52
0,54322,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(2048, 1, 1)",0,7.5,Memory Workload Analysis,Memory Throughput,byte/second,"157,883,680,555.56",,,,,
0,54322,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(2048, 1, 1)",0,7.5,Memory Workload Analysis,Mem Busy,%,54.64,,,,,
0,54322,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(2048, 1, 1)",0,7.5,Memory Workload Analysis,Max Bandwidth,%,88.81,,,,,
0,54322,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(2048, 1, 1)",0,7.5,Memory Workload Analysis,L1/TEX Hit Rate,%,0,,,,,
0,54322,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(2048, 1, 1)",0,7.5,Memory Workload Analysis,L2 Hit Rate,%,33.38,,,,,
0,54322,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(2048, 1, 1)",0,7.5,Memory Workload Analysis,Mem Pipes Busy,%,19.91,,,,,
0,54322,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(2048, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Chart,,,,MemoryL2Compression,WRN,The optional metric lts__average_gcomp_input_sector_success_rate.pct could not be found. Collecting it as an additional metric could enable the rule to provide more guidance.,,
0,54322,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(2048, 1, 1)",0,7.5,Scheduler Statistics,One or More Eligible,%,8.55,,,,,
0,54322,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(2048, 1, 1)",0,7.5,Scheduler Statistics,Issued Warp Per Scheduler,,0.09,,,,,
0,54322,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(2048, 1, 1)",0,7.5,Scheduler Statistics,No Eligible,%,91.45,,,,,
0,54322,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(2048, 1, 1)",0,7.5,Scheduler Statistics,Active Warps Per Scheduler,warp,6.74,,,,,
0,54322,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(2048, 1, 1)",0,7.5,Scheduler Statistics,Eligible Warps Per Scheduler,warp,0.10,,,,,
0,54322,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(2048, 1, 1)",0,7.5,SchedulerStats,,,,IssueSlotUtilization,OPT,"Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 11.7 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of 6.74 active warps per scheduler, but only an average of 0.10 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, avoid possible load imbalances due to highly different execution durations per warp. Reducing stalls indicated on the Warp State Statistics and Source Counters sections can help, too.",local,11.19
0,54322,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(2048, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Issued Instruction,cycle,78.92,,,,,
0,54322,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(2048, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Executed Instruction,cycle,79.57,,,,,
0,54322,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(2048, 1, 1)",0,7.5,Warp State Statistics,Avg. Active Threads Per Warp,,32,,,,,
0,54322,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(2048, 1, 1)",0,7.5,Warp State Statistics,Avg. Not Predicated Off Threads Per Warp,,32,,,,,
0,54322,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(2048, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,OPT,"On average, each warp of this kernel spends 67.5 cycles being stalled waiting for a scoreboard dependency on a L1TEX (local, global, surface, texture) operation. Find the instruction producing the data being waited upon to identify the culprit. To reduce the number of cycles waiting on L1TEX data accesses verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit rates by increasing data locality (coalescing), or by changing the cache configuration. Consider moving frequently used data to shared memory. This stall type represents about 85.5% of the total average of 78.9 cycles between issuing two instructions.",global,11.19
0,54322,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(2048, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,INF,Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.,,
0,54322,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(2048, 1, 1)",0,7.5,Instruction Statistics,Avg. Executed Instructions Per Scheduler,inst,"3,803.43",,,,,
0,54322,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(2048, 1, 1)",0,7.5,Instruction Statistics,Executed Instructions,inst,"212,992",,,,,
0,54322,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(2048, 1, 1)",0,7.5,Instruction Statistics,Avg. Issued Instructions Per Scheduler,inst,"3,834.93",,,,,
0,54322,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(2048, 1, 1)",0,7.5,Instruction Statistics,Issued Instructions,inst,"214,756",,,,,
0,54322,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(2048, 1, 1)",0,7.5,InstructionStats,,,,FPInstructions,OPT,"This kernel executes 0 fused and 16384 non-fused FP32 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP32 performance could be increased by up to 50% (relative to its current performance). Check the Source page to identify where this kernel executes FP32 instructions.",global,3.241
0,54322,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(2048, 1, 1)",0,7.5,Launch Statistics,Block Size,,256,,,,,
0,54322,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(2048, 1, 1)",0,7.5,Launch Statistics,Function Cache Configuration,,CachePreferNone,,,,,
0,54322,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(2048, 1, 1)",0,7.5,Launch Statistics,Grid Size,,"2,048",,,,,
0,54322,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(2048, 1, 1)",0,7.5,Launch Statistics,Registers Per Thread,register/thread,16,,,,,
0,54322,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(2048, 1, 1)",0,7.5,Launch Statistics,Shared Memory Configuration Size,byte,"32,768",,,,,
0,54322,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(2048, 1, 1)",0,7.5,Launch Statistics,Driver Shared Memory Per Block,byte/block,0,,,,,
0,54322,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(2048, 1, 1)",0,7.5,Launch Statistics,Dynamic Shared Memory Per Block,byte/block,0,,,,,
0,54322,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(2048, 1, 1)",0,7.5,Launch Statistics,Static Shared Memory Per Block,byte/block,0,,,,,
0,54322,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(2048, 1, 1)",0,7.5,Launch Statistics,Threads,thread,"524,288",,,,,
0,54322,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(2048, 1, 1)",0,7.5,Launch Statistics,Waves Per SM,,36.57,,,,,
0,54322,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(2048, 1, 1)",0,7.5,Occupancy,Block Limit SM,block,16,,,,,
0,54322,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(2048, 1, 1)",0,7.5,Occupancy,Block Limit Registers,block,16,,,,,
0,54322,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(2048, 1, 1)",0,7.5,Occupancy,Block Limit Shared Mem,block,16,,,,,
0,54322,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(2048, 1, 1)",0,7.5,Occupancy,Block Limit Warps,block,4,,,,,
0,54322,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(2048, 1, 1)",0,7.5,Occupancy,Theoretical Active Warps per SM,warp,32,,,,,
0,54322,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(2048, 1, 1)",0,7.5,Occupancy,Theoretical Occupancy,%,100,,,,,
0,54322,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(2048, 1, 1)",0,7.5,Occupancy,Achieved Occupancy,%,84.98,,,,,
0,54322,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(2048, 1, 1)",0,7.5,Occupancy,Achieved Active Warps Per SM,warp,27.19,,,,,
0,54322,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(2048, 1, 1)",0,7.5,Occupancy,,,,AchievedOccupancy,OPT,The difference between calculated theoretical (100.0%) and measured achieved occupancy (85.0%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy.,global,11.19
0,54322,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(2048, 1, 1)",0,7.5,Source Counters,Branch Instructions Ratio,%,0.08,,,,,
0,54322,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(2048, 1, 1)",0,7.5,Source Counters,Branch Instructions,inst,"16,384",,,,,
0,54322,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(2048, 1, 1)",0,7.5,Source Counters,Branch Efficiency,%,0,,,,,
0,54322,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(256, 1, 1)","(2048, 1, 1)",0,7.5,Source Counters,Avg. Divergent Branches,,0,,,,,
0,54407,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(1024, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Frequency,cycle/second,"5,577,221,742.88",,,,,
0,54407,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(1024, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Frequency,cycle/second,"1,278,971,635.03",,,,,
0,54407,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(1024, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Elapsed Cycles,cycle,"47,603",,,,,
0,54407,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(1024, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Memory Throughput,%,87.88,,,,,
0,54407,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(1024, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Throughput,%,87.88,,,,,
0,54407,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(1024, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Duration,nsecond,"37,088",,,,,
0,54407,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(1024, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L1/TEX Cache Throughput,%,25.38,,,,,
0,54407,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(1024, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L2 Cache Throughput,%,54.13,,,,,
0,54407,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(1024, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Active Cycles,cycle,"44,816.07",,,,,
0,54407,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(1024, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Compute (SM) Throughput,%,19.73,,,,,
0,54407,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(1024, 1, 1)",0,7.5,SpeedOfLight,,,,SOLBottleneck,INF,"The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To further improve performance, work will likely need to be shifted from the most utilized to another unit. Start by analyzing DRAM in the Memory Workload Analysis section.",,
0,54407,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(1024, 1, 1)",0,7.5,SpeedOfLight_RooflineChart,,,,SOLFPRoofline,INF,The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved  close to 1% of this device's fp32 peak performance and 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.,,
0,54407,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(1024, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Active,inst/cycle,0.34,,,,,
0,54407,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(1024, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Elapsed,inst/cycle,0.32,,,,,
0,54407,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(1024, 1, 1)",0,7.5,Compute Workload Analysis,Issue Slots Busy,%,8.56,,,,,
0,54407,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(1024, 1, 1)",0,7.5,Compute Workload Analysis,Issued Ipc Active,inst/cycle,0.34,,,,,
0,54407,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(1024, 1, 1)",0,7.5,Compute Workload Analysis,SM Busy,%,8.70,,,,,
0,54407,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(1024, 1, 1)",0,7.5,ComputeWorkloadAnalysis,,,,HighPipeUtilization,OPT,All compute pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.,local,93.47
0,54407,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(1024, 1, 1)",0,7.5,Memory Workload Analysis,Memory Throughput,byte/second,"156,842,968,075.93",,,,,
0,54407,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(1024, 1, 1)",0,7.5,Memory Workload Analysis,Mem Busy,%,54.13,,,,,
0,54407,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(1024, 1, 1)",0,7.5,Memory Workload Analysis,Max Bandwidth,%,87.88,,,,,
0,54407,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(1024, 1, 1)",0,7.5,Memory Workload Analysis,L1/TEX Hit Rate,%,0,,,,,
0,54407,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(1024, 1, 1)",0,7.5,Memory Workload Analysis,L2 Hit Rate,%,33.38,,,,,
0,54407,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(1024, 1, 1)",0,7.5,Memory Workload Analysis,Mem Pipes Busy,%,19.73,,,,,
0,54407,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(1024, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Chart,,,,MemoryL2Compression,WRN,The optional metric lts__average_gcomp_input_sector_success_rate.pct could not be found. Collecting it as an additional metric could enable the rule to provide more guidance.,,
0,54407,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(1024, 1, 1)",0,7.5,Scheduler Statistics,One or More Eligible,%,8.65,,,,,
0,54407,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(1024, 1, 1)",0,7.5,Scheduler Statistics,Issued Warp Per Scheduler,,0.09,,,,,
0,54407,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(1024, 1, 1)",0,7.5,Scheduler Statistics,No Eligible,%,91.35,,,,,
0,54407,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(1024, 1, 1)",0,7.5,Scheduler Statistics,Active Warps Per Scheduler,warp,6.64,,,,,
0,54407,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(1024, 1, 1)",0,7.5,Scheduler Statistics,Eligible Warps Per Scheduler,warp,0.12,,,,,
0,54407,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(1024, 1, 1)",0,7.5,SchedulerStats,,,,IssueSlotUtilization,OPT,"Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 11.6 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of 6.64 active warps per scheduler, but only an average of 0.12 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, avoid possible load imbalances due to highly different execution durations per warp. Reducing stalls indicated on the Warp State Statistics and Source Counters sections can help, too.",local,12.12
0,54407,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(1024, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Issued Instruction,cycle,76.73,,,,,
0,54407,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(1024, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Executed Instruction,cycle,77.38,,,,,
0,54407,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(1024, 1, 1)",0,7.5,Warp State Statistics,Avg. Active Threads Per Warp,,32,,,,,
0,54407,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(1024, 1, 1)",0,7.5,Warp State Statistics,Avg. Not Predicated Off Threads Per Warp,,32,,,,,
0,54407,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(1024, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,OPT,"On average, each warp of this kernel spends 65.3 cycles being stalled waiting for a scoreboard dependency on a L1TEX (local, global, surface, texture) operation. Find the instruction producing the data being waited upon to identify the culprit. To reduce the number of cycles waiting on L1TEX data accesses verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit rates by increasing data locality (coalescing), or by changing the cache configuration. Consider moving frequently used data to shared memory. This stall type represents about 85.1% of the total average of 76.7 cycles between issuing two instructions.",global,12.12
0,54407,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(1024, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,INF,Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.,,
0,54407,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(1024, 1, 1)",0,7.5,Instruction Statistics,Avg. Executed Instructions Per Scheduler,inst,"3,803.43",,,,,
0,54407,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(1024, 1, 1)",0,7.5,Instruction Statistics,Executed Instructions,inst,"212,992",,,,,
0,54407,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(1024, 1, 1)",0,7.5,Instruction Statistics,Avg. Issued Instructions Per Scheduler,inst,"3,835.43",,,,,
0,54407,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(1024, 1, 1)",0,7.5,Instruction Statistics,Issued Instructions,inst,"214,784",,,,,
0,54407,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(1024, 1, 1)",0,7.5,InstructionStats,,,,FPInstructions,OPT,"This kernel executes 0 fused and 16384 non-fused FP32 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP32 performance could be increased by up to 50% (relative to its current performance). Check the Source page to identify where this kernel executes FP32 instructions.",global,3.264
0,54407,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(1024, 1, 1)",0,7.5,Launch Statistics,Block Size,,512,,,,,
0,54407,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(1024, 1, 1)",0,7.5,Launch Statistics,Function Cache Configuration,,CachePreferNone,,,,,
0,54407,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(1024, 1, 1)",0,7.5,Launch Statistics,Grid Size,,"1,024",,,,,
0,54407,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(1024, 1, 1)",0,7.5,Launch Statistics,Registers Per Thread,register/thread,16,,,,,
0,54407,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(1024, 1, 1)",0,7.5,Launch Statistics,Shared Memory Configuration Size,byte,"32,768",,,,,
0,54407,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(1024, 1, 1)",0,7.5,Launch Statistics,Driver Shared Memory Per Block,byte/block,0,,,,,
0,54407,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(1024, 1, 1)",0,7.5,Launch Statistics,Dynamic Shared Memory Per Block,byte/block,0,,,,,
0,54407,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(1024, 1, 1)",0,7.5,Launch Statistics,Static Shared Memory Per Block,byte/block,0,,,,,
0,54407,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(1024, 1, 1)",0,7.5,Launch Statistics,Threads,thread,"524,288",,,,,
0,54407,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(1024, 1, 1)",0,7.5,Launch Statistics,Waves Per SM,,36.57,,,,,
0,54407,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(1024, 1, 1)",0,7.5,Occupancy,Block Limit SM,block,16,,,,,
0,54407,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(1024, 1, 1)",0,7.5,Occupancy,Block Limit Registers,block,8,,,,,
0,54407,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(1024, 1, 1)",0,7.5,Occupancy,Block Limit Shared Mem,block,16,,,,,
0,54407,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(1024, 1, 1)",0,7.5,Occupancy,Block Limit Warps,block,2,,,,,
0,54407,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(1024, 1, 1)",0,7.5,Occupancy,Theoretical Active Warps per SM,warp,32,,,,,
0,54407,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(1024, 1, 1)",0,7.5,Occupancy,Theoretical Occupancy,%,100,,,,,
0,54407,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(1024, 1, 1)",0,7.5,Occupancy,Achieved Occupancy,%,84.21,,,,,
0,54407,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(1024, 1, 1)",0,7.5,Occupancy,Achieved Active Warps Per SM,warp,26.95,,,,,
0,54407,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(1024, 1, 1)",0,7.5,Occupancy,,,,AchievedOccupancy,OPT,The difference between calculated theoretical (100.0%) and measured achieved occupancy (84.2%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy.,global,12.12
0,54407,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(1024, 1, 1)",0,7.5,Source Counters,Branch Instructions Ratio,%,0.08,,,,,
0,54407,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(1024, 1, 1)",0,7.5,Source Counters,Branch Instructions,inst,"16,384",,,,,
0,54407,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(1024, 1, 1)",0,7.5,Source Counters,Branch Efficiency,%,0,,,,,
0,54407,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(512, 1, 1)","(1024, 1, 1)",0,7.5,Source Counters,Avg. Divergent Branches,,0,,,,,
0,54491,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(512, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Frequency,cycle/second,"5,706,484,641.64",,,,,
0,54491,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(512, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Frequency,cycle/second,"1,309,780,290.10",,,,,
0,54491,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(512, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Elapsed Cycles,cycle,"49,261",,,,,
0,54491,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(512, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Memory Throughput,%,85.31,,,,,
0,54491,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(512, 1, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Throughput,%,85.31,,,,,
0,54491,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(512, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Duration,nsecond,"37,504",,,,,
0,54491,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(512, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L1/TEX Cache Throughput,%,23.96,,,,,
0,54491,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(512, 1, 1)",0,7.5,GPU Speed Of Light Throughput,L2 Cache Throughput,%,52.27,,,,,
0,54491,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(512, 1, 1)",0,7.5,GPU Speed Of Light Throughput,SM Active Cycles,cycle,"42,074.29",,,,,
0,54491,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(512, 1, 1)",0,7.5,GPU Speed Of Light Throughput,Compute (SM) Throughput,%,19.05,,,,,
0,54491,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(512, 1, 1)",0,7.5,SpeedOfLight,,,,SOLBottleneck,INF,"The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To further improve performance, work will likely need to be shifted from the most utilized to another unit. Start by analyzing DRAM in the Memory Workload Analysis section.",,
0,54491,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(512, 1, 1)",0,7.5,SpeedOfLight_RooflineChart,,,,SOLFPRoofline,INF,The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved  close to 1% of this device's fp32 peak performance and 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.,,
0,54491,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(512, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Active,inst/cycle,0.36,,,,,
0,54491,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(512, 1, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Elapsed,inst/cycle,0.31,,,,,
0,54491,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(512, 1, 1)",0,7.5,Compute Workload Analysis,Issue Slots Busy,%,9.12,,,,,
0,54491,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(512, 1, 1)",0,7.5,Compute Workload Analysis,Issued Ipc Active,inst/cycle,0.36,,,,,
0,54491,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(512, 1, 1)",0,7.5,Compute Workload Analysis,SM Busy,%,9.27,,,,,
0,54491,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(512, 1, 1)",0,7.5,ComputeWorkloadAnalysis,,,,HighPipeUtilization,OPT,All compute pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.,local,93.05
0,54491,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(512, 1, 1)",0,7.5,Memory Workload Analysis,Memory Throughput,byte/second,"155,779,863,481.23",,,,,
0,54491,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(512, 1, 1)",0,7.5,Memory Workload Analysis,Mem Busy,%,52.27,,,,,
0,54491,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(512, 1, 1)",0,7.5,Memory Workload Analysis,Max Bandwidth,%,85.31,,,,,
0,54491,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(512, 1, 1)",0,7.5,Memory Workload Analysis,L1/TEX Hit Rate,%,0,,,,,
0,54491,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(512, 1, 1)",0,7.5,Memory Workload Analysis,L2 Hit Rate,%,33.38,,,,,
0,54491,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(512, 1, 1)",0,7.5,Memory Workload Analysis,Mem Pipes Busy,%,19.05,,,,,
0,54491,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(512, 1, 1)",0,7.5,MemoryWorkloadAnalysis_Chart,,,,MemoryL2Compression,WRN,The optional metric lts__average_gcomp_input_sector_success_rate.pct could not be found. Collecting it as an additional metric could enable the rule to provide more guidance.,,
0,54491,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(512, 1, 1)",0,7.5,Scheduler Statistics,One or More Eligible,%,9.26,,,,,
0,54491,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(512, 1, 1)",0,7.5,Scheduler Statistics,Issued Warp Per Scheduler,,0.09,,,,,
0,54491,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(512, 1, 1)",0,7.5,Scheduler Statistics,No Eligible,%,90.74,,,,,
0,54491,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(512, 1, 1)",0,7.5,Scheduler Statistics,Active Warps Per Scheduler,warp,7.03,,,,,
0,54491,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(512, 1, 1)",0,7.5,Scheduler Statistics,Eligible Warps Per Scheduler,warp,0.21,,,,,
0,54491,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(512, 1, 1)",0,7.5,SchedulerStats,,,,IssueSlotUtilization,OPT,"Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 10.8 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of 7.03 active warps per scheduler, but only an average of 0.21 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, avoid possible load imbalances due to highly different execution durations per warp. Reducing stalls indicated on the Warp State Statistics and Source Counters sections can help, too.",local,14.69
0,54491,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(512, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Issued Instruction,cycle,75.91,,,,,
0,54491,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(512, 1, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Executed Instruction,cycle,76.54,,,,,
0,54491,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(512, 1, 1)",0,7.5,Warp State Statistics,Avg. Active Threads Per Warp,,32,,,,,
0,54491,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(512, 1, 1)",0,7.5,Warp State Statistics,Avg. Not Predicated Off Threads Per Warp,,32,,,,,
0,54491,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(512, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,OPT,"On average, each warp of this kernel spends 61.4 cycles being stalled waiting for a scoreboard dependency on a L1TEX (local, global, surface, texture) operation. Find the instruction producing the data being waited upon to identify the culprit. To reduce the number of cycles waiting on L1TEX data accesses verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit rates by increasing data locality (coalescing), or by changing the cache configuration. Consider moving frequently used data to shared memory. This stall type represents about 80.8% of the total average of 75.9 cycles between issuing two instructions.",global,14.69
0,54491,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(512, 1, 1)",0,7.5,WarpStateStats,,,,CPIStall,INF,Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.,,
0,54491,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(512, 1, 1)",0,7.5,Instruction Statistics,Avg. Executed Instructions Per Scheduler,inst,"3,803.43",,,,,
0,54491,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(512, 1, 1)",0,7.5,Instruction Statistics,Executed Instructions,inst,"212,992",,,,,
0,54491,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(512, 1, 1)",0,7.5,Instruction Statistics,Avg. Issued Instructions Per Scheduler,inst,"3,835.43",,,,,
0,54491,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(512, 1, 1)",0,7.5,Instruction Statistics,Issued Instructions,inst,"214,784",,,,,
0,54491,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(512, 1, 1)",0,7.5,InstructionStats,,,,FPInstructions,OPT,"This kernel executes 0 fused and 16384 non-fused FP32 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP32 performance could be increased by up to 50% (relative to its current performance). Check the Source page to identify where this kernel executes FP32 instructions.",global,3.477
0,54491,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(512, 1, 1)",0,7.5,Launch Statistics,Block Size,,"1,024",,,,,
0,54491,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(512, 1, 1)",0,7.5,Launch Statistics,Function Cache Configuration,,CachePreferNone,,,,,
0,54491,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(512, 1, 1)",0,7.5,Launch Statistics,Grid Size,,512,,,,,
0,54491,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(512, 1, 1)",0,7.5,Launch Statistics,Registers Per Thread,register/thread,16,,,,,
0,54491,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(512, 1, 1)",0,7.5,Launch Statistics,Shared Memory Configuration Size,byte,"32,768",,,,,
0,54491,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(512, 1, 1)",0,7.5,Launch Statistics,Driver Shared Memory Per Block,byte/block,0,,,,,
0,54491,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(512, 1, 1)",0,7.5,Launch Statistics,Dynamic Shared Memory Per Block,byte/block,0,,,,,
0,54491,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(512, 1, 1)",0,7.5,Launch Statistics,Static Shared Memory Per Block,byte/block,0,,,,,
0,54491,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(512, 1, 1)",0,7.5,Launch Statistics,Threads,thread,"524,288",,,,,
0,54491,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(512, 1, 1)",0,7.5,Launch Statistics,Waves Per SM,,36.57,,,,,
0,54491,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(512, 1, 1)",0,7.5,Occupancy,Block Limit SM,block,16,,,,,
0,54491,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(512, 1, 1)",0,7.5,Occupancy,Block Limit Registers,block,4,,,,,
0,54491,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(512, 1, 1)",0,7.5,Occupancy,Block Limit Shared Mem,block,16,,,,,
0,54491,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(512, 1, 1)",0,7.5,Occupancy,Block Limit Warps,block,1,,,,,
0,54491,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(512, 1, 1)",0,7.5,Occupancy,Theoretical Active Warps per SM,warp,32,,,,,
0,54491,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(512, 1, 1)",0,7.5,Occupancy,Theoretical Occupancy,%,100,,,,,
0,54491,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(512, 1, 1)",0,7.5,Occupancy,Achieved Occupancy,%,88.12,,,,,
0,54491,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(512, 1, 1)",0,7.5,Occupancy,Achieved Active Warps Per SM,warp,28.20,,,,,
0,54491,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(512, 1, 1)",0,7.5,Occupancy,,,,AchievedOccupancy,OPT,The difference between calculated theoretical (100.0%) and measured achieved occupancy (88.1%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy.,global,11.88
0,54491,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(512, 1, 1)",0,7.5,Source Counters,Branch Instructions Ratio,%,0.08,,,,,
0,54491,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(512, 1, 1)",0,7.5,Source Counters,Branch Instructions,inst,"16,384",,,,,
0,54491,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(512, 1, 1)",0,7.5,Source Counters,Branch Efficiency,%,0,,,,,
0,54491,vectorAdd,127.0.0.1,"vectorAdd(const float *, const float *, float *)",1,7,"(1024, 1, 1)","(512, 1, 1)",0,7.5,Source Counters,Avg. Divergent Branches,,0,,,,,
0,54568,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(1024, 1024, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Frequency,cycle/second,"5,985,288,176.99",,,,,
0,54568,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(1024, 1024, 1)",0,7.5,GPU Speed Of Light Throughput,SM Frequency,cycle/second,"1,375,674,497.39",,,,,
0,54568,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(1024, 1024, 1)",0,7.5,GPU Speed Of Light Throughput,Elapsed Cycles,cycle,"4,692,999",,,,,
0,54568,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(1024, 1024, 1)",0,7.5,GPU Speed Of Light Throughput,Memory Throughput,%,15.98,,,,,
0,54568,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(1024, 1024, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Throughput,%,1.89,,,,,
0,54568,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(1024, 1024, 1)",0,7.5,GPU Speed Of Light Throughput,Duration,nsecond,"3,406,240",,,,,
0,54568,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(1024, 1024, 1)",0,7.5,GPU Speed Of Light Throughput,L1/TEX Cache Throughput,%,26.95,,,,,
0,54568,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(1024, 1024, 1)",0,7.5,GPU Speed Of Light Throughput,L2 Cache Throughput,%,11.42,,,,,
0,54568,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(1024, 1024, 1)",0,7.5,GPU Speed Of Light Throughput,SM Active Cycles,cycle,"2,779,531.79",,,,,
0,54568,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(1024, 1024, 1)",0,7.5,GPU Speed Of Light Throughput,Compute (SM) Throughput,%,15.98,,,,,
0,54568,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(1024, 1024, 1)",0,7.5,SpeedOfLight,,,,SOLBottleneck,OPT,This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.,,
0,54568,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(1024, 1024, 1)",0,7.5,SpeedOfLight_RooflineChart,,,,SOLFPRoofline,INF,The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved  close to 0% of this device's fp32 peak performance and 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.,,
0,54568,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(1024, 1024, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Active,inst/cycle,0.46,,,,,
0,54568,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(1024, 1024, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Elapsed,inst/cycle,0.27,,,,,
0,54568,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(1024, 1024, 1)",0,7.5,Compute Workload Analysis,Issue Slots Busy,%,11.45,,,,,
0,54568,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(1024, 1024, 1)",0,7.5,Compute Workload Analysis,Issued Ipc Active,inst/cycle,0.46,,,,,
0,54568,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(1024, 1024, 1)",0,7.5,Compute Workload Analysis,SM Busy,%,12.57,,,,,
0,54568,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(1024, 1024, 1)",0,7.5,ComputeWorkloadAnalysis,,,,HighPipeUtilization,OPT,All compute pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.,local,90.57
0,54568,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(1024, 1024, 1)",0,7.5,Memory Workload Analysis,Memory Throughput,byte/second,"3,610,747,334.30",,,,,
0,54568,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(1024, 1024, 1)",0,7.5,Memory Workload Analysis,Mem Busy,%,8.51,,,,,
0,54568,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(1024, 1024, 1)",0,7.5,Memory Workload Analysis,Max Bandwidth,%,15.98,,,,,
0,54568,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(1024, 1024, 1)",0,7.5,Memory Workload Analysis,L1/TEX Hit Rate,%,5.01,,,,,
0,54568,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(1024, 1024, 1)",0,7.5,Memory Workload Analysis,L2 Hit Rate,%,95.67,,,,,
0,54568,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(1024, 1024, 1)",0,7.5,Memory Workload Analysis,Mem Pipes Busy,%,15.98,,,,,
0,54568,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(1024, 1024, 1)",0,7.5,MemoryWorkloadAnalysis_Chart,,,,MemoryL2Compression,WRN,The optional metric lts__average_gcomp_input_sector_success_rate.pct could not be found. Collecting it as an additional metric could enable the rule to provide more guidance.,,
0,54568,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(1024, 1024, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for loads from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced loads and try to minimize how many cache lines need to be accessed per memory request.",global,4.194
0,54568,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(1024, 1024, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for stores from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced stores and try to minimize how many cache lines need to be accessed per memory request.",global,2.19
0,54568,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(1024, 1024, 1)",0,7.5,Scheduler Statistics,One or More Eligible,%,13.05,,,,,
0,54568,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(1024, 1024, 1)",0,7.5,Scheduler Statistics,Issued Warp Per Scheduler,,0.13,,,,,
0,54568,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(1024, 1024, 1)",0,7.5,Scheduler Statistics,No Eligible,%,86.95,,,,,
0,54568,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(1024, 1024, 1)",0,7.5,Scheduler Statistics,Active Warps Per Scheduler,warp,2.49,,,,,
0,54568,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(1024, 1024, 1)",0,7.5,Scheduler Statistics,Eligible Warps Per Scheduler,warp,0.14,,,,,
0,54568,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(1024, 1024, 1)",0,7.5,SchedulerStats,,,,IssueSlotUtilization,OPT,"Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 7.7 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of 2.49 active warps per scheduler, but only an average of 0.14 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections.",local,84.02
0,54568,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(1024, 1024, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Issued Instruction,cycle,19.12,,,,,
0,54568,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(1024, 1024, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Executed Instruction,cycle,19.12,,,,,
0,54568,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(1024, 1024, 1)",0,7.5,Warp State Statistics,Avg. Active Threads Per Warp,,1,,,,,
0,54568,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(1024, 1024, 1)",0,7.5,Warp State Statistics,Avg. Not Predicated Off Threads Per Warp,,1,,,,,
0,54568,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(1024, 1024, 1)",0,7.5,WarpStateStats,,,,CPIStall,OPT,"On average, each warp of this kernel spends 12.1 cycles being stalled waiting for a scoreboard dependency on a L1TEX (local, global, surface, texture) operation. Find the instruction producing the data being waited upon to identify the culprit. To reduce the number of cycles waiting on L1TEX data accesses verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit rates by increasing data locality (coalescing), or by changing the cache configuration. Consider moving frequently used data to shared memory. This stall type represents about 63.4% of the total average of 19.1 cycles between issuing two instructions.",global,63.43
0,54568,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(1024, 1024, 1)",0,7.5,WarpStateStats,,,,CPIStall,INF,Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.,,
0,54568,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(1024, 1024, 1)",0,7.5,WarpStateStats,,,,ThreadDivergence,OPT,"Instructions are executed in warps, which are groups of 32 threads. Optimal instruction throughput is achieved if all 32 threads of a warp execute the same instruction. The chosen launch configuration, early thread completion, and divergent flow control can significantly lower the number of active threads in a warp per cycle. This kernel achieves an average of 1.0 threads being active per cycle.",global,15.48
0,54568,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(1024, 1024, 1)",0,7.5,Instruction Statistics,Avg. Executed Instructions Per Scheduler,inst,"318,317.71",,,,,
0,54568,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(1024, 1024, 1)",0,7.5,Instruction Statistics,Executed Instructions,inst,"17,825,792",,,,,
0,54568,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(1024, 1024, 1)",0,7.5,Instruction Statistics,Avg. Issued Instructions Per Scheduler,inst,"318,331.36",,,,,
0,54568,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(1024, 1024, 1)",0,7.5,Instruction Statistics,Issued Instructions,inst,"17,826,556",,,,,
0,54568,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(1024, 1024, 1)",0,7.5,InstructionStats,,,,FPInstructions,OPT,"This kernel executes 0 fused and 1048576 non-fused FP32 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP32 performance could be increased by up to 50% (relative to its current performance). Check the Source page to identify where this kernel executes FP32 instructions.",global,4.716
0,54568,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(1024, 1024, 1)",0,7.5,Launch Statistics,Block Size,,1,,,,,
0,54568,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(1024, 1024, 1)",0,7.5,Launch Statistics,Function Cache Configuration,,CachePreferNone,,,,,
0,54568,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(1024, 1024, 1)",0,7.5,Launch Statistics,Grid Size,,"1,048,576",,,,,
0,54568,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(1024, 1024, 1)",0,7.5,Launch Statistics,Registers Per Thread,register/thread,16,,,,,
0,54568,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(1024, 1024, 1)",0,7.5,Launch Statistics,Shared Memory Configuration Size,byte,"32,768",,,,,
0,54568,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(1024, 1024, 1)",0,7.5,Launch Statistics,Driver Shared Memory Per Block,byte/block,0,,,,,
0,54568,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(1024, 1024, 1)",0,7.5,Launch Statistics,Dynamic Shared Memory Per Block,byte/block,0,,,,,
0,54568,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(1024, 1024, 1)",0,7.5,Launch Statistics,Static Shared Memory Per Block,byte/block,0,,,,,
0,54568,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(1024, 1024, 1)",0,7.5,Launch Statistics,Threads,thread,"1,048,576",,,,,
0,54568,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(1024, 1024, 1)",0,7.5,Launch Statistics,Waves Per SM,,"4,681.14",,,,,
0,54568,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(1024, 1024, 1)",0,7.5,LaunchStats,,,,LaunchConfiguration,OPT,"Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 1 threads per block. Consequently, some threads in a warp are masked off and those hardware resources are unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256 threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to kernels that frequently call __syncthreads(). See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations.",global,96.88
0,54568,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(1024, 1024, 1)",0,7.5,Occupancy,Block Limit SM,block,16,,,,,
0,54568,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(1024, 1024, 1)",0,7.5,Occupancy,Block Limit Registers,block,128,,,,,
0,54568,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(1024, 1024, 1)",0,7.5,Occupancy,Block Limit Shared Mem,block,16,,,,,
0,54568,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(1024, 1024, 1)",0,7.5,Occupancy,Block Limit Warps,block,32,,,,,
0,54568,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(1024, 1024, 1)",0,7.5,Occupancy,Theoretical Active Warps per SM,warp,16,,,,,
0,54568,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(1024, 1024, 1)",0,7.5,Occupancy,Theoretical Occupancy,%,50,,,,,
0,54568,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(1024, 1024, 1)",0,7.5,Occupancy,Achieved Occupancy,%,28.88,,,,,
0,54568,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(1024, 1024, 1)",0,7.5,Occupancy,Achieved Active Warps Per SM,warp,9.24,,,,,
0,54568,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(1024, 1024, 1)",0,7.5,Occupancy,,,,AchievedOccupancy,OPT,The difference between calculated theoretical (50.0%) and measured achieved occupancy (28.9%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy.,global,42.24
0,54568,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(1024, 1024, 1)",0,7.5,Occupancy,,,,TheoreticalOccupancy,OPT,The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared memory.,global,50.0
0,54568,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(1024, 1024, 1)",0,7.5,Source Counters,Branch Instructions Ratio,%,0.06,,,,,
0,54568,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(1024, 1024, 1)",0,7.5,Source Counters,Branch Instructions,inst,"1,048,576",,,,,
0,54568,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(1024, 1024, 1)",0,7.5,Source Counters,Branch Efficiency,%,0,,,,,
0,54568,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(1024, 1024, 1)",0,7.5,Source Counters,Avg. Divergent Branches,,0,,,,,
0,54655,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(512, 512, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Frequency,cycle/second,"5,987,590,187.59",,,,,
0,54655,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(512, 512, 1)",0,7.5,GPU Speed Of Light Throughput,SM Frequency,cycle/second,"1,375,996,009.20",,,,,
0,54655,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(512, 512, 1)",0,7.5,GPU Speed Of Light Throughput,Elapsed Cycles,cycle,"1,223,265",,,,,
0,54655,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(512, 512, 1)",0,7.5,GPU Speed Of Light Throughput,Memory Throughput,%,22.07,,,,,
0,54655,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(512, 512, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Throughput,%,7.21,,,,,
0,54655,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(512, 512, 1)",0,7.5,GPU Speed Of Light Throughput,Duration,nsecond,"887,040",,,,,
0,54655,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(512, 512, 1)",0,7.5,GPU Speed Of Light Throughput,L1/TEX Cache Throughput,%,26.93,,,,,
0,54655,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(512, 512, 1)",0,7.5,GPU Speed Of Light Throughput,L2 Cache Throughput,%,22.07,,,,,
0,54655,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(512, 512, 1)",0,7.5,GPU Speed Of Light Throughput,SM Active Cycles,cycle,"762,046.71",,,,,
0,54655,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(512, 512, 1)",0,7.5,GPU Speed Of Light Throughput,Compute (SM) Throughput,%,15.34,,,,,
0,54655,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(512, 512, 1)",0,7.5,SpeedOfLight,,,,SOLBottleneck,OPT,This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.,,
0,54655,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(512, 512, 1)",0,7.5,SpeedOfLight_RooflineChart,,,,SOLFPRoofline,INF,The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved  close to 0% of this device's fp32 peak performance and 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.,,
0,54655,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(512, 512, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Active,inst/cycle,0.42,,,,,
0,54655,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(512, 512, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Elapsed,inst/cycle,0.26,,,,,
0,54655,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(512, 512, 1)",0,7.5,Compute Workload Analysis,Issue Slots Busy,%,10.44,,,,,
0,54655,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(512, 512, 1)",0,7.5,Compute Workload Analysis,Issued Ipc Active,inst/cycle,0.42,,,,,
0,54655,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(512, 512, 1)",0,7.5,Compute Workload Analysis,SM Busy,%,11.47,,,,,
0,54655,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(512, 512, 1)",0,7.5,ComputeWorkloadAnalysis,,,,HighPipeUtilization,OPT,All compute pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.,local,91.4
0,54655,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(512, 512, 1)",0,7.5,Memory Workload Analysis,Memory Throughput,byte/second,"13,821,103,896.10",,,,,
0,54655,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(512, 512, 1)",0,7.5,Memory Workload Analysis,Mem Busy,%,16.50,,,,,
0,54655,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(512, 512, 1)",0,7.5,Memory Workload Analysis,Max Bandwidth,%,22.07,,,,,
0,54655,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(512, 512, 1)",0,7.5,Memory Workload Analysis,L1/TEX Hit Rate,%,3.61,,,,,
0,54655,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(512, 512, 1)",0,7.5,Memory Workload Analysis,L2 Hit Rate,%,91.49,,,,,
0,54655,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(512, 512, 1)",0,7.5,Memory Workload Analysis,Mem Pipes Busy,%,15.34,,,,,
0,54655,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(512, 512, 1)",0,7.5,MemoryWorkloadAnalysis_Chart,,,,MemoryL2Compression,WRN,The optional metric lts__average_gcomp_input_sector_success_rate.pct could not be found. Collecting it as an additional metric could enable the rule to provide more guidance.,,
0,54655,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(512, 512, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for loads from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced loads and try to minimize how many cache lines need to be accessed per memory request.",global,8.167
0,54655,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(512, 512, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for stores from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced stores and try to minimize how many cache lines need to be accessed per memory request.",global,4.205
0,54655,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(512, 512, 1)",0,7.5,Scheduler Statistics,One or More Eligible,%,11.74,,,,,
0,54655,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(512, 512, 1)",0,7.5,Scheduler Statistics,Issued Warp Per Scheduler,,0.12,,,,,
0,54655,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(512, 512, 1)",0,7.5,Scheduler Statistics,No Eligible,%,88.26,,,,,
0,54655,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(512, 512, 1)",0,7.5,Scheduler Statistics,Active Warps Per Scheduler,warp,2.62,,,,,
0,54655,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(512, 512, 1)",0,7.5,Scheduler Statistics,Eligible Warps Per Scheduler,warp,0.12,,,,,
0,54655,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(512, 512, 1)",0,7.5,SchedulerStats,,,,IssueSlotUtilization,OPT,"Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 8.5 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of 2.62 active warps per scheduler, but only an average of 0.12 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections.",local,77.93
0,54655,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(512, 512, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Issued Instruction,cycle,22.28,,,,,
0,54655,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(512, 512, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Executed Instruction,cycle,22.28,,,,,
0,54655,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(512, 512, 1)",0,7.5,Warp State Statistics,Avg. Active Threads Per Warp,,4,,,,,
0,54655,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(512, 512, 1)",0,7.5,Warp State Statistics,Avg. Not Predicated Off Threads Per Warp,,4,,,,,
0,54655,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(512, 512, 1)",0,7.5,WarpStateStats,,,,CPIStall,OPT,"On average, each warp of this kernel spends 15.0 cycles being stalled waiting for a scoreboard dependency on a L1TEX (local, global, surface, texture) operation. Find the instruction producing the data being waited upon to identify the culprit. To reduce the number of cycles waiting on L1TEX data accesses verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit rates by increasing data locality (coalescing), or by changing the cache configuration. Consider moving frequently used data to shared memory. This stall type represents about 67.3% of the total average of 22.3 cycles between issuing two instructions.",global,67.33
0,54655,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(512, 512, 1)",0,7.5,WarpStateStats,,,,CPIStall,INF,Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.,,
0,54655,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(512, 512, 1)",0,7.5,WarpStateStats,,,,ThreadDivergence,OPT,"Instructions are executed in warps, which are groups of 32 threads. Optimal instruction throughput is achieved if all 32 threads of a warp execute the same instruction. The chosen launch configuration, early thread completion, and divergent flow control can significantly lower the number of active threads in a warp per cycle. This kernel achieves an average of 4.0 threads being active per cycle.",global,13.42
0,54655,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(512, 512, 1)",0,7.5,Instruction Statistics,Avg. Executed Instructions Per Scheduler,inst,"79,579.43",,,,,
0,54655,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(512, 512, 1)",0,7.5,Instruction Statistics,Executed Instructions,inst,"4,456,448",,,,,
0,54655,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(512, 512, 1)",0,7.5,Instruction Statistics,Avg. Issued Instructions Per Scheduler,inst,"79,593.07",,,,,
0,54655,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(512, 512, 1)",0,7.5,Instruction Statistics,Issued Instructions,inst,"4,457,212",,,,,
0,54655,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(512, 512, 1)",0,7.5,InstructionStats,,,,FPInstructions,OPT,"This kernel executes 0 fused and 262144 non-fused FP32 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP32 performance could be increased by up to 50% (relative to its current performance). Check the Source page to identify where this kernel executes FP32 instructions.",global,4.3
0,54655,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(512, 512, 1)",0,7.5,Launch Statistics,Block Size,,4,,,,,
0,54655,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(512, 512, 1)",0,7.5,Launch Statistics,Function Cache Configuration,,CachePreferNone,,,,,
0,54655,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(512, 512, 1)",0,7.5,Launch Statistics,Grid Size,,"262,144",,,,,
0,54655,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(512, 512, 1)",0,7.5,Launch Statistics,Registers Per Thread,register/thread,16,,,,,
0,54655,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(512, 512, 1)",0,7.5,Launch Statistics,Shared Memory Configuration Size,byte,"32,768",,,,,
0,54655,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(512, 512, 1)",0,7.5,Launch Statistics,Driver Shared Memory Per Block,byte/block,0,,,,,
0,54655,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(512, 512, 1)",0,7.5,Launch Statistics,Dynamic Shared Memory Per Block,byte/block,0,,,,,
0,54655,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(512, 512, 1)",0,7.5,Launch Statistics,Static Shared Memory Per Block,byte/block,0,,,,,
0,54655,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(512, 512, 1)",0,7.5,Launch Statistics,Threads,thread,"1,048,576",,,,,
0,54655,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(512, 512, 1)",0,7.5,Launch Statistics,Waves Per SM,,"1,170.29",,,,,
0,54655,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(512, 512, 1)",0,7.5,LaunchStats,,,,LaunchConfiguration,OPT,"Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 4 threads per block. Consequently, some threads in a warp are masked off and those hardware resources are unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256 threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to kernels that frequently call __syncthreads(). See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations.",global,87.5
0,54655,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(512, 512, 1)",0,7.5,Occupancy,Block Limit SM,block,16,,,,,
0,54655,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(512, 512, 1)",0,7.5,Occupancy,Block Limit Registers,block,128,,,,,
0,54655,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(512, 512, 1)",0,7.5,Occupancy,Block Limit Shared Mem,block,16,,,,,
0,54655,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(512, 512, 1)",0,7.5,Occupancy,Block Limit Warps,block,32,,,,,
0,54655,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(512, 512, 1)",0,7.5,Occupancy,Theoretical Active Warps per SM,warp,16,,,,,
0,54655,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(512, 512, 1)",0,7.5,Occupancy,Theoretical Occupancy,%,50,,,,,
0,54655,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(512, 512, 1)",0,7.5,Occupancy,Achieved Occupancy,%,30.49,,,,,
0,54655,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(512, 512, 1)",0,7.5,Occupancy,Achieved Active Warps Per SM,warp,9.76,,,,,
0,54655,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(512, 512, 1)",0,7.5,Occupancy,,,,AchievedOccupancy,OPT,The difference between calculated theoretical (50.0%) and measured achieved occupancy (30.5%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy.,global,39.02
0,54655,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(512, 512, 1)",0,7.5,Occupancy,,,,TheoreticalOccupancy,OPT,The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared memory.,global,50.0
0,54655,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(512, 512, 1)",0,7.5,Source Counters,Branch Instructions Ratio,%,0.06,,,,,
0,54655,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(512, 512, 1)",0,7.5,Source Counters,Branch Instructions,inst,"262,144",,,,,
0,54655,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(512, 512, 1)",0,7.5,Source Counters,Branch Efficiency,%,0,,,,,
0,54655,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(512, 512, 1)",0,7.5,Source Counters,Avg. Divergent Branches,,0,,,,,
0,54655,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(512, 512, 1)",0,7.5,SourceCounters,,,,UncoalescedGlobalAccess,OPT,This kernel has uncoalesced global accesses resulting in a total of 786432 excessive sectors (50% of the total 1572864 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source locations. The CUDA Programming Guide (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) has additional information on reducing uncoalesced device memory accesses.,global,47.62
0,54732,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(256, 256, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Frequency,cycle/second,"5,937,500,000",,,,,
0,54732,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(256, 256, 1)",0,7.5,GPU Speed Of Light Throughput,SM Frequency,cycle/second,"1,362,915,039.06",,,,,
0,54732,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(256, 256, 1)",0,7.5,GPU Speed Of Light Throughput,Elapsed Cycles,cycle,"346,829",,,,,
0,54732,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(256, 256, 1)",0,7.5,GPU Speed Of Light Throughput,Memory Throughput,%,38.57,,,,,
0,54732,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(256, 256, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Throughput,%,25.39,,,,,
0,54732,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(256, 256, 1)",0,7.5,GPU Speed Of Light Throughput,Duration,nsecond,"253,952",,,,,
0,54732,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(256, 256, 1)",0,7.5,GPU Speed Of Light Throughput,L1/TEX Cache Throughput,%,42.80,,,,,
0,54732,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(256, 256, 1)",0,7.5,GPU Speed Of Light Throughput,L2 Cache Throughput,%,38.57,,,,,
0,54732,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(256, 256, 1)",0,7.5,GPU Speed Of Light Throughput,SM Active Cycles,cycle,"291,809.21",,,,,
0,54732,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(256, 256, 1)",0,7.5,GPU Speed Of Light Throughput,Compute (SM) Throughput,%,13.52,,,,,
0,54732,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(256, 256, 1)",0,7.5,SpeedOfLight,,,,SOLBottleneck,OPT,This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.,,
0,54732,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(256, 256, 1)",0,7.5,SpeedOfLight_RooflineChart,,,,SOLFPRoofline,INF,The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved  close to 0% of this device's fp32 peak performance and 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.,,
0,54732,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(256, 256, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Active,inst/cycle,0.27,,,,,
0,54732,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(256, 256, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Elapsed,inst/cycle,0.23,,,,,
0,54732,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(256, 256, 1)",0,7.5,Compute Workload Analysis,Issue Slots Busy,%,6.82,,,,,
0,54732,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(256, 256, 1)",0,7.5,Compute Workload Analysis,Issued Ipc Active,inst/cycle,0.27,,,,,
0,54732,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(256, 256, 1)",0,7.5,Compute Workload Analysis,SM Busy,%,7.49,,,,,
0,54732,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(256, 256, 1)",0,7.5,ComputeWorkloadAnalysis,,,,HighPipeUtilization,OPT,All compute pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.,local,94.39
0,54732,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(256, 256, 1)",0,7.5,Memory Workload Analysis,Memory Throughput,byte/second,"48,243,699,596.77",,,,,
0,54732,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(256, 256, 1)",0,7.5,Memory Workload Analysis,Mem Busy,%,29.51,,,,,
0,54732,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(256, 256, 1)",0,7.5,Memory Workload Analysis,Max Bandwidth,%,38.57,,,,,
0,54732,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(256, 256, 1)",0,7.5,Memory Workload Analysis,L1/TEX Hit Rate,%,2.99,,,,,
0,54732,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(256, 256, 1)",0,7.5,Memory Workload Analysis,L2 Hit Rate,%,83.12,,,,,
0,54732,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(256, 256, 1)",0,7.5,Memory Workload Analysis,Mem Pipes Busy,%,13.52,,,,,
0,54732,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(256, 256, 1)",0,7.5,MemoryWorkloadAnalysis_Chart,,,,MemoryL2Compression,WRN,The optional metric lts__average_gcomp_input_sector_success_rate.pct could not be found. Collecting it as an additional metric could enable the rule to provide more guidance.,,
0,54732,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(256, 256, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for loads from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced loads and try to minimize how many cache lines need to be accessed per memory request.",global,14.5
0,54732,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(256, 256, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for stores from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced stores and try to minimize how many cache lines need to be accessed per memory request.",global,7.407
0,54732,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(256, 256, 1)",0,7.5,Scheduler Statistics,One or More Eligible,%,7.36,,,,,
0,54732,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(256, 256, 1)",0,7.5,Scheduler Statistics,Issued Warp Per Scheduler,,0.07,,,,,
0,54732,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(256, 256, 1)",0,7.5,Scheduler Statistics,No Eligible,%,92.64,,,,,
0,54732,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(256, 256, 1)",0,7.5,Scheduler Statistics,Active Warps Per Scheduler,warp,2.87,,,,,
0,54732,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(256, 256, 1)",0,7.5,Scheduler Statistics,Eligible Warps Per Scheduler,warp,0.08,,,,,
0,54732,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(256, 256, 1)",0,7.5,SchedulerStats,,,,IssueSlotUtilization,OPT,"Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 13.6 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of 2.87 active warps per scheduler, but only an average of 0.08 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections.",local,61.43
0,54732,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(256, 256, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Issued Instruction,cycle,39.02,,,,,
0,54732,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(256, 256, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Executed Instruction,cycle,39.04,,,,,
0,54732,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(256, 256, 1)",0,7.5,Warp State Statistics,Avg. Active Threads Per Warp,,16,,,,,
0,54732,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(256, 256, 1)",0,7.5,Warp State Statistics,Avg. Not Predicated Off Threads Per Warp,,16,,,,,
0,54732,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(256, 256, 1)",0,7.5,WarpStateStats,,,,CPIStall,OPT,"On average, each warp of this kernel spends 30.1 cycles being stalled waiting for a scoreboard dependency on a L1TEX (local, global, surface, texture) operation. Find the instruction producing the data being waited upon to identify the culprit. To reduce the number of cycles waiting on L1TEX data accesses verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit rates by increasing data locality (coalescing), or by changing the cache configuration. Consider moving frequently used data to shared memory. This stall type represents about 77.1% of the total average of 39.0 cycles between issuing two instructions.",global,61.43
0,54732,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(256, 256, 1)",0,7.5,WarpStateStats,,,,CPIStall,INF,Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.,,
0,54732,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(256, 256, 1)",0,7.5,WarpStateStats,,,,ThreadDivergence,OPT,"Instructions are executed in warps, which are groups of 32 threads. Optimal instruction throughput is achieved if all 32 threads of a warp execute the same instruction. The chosen launch configuration, early thread completion, and divergent flow control can significantly lower the number of active threads in a warp per cycle. This kernel achieves an average of 16.0 threads being active per cycle.",global,6.76
0,54732,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(256, 256, 1)",0,7.5,Instruction Statistics,Avg. Executed Instructions Per Scheduler,inst,"19,894.86",,,,,
0,54732,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(256, 256, 1)",0,7.5,Instruction Statistics,Executed Instructions,inst,"1,114,112",,,,,
0,54732,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(256, 256, 1)",0,7.5,Instruction Statistics,Avg. Issued Instructions Per Scheduler,inst,"19,908.50",,,,,
0,54732,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(256, 256, 1)",0,7.5,Instruction Statistics,Issued Instructions,inst,"1,114,876",,,,,
0,54732,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(256, 256, 1)",0,7.5,InstructionStats,,,,FPInstructions,OPT,"This kernel executes 0 fused and 65536 non-fused FP32 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP32 performance could be increased by up to 50% (relative to its current performance). Check the Source page to identify where this kernel executes FP32 instructions.",global,2.807
0,54732,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(256, 256, 1)",0,7.5,Launch Statistics,Block Size,,16,,,,,
0,54732,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(256, 256, 1)",0,7.5,Launch Statistics,Function Cache Configuration,,CachePreferNone,,,,,
0,54732,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(256, 256, 1)",0,7.5,Launch Statistics,Grid Size,,"65,536",,,,,
0,54732,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(256, 256, 1)",0,7.5,Launch Statistics,Registers Per Thread,register/thread,16,,,,,
0,54732,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(256, 256, 1)",0,7.5,Launch Statistics,Shared Memory Configuration Size,byte,"32,768",,,,,
0,54732,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(256, 256, 1)",0,7.5,Launch Statistics,Driver Shared Memory Per Block,byte/block,0,,,,,
0,54732,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(256, 256, 1)",0,7.5,Launch Statistics,Dynamic Shared Memory Per Block,byte/block,0,,,,,
0,54732,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(256, 256, 1)",0,7.5,Launch Statistics,Static Shared Memory Per Block,byte/block,0,,,,,
0,54732,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(256, 256, 1)",0,7.5,Launch Statistics,Threads,thread,"1,048,576",,,,,
0,54732,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(256, 256, 1)",0,7.5,Launch Statistics,Waves Per SM,,292.57,,,,,
0,54732,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(256, 256, 1)",0,7.5,LaunchStats,,,,LaunchConfiguration,OPT,"Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 16 threads per block. Consequently, some threads in a warp are masked off and those hardware resources are unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256 threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to kernels that frequently call __syncthreads(). See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations.",global,50.0
0,54732,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(256, 256, 1)",0,7.5,Occupancy,Block Limit SM,block,16,,,,,
0,54732,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(256, 256, 1)",0,7.5,Occupancy,Block Limit Registers,block,128,,,,,
0,54732,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(256, 256, 1)",0,7.5,Occupancy,Block Limit Shared Mem,block,16,,,,,
0,54732,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(256, 256, 1)",0,7.5,Occupancy,Block Limit Warps,block,32,,,,,
0,54732,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(256, 256, 1)",0,7.5,Occupancy,Theoretical Active Warps per SM,warp,16,,,,,
0,54732,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(256, 256, 1)",0,7.5,Occupancy,Theoretical Occupancy,%,50,,,,,
0,54732,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(256, 256, 1)",0,7.5,Occupancy,Achieved Occupancy,%,33.98,,,,,
0,54732,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(256, 256, 1)",0,7.5,Occupancy,Achieved Active Warps Per SM,warp,10.87,,,,,
0,54732,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(256, 256, 1)",0,7.5,Occupancy,,,,AchievedOccupancy,OPT,The difference between calculated theoretical (50.0%) and measured achieved occupancy (34.0%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy.,global,32.04
0,54732,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(256, 256, 1)",0,7.5,Occupancy,,,,TheoreticalOccupancy,OPT,The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared memory.,global,50.0
0,54732,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(256, 256, 1)",0,7.5,Source Counters,Branch Instructions Ratio,%,0.06,,,,,
0,54732,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(256, 256, 1)",0,7.5,Source Counters,Branch Instructions,inst,"65,536",,,,,
0,54732,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(256, 256, 1)",0,7.5,Source Counters,Branch Efficiency,%,0,,,,,
0,54732,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(256, 256, 1)",0,7.5,Source Counters,Avg. Divergent Branches,,0,,,,,
0,54732,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(256, 256, 1)",0,7.5,SourceCounters,,,,UncoalescedGlobalAccess,OPT,This kernel has uncoalesced global accesses resulting in a total of 393216 excessive sectors (50% of the total 786432 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source locations. The CUDA Programming Guide (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) has additional information on reducing uncoalesced device memory accesses.,global,49.64
0,54816,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(128, 128, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Frequency,cycle/second,"6,030,952,380.95",,,,,
0,54816,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(128, 128, 1)",0,7.5,GPU Speed Of Light Throughput,SM Frequency,cycle/second,"1,383,933,221.73",,,,,
0,54816,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(128, 128, 1)",0,7.5,GPU Speed Of Light Throughput,Elapsed Cycles,cycle,"149,256",,,,,
0,54816,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(128, 128, 1)",0,7.5,GPU Speed Of Light Throughput,Memory Throughput,%,61.80,,,,,
0,54816,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(128, 128, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Throughput,%,58.90,,,,,
0,54816,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(128, 128, 1)",0,7.5,GPU Speed Of Light Throughput,Duration,nsecond,"107,520",,,,,
0,54816,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(128, 128, 1)",0,7.5,GPU Speed Of Light Throughput,L1/TEX Cache Throughput,%,86.41,,,,,
0,54816,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(128, 128, 1)",0,7.5,GPU Speed Of Light Throughput,L2 Cache Throughput,%,61.80,,,,,
0,54816,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(128, 128, 1)",0,7.5,GPU Speed Of Light Throughput,SM Active Cycles,cycle,"147,889.50",,,,,
0,54816,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(128, 128, 1)",0,7.5,GPU Speed Of Light Throughput,Compute (SM) Throughput,%,15.72,,,,,
0,54816,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(128, 128, 1)",0,7.5,SpeedOfLight,,,,SOLBottleneck,OPT,Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the L2 bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or whether there are values you can (re)compute.,,
0,54816,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(128, 128, 1)",0,7.5,SpeedOfLight_RooflineChart,,,,SOLFPRoofline,INF,The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved  close to 0% of this device's fp32 peak performance and 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.,,
0,54816,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(128, 128, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Active,inst/cycle,0.27,,,,,
0,54816,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(128, 128, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Elapsed,inst/cycle,0.27,,,,,
0,54816,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(128, 128, 1)",0,7.5,Compute Workload Analysis,Issue Slots Busy,%,6.74,,,,,
0,54816,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(128, 128, 1)",0,7.5,Compute Workload Analysis,Issued Ipc Active,inst/cycle,0.27,,,,,
0,54816,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(128, 128, 1)",0,7.5,Compute Workload Analysis,SM Busy,%,7.39,,,,,
0,54816,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(128, 128, 1)",0,7.5,ComputeWorkloadAnalysis,,,,HighPipeUtilization,OPT,All compute pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.,local,94.46
0,54816,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(128, 128, 1)",0,7.5,Memory Workload Analysis,Memory Throughput,byte/second,"113,669,642,857.14",,,,,
0,54816,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(128, 128, 1)",0,7.5,Memory Workload Analysis,Mem Busy,%,44.40,,,,,
0,54816,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(128, 128, 1)",0,7.5,Memory Workload Analysis,Max Bandwidth,%,61.80,,,,,
0,54816,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(128, 128, 1)",0,7.5,Memory Workload Analysis,L1/TEX Hit Rate,%,50.72,,,,,
0,54816,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(128, 128, 1)",0,7.5,Memory Workload Analysis,L2 Hit Rate,%,74.03,,,,,
0,54816,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(128, 128, 1)",0,7.5,Memory Workload Analysis,Mem Pipes Busy,%,15.72,,,,,
0,54816,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(128, 128, 1)",0,7.5,MemoryWorkloadAnalysis_Chart,,,,MemoryL2Compression,WRN,The optional metric lts__average_gcomp_input_sector_success_rate.pct could not be found. Collecting it as an additional metric could enable the rule to provide more guidance.,,
0,54816,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(128, 128, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for global loads in L1TEX might not be optimal. On average, this kernel accesses 4.0 bytes per thread per memory request; but the address pattern, possibly caused by the stride between threads, results in 8.0 sectors per request, or 8.0*32 = 255.7 bytes of cache data transfers per request. The optimal thread address pattern for 4.0 byte accesses would result in 4.0*32 = 128.0 bytes of cache data transfers per request, to maximize L1TEX cache performance. Check the Source Counters section for uncoalesced global loads.",global,1.178
0,54816,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(128, 128, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for global stores in L1TEX might not be optimal. On average, this kernel accesses 4.0 bytes per thread per memory request; but the address pattern, possibly caused by the stride between threads, results in 8.0 sectors per request, or 8.0*32 = 256.0 bytes of cache data transfers per request. The optimal thread address pattern for 4.0 byte accesses would result in 4.0*32 = 128.0 bytes of cache data transfers per request, to maximize L1TEX cache performance. Check the Source Counters section for uncoalesced global stores.",global,1.179
0,54816,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(128, 128, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for loads from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced loads and try to minimize how many cache lines need to be accessed per memory request.",global,17.44
0,54816,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(128, 128, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for stores from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced stores and try to minimize how many cache lines need to be accessed per memory request.",global,15.74
0,54816,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(128, 128, 1)",0,7.5,Scheduler Statistics,One or More Eligible,%,6.67,,,,,
0,54816,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(128, 128, 1)",0,7.5,Scheduler Statistics,Issued Warp Per Scheduler,,0.07,,,,,
0,54816,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(128, 128, 1)",0,7.5,Scheduler Statistics,No Eligible,%,93.33,,,,,
0,54816,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(128, 128, 1)",0,7.5,Scheduler Statistics,Active Warps Per Scheduler,warp,6.98,,,,,
0,54816,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(128, 128, 1)",0,7.5,Scheduler Statistics,Eligible Warps Per Scheduler,warp,0.07,,,,,
0,54816,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(128, 128, 1)",0,7.5,SchedulerStats,,,,IssueSlotUtilization,OPT,"Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 15.0 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of 6.98 active warps per scheduler, but only an average of 0.07 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, avoid possible load imbalances due to highly different execution durations per warp. Reducing stalls indicated on the Warp State Statistics and Source Counters sections can help, too.",local,38.2
0,54816,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(128, 128, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Issued Instruction,cycle,104.62,,,,,
0,54816,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(128, 128, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Executed Instruction,cycle,104.88,,,,,
0,54816,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(128, 128, 1)",0,7.5,Warp State Statistics,Avg. Active Threads Per Warp,,32,,,,,
0,54816,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(128, 128, 1)",0,7.5,Warp State Statistics,Avg. Not Predicated Off Threads Per Warp,,32,,,,,
0,54816,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(128, 128, 1)",0,7.5,WarpStateStats,,,,CPIStall,OPT,"On average, each warp of this kernel spends 80.2 cycles being stalled waiting for a scoreboard dependency on a L1TEX (local, global, surface, texture) operation. Find the instruction producing the data being waited upon to identify the culprit. To reduce the number of cycles waiting on L1TEX data accesses verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit rates by increasing data locality (coalescing), or by changing the cache configuration. Consider moving frequently used data to shared memory. This stall type represents about 76.7% of the total average of 104.6 cycles between issuing two instructions.",global,38.2
0,54816,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(128, 128, 1)",0,7.5,WarpStateStats,,,,CPIStall,INF,Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.,,
0,54816,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(128, 128, 1)",0,7.5,Instruction Statistics,Avg. Executed Instructions Per Scheduler,inst,"9,947.43",,,,,
0,54816,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(128, 128, 1)",0,7.5,Instruction Statistics,Executed Instructions,inst,"557,056",,,,,
0,54816,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(128, 128, 1)",0,7.5,Instruction Statistics,Avg. Issued Instructions Per Scheduler,inst,"9,972.46",,,,,
0,54816,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(128, 128, 1)",0,7.5,Instruction Statistics,Issued Instructions,inst,"558,458",,,,,
0,54816,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(128, 128, 1)",0,7.5,InstructionStats,,,,FPInstructions,OPT,"This kernel executes 0 fused and 32768 non-fused FP32 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP32 performance could be increased by up to 50% (relative to its current performance). Check the Source page to identify where this kernel executes FP32 instructions.",global,2.77
0,54816,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(128, 128, 1)",0,7.5,Launch Statistics,Block Size,,64,,,,,
0,54816,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(128, 128, 1)",0,7.5,Launch Statistics,Function Cache Configuration,,CachePreferNone,,,,,
0,54816,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(128, 128, 1)",0,7.5,Launch Statistics,Grid Size,,"16,384",,,,,
0,54816,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(128, 128, 1)",0,7.5,Launch Statistics,Registers Per Thread,register/thread,16,,,,,
0,54816,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(128, 128, 1)",0,7.5,Launch Statistics,Shared Memory Configuration Size,byte,"32,768",,,,,
0,54816,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(128, 128, 1)",0,7.5,Launch Statistics,Driver Shared Memory Per Block,byte/block,0,,,,,
0,54816,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(128, 128, 1)",0,7.5,Launch Statistics,Dynamic Shared Memory Per Block,byte/block,0,,,,,
0,54816,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(128, 128, 1)",0,7.5,Launch Statistics,Static Shared Memory Per Block,byte/block,0,,,,,
0,54816,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(128, 128, 1)",0,7.5,Launch Statistics,Threads,thread,"1,048,576",,,,,
0,54816,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(128, 128, 1)",0,7.5,Launch Statistics,Waves Per SM,,73.14,,,,,
0,54816,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(128, 128, 1)",0,7.5,Occupancy,Block Limit SM,block,16,,,,,
0,54816,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(128, 128, 1)",0,7.5,Occupancy,Block Limit Registers,block,64,,,,,
0,54816,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(128, 128, 1)",0,7.5,Occupancy,Block Limit Shared Mem,block,16,,,,,
0,54816,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(128, 128, 1)",0,7.5,Occupancy,Block Limit Warps,block,16,,,,,
0,54816,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(128, 128, 1)",0,7.5,Occupancy,Theoretical Active Warps per SM,warp,32,,,,,
0,54816,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(128, 128, 1)",0,7.5,Occupancy,Theoretical Occupancy,%,100,,,,,
0,54816,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(128, 128, 1)",0,7.5,Occupancy,Achieved Occupancy,%,89.00,,,,,
0,54816,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(128, 128, 1)",0,7.5,Occupancy,Achieved Active Warps Per SM,warp,28.48,,,,,
0,54816,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(128, 128, 1)",0,7.5,Occupancy,,,,AchievedOccupancy,OPT,The difference between calculated theoretical (100.0%) and measured achieved occupancy (89.0%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy.,global,11.0
0,54816,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(128, 128, 1)",0,7.5,Source Counters,Branch Instructions Ratio,%,0.06,,,,,
0,54816,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(128, 128, 1)",0,7.5,Source Counters,Branch Instructions,inst,"32,768",,,,,
0,54816,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(128, 128, 1)",0,7.5,Source Counters,Branch Efficiency,%,0,,,,,
0,54816,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(128, 128, 1)",0,7.5,Source Counters,Avg. Divergent Branches,,0,,,,,
0,54816,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(128, 128, 1)",0,7.5,SourceCounters,,,,UncoalescedGlobalAccess,OPT,This kernel has uncoalesced global accesses resulting in a total of 393216 excessive sectors (50% of the total 786432 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source locations. The CUDA Programming Guide (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) has additional information on reducing uncoalesced device memory accesses.,global,49.39
0,54900,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(64, 64, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Frequency,cycle/second,"5,996,072,129.98",,,,,
0,54900,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(64, 64, 1)",0,7.5,GPU Speed Of Light Throughput,SM Frequency,cycle/second,"1,376,475,740.94",,,,,
0,54900,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(64, 64, 1)",0,7.5,GPU Speed Of Light Throughput,Elapsed Cycles,cycle,"247,518",,,,,
0,54900,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(64, 64, 1)",0,7.5,GPU Speed Of Light Throughput,Memory Throughput,%,63.71,,,,,
0,54900,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(64, 64, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Throughput,%,35.60,,,,,
0,54900,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(64, 64, 1)",0,7.5,GPU Speed Of Light Throughput,Duration,nsecond,"179,232",,,,,
0,54900,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(64, 64, 1)",0,7.5,GPU Speed Of Light Throughput,L1/TEX Cache Throughput,%,96.58,,,,,
0,54900,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(64, 64, 1)",0,7.5,GPU Speed Of Light Throughput,L2 Cache Throughput,%,63.71,,,,,
0,54900,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(64, 64, 1)",0,7.5,GPU Speed Of Light Throughput,SM Active Cycles,cycle,"244,292.29",,,,,
0,54900,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(64, 64, 1)",0,7.5,GPU Speed Of Light Throughput,Compute (SM) Throughput,%,9.48,,,,,
0,54900,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(64, 64, 1)",0,7.5,SpeedOfLight,,,,SOLBottleneck,OPT,Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the L2 bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or whether there are values you can (re)compute.,,
0,54900,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(64, 64, 1)",0,7.5,SpeedOfLight_RooflineChart,,,,SOLFPRoofline,INF,The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved  close to 0% of this device's fp32 peak performance and 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.,,
0,54900,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(64, 64, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Active,inst/cycle,0.16,,,,,
0,54900,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(64, 64, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Elapsed,inst/cycle,0.16,,,,,
0,54900,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(64, 64, 1)",0,7.5,Compute Workload Analysis,Issue Slots Busy,%,4.08,,,,,
0,54900,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(64, 64, 1)",0,7.5,Compute Workload Analysis,Issued Ipc Active,inst/cycle,0.16,,,,,
0,54900,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(64, 64, 1)",0,7.5,Compute Workload Analysis,SM Busy,%,4.47,,,,,
0,54900,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(64, 64, 1)",0,7.5,ComputeWorkloadAnalysis,,,,HighPipeUtilization,OPT,All compute pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.,local,96.65
0,54900,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(64, 64, 1)",0,7.5,Memory Workload Analysis,Memory Throughput,byte/second,"68,297,982,503.12",,,,,
0,54900,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(64, 64, 1)",0,7.5,Memory Workload Analysis,Mem Busy,%,48.29,,,,,
0,54900,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(64, 64, 1)",0,7.5,Memory Workload Analysis,Max Bandwidth,%,63.71,,,,,
0,54900,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(64, 64, 1)",0,7.5,Memory Workload Analysis,L1/TEX Hit Rate,%,79.31,,,,,
0,54900,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(64, 64, 1)",0,7.5,Memory Workload Analysis,L2 Hit Rate,%,82.09,,,,,
0,54900,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(64, 64, 1)",0,7.5,Memory Workload Analysis,Mem Pipes Busy,%,9.48,,,,,
0,54900,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(64, 64, 1)",0,7.5,MemoryWorkloadAnalysis_Chart,,,,MemoryL2Compression,WRN,The optional metric lts__average_gcomp_input_sector_success_rate.pct could not be found. Collecting it as an additional metric could enable the rule to provide more guidance.,,
0,54900,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(64, 64, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for global loads in L1TEX might not be optimal. On average, this kernel accesses 4.0 bytes per thread per memory request; but the address pattern, possibly caused by the stride between threads, results in 16.0 sectors per request, or 16.0*32 = 512.0 bytes of cache data transfers per request. The optimal thread address pattern for 4.0 byte accesses would result in 4.0*32 = 128.0 bytes of cache data transfers per request, to maximize L1TEX cache performance. Check the Source Counters section for uncoalesced global loads.",global,2.134
0,54900,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(64, 64, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for global stores in L1TEX might not be optimal. On average, this kernel accesses 4.0 bytes per thread per memory request; but the address pattern, possibly caused by the stride between threads, results in 16.0 sectors per request, or 16.0*32 = 512.0 bytes of cache data transfers per request. The optimal thread address pattern for 4.0 byte accesses would result in 4.0*32 = 128.0 bytes of cache data transfers per request, to maximize L1TEX cache performance. Check the Source Counters section for uncoalesced global stores.",global,2.134
0,54900,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(64, 64, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for loads from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced loads and try to minimize how many cache lines need to be accessed per memory request.",global,10.33
0,54900,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(64, 64, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for stores from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.1 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced stores and try to minimize how many cache lines need to be accessed per memory request.",global,19.25
0,54900,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(64, 64, 1)",0,7.5,Scheduler Statistics,One or More Eligible,%,4.08,,,,,
0,54900,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(64, 64, 1)",0,7.5,Scheduler Statistics,Issued Warp Per Scheduler,,0.04,,,,,
0,54900,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(64, 64, 1)",0,7.5,Scheduler Statistics,No Eligible,%,95.92,,,,,
0,54900,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(64, 64, 1)",0,7.5,Scheduler Statistics,Active Warps Per Scheduler,warp,6.44,,,,,
0,54900,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(64, 64, 1)",0,7.5,Scheduler Statistics,Eligible Warps Per Scheduler,warp,0.05,,,,,
0,54900,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(64, 64, 1)",0,7.5,SchedulerStats,,,,IssueSlotUtilization,OPT,"Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 24.5 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of 6.44 active warps per scheduler, but only an average of 0.05 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, avoid possible load imbalances due to highly different execution durations per warp. Reducing stalls indicated on the Warp State Statistics and Source Counters sections can help, too.",local,36.29
0,54900,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(64, 64, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Issued Instruction,cycle,157.57,,,,,
0,54900,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(64, 64, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Executed Instruction,cycle,158.07,,,,,
0,54900,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(64, 64, 1)",0,7.5,Warp State Statistics,Avg. Active Threads Per Warp,,32,,,,,
0,54900,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(64, 64, 1)",0,7.5,Warp State Statistics,Avg. Not Predicated Off Threads Per Warp,,32,,,,,
0,54900,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(64, 64, 1)",0,7.5,WarpStateStats,,,,CPIStall,OPT,"On average, each warp of this kernel spends 85.8 cycles being stalled waiting for a scoreboard dependency on a L1TEX (local, global, surface, texture) operation. Find the instruction producing the data being waited upon to identify the culprit. To reduce the number of cycles waiting on L1TEX data accesses verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit rates by increasing data locality (coalescing), or by changing the cache configuration. Consider moving frequently used data to shared memory. This stall type represents about 54.5% of the total average of 157.6 cycles between issuing two instructions.",global,36.29
0,54900,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(64, 64, 1)",0,7.5,WarpStateStats,,,,CPIStall,INF,Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.,,
0,54900,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(64, 64, 1)",0,7.5,Instruction Statistics,Avg. Executed Instructions Per Scheduler,inst,"9,947.43",,,,,
0,54900,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(64, 64, 1)",0,7.5,Instruction Statistics,Executed Instructions,inst,"557,056",,,,,
0,54900,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(64, 64, 1)",0,7.5,Instruction Statistics,Avg. Issued Instructions Per Scheduler,inst,"9,978.93",,,,,
0,54900,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(64, 64, 1)",0,7.5,Instruction Statistics,Issued Instructions,inst,"558,820",,,,,
0,54900,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(64, 64, 1)",0,7.5,InstructionStats,,,,FPInstructions,OPT,"This kernel executes 0 fused and 32768 non-fused FP32 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP32 performance could be increased by up to 50% (relative to its current performance). Check the Source page to identify where this kernel executes FP32 instructions.",global,1.677
0,54900,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(64, 64, 1)",0,7.5,Launch Statistics,Block Size,,256,,,,,
0,54900,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(64, 64, 1)",0,7.5,Launch Statistics,Function Cache Configuration,,CachePreferNone,,,,,
0,54900,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(64, 64, 1)",0,7.5,Launch Statistics,Grid Size,,"4,096",,,,,
0,54900,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(64, 64, 1)",0,7.5,Launch Statistics,Registers Per Thread,register/thread,16,,,,,
0,54900,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(64, 64, 1)",0,7.5,Launch Statistics,Shared Memory Configuration Size,byte,"32,768",,,,,
0,54900,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(64, 64, 1)",0,7.5,Launch Statistics,Driver Shared Memory Per Block,byte/block,0,,,,,
0,54900,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(64, 64, 1)",0,7.5,Launch Statistics,Dynamic Shared Memory Per Block,byte/block,0,,,,,
0,54900,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(64, 64, 1)",0,7.5,Launch Statistics,Static Shared Memory Per Block,byte/block,0,,,,,
0,54900,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(64, 64, 1)",0,7.5,Launch Statistics,Threads,thread,"1,048,576",,,,,
0,54900,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(64, 64, 1)",0,7.5,Launch Statistics,Waves Per SM,,73.14,,,,,
0,54900,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(64, 64, 1)",0,7.5,Occupancy,Block Limit SM,block,16,,,,,
0,54900,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(64, 64, 1)",0,7.5,Occupancy,Block Limit Registers,block,16,,,,,
0,54900,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(64, 64, 1)",0,7.5,Occupancy,Block Limit Shared Mem,block,16,,,,,
0,54900,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(64, 64, 1)",0,7.5,Occupancy,Block Limit Warps,block,4,,,,,
0,54900,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(64, 64, 1)",0,7.5,Occupancy,Theoretical Active Warps per SM,warp,32,,,,,
0,54900,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(64, 64, 1)",0,7.5,Occupancy,Theoretical Occupancy,%,100,,,,,
0,54900,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(64, 64, 1)",0,7.5,Occupancy,Achieved Occupancy,%,80.92,,,,,
0,54900,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(64, 64, 1)",0,7.5,Occupancy,Achieved Active Warps Per SM,warp,25.89,,,,,
0,54900,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(64, 64, 1)",0,7.5,Occupancy,,,,AchievedOccupancy,OPT,The difference between calculated theoretical (100.0%) and measured achieved occupancy (80.9%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy.,global,19.08
0,54900,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(64, 64, 1)",0,7.5,Source Counters,Branch Instructions Ratio,%,0.06,,,,,
0,54900,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(64, 64, 1)",0,7.5,Source Counters,Branch Instructions,inst,"32,768",,,,,
0,54900,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(64, 64, 1)",0,7.5,Source Counters,Branch Efficiency,%,0,,,,,
0,54900,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(64, 64, 1)",0,7.5,Source Counters,Avg. Divergent Branches,,0,,,,,
0,54900,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(64, 64, 1)",0,7.5,SourceCounters,,,,UncoalescedGlobalAccess,OPT,This kernel has uncoalesced global accesses resulting in a total of 1179648 excessive sectors (75% of the total 1572864 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source locations. The CUDA Programming Guide (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) has additional information on reducing uncoalesced device memory accesses.,global,74.09
0,54977,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(32, 32, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Frequency,cycle/second,"6,008,865,099.94",,,,,
0,54977,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(32, 32, 1)",0,7.5,GPU Speed Of Light Throughput,SM Frequency,cycle/second,"1,380,628,240.78",,,,,
0,54977,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(32, 32, 1)",0,7.5,GPU Speed Of Light Throughput,Elapsed Cycles,cycle,"529,271",,,,,
0,54977,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(32, 32, 1)",0,7.5,GPU Speed Of Light Throughput,Memory Throughput,%,58.16,,,,,
0,54977,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(32, 32, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Throughput,%,16.66,,,,,
0,54977,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(32, 32, 1)",0,7.5,GPU Speed Of Light Throughput,Duration,nsecond,"382,624",,,,,
0,54977,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(32, 32, 1)",0,7.5,GPU Speed Of Light Throughput,L1/TEX Cache Throughput,%,86.84,,,,,
0,54977,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(32, 32, 1)",0,7.5,GPU Speed Of Light Throughput,L2 Cache Throughput,%,58.16,,,,,
0,54977,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(32, 32, 1)",0,7.5,GPU Speed Of Light Throughput,SM Active Cycles,cycle,"500,657.79",,,,,
0,54977,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(32, 32, 1)",0,7.5,GPU Speed Of Light Throughput,Compute (SM) Throughput,%,4.43,,,,,
0,54977,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(32, 32, 1)",0,7.5,SpeedOfLight,,,,SOLBottleneck,OPT,This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.,,
0,54977,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(32, 32, 1)",0,7.5,SpeedOfLight_RooflineChart,,,,SOLFPRoofline,INF,The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved  close to 0% of this device's fp32 peak performance and 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.,,
0,54977,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(32, 32, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Active,inst/cycle,0.08,,,,,
0,54977,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(32, 32, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Elapsed,inst/cycle,0.08,,,,,
0,54977,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(32, 32, 1)",0,7.5,Compute Workload Analysis,Issue Slots Busy,%,1.99,,,,,
0,54977,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(32, 32, 1)",0,7.5,Compute Workload Analysis,Issued Ipc Active,inst/cycle,0.08,,,,,
0,54977,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(32, 32, 1)",0,7.5,Compute Workload Analysis,SM Busy,%,2.18,,,,,
0,54977,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(32, 32, 1)",0,7.5,ComputeWorkloadAnalysis,,,,HighPipeUtilization,OPT,All compute pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.,local,98.36
0,54977,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(32, 32, 1)",0,7.5,Memory Workload Analysis,Memory Throughput,byte/second,"32,034,038,638.45",,,,,
0,54977,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(32, 32, 1)",0,7.5,Memory Workload Analysis,Mem Busy,%,43.42,,,,,
0,54977,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(32, 32, 1)",0,7.5,Memory Workload Analysis,Max Bandwidth,%,58.16,,,,,
0,54977,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(32, 32, 1)",0,7.5,Memory Workload Analysis,L1/TEX Hit Rate,%,90.62,,,,,
0,54977,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(32, 32, 1)",0,7.5,Memory Workload Analysis,L2 Hit Rate,%,90.00,,,,,
0,54977,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(32, 32, 1)",0,7.5,Memory Workload Analysis,Mem Pipes Busy,%,4.43,,,,,
0,54977,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(32, 32, 1)",0,7.5,MemoryWorkloadAnalysis_Chart,,,,MemoryL2Compression,WRN,The optional metric lts__average_gcomp_input_sector_success_rate.pct could not be found. Collecting it as an additional metric could enable the rule to provide more guidance.,,
0,54977,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(32, 32, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for global loads in L1TEX might not be optimal. On average, this kernel accesses 4.0 bytes per thread per memory request; but the address pattern, possibly caused by the stride between threads, results in 32.0 sectors per request, or 32.0*32 = 1024.0 bytes of cache data transfers per request. The optimal thread address pattern for 4.0 byte accesses would result in 4.0*32 = 128.0 bytes of cache data transfers per request, to maximize L1TEX cache performance. Check the Source Counters section for uncoalesced global loads.",global,2.325
0,54977,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(32, 32, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for global stores in L1TEX might not be optimal. On average, this kernel accesses 4.0 bytes per thread per memory request; but the address pattern, possibly caused by the stride between threads, results in 32.0 sectors per request, or 32.0*32 = 1024.0 bytes of cache data transfers per request. The optimal thread address pattern for 4.0 byte accesses would result in 4.0*32 = 128.0 bytes of cache data transfers per request, to maximize L1TEX cache performance. Check the Source Counters section for uncoalesced global stores.",global,2.325
0,54977,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(32, 32, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for loads from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced loads and try to minimize how many cache lines need to be accessed per memory request.",global,4.86
0,54977,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(32, 32, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for stores from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced stores and try to minimize how many cache lines need to be accessed per memory request.",global,19.44
0,54977,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(32, 32, 1)",0,7.5,Scheduler Statistics,One or More Eligible,%,2.10,,,,,
0,54977,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(32, 32, 1)",0,7.5,Scheduler Statistics,Issued Warp Per Scheduler,,0.02,,,,,
0,54977,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(32, 32, 1)",0,7.5,Scheduler Statistics,No Eligible,%,97.90,,,,,
0,54977,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(32, 32, 1)",0,7.5,Scheduler Statistics,Active Warps Per Scheduler,warp,6.26,,,,,
0,54977,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(32, 32, 1)",0,7.5,Scheduler Statistics,Eligible Warps Per Scheduler,warp,0.04,,,,,
0,54977,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(32, 32, 1)",0,7.5,SchedulerStats,,,,IssueSlotUtilization,OPT,"Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 47.6 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of 6.26 active warps per scheduler, but only an average of 0.04 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections.",local,41.84
0,54977,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(32, 32, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Issued Instruction,cycle,298.39,,,,,
0,54977,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(32, 32, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Executed Instruction,cycle,299.35,,,,,
0,54977,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(32, 32, 1)",0,7.5,Warp State Statistics,Avg. Active Threads Per Warp,,32,,,,,
0,54977,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(32, 32, 1)",0,7.5,Warp State Statistics,Avg. Not Predicated Off Threads Per Warp,,32,,,,,
0,54977,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(32, 32, 1)",0,7.5,WarpStateStats,,,,CPIStall,OPT,"On average, each warp of this kernel spends 179.0 cycles being stalled waiting for a scoreboard dependency on a L1TEX (local, global, surface, texture) operation. Find the instruction producing the data being waited upon to identify the culprit. To reduce the number of cycles waiting on L1TEX data accesses verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit rates by increasing data locality (coalescing), or by changing the cache configuration. Consider moving frequently used data to shared memory. This stall type represents about 60.0% of the total average of 298.4 cycles between issuing two instructions.",global,41.84
0,54977,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(32, 32, 1)",0,7.5,WarpStateStats,,,,CPIStall,INF,Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.,,
0,54977,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(32, 32, 1)",0,7.5,Instruction Statistics,Avg. Executed Instructions Per Scheduler,inst,"9,947.43",,,,,
0,54977,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(32, 32, 1)",0,7.5,Instruction Statistics,Executed Instructions,inst,"557,056",,,,,
0,54977,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(32, 32, 1)",0,7.5,Instruction Statistics,Avg. Issued Instructions Per Scheduler,inst,"9,979.43",,,,,
0,54977,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(32, 32, 1)",0,7.5,Instruction Statistics,Issued Instructions,inst,"558,848",,,,,
0,54977,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(32, 32, 1)",0,7.5,InstructionStats,,,,FPInstructions,OPT,"This kernel executes 0 fused and 32768 non-fused FP32 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP32 performance could be increased by up to 50% (relative to its current performance). Check the Source page to identify where this kernel executes FP32 instructions.",global,0.8181
0,54977,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(32, 32, 1)",0,7.5,Launch Statistics,Block Size,,"1,024",,,,,
0,54977,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(32, 32, 1)",0,7.5,Launch Statistics,Function Cache Configuration,,CachePreferNone,,,,,
0,54977,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(32, 32, 1)",0,7.5,Launch Statistics,Grid Size,,"1,024",,,,,
0,54977,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(32, 32, 1)",0,7.5,Launch Statistics,Registers Per Thread,register/thread,16,,,,,
0,54977,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(32, 32, 1)",0,7.5,Launch Statistics,Shared Memory Configuration Size,byte,"32,768",,,,,
0,54977,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(32, 32, 1)",0,7.5,Launch Statistics,Driver Shared Memory Per Block,byte/block,0,,,,,
0,54977,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(32, 32, 1)",0,7.5,Launch Statistics,Dynamic Shared Memory Per Block,byte/block,0,,,,,
0,54977,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(32, 32, 1)",0,7.5,Launch Statistics,Static Shared Memory Per Block,byte/block,0,,,,,
0,54977,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(32, 32, 1)",0,7.5,Launch Statistics,Threads,thread,"1,048,576",,,,,
0,54977,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(32, 32, 1)",0,7.5,Launch Statistics,Waves Per SM,,73.14,,,,,
0,54977,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(32, 32, 1)",0,7.5,Occupancy,Block Limit SM,block,16,,,,,
0,54977,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(32, 32, 1)",0,7.5,Occupancy,Block Limit Registers,block,4,,,,,
0,54977,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(32, 32, 1)",0,7.5,Occupancy,Block Limit Shared Mem,block,16,,,,,
0,54977,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(32, 32, 1)",0,7.5,Occupancy,Block Limit Warps,block,1,,,,,
0,54977,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(32, 32, 1)",0,7.5,Occupancy,Theoretical Active Warps per SM,warp,32,,,,,
0,54977,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(32, 32, 1)",0,7.5,Occupancy,Theoretical Occupancy,%,100,,,,,
0,54977,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(32, 32, 1)",0,7.5,Occupancy,Achieved Occupancy,%,74.60,,,,,
0,54977,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(32, 32, 1)",0,7.5,Occupancy,Achieved Active Warps Per SM,warp,23.87,,,,,
0,54977,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(32, 32, 1)",0,7.5,Occupancy,,,,AchievedOccupancy,OPT,The difference between calculated theoretical (100.0%) and measured achieved occupancy (74.6%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy.,global,25.4
0,54977,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(32, 32, 1)",0,7.5,Source Counters,Branch Instructions Ratio,%,0.06,,,,,
0,54977,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(32, 32, 1)",0,7.5,Source Counters,Branch Instructions,inst,"32,768",,,,,
0,54977,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(32, 32, 1)",0,7.5,Source Counters,Branch Efficiency,%,0,,,,,
0,54977,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(32, 32, 1)",0,7.5,Source Counters,Avg. Divergent Branches,,0,,,,,
0,54977,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(32, 32, 1)",0,7.5,SourceCounters,,,,UncoalescedGlobalAccess,OPT,This kernel has uncoalesced global accesses resulting in a total of 2752512 excessive sectors (88% of the total 3145728 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source locations. The CUDA Programming Guide (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) has additional information on reducing uncoalesced device memory accesses.,global,86.55
0,55061,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(2048, 2048, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Frequency,cycle/second,"5,995,977,464.39",,,,,
0,55061,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(2048, 2048, 1)",0,7.5,GPU Speed Of Light Throughput,SM Frequency,cycle/second,"1,394,684,401.50",,,,,
0,55061,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(2048, 2048, 1)",0,7.5,GPU Speed Of Light Throughput,Elapsed Cycles,cycle,"18,979,525",,,,,
0,55061,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(2048, 2048, 1)",0,7.5,GPU Speed Of Light Throughput,Memory Throughput,%,15.79,,,,,
0,55061,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(2048, 2048, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Throughput,%,1.92,,,,,
0,55061,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(2048, 2048, 1)",0,7.5,GPU Speed Of Light Throughput,Duration,nsecond,"13,603,360",,,,,
0,55061,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(2048, 2048, 1)",0,7.5,GPU Speed Of Light Throughput,L1/TEX Cache Throughput,%,27.14,,,,,
0,55061,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(2048, 2048, 1)",0,7.5,GPU Speed Of Light Throughput,L2 Cache Throughput,%,11.61,,,,,
0,55061,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(2048, 2048, 1)",0,7.5,GPU Speed Of Light Throughput,SM Active Cycles,cycle,"11,038,903",,,,,
0,55061,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(2048, 2048, 1)",0,7.5,GPU Speed Of Light Throughput,Compute (SM) Throughput,%,15.79,,,,,
0,55061,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(2048, 2048, 1)",0,7.5,SpeedOfLight,,,,SOLBottleneck,OPT,This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.,,
0,55061,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(2048, 2048, 1)",0,7.5,SpeedOfLight_RooflineChart,,,,SOLFPRoofline,INF,The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved  close to 0% of this device's fp32 peak performance and 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.,,
0,55061,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(2048, 2048, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Active,inst/cycle,0.46,,,,,
0,55061,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(2048, 2048, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Elapsed,inst/cycle,0.27,,,,,
0,55061,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(2048, 2048, 1)",0,7.5,Compute Workload Analysis,Issue Slots Busy,%,11.53,,,,,
0,55061,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(2048, 2048, 1)",0,7.5,Compute Workload Analysis,Issued Ipc Active,inst/cycle,0.46,,,,,
0,55061,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(2048, 2048, 1)",0,7.5,Compute Workload Analysis,SM Busy,%,12.67,,,,,
0,55061,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(2048, 2048, 1)",0,7.5,ComputeWorkloadAnalysis,,,,HighPipeUtilization,OPT,All compute pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.,local,90.5
0,55061,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(2048, 2048, 1)",0,7.5,Memory Workload Analysis,Memory Throughput,byte/second,"3,677,759,612.33",,,,,
0,55061,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(2048, 2048, 1)",0,7.5,Memory Workload Analysis,Mem Busy,%,8.69,,,,,
0,55061,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(2048, 2048, 1)",0,7.5,Memory Workload Analysis,Max Bandwidth,%,15.79,,,,,
0,55061,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(2048, 2048, 1)",0,7.5,Memory Workload Analysis,L1/TEX Hit Rate,%,1.35,,,,,
0,55061,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(2048, 2048, 1)",0,7.5,Memory Workload Analysis,L2 Hit Rate,%,95.80,,,,,
0,55061,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(2048, 2048, 1)",0,7.5,Memory Workload Analysis,Mem Pipes Busy,%,15.79,,,,,
0,55061,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(2048, 2048, 1)",0,7.5,MemoryWorkloadAnalysis_Chart,,,,MemoryL2Compression,WRN,The optional metric lts__average_gcomp_input_sector_success_rate.pct could not be found. Collecting it as an additional metric could enable the rule to provide more guidance.,,
0,55061,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(2048, 2048, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for loads from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced loads and try to minimize how many cache lines need to be accessed per memory request.",global,4.329
0,55061,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(2048, 2048, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for stores from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced stores and try to minimize how many cache lines need to be accessed per memory request.",global,2.189
0,55061,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(2048, 2048, 1)",0,7.5,Scheduler Statistics,One or More Eligible,%,13.00,,,,,
0,55061,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(2048, 2048, 1)",0,7.5,Scheduler Statistics,Issued Warp Per Scheduler,,0.13,,,,,
0,55061,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(2048, 2048, 1)",0,7.5,Scheduler Statistics,No Eligible,%,87.00,,,,,
0,55061,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(2048, 2048, 1)",0,7.5,Scheduler Statistics,Active Warps Per Scheduler,warp,2.53,,,,,
0,55061,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(2048, 2048, 1)",0,7.5,Scheduler Statistics,Eligible Warps Per Scheduler,warp,0.13,,,,,
0,55061,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(2048, 2048, 1)",0,7.5,SchedulerStats,,,,IssueSlotUtilization,OPT,"Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 7.7 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of 2.53 active warps per scheduler, but only an average of 0.13 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections.",local,84.21
0,55061,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(2048, 2048, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Issued Instruction,cycle,19.44,,,,,
0,55061,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(2048, 2048, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Executed Instruction,cycle,19.44,,,,,
0,55061,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(2048, 2048, 1)",0,7.5,Warp State Statistics,Avg. Active Threads Per Warp,,1,,,,,
0,55061,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(2048, 2048, 1)",0,7.5,Warp State Statistics,Avg. Not Predicated Off Threads Per Warp,,1,,,,,
0,55061,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(2048, 2048, 1)",0,7.5,WarpStateStats,,,,CPIStall,OPT,"On average, each warp of this kernel spends 12.5 cycles being stalled waiting for a scoreboard dependency on a L1TEX (local, global, surface, texture) operation. Find the instruction producing the data being waited upon to identify the culprit. To reduce the number of cycles waiting on L1TEX data accesses verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit rates by increasing data locality (coalescing), or by changing the cache configuration. Consider moving frequently used data to shared memory. This stall type represents about 64.2% of the total average of 19.4 cycles between issuing two instructions.",global,64.21
0,55061,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(2048, 2048, 1)",0,7.5,WarpStateStats,,,,CPIStall,INF,Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.,,
0,55061,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(2048, 2048, 1)",0,7.5,WarpStateStats,,,,ThreadDivergence,OPT,"Instructions are executed in warps, which are groups of 32 threads. Optimal instruction throughput is achieved if all 32 threads of a warp execute the same instruction. The chosen launch configuration, early thread completion, and divergent flow control can significantly lower the number of active threads in a warp per cycle. This kernel achieves an average of 1.0 threads being active per cycle.",global,15.3
0,55061,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(2048, 2048, 1)",0,7.5,Instruction Statistics,Avg. Executed Instructions Per Scheduler,inst,"1,273,270.86",,,,,
0,55061,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(2048, 2048, 1)",0,7.5,Instruction Statistics,Executed Instructions,inst,"71,303,168",,,,,
0,55061,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(2048, 2048, 1)",0,7.5,Instruction Statistics,Avg. Issued Instructions Per Scheduler,inst,"1,273,284.50",,,,,
0,55061,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(2048, 2048, 1)",0,7.5,Instruction Statistics,Issued Instructions,inst,"71,303,932",,,,,
0,55061,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(2048, 2048, 1)",0,7.5,InstructionStats,,,,FPInstructions,OPT,"This kernel executes 0 fused and 4194304 non-fused FP32 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP32 performance could be increased by up to 50% (relative to its current performance). Check the Source page to identify where this kernel executes FP32 instructions.",global,4.749
0,55061,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(2048, 2048, 1)",0,7.5,Launch Statistics,Block Size,,1,,,,,
0,55061,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(2048, 2048, 1)",0,7.5,Launch Statistics,Function Cache Configuration,,CachePreferNone,,,,,
0,55061,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(2048, 2048, 1)",0,7.5,Launch Statistics,Grid Size,,"4,194,304",,,,,
0,55061,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(2048, 2048, 1)",0,7.5,Launch Statistics,Registers Per Thread,register/thread,16,,,,,
0,55061,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(2048, 2048, 1)",0,7.5,Launch Statistics,Shared Memory Configuration Size,byte,"32,768",,,,,
0,55061,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(2048, 2048, 1)",0,7.5,Launch Statistics,Driver Shared Memory Per Block,byte/block,0,,,,,
0,55061,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(2048, 2048, 1)",0,7.5,Launch Statistics,Dynamic Shared Memory Per Block,byte/block,0,,,,,
0,55061,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(2048, 2048, 1)",0,7.5,Launch Statistics,Static Shared Memory Per Block,byte/block,0,,,,,
0,55061,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(2048, 2048, 1)",0,7.5,Launch Statistics,Threads,thread,"4,194,304",,,,,
0,55061,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(2048, 2048, 1)",0,7.5,Launch Statistics,Waves Per SM,,"18,724.57",,,,,
0,55061,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(2048, 2048, 1)",0,7.5,LaunchStats,,,,LaunchConfiguration,OPT,"Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 1 threads per block. Consequently, some threads in a warp are masked off and those hardware resources are unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256 threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to kernels that frequently call __syncthreads(). See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations.",global,96.88
0,55061,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(2048, 2048, 1)",0,7.5,Occupancy,Block Limit SM,block,16,,,,,
0,55061,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(2048, 2048, 1)",0,7.5,Occupancy,Block Limit Registers,block,128,,,,,
0,55061,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(2048, 2048, 1)",0,7.5,Occupancy,Block Limit Shared Mem,block,16,,,,,
0,55061,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(2048, 2048, 1)",0,7.5,Occupancy,Block Limit Warps,block,32,,,,,
0,55061,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(2048, 2048, 1)",0,7.5,Occupancy,Theoretical Active Warps per SM,warp,16,,,,,
0,55061,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(2048, 2048, 1)",0,7.5,Occupancy,Theoretical Occupancy,%,50,,,,,
0,55061,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(2048, 2048, 1)",0,7.5,Occupancy,Achieved Occupancy,%,29.56,,,,,
0,55061,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(2048, 2048, 1)",0,7.5,Occupancy,Achieved Active Warps Per SM,warp,9.46,,,,,
0,55061,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(2048, 2048, 1)",0,7.5,Occupancy,,,,AchievedOccupancy,OPT,The difference between calculated theoretical (50.0%) and measured achieved occupancy (29.6%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy.,global,40.89
0,55061,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(2048, 2048, 1)",0,7.5,Occupancy,,,,TheoreticalOccupancy,OPT,The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared memory.,global,50.0
0,55061,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(2048, 2048, 1)",0,7.5,Source Counters,Branch Instructions Ratio,%,0.06,,,,,
0,55061,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(2048, 2048, 1)",0,7.5,Source Counters,Branch Instructions,inst,"4,194,304",,,,,
0,55061,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(2048, 2048, 1)",0,7.5,Source Counters,Branch Efficiency,%,0,,,,,
0,55061,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(2048, 2048, 1)",0,7.5,Source Counters,Avg. Divergent Branches,,0,,,,,
0,55147,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(1024, 1024, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Frequency,cycle/second,"5,988,349,723.06",,,,,
0,55147,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(1024, 1024, 1)",0,7.5,GPU Speed Of Light Throughput,SM Frequency,cycle/second,"1,376,345,972.74",,,,,
0,55147,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(1024, 1024, 1)",0,7.5,GPU Speed Of Light Throughput,Elapsed Cycles,cycle,"4,933,304",,,,,
0,55147,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(1024, 1024, 1)",0,7.5,GPU Speed Of Light Throughput,Memory Throughput,%,22.14,,,,,
0,55147,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(1024, 1024, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Throughput,%,7.31,,,,,
0,55147,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(1024, 1024, 1)",0,7.5,GPU Speed Of Light Throughput,Duration,nsecond,"3,576,224",,,,,
0,55147,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(1024, 1024, 1)",0,7.5,GPU Speed Of Light Throughput,L1/TEX Cache Throughput,%,26.93,,,,,
0,55147,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(1024, 1024, 1)",0,7.5,GPU Speed Of Light Throughput,L2 Cache Throughput,%,22.14,,,,,
0,55147,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(1024, 1024, 1)",0,7.5,GPU Speed Of Light Throughput,SM Active Cycles,cycle,"3,081,835.50",,,,,
0,55147,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(1024, 1024, 1)",0,7.5,GPU Speed Of Light Throughput,Compute (SM) Throughput,%,15.21,,,,,
0,55147,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(1024, 1024, 1)",0,7.5,SpeedOfLight,,,,SOLBottleneck,OPT,This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.,,
0,55147,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(1024, 1024, 1)",0,7.5,SpeedOfLight_RooflineChart,,,,SOLFPRoofline,INF,The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved  close to 0% of this device's fp32 peak performance and 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.,,
0,55147,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(1024, 1024, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Active,inst/cycle,0.41,,,,,
0,55147,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(1024, 1024, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Elapsed,inst/cycle,0.26,,,,,
0,55147,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(1024, 1024, 1)",0,7.5,Compute Workload Analysis,Issue Slots Busy,%,10.33,,,,,
0,55147,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(1024, 1024, 1)",0,7.5,Compute Workload Analysis,Issued Ipc Active,inst/cycle,0.41,,,,,
0,55147,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(1024, 1024, 1)",0,7.5,Compute Workload Analysis,SM Busy,%,11.34,,,,,
0,55147,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(1024, 1024, 1)",0,7.5,ComputeWorkloadAnalysis,,,,HighPipeUtilization,OPT,All compute pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.,local,91.49
0,55147,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(1024, 1024, 1)",0,7.5,Memory Workload Analysis,Memory Throughput,byte/second,"14,005,699,866.68",,,,,
0,55147,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(1024, 1024, 1)",0,7.5,Memory Workload Analysis,Mem Busy,%,16.62,,,,,
0,55147,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(1024, 1024, 1)",0,7.5,Memory Workload Analysis,Max Bandwidth,%,22.14,,,,,
0,55147,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(1024, 1024, 1)",0,7.5,Memory Workload Analysis,L1/TEX Hit Rate,%,0.68,,,,,
0,55147,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(1024, 1024, 1)",0,7.5,Memory Workload Analysis,L2 Hit Rate,%,91.60,,,,,
0,55147,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(1024, 1024, 1)",0,7.5,Memory Workload Analysis,Mem Pipes Busy,%,15.21,,,,,
0,55147,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(1024, 1024, 1)",0,7.5,MemoryWorkloadAnalysis_Chart,,,,MemoryL2Compression,WRN,The optional metric lts__average_gcomp_input_sector_success_rate.pct could not be found. Collecting it as an additional metric could enable the rule to provide more guidance.,,
0,55147,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(1024, 1024, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for loads from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced loads and try to minimize how many cache lines need to be accessed per memory request.",global,8.296
0,55147,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(1024, 1024, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for stores from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced stores and try to minimize how many cache lines need to be accessed per memory request.",global,4.171
0,55147,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(1024, 1024, 1)",0,7.5,Scheduler Statistics,One or More Eligible,%,11.56,,,,,
0,55147,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(1024, 1024, 1)",0,7.5,Scheduler Statistics,Issued Warp Per Scheduler,,0.12,,,,,
0,55147,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(1024, 1024, 1)",0,7.5,Scheduler Statistics,No Eligible,%,88.44,,,,,
0,55147,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(1024, 1024, 1)",0,7.5,Scheduler Statistics,Active Warps Per Scheduler,warp,2.64,,,,,
0,55147,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(1024, 1024, 1)",0,7.5,Scheduler Statistics,Eligible Warps Per Scheduler,warp,0.12,,,,,
0,55147,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(1024, 1024, 1)",0,7.5,SchedulerStats,,,,IssueSlotUtilization,OPT,"Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 8.7 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of 2.64 active warps per scheduler, but only an average of 0.12 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections.",local,77.86
0,55147,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(1024, 1024, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Issued Instruction,cycle,22.85,,,,,
0,55147,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(1024, 1024, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Executed Instruction,cycle,22.85,,,,,
0,55147,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(1024, 1024, 1)",0,7.5,Warp State Statistics,Avg. Active Threads Per Warp,,4,,,,,
0,55147,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(1024, 1024, 1)",0,7.5,Warp State Statistics,Avg. Not Predicated Off Threads Per Warp,,4,,,,,
0,55147,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(1024, 1024, 1)",0,7.5,WarpStateStats,,,,CPIStall,OPT,"On average, each warp of this kernel spends 15.6 cycles being stalled waiting for a scoreboard dependency on a L1TEX (local, global, surface, texture) operation. Find the instruction producing the data being waited upon to identify the culprit. To reduce the number of cycles waiting on L1TEX data accesses verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit rates by increasing data locality (coalescing), or by changing the cache configuration. Consider moving frequently used data to shared memory. This stall type represents about 68.4% of the total average of 22.8 cycles between issuing two instructions.",global,68.42
0,55147,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(1024, 1024, 1)",0,7.5,WarpStateStats,,,,CPIStall,INF,Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.,,
0,55147,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(1024, 1024, 1)",0,7.5,WarpStateStats,,,,ThreadDivergence,OPT,"Instructions are executed in warps, which are groups of 32 threads. Optimal instruction throughput is achieved if all 32 threads of a warp execute the same instruction. The chosen launch configuration, early thread completion, and divergent flow control can significantly lower the number of active threads in a warp per cycle. This kernel achieves an average of 4.0 threads being active per cycle.",global,13.31
0,55147,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(1024, 1024, 1)",0,7.5,Instruction Statistics,Avg. Executed Instructions Per Scheduler,inst,"318,317.71",,,,,
0,55147,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(1024, 1024, 1)",0,7.5,Instruction Statistics,Executed Instructions,inst,"17,825,792",,,,,
0,55147,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(1024, 1024, 1)",0,7.5,Instruction Statistics,Avg. Issued Instructions Per Scheduler,inst,"318,331.36",,,,,
0,55147,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(1024, 1024, 1)",0,7.5,Instruction Statistics,Issued Instructions,inst,"17,826,556",,,,,
0,55147,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(1024, 1024, 1)",0,7.5,InstructionStats,,,,FPInstructions,OPT,"This kernel executes 0 fused and 1048576 non-fused FP32 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP32 performance could be increased by up to 50% (relative to its current performance). Check the Source page to identify where this kernel executes FP32 instructions.",global,4.253
0,55147,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(1024, 1024, 1)",0,7.5,Launch Statistics,Block Size,,4,,,,,
0,55147,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(1024, 1024, 1)",0,7.5,Launch Statistics,Function Cache Configuration,,CachePreferNone,,,,,
0,55147,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(1024, 1024, 1)",0,7.5,Launch Statistics,Grid Size,,"1,048,576",,,,,
0,55147,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(1024, 1024, 1)",0,7.5,Launch Statistics,Registers Per Thread,register/thread,16,,,,,
0,55147,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(1024, 1024, 1)",0,7.5,Launch Statistics,Shared Memory Configuration Size,byte,"32,768",,,,,
0,55147,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(1024, 1024, 1)",0,7.5,Launch Statistics,Driver Shared Memory Per Block,byte/block,0,,,,,
0,55147,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(1024, 1024, 1)",0,7.5,Launch Statistics,Dynamic Shared Memory Per Block,byte/block,0,,,,,
0,55147,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(1024, 1024, 1)",0,7.5,Launch Statistics,Static Shared Memory Per Block,byte/block,0,,,,,
0,55147,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(1024, 1024, 1)",0,7.5,Launch Statistics,Threads,thread,"4,194,304",,,,,
0,55147,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(1024, 1024, 1)",0,7.5,Launch Statistics,Waves Per SM,,"4,681.14",,,,,
0,55147,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(1024, 1024, 1)",0,7.5,LaunchStats,,,,LaunchConfiguration,OPT,"Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 4 threads per block. Consequently, some threads in a warp are masked off and those hardware resources are unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256 threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to kernels that frequently call __syncthreads(). See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations.",global,87.5
0,55147,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(1024, 1024, 1)",0,7.5,Occupancy,Block Limit SM,block,16,,,,,
0,55147,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(1024, 1024, 1)",0,7.5,Occupancy,Block Limit Registers,block,128,,,,,
0,55147,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(1024, 1024, 1)",0,7.5,Occupancy,Block Limit Shared Mem,block,16,,,,,
0,55147,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(1024, 1024, 1)",0,7.5,Occupancy,Block Limit Warps,block,32,,,,,
0,55147,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(1024, 1024, 1)",0,7.5,Occupancy,Theoretical Active Warps per SM,warp,16,,,,,
0,55147,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(1024, 1024, 1)",0,7.5,Occupancy,Theoretical Occupancy,%,50,,,,,
0,55147,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(1024, 1024, 1)",0,7.5,Occupancy,Achieved Occupancy,%,30.91,,,,,
0,55147,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(1024, 1024, 1)",0,7.5,Occupancy,Achieved Active Warps Per SM,warp,9.89,,,,,
0,55147,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(1024, 1024, 1)",0,7.5,Occupancy,,,,AchievedOccupancy,OPT,The difference between calculated theoretical (50.0%) and measured achieved occupancy (30.9%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy.,global,38.17
0,55147,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(1024, 1024, 1)",0,7.5,Occupancy,,,,TheoreticalOccupancy,OPT,The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared memory.,global,50.0
0,55147,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(1024, 1024, 1)",0,7.5,Source Counters,Branch Instructions Ratio,%,0.06,,,,,
0,55147,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(1024, 1024, 1)",0,7.5,Source Counters,Branch Instructions,inst,"1,048,576",,,,,
0,55147,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(1024, 1024, 1)",0,7.5,Source Counters,Branch Efficiency,%,0,,,,,
0,55147,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(1024, 1024, 1)",0,7.5,Source Counters,Avg. Divergent Branches,,0,,,,,
0,55147,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(1024, 1024, 1)",0,7.5,SourceCounters,,,,UncoalescedGlobalAccess,OPT,This kernel has uncoalesced global accesses resulting in a total of 3145728 excessive sectors (50% of the total 6291456 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source locations. The CUDA Programming Guide (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) has additional information on reducing uncoalesced device memory accesses.,global,48.12
0,55224,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(512, 512, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Frequency,cycle/second,"5,980,753,298.07",,,,,
0,55224,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(512, 512, 1)",0,7.5,GPU Speed Of Light Throughput,SM Frequency,cycle/second,"1,373,951,927.06",,,,,
0,55224,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(512, 512, 1)",0,7.5,GPU Speed Of Light Throughput,Elapsed Cycles,cycle,"1,382,616",,,,,
0,55224,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(512, 512, 1)",0,7.5,GPU Speed Of Light Throughput,Memory Throughput,%,39.15,,,,,
0,55224,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(512, 512, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Throughput,%,27.29,,,,,
0,55224,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(512, 512, 1)",0,7.5,GPU Speed Of Light Throughput,Duration,nsecond,"1,004,224",,,,,
0,55224,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(512, 512, 1)",0,7.5,GPU Speed Of Light Throughput,L1/TEX Cache Throughput,%,43.53,,,,,
0,55224,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(512, 512, 1)",0,7.5,GPU Speed Of Light Throughput,L2 Cache Throughput,%,39.15,,,,,
0,55224,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(512, 512, 1)",0,7.5,GPU Speed Of Light Throughput,SM Active Cycles,cycle,"1,196,185.14",,,,,
0,55224,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(512, 512, 1)",0,7.5,GPU Speed Of Light Throughput,Compute (SM) Throughput,%,13.57,,,,,
0,55224,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(512, 512, 1)",0,7.5,SpeedOfLight,,,,SOLBottleneck,OPT,This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.,,
0,55224,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(512, 512, 1)",0,7.5,SpeedOfLight_RooflineChart,,,,SOLFPRoofline,INF,The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved  close to 0% of this device's fp32 peak performance and 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.,,
0,55224,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(512, 512, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Active,inst/cycle,0.27,,,,,
0,55224,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(512, 512, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Elapsed,inst/cycle,0.23,,,,,
0,55224,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(512, 512, 1)",0,7.5,Compute Workload Analysis,Issue Slots Busy,%,6.65,,,,,
0,55224,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(512, 512, 1)",0,7.5,Compute Workload Analysis,Issued Ipc Active,inst/cycle,0.27,,,,,
0,55224,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(512, 512, 1)",0,7.5,Compute Workload Analysis,SM Busy,%,7.31,,,,,
0,55224,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(512, 512, 1)",0,7.5,ComputeWorkloadAnalysis,,,,HighPipeUtilization,OPT,All compute pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.,local,94.52
0,55224,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(512, 512, 1)",0,7.5,Memory Workload Analysis,Memory Throughput,byte/second,"52,224,045,631.25",,,,,
0,55224,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(512, 512, 1)",0,7.5,Memory Workload Analysis,Mem Busy,%,29.71,,,,,
0,55224,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(512, 512, 1)",0,7.5,Memory Workload Analysis,Max Bandwidth,%,39.15,,,,,
0,55224,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(512, 512, 1)",0,7.5,Memory Workload Analysis,L1/TEX Hit Rate,%,0.58,,,,,
0,55224,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(512, 512, 1)",0,7.5,Memory Workload Analysis,L2 Hit Rate,%,82.10,,,,,
0,55224,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(512, 512, 1)",0,7.5,Memory Workload Analysis,Mem Pipes Busy,%,13.57,,,,,
0,55224,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(512, 512, 1)",0,7.5,MemoryWorkloadAnalysis_Chart,,,,MemoryL2Compression,WRN,The optional metric lts__average_gcomp_input_sector_success_rate.pct could not be found. Collecting it as an additional metric could enable the rule to provide more guidance.,,
0,55224,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(512, 512, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for loads from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced loads and try to minimize how many cache lines need to be accessed per memory request.",global,14.82
0,55224,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(512, 512, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for stores from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced stores and try to minimize how many cache lines need to be accessed per memory request.",global,7.44
0,55224,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(512, 512, 1)",0,7.5,Scheduler Statistics,One or More Eligible,%,7.30,,,,,
0,55224,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(512, 512, 1)",0,7.5,Scheduler Statistics,Issued Warp Per Scheduler,,0.07,,,,,
0,55224,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(512, 512, 1)",0,7.5,Scheduler Statistics,No Eligible,%,92.70,,,,,
0,55224,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(512, 512, 1)",0,7.5,Scheduler Statistics,Active Warps Per Scheduler,warp,2.87,,,,,
0,55224,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(512, 512, 1)",0,7.5,Scheduler Statistics,Eligible Warps Per Scheduler,warp,0.07,,,,,
0,55224,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(512, 512, 1)",0,7.5,SchedulerStats,,,,IssueSlotUtilization,OPT,"Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 13.7 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of 2.87 active warps per scheduler, but only an average of 0.07 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections.",local,60.85
0,55224,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(512, 512, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Issued Instruction,cycle,39.35,,,,,
0,55224,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(512, 512, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Executed Instruction,cycle,39.36,,,,,
0,55224,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(512, 512, 1)",0,7.5,Warp State Statistics,Avg. Active Threads Per Warp,,16,,,,,
0,55224,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(512, 512, 1)",0,7.5,Warp State Statistics,Avg. Not Predicated Off Threads Per Warp,,16,,,,,
0,55224,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(512, 512, 1)",0,7.5,WarpStateStats,,,,CPIStall,OPT,"On average, each warp of this kernel spends 30.6 cycles being stalled waiting for a scoreboard dependency on a L1TEX (local, global, surface, texture) operation. Find the instruction producing the data being waited upon to identify the culprit. To reduce the number of cycles waiting on L1TEX data accesses verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit rates by increasing data locality (coalescing), or by changing the cache configuration. Consider moving frequently used data to shared memory. This stall type represents about 77.7% of the total average of 39.3 cycles between issuing two instructions.",global,60.85
0,55224,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(512, 512, 1)",0,7.5,WarpStateStats,,,,CPIStall,INF,Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.,,
0,55224,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(512, 512, 1)",0,7.5,WarpStateStats,,,,ThreadDivergence,OPT,"Instructions are executed in warps, which are groups of 32 threads. Optimal instruction throughput is achieved if all 32 threads of a warp execute the same instruction. The chosen launch configuration, early thread completion, and divergent flow control can significantly lower the number of active threads in a warp per cycle. This kernel achieves an average of 16.0 threads being active per cycle.",global,6.783
0,55224,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(512, 512, 1)",0,7.5,Instruction Statistics,Avg. Executed Instructions Per Scheduler,inst,"79,579.43",,,,,
0,55224,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(512, 512, 1)",0,7.5,Instruction Statistics,Executed Instructions,inst,"4,456,448",,,,,
0,55224,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(512, 512, 1)",0,7.5,Instruction Statistics,Avg. Issued Instructions Per Scheduler,inst,"79,593.07",,,,,
0,55224,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(512, 512, 1)",0,7.5,Instruction Statistics,Issued Instructions,inst,"4,457,212",,,,,
0,55224,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(512, 512, 1)",0,7.5,InstructionStats,,,,FPInstructions,OPT,"This kernel executes 0 fused and 262144 non-fused FP32 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP32 performance could be increased by up to 50% (relative to its current performance). Check the Source page to identify where this kernel executes FP32 instructions.",global,2.739
0,55224,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(512, 512, 1)",0,7.5,Launch Statistics,Block Size,,16,,,,,
0,55224,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(512, 512, 1)",0,7.5,Launch Statistics,Function Cache Configuration,,CachePreferNone,,,,,
0,55224,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(512, 512, 1)",0,7.5,Launch Statistics,Grid Size,,"262,144",,,,,
0,55224,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(512, 512, 1)",0,7.5,Launch Statistics,Registers Per Thread,register/thread,16,,,,,
0,55224,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(512, 512, 1)",0,7.5,Launch Statistics,Shared Memory Configuration Size,byte,"32,768",,,,,
0,55224,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(512, 512, 1)",0,7.5,Launch Statistics,Driver Shared Memory Per Block,byte/block,0,,,,,
0,55224,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(512, 512, 1)",0,7.5,Launch Statistics,Dynamic Shared Memory Per Block,byte/block,0,,,,,
0,55224,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(512, 512, 1)",0,7.5,Launch Statistics,Static Shared Memory Per Block,byte/block,0,,,,,
0,55224,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(512, 512, 1)",0,7.5,Launch Statistics,Threads,thread,"4,194,304",,,,,
0,55224,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(512, 512, 1)",0,7.5,Launch Statistics,Waves Per SM,,"1,170.29",,,,,
0,55224,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(512, 512, 1)",0,7.5,LaunchStats,,,,LaunchConfiguration,OPT,"Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 16 threads per block. Consequently, some threads in a warp are masked off and those hardware resources are unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256 threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to kernels that frequently call __syncthreads(). See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations.",global,50.0
0,55224,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(512, 512, 1)",0,7.5,Occupancy,Block Limit SM,block,16,,,,,
0,55224,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(512, 512, 1)",0,7.5,Occupancy,Block Limit Registers,block,128,,,,,
0,55224,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(512, 512, 1)",0,7.5,Occupancy,Block Limit Shared Mem,block,16,,,,,
0,55224,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(512, 512, 1)",0,7.5,Occupancy,Block Limit Warps,block,32,,,,,
0,55224,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(512, 512, 1)",0,7.5,Occupancy,Theoretical Active Warps per SM,warp,16,,,,,
0,55224,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(512, 512, 1)",0,7.5,Occupancy,Theoretical Occupancy,%,50,,,,,
0,55224,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(512, 512, 1)",0,7.5,Occupancy,Achieved Occupancy,%,33.66,,,,,
0,55224,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(512, 512, 1)",0,7.5,Occupancy,Achieved Active Warps Per SM,warp,10.77,,,,,
0,55224,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(512, 512, 1)",0,7.5,Occupancy,,,,AchievedOccupancy,OPT,The difference between calculated theoretical (50.0%) and measured achieved occupancy (33.7%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy.,global,32.67
0,55224,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(512, 512, 1)",0,7.5,Occupancy,,,,TheoreticalOccupancy,OPT,The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared memory.,global,50.0
0,55224,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(512, 512, 1)",0,7.5,Source Counters,Branch Instructions Ratio,%,0.06,,,,,
0,55224,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(512, 512, 1)",0,7.5,Source Counters,Branch Instructions,inst,"262,144",,,,,
0,55224,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(512, 512, 1)",0,7.5,Source Counters,Branch Efficiency,%,0,,,,,
0,55224,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(512, 512, 1)",0,7.5,Source Counters,Avg. Divergent Branches,,0,,,,,
0,55224,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(512, 512, 1)",0,7.5,SourceCounters,,,,UncoalescedGlobalAccess,OPT,This kernel has uncoalesced global accesses resulting in a total of 1572864 excessive sectors (50% of the total 3145728 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source locations. The CUDA Programming Guide (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) has additional information on reducing uncoalesced device memory accesses.,global,49.57
0,55310,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(256, 256, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Frequency,cycle/second,"5,963,675,501.14",,,,,
0,55310,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(256, 256, 1)",0,7.5,GPU Speed Of Light Throughput,SM Frequency,cycle/second,"1,369,963,339.16",,,,,
0,55310,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(256, 256, 1)",0,7.5,GPU Speed Of Light Throughput,Elapsed Cycles,cycle,"653,433",,,,,
0,55310,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(256, 256, 1)",0,7.5,GPU Speed Of Light Throughput,Memory Throughput,%,58.85,,,,,
0,55310,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(256, 256, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Throughput,%,58.85,,,,,
0,55310,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(256, 256, 1)",0,7.5,GPU Speed Of Light Throughput,Duration,nsecond,"475,712",,,,,
0,55310,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(256, 256, 1)",0,7.5,GPU Speed Of Light Throughput,L1/TEX Cache Throughput,%,80.44,,,,,
0,55310,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(256, 256, 1)",0,7.5,GPU Speed Of Light Throughput,L2 Cache Throughput,%,53.42,,,,,
0,55310,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(256, 256, 1)",0,7.5,GPU Speed Of Light Throughput,SM Active Cycles,cycle,"648,701.86",,,,,
0,55310,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(256, 256, 1)",0,7.5,GPU Speed Of Light Throughput,Compute (SM) Throughput,%,14.36,,,,,
0,55310,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(256, 256, 1)",0,7.5,SpeedOfLight,,,,SOLBottleneck,OPT,This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.,,
0,55310,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(256, 256, 1)",0,7.5,SpeedOfLight_RooflineChart,,,,SOLFPRoofline,INF,The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved  close to 0% of this device's fp32 peak performance and 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.,,
0,55310,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(256, 256, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Active,inst/cycle,0.25,,,,,
0,55310,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(256, 256, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Elapsed,inst/cycle,0.24,,,,,
0,55310,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(256, 256, 1)",0,7.5,Compute Workload Analysis,Issue Slots Busy,%,6.14,,,,,
0,55310,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(256, 256, 1)",0,7.5,Compute Workload Analysis,Issued Ipc Active,inst/cycle,0.25,,,,,
0,55310,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(256, 256, 1)",0,7.5,Compute Workload Analysis,SM Busy,%,6.74,,,,,
0,55310,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(256, 256, 1)",0,7.5,ComputeWorkloadAnalysis,,,,HighPipeUtilization,OPT,All compute pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.,local,94.95
0,55310,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(256, 256, 1)",0,7.5,Memory Workload Analysis,Memory Throughput,byte/second,"112,317,233,956.68",,,,,
0,55310,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(256, 256, 1)",0,7.5,Memory Workload Analysis,Mem Busy,%,43.23,,,,,
0,55310,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(256, 256, 1)",0,7.5,Memory Workload Analysis,Max Bandwidth,%,58.85,,,,,
0,55310,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(256, 256, 1)",0,7.5,Memory Workload Analysis,L1/TEX Hit Rate,%,50.31,,,,,
0,55310,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(256, 256, 1)",0,7.5,Memory Workload Analysis,L2 Hit Rate,%,70.58,,,,,
0,55310,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(256, 256, 1)",0,7.5,Memory Workload Analysis,Mem Pipes Busy,%,14.36,,,,,
0,55310,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(256, 256, 1)",0,7.5,MemoryWorkloadAnalysis_Chart,,,,MemoryL2Compression,WRN,The optional metric lts__average_gcomp_input_sector_success_rate.pct could not be found. Collecting it as an additional metric could enable the rule to provide more guidance.,,
0,55310,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(256, 256, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for global loads in L1TEX might not be optimal. On average, this kernel accesses 4.0 bytes per thread per memory request; but the address pattern, possibly caused by the stride between threads, results in 8.0 sectors per request, or 8.0*32 = 255.6 bytes of cache data transfers per request. The optimal thread address pattern for 4.0 byte accesses would result in 4.0*32 = 128.0 bytes of cache data transfers per request, to maximize L1TEX cache performance. Check the Source Counters section for uncoalesced global loads.",global,1.074
0,55310,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(256, 256, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for global stores in L1TEX might not be optimal. On average, this kernel accesses 4.0 bytes per thread per memory request; but the address pattern, possibly caused by the stride between threads, results in 8.0 sectors per request, or 8.0*32 = 256.0 bytes of cache data transfers per request. The optimal thread address pattern for 4.0 byte accesses would result in 4.0*32 = 128.0 bytes of cache data transfers per request, to maximize L1TEX cache performance. Check the Source Counters section for uncoalesced global stores.",global,1.076
0,55310,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(256, 256, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for loads from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced loads and try to minimize how many cache lines need to be accessed per memory request.",global,15.83
0,55310,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(256, 256, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for stores from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced stores and try to minimize how many cache lines need to be accessed per memory request.",global,13.57
0,55310,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(256, 256, 1)",0,7.5,Scheduler Statistics,One or More Eligible,%,6.13,,,,,
0,55310,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(256, 256, 1)",0,7.5,Scheduler Statistics,Issued Warp Per Scheduler,,0.06,,,,,
0,55310,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(256, 256, 1)",0,7.5,Scheduler Statistics,No Eligible,%,93.87,,,,,
0,55310,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(256, 256, 1)",0,7.5,Scheduler Statistics,Active Warps Per Scheduler,warp,7.23,,,,,
0,55310,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(256, 256, 1)",0,7.5,Scheduler Statistics,Eligible Warps Per Scheduler,warp,0.06,,,,,
0,55310,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(256, 256, 1)",0,7.5,SchedulerStats,,,,IssueSlotUtilization,OPT,"Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 16.3 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of 7.23 active warps per scheduler, but only an average of 0.06 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, avoid possible load imbalances due to highly different execution durations per warp. Reducing stalls indicated on the Warp State Statistics and Source Counters sections can help, too.",local,41.15
0,55310,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(256, 256, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Issued Instruction,cycle,117.98,,,,,
0,55310,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(256, 256, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Executed Instruction,cycle,118.05,,,,,
0,55310,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(256, 256, 1)",0,7.5,Warp State Statistics,Avg. Active Threads Per Warp,,32,,,,,
0,55310,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(256, 256, 1)",0,7.5,Warp State Statistics,Avg. Not Predicated Off Threads Per Warp,,32,,,,,
0,55310,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(256, 256, 1)",0,7.5,WarpStateStats,,,,CPIStall,OPT,"On average, each warp of this kernel spends 98.8 cycles being stalled waiting for a scoreboard dependency on a L1TEX (local, global, surface, texture) operation. Find the instruction producing the data being waited upon to identify the culprit. To reduce the number of cycles waiting on L1TEX data accesses verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit rates by increasing data locality (coalescing), or by changing the cache configuration. Consider moving frequently used data to shared memory. This stall type represents about 83.7% of the total average of 118.0 cycles between issuing two instructions.",global,41.15
0,55310,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(256, 256, 1)",0,7.5,WarpStateStats,,,,CPIStall,INF,Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.,,
0,55310,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(256, 256, 1)",0,7.5,Instruction Statistics,Avg. Executed Instructions Per Scheduler,inst,"39,789.71",,,,,
0,55310,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(256, 256, 1)",0,7.5,Instruction Statistics,Executed Instructions,inst,"2,228,224",,,,,
0,55310,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(256, 256, 1)",0,7.5,Instruction Statistics,Avg. Issued Instructions Per Scheduler,inst,"39,814.91",,,,,
0,55310,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(256, 256, 1)",0,7.5,Instruction Statistics,Issued Instructions,inst,"2,229,635",,,,,
0,55310,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(256, 256, 1)",0,7.5,InstructionStats,,,,FPInstructions,OPT,"This kernel executes 0 fused and 131072 non-fused FP32 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP32 performance could be increased by up to 50% (relative to its current performance). Check the Source page to identify where this kernel executes FP32 instructions.",global,2.526
0,55310,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(256, 256, 1)",0,7.5,Launch Statistics,Block Size,,64,,,,,
0,55310,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(256, 256, 1)",0,7.5,Launch Statistics,Function Cache Configuration,,CachePreferNone,,,,,
0,55310,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(256, 256, 1)",0,7.5,Launch Statistics,Grid Size,,"65,536",,,,,
0,55310,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(256, 256, 1)",0,7.5,Launch Statistics,Registers Per Thread,register/thread,16,,,,,
0,55310,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(256, 256, 1)",0,7.5,Launch Statistics,Shared Memory Configuration Size,byte,"32,768",,,,,
0,55310,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(256, 256, 1)",0,7.5,Launch Statistics,Driver Shared Memory Per Block,byte/block,0,,,,,
0,55310,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(256, 256, 1)",0,7.5,Launch Statistics,Dynamic Shared Memory Per Block,byte/block,0,,,,,
0,55310,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(256, 256, 1)",0,7.5,Launch Statistics,Static Shared Memory Per Block,byte/block,0,,,,,
0,55310,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(256, 256, 1)",0,7.5,Launch Statistics,Threads,thread,"4,194,304",,,,,
0,55310,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(256, 256, 1)",0,7.5,Launch Statistics,Waves Per SM,,292.57,,,,,
0,55310,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(256, 256, 1)",0,7.5,Occupancy,Block Limit SM,block,16,,,,,
0,55310,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(256, 256, 1)",0,7.5,Occupancy,Block Limit Registers,block,64,,,,,
0,55310,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(256, 256, 1)",0,7.5,Occupancy,Block Limit Shared Mem,block,16,,,,,
0,55310,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(256, 256, 1)",0,7.5,Occupancy,Block Limit Warps,block,16,,,,,
0,55310,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(256, 256, 1)",0,7.5,Occupancy,Theoretical Active Warps per SM,warp,32,,,,,
0,55310,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(256, 256, 1)",0,7.5,Occupancy,Theoretical Occupancy,%,100,,,,,
0,55310,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(256, 256, 1)",0,7.5,Occupancy,Achieved Occupancy,%,91.23,,,,,
0,55310,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(256, 256, 1)",0,7.5,Occupancy,Achieved Active Warps Per SM,warp,29.19,,,,,
0,55310,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(256, 256, 1)",0,7.5,Source Counters,Branch Instructions Ratio,%,0.06,,,,,
0,55310,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(256, 256, 1)",0,7.5,Source Counters,Branch Instructions,inst,"131,072",,,,,
0,55310,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(256, 256, 1)",0,7.5,Source Counters,Branch Efficiency,%,0,,,,,
0,55310,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(256, 256, 1)",0,7.5,Source Counters,Avg. Divergent Branches,,0,,,,,
0,55310,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(256, 256, 1)",0,7.5,SourceCounters,,,,UncoalescedGlobalAccess,OPT,This kernel has uncoalesced global accesses resulting in a total of 1572864 excessive sectors (50% of the total 3145728 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source locations. The CUDA Programming Guide (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) has additional information on reducing uncoalesced device memory accesses.,global,49.72
0,55397,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(128, 128, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Frequency,cycle/second,"5,984,796,005.58",,,,,
0,55397,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(128, 128, 1)",0,7.5,GPU Speed Of Light Throughput,SM Frequency,cycle/second,"1,375,693,007.51",,,,,
0,55397,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(128, 128, 1)",0,7.5,GPU Speed Of Light Throughput,Elapsed Cycles,cycle,"981,421",,,,,
0,55397,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(128, 128, 1)",0,7.5,GPU Speed Of Light Throughput,Memory Throughput,%,64.41,,,,,
0,55397,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(128, 128, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Throughput,%,36.70,,,,,
0,55397,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(128, 128, 1)",0,7.5,GPU Speed Of Light Throughput,Duration,nsecond,"711,392",,,,,
0,55397,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(128, 128, 1)",0,7.5,GPU Speed Of Light Throughput,L1/TEX Cache Throughput,%,97.86,,,,,
0,55397,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(128, 128, 1)",0,7.5,GPU Speed Of Light Throughput,L2 Cache Throughput,%,64.41,,,,,
0,55397,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(128, 128, 1)",0,7.5,GPU Speed Of Light Throughput,SM Active Cycles,cycle,"977,030.93",,,,,
0,55397,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(128, 128, 1)",0,7.5,GPU Speed Of Light Throughput,Compute (SM) Throughput,%,9.56,,,,,
0,55397,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(128, 128, 1)",0,7.5,SpeedOfLight,,,,SOLBottleneck,OPT,Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the L2 bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or whether there are values you can (re)compute.,,
0,55397,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(128, 128, 1)",0,7.5,SpeedOfLight_RooflineChart,,,,SOLFPRoofline,INF,The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved  close to 0% of this device's fp32 peak performance and 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.,,
0,55397,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(128, 128, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Active,inst/cycle,0.16,,,,,
0,55397,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(128, 128, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Elapsed,inst/cycle,0.16,,,,,
0,55397,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(128, 128, 1)",0,7.5,Compute Workload Analysis,Issue Slots Busy,%,4.08,,,,,
0,55397,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(128, 128, 1)",0,7.5,Compute Workload Analysis,Issued Ipc Active,inst/cycle,0.16,,,,,
0,55397,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(128, 128, 1)",0,7.5,Compute Workload Analysis,SM Busy,%,4.47,,,,,
0,55397,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(128, 128, 1)",0,7.5,ComputeWorkloadAnalysis,,,,HighPipeUtilization,OPT,All compute pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.,local,96.65
0,55397,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(128, 128, 1)",0,7.5,Memory Workload Analysis,Memory Throughput,byte/second,"70,281,858,665.83",,,,,
0,55397,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(128, 128, 1)",0,7.5,Memory Workload Analysis,Mem Busy,%,48.93,,,,,
0,55397,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(128, 128, 1)",0,7.5,Memory Workload Analysis,Max Bandwidth,%,64.41,,,,,
0,55397,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(128, 128, 1)",0,7.5,Memory Workload Analysis,L1/TEX Hit Rate,%,79.26,,,,,
0,55397,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(128, 128, 1)",0,7.5,Memory Workload Analysis,L2 Hit Rate,%,82.21,,,,,
0,55397,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(128, 128, 1)",0,7.5,Memory Workload Analysis,Mem Pipes Busy,%,9.56,,,,,
0,55397,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(128, 128, 1)",0,7.5,MemoryWorkloadAnalysis_Chart,,,,MemoryL2Compression,WRN,The optional metric lts__average_gcomp_input_sector_success_rate.pct could not be found. Collecting it as an additional metric could enable the rule to provide more guidance.,,
0,55397,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(128, 128, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for global loads in L1TEX might not be optimal. On average, this kernel accesses 4.0 bytes per thread per memory request; but the address pattern, possibly caused by the stride between threads, results in 16.0 sectors per request, or 16.0*32 = 511.9 bytes of cache data transfers per request. The optimal thread address pattern for 4.0 byte accesses would result in 4.0*32 = 128.0 bytes of cache data transfers per request, to maximize L1TEX cache performance. Check the Source Counters section for uncoalesced global loads.",global,2.151
0,55397,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(128, 128, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for global stores in L1TEX might not be optimal. On average, this kernel accesses 4.0 bytes per thread per memory request; but the address pattern, possibly caused by the stride between threads, results in 16.0 sectors per request, or 16.0*32 = 512.0 bytes of cache data transfers per request. The optimal thread address pattern for 4.0 byte accesses would result in 4.0*32 = 128.0 bytes of cache data transfers per request, to maximize L1TEX cache performance. Check the Source Counters section for uncoalesced global stores.",global,2.151
0,55397,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(128, 128, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for loads from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced loads and try to minimize how many cache lines need to be accessed per memory request.",global,10.43
0,55397,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(128, 128, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for stores from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.1 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced stores and try to minimize how many cache lines need to be accessed per memory request.",global,19.37
0,55397,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(128, 128, 1)",0,7.5,Scheduler Statistics,One or More Eligible,%,4.07,,,,,
0,55397,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(128, 128, 1)",0,7.5,Scheduler Statistics,Issued Warp Per Scheduler,,0.04,,,,,
0,55397,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(128, 128, 1)",0,7.5,Scheduler Statistics,No Eligible,%,95.93,,,,,
0,55397,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(128, 128, 1)",0,7.5,Scheduler Statistics,Active Warps Per Scheduler,warp,6.43,,,,,
0,55397,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(128, 128, 1)",0,7.5,Scheduler Statistics,Eligible Warps Per Scheduler,warp,0.05,,,,,
0,55397,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(128, 128, 1)",0,7.5,SchedulerStats,,,,IssueSlotUtilization,OPT,"Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 24.6 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of 6.43 active warps per scheduler, but only an average of 0.05 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, avoid possible load imbalances due to highly different execution durations per warp. Reducing stalls indicated on the Warp State Statistics and Source Counters sections can help, too.",local,35.59
0,55397,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(128, 128, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Issued Instruction,cycle,157.75,,,,,
0,55397,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(128, 128, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Executed Instruction,cycle,157.88,,,,,
0,55397,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(128, 128, 1)",0,7.5,Warp State Statistics,Avg. Active Threads Per Warp,,32,,,,,
0,55397,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(128, 128, 1)",0,7.5,Warp State Statistics,Avg. Not Predicated Off Threads Per Warp,,32,,,,,
0,55397,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(128, 128, 1)",0,7.5,WarpStateStats,,,,CPIStall,OPT,"On average, each warp of this kernel spends 82.8 cycles being stalled waiting for a scoreboard dependency on a L1TEX (local, global, surface, texture) operation. Find the instruction producing the data being waited upon to identify the culprit. To reduce the number of cycles waiting on L1TEX data accesses verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit rates by increasing data locality (coalescing), or by changing the cache configuration. Consider moving frequently used data to shared memory. This stall type represents about 52.5% of the total average of 157.8 cycles between issuing two instructions.",global,35.59
0,55397,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(128, 128, 1)",0,7.5,WarpStateStats,,,,CPIStall,INF,Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.,,
0,55397,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(128, 128, 1)",0,7.5,Instruction Statistics,Avg. Executed Instructions Per Scheduler,inst,"39,789.71",,,,,
0,55397,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(128, 128, 1)",0,7.5,Instruction Statistics,Executed Instructions,inst,"2,228,224",,,,,
0,55397,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(128, 128, 1)",0,7.5,Instruction Statistics,Avg. Issued Instructions Per Scheduler,inst,"39,821.21",,,,,
0,55397,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(128, 128, 1)",0,7.5,Instruction Statistics,Issued Instructions,inst,"2,229,988",,,,,
0,55397,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(128, 128, 1)",0,7.5,InstructionStats,,,,FPInstructions,OPT,"This kernel executes 0 fused and 131072 non-fused FP32 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP32 performance could be increased by up to 50% (relative to its current performance). Check the Source page to identify where this kernel executes FP32 instructions.",global,1.677
0,55397,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(128, 128, 1)",0,7.5,Launch Statistics,Block Size,,256,,,,,
0,55397,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(128, 128, 1)",0,7.5,Launch Statistics,Function Cache Configuration,,CachePreferNone,,,,,
0,55397,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(128, 128, 1)",0,7.5,Launch Statistics,Grid Size,,"16,384",,,,,
0,55397,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(128, 128, 1)",0,7.5,Launch Statistics,Registers Per Thread,register/thread,16,,,,,
0,55397,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(128, 128, 1)",0,7.5,Launch Statistics,Shared Memory Configuration Size,byte,"32,768",,,,,
0,55397,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(128, 128, 1)",0,7.5,Launch Statistics,Driver Shared Memory Per Block,byte/block,0,,,,,
0,55397,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(128, 128, 1)",0,7.5,Launch Statistics,Dynamic Shared Memory Per Block,byte/block,0,,,,,
0,55397,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(128, 128, 1)",0,7.5,Launch Statistics,Static Shared Memory Per Block,byte/block,0,,,,,
0,55397,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(128, 128, 1)",0,7.5,Launch Statistics,Threads,thread,"4,194,304",,,,,
0,55397,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(128, 128, 1)",0,7.5,Launch Statistics,Waves Per SM,,292.57,,,,,
0,55397,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(128, 128, 1)",0,7.5,Occupancy,Block Limit SM,block,16,,,,,
0,55397,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(128, 128, 1)",0,7.5,Occupancy,Block Limit Registers,block,16,,,,,
0,55397,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(128, 128, 1)",0,7.5,Occupancy,Block Limit Shared Mem,block,16,,,,,
0,55397,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(128, 128, 1)",0,7.5,Occupancy,Block Limit Warps,block,4,,,,,
0,55397,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(128, 128, 1)",0,7.5,Occupancy,Theoretical Active Warps per SM,warp,32,,,,,
0,55397,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(128, 128, 1)",0,7.5,Occupancy,Theoretical Occupancy,%,100,,,,,
0,55397,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(128, 128, 1)",0,7.5,Occupancy,Achieved Occupancy,%,80.81,,,,,
0,55397,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(128, 128, 1)",0,7.5,Occupancy,Achieved Active Warps Per SM,warp,25.86,,,,,
0,55397,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(128, 128, 1)",0,7.5,Occupancy,,,,AchievedOccupancy,OPT,The difference between calculated theoretical (100.0%) and measured achieved occupancy (80.8%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy.,global,19.19
0,55397,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(128, 128, 1)",0,7.5,Source Counters,Branch Instructions Ratio,%,0.06,,,,,
0,55397,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(128, 128, 1)",0,7.5,Source Counters,Branch Instructions,inst,"131,072",,,,,
0,55397,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(128, 128, 1)",0,7.5,Source Counters,Branch Efficiency,%,0,,,,,
0,55397,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(128, 128, 1)",0,7.5,Source Counters,Avg. Divergent Branches,,0,,,,,
0,55397,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(128, 128, 1)",0,7.5,SourceCounters,,,,UncoalescedGlobalAccess,OPT,This kernel has uncoalesced global accesses resulting in a total of 4718592 excessive sectors (75% of the total 6291456 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source locations. The CUDA Programming Guide (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) has additional information on reducing uncoalesced device memory accesses.,global,74.9
0,55483,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(64, 64, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Frequency,cycle/second,"6,001,899,174.91",,,,,
0,55483,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(64, 64, 1)",0,7.5,GPU Speed Of Light Throughput,SM Frequency,cycle/second,"1,377,805,569.33",,,,,
0,55483,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(64, 64, 1)",0,7.5,GPU Speed Of Light Throughput,Elapsed Cycles,cycle,"2,093,510",,,,,
0,55483,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(64, 64, 1)",0,7.5,GPU Speed Of Light Throughput,Memory Throughput,%,58.77,,,,,
0,55483,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(64, 64, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Throughput,%,17.23,,,,,
0,55483,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(64, 64, 1)",0,7.5,GPU Speed Of Light Throughput,Duration,nsecond,"1,516,448",,,,,
0,55483,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(64, 64, 1)",0,7.5,GPU Speed Of Light Throughput,L1/TEX Cache Throughput,%,87.83,,,,,
0,55483,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(64, 64, 1)",0,7.5,GPU Speed Of Light Throughput,L2 Cache Throughput,%,58.77,,,,,
0,55483,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(64, 64, 1)",0,7.5,GPU Speed Of Light Throughput,SM Active Cycles,cycle,"2,044,954.50",,,,,
0,55483,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(64, 64, 1)",0,7.5,GPU Speed Of Light Throughput,Compute (SM) Throughput,%,4.48,,,,,
0,55483,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(64, 64, 1)",0,7.5,SpeedOfLight,,,,SOLBottleneck,OPT,This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.,,
0,55483,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(64, 64, 1)",0,7.5,SpeedOfLight_RooflineChart,,,,SOLFPRoofline,INF,The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved  close to 0% of this device's fp32 peak performance and 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.,,
0,55483,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(64, 64, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Active,inst/cycle,0.08,,,,,
0,55483,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(64, 64, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Elapsed,inst/cycle,0.08,,,,,
0,55483,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(64, 64, 1)",0,7.5,Compute Workload Analysis,Issue Slots Busy,%,1.95,,,,,
0,55483,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(64, 64, 1)",0,7.5,Compute Workload Analysis,Issued Ipc Active,inst/cycle,0.08,,,,,
0,55483,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(64, 64, 1)",0,7.5,Compute Workload Analysis,SM Busy,%,2.14,,,,,
0,55483,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(64, 64, 1)",0,7.5,ComputeWorkloadAnalysis,,,,HighPipeUtilization,OPT,All compute pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.,local,98.4
0,55483,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(64, 64, 1)",0,7.5,Memory Workload Analysis,Memory Throughput,byte/second,"33,083,247,167.06",,,,,
0,55483,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(64, 64, 1)",0,7.5,Memory Workload Analysis,Mem Busy,%,43.91,,,,,
0,55483,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(64, 64, 1)",0,7.5,Memory Workload Analysis,Max Bandwidth,%,58.77,,,,,
0,55483,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(64, 64, 1)",0,7.5,Memory Workload Analysis,L1/TEX Hit Rate,%,90.62,,,,,
0,55483,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(64, 64, 1)",0,7.5,Memory Workload Analysis,L2 Hit Rate,%,90.00,,,,,
0,55483,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(64, 64, 1)",0,7.5,Memory Workload Analysis,Mem Pipes Busy,%,4.48,,,,,
0,55483,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(64, 64, 1)",0,7.5,MemoryWorkloadAnalysis_Chart,,,,MemoryL2Compression,WRN,The optional metric lts__average_gcomp_input_sector_success_rate.pct could not be found. Collecting it as an additional metric could enable the rule to provide more guidance.,,
0,55483,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(64, 64, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for global loads in L1TEX might not be optimal. On average, this kernel accesses 4.0 bytes per thread per memory request; but the address pattern, possibly caused by the stride between threads, results in 32.0 sectors per request, or 32.0*32 = 1024.0 bytes of cache data transfers per request. The optimal thread address pattern for 4.0 byte accesses would result in 4.0*32 = 128.0 bytes of cache data transfers per request, to maximize L1TEX cache performance. Check the Source Counters section for uncoalesced global loads.",global,2.352
0,55483,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(64, 64, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for global stores in L1TEX might not be optimal. On average, this kernel accesses 4.0 bytes per thread per memory request; but the address pattern, possibly caused by the stride between threads, results in 32.0 sectors per request, or 32.0*32 = 1024.0 bytes of cache data transfers per request. The optimal thread address pattern for 4.0 byte accesses would result in 4.0*32 = 128.0 bytes of cache data transfers per request, to maximize L1TEX cache performance. Check the Source Counters section for uncoalesced global stores.",global,2.352
0,55483,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(64, 64, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for loads from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced loads and try to minimize how many cache lines need to be accessed per memory request.",global,4.909
0,55483,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(64, 64, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for stores from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced stores and try to minimize how many cache lines need to be accessed per memory request.",global,19.64
0,55483,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(64, 64, 1)",0,7.5,Scheduler Statistics,One or More Eligible,%,2.06,,,,,
0,55483,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(64, 64, 1)",0,7.5,Scheduler Statistics,Issued Warp Per Scheduler,,0.02,,,,,
0,55483,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(64, 64, 1)",0,7.5,Scheduler Statistics,No Eligible,%,97.94,,,,,
0,55483,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(64, 64, 1)",0,7.5,Scheduler Statistics,Active Warps Per Scheduler,warp,6.21,,,,,
0,55483,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(64, 64, 1)",0,7.5,Scheduler Statistics,Eligible Warps Per Scheduler,warp,0.04,,,,,
0,55483,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(64, 64, 1)",0,7.5,SchedulerStats,,,,IssueSlotUtilization,OPT,"Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 48.5 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of 6.21 active warps per scheduler, but only an average of 0.04 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections.",local,41.23
0,55483,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(64, 64, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Issued Instruction,cycle,300.95,,,,,
0,55483,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(64, 64, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Executed Instruction,cycle,301.19,,,,,
0,55483,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(64, 64, 1)",0,7.5,Warp State Statistics,Avg. Active Threads Per Warp,,32,,,,,
0,55483,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(64, 64, 1)",0,7.5,Warp State Statistics,Avg. Not Predicated Off Threads Per Warp,,32,,,,,
0,55483,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(64, 64, 1)",0,7.5,WarpStateStats,,,,CPIStall,OPT,"On average, each warp of this kernel spends 180.4 cycles being stalled waiting for a scoreboard dependency on a L1TEX (local, global, surface, texture) operation. Find the instruction producing the data being waited upon to identify the culprit. To reduce the number of cycles waiting on L1TEX data accesses verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit rates by increasing data locality (coalescing), or by changing the cache configuration. Consider moving frequently used data to shared memory. This stall type represents about 59.9% of the total average of 300.9 cycles between issuing two instructions.",global,41.23
0,55483,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(64, 64, 1)",0,7.5,WarpStateStats,,,,CPIStall,INF,Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.,,
0,55483,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(64, 64, 1)",0,7.5,Instruction Statistics,Avg. Executed Instructions Per Scheduler,inst,"39,789.71",,,,,
0,55483,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(64, 64, 1)",0,7.5,Instruction Statistics,Executed Instructions,inst,"2,228,224",,,,,
0,55483,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(64, 64, 1)",0,7.5,Instruction Statistics,Avg. Issued Instructions Per Scheduler,inst,"39,821.71",,,,,
0,55483,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(64, 64, 1)",0,7.5,Instruction Statistics,Issued Instructions,inst,"2,230,016",,,,,
0,55483,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(64, 64, 1)",0,7.5,InstructionStats,,,,FPInstructions,OPT,"This kernel executes 0 fused and 131072 non-fused FP32 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP32 performance could be increased by up to 50% (relative to its current performance). Check the Source page to identify where this kernel executes FP32 instructions.",global,0.8012
0,55483,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(64, 64, 1)",0,7.5,Launch Statistics,Block Size,,"1,024",,,,,
0,55483,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(64, 64, 1)",0,7.5,Launch Statistics,Function Cache Configuration,,CachePreferNone,,,,,
0,55483,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(64, 64, 1)",0,7.5,Launch Statistics,Grid Size,,"4,096",,,,,
0,55483,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(64, 64, 1)",0,7.5,Launch Statistics,Registers Per Thread,register/thread,16,,,,,
0,55483,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(64, 64, 1)",0,7.5,Launch Statistics,Shared Memory Configuration Size,byte,"32,768",,,,,
0,55483,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(64, 64, 1)",0,7.5,Launch Statistics,Driver Shared Memory Per Block,byte/block,0,,,,,
0,55483,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(64, 64, 1)",0,7.5,Launch Statistics,Dynamic Shared Memory Per Block,byte/block,0,,,,,
0,55483,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(64, 64, 1)",0,7.5,Launch Statistics,Static Shared Memory Per Block,byte/block,0,,,,,
0,55483,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(64, 64, 1)",0,7.5,Launch Statistics,Threads,thread,"4,194,304",,,,,
0,55483,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(64, 64, 1)",0,7.5,Launch Statistics,Waves Per SM,,292.57,,,,,
0,55483,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(64, 64, 1)",0,7.5,Occupancy,Block Limit SM,block,16,,,,,
0,55483,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(64, 64, 1)",0,7.5,Occupancy,Block Limit Registers,block,4,,,,,
0,55483,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(64, 64, 1)",0,7.5,Occupancy,Block Limit Shared Mem,block,16,,,,,
0,55483,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(64, 64, 1)",0,7.5,Occupancy,Block Limit Warps,block,1,,,,,
0,55483,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(64, 64, 1)",0,7.5,Occupancy,Theoretical Active Warps per SM,warp,32,,,,,
0,55483,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(64, 64, 1)",0,7.5,Occupancy,Theoretical Occupancy,%,100,,,,,
0,55483,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(64, 64, 1)",0,7.5,Occupancy,Achieved Occupancy,%,73.29,,,,,
0,55483,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(64, 64, 1)",0,7.5,Occupancy,Achieved Active Warps Per SM,warp,23.45,,,,,
0,55483,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(64, 64, 1)",0,7.5,Occupancy,,,,AchievedOccupancy,OPT,The difference between calculated theoretical (100.0%) and measured achieved occupancy (73.3%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy.,global,26.71
0,55483,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(64, 64, 1)",0,7.5,Source Counters,Branch Instructions Ratio,%,0.06,,,,,
0,55483,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(64, 64, 1)",0,7.5,Source Counters,Branch Instructions,inst,"131,072",,,,,
0,55483,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(64, 64, 1)",0,7.5,Source Counters,Branch Efficiency,%,0,,,,,
0,55483,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(64, 64, 1)",0,7.5,Source Counters,Avg. Divergent Branches,,0,,,,,
0,55483,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(64, 64, 1)",0,7.5,SourceCounters,,,,UncoalescedGlobalAccess,OPT,This kernel has uncoalesced global accesses resulting in a total of 11010048 excessive sectors (88% of the total 12582912 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source locations. The CUDA Programming Guide (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) has additional information on reducing uncoalesced device memory accesses.,global,88.01
0,55561,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(4096, 4096, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Frequency,cycle/second,"5,991,993,445.81",,,,,
0,55561,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(4096, 4096, 1)",0,7.5,GPU Speed Of Light Throughput,SM Frequency,cycle/second,"1,377,865,246.22",,,,,
0,55561,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(4096, 4096, 1)",0,7.5,GPU Speed Of Light Throughput,Elapsed Cycles,cycle,"97,682,529",,,,,
0,55561,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(4096, 4096, 1)",0,7.5,GPU Speed Of Light Throughput,Memory Throughput,%,19.76,,,,,
0,55561,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(4096, 4096, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Throughput,%,19.76,,,,,
0,55561,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(4096, 4096, 1)",0,7.5,GPU Speed Of Light Throughput,Duration,nsecond,"70,813,984",,,,,
0,55561,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(4096, 4096, 1)",0,7.5,GPU Speed Of Light Throughput,L1/TEX Cache Throughput,%,14.96,,,,,
0,55561,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(4096, 4096, 1)",0,7.5,GPU Speed Of Light Throughput,L2 Cache Throughput,%,8.98,,,,,
0,55561,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(4096, 4096, 1)",0,7.5,GPU Speed Of Light Throughput,SM Active Cycles,cycle,"80,104,092.50",,,,,
0,55561,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(4096, 4096, 1)",0,7.5,GPU Speed Of Light Throughput,Compute (SM) Throughput,%,12.28,,,,,
0,55561,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(4096, 4096, 1)",0,7.5,SpeedOfLight,,,,SOLBottleneck,OPT,This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.,,
0,55561,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(4096, 4096, 1)",0,7.5,SpeedOfLight_RooflineChart,,,,SOLFPRoofline,INF,The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved  close to 0% of this device's fp32 peak performance and 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.,,
0,55561,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(4096, 4096, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Active,inst/cycle,0.25,,,,,
0,55561,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(4096, 4096, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Elapsed,inst/cycle,0.21,,,,,
0,55561,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(4096, 4096, 1)",0,7.5,Compute Workload Analysis,Issue Slots Busy,%,6.36,,,,,
0,55561,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(4096, 4096, 1)",0,7.5,Compute Workload Analysis,Issued Ipc Active,inst/cycle,0.25,,,,,
0,55561,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(4096, 4096, 1)",0,7.5,Compute Workload Analysis,SM Busy,%,6.98,,,,,
0,55561,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(4096, 4096, 1)",0,7.5,ComputeWorkloadAnalysis,,,,HighPipeUtilization,OPT,All compute pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.,local,94.76
0,55561,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(4096, 4096, 1)",0,7.5,Memory Workload Analysis,Memory Throughput,byte/second,"37,893,186,746.84",,,,,
0,55561,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(4096, 4096, 1)",0,7.5,Memory Workload Analysis,Mem Busy,%,6.73,,,,,
0,55561,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(4096, 4096, 1)",0,7.5,Memory Workload Analysis,Max Bandwidth,%,19.76,,,,,
0,55561,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(4096, 4096, 1)",0,7.5,Memory Workload Analysis,L1/TEX Hit Rate,%,0.06,,,,,
0,55561,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(4096, 4096, 1)",0,7.5,Memory Workload Analysis,L2 Hit Rate,%,33.34,,,,,
0,55561,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(4096, 4096, 1)",0,7.5,Memory Workload Analysis,Mem Pipes Busy,%,12.28,,,,,
0,55561,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(4096, 4096, 1)",0,7.5,MemoryWorkloadAnalysis_Chart,,,,MemoryL2Compression,WRN,The optional metric lts__average_gcomp_input_sector_success_rate.pct could not be found. Collecting it as an additional metric could enable the rule to provide more guidance.,,
0,55561,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(4096, 4096, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for loads from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced loads and try to minimize how many cache lines need to be accessed per memory request.",global,3.366
0,55561,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(4096, 4096, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for stores from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced stores and try to minimize how many cache lines need to be accessed per memory request.",global,1.684
0,55561,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(4096, 4096, 1)",0,7.5,Scheduler Statistics,One or More Eligible,%,7.10,,,,,
0,55561,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(4096, 4096, 1)",0,7.5,Scheduler Statistics,Issued Warp Per Scheduler,,0.07,,,,,
0,55561,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(4096, 4096, 1)",0,7.5,Scheduler Statistics,No Eligible,%,92.90,,,,,
0,55561,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(4096, 4096, 1)",0,7.5,Scheduler Statistics,Active Warps Per Scheduler,warp,2.94,,,,,
0,55561,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(4096, 4096, 1)",0,7.5,Scheduler Statistics,Eligible Warps Per Scheduler,warp,0.07,,,,,
0,55561,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(4096, 4096, 1)",0,7.5,SchedulerStats,,,,IssueSlotUtilization,OPT,"Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 14.1 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of 2.94 active warps per scheduler, but only an average of 0.07 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections.",local,80.24
0,55561,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(4096, 4096, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Issued Instruction,cycle,41.41,,,,,
0,55561,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(4096, 4096, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Executed Instruction,cycle,41.41,,,,,
0,55561,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(4096, 4096, 1)",0,7.5,Warp State Statistics,Avg. Active Threads Per Warp,,1,,,,,
0,55561,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(4096, 4096, 1)",0,7.5,Warp State Statistics,Avg. Not Predicated Off Threads Per Warp,,1,,,,,
0,55561,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(4096, 4096, 1)",0,7.5,WarpStateStats,,,,CPIStall,OPT,"On average, each warp of this kernel spends 34.4 cycles being stalled waiting for a scoreboard dependency on a L1TEX (local, global, surface, texture) operation. Find the instruction producing the data being waited upon to identify the culprit. To reduce the number of cycles waiting on L1TEX data accesses verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit rates by increasing data locality (coalescing), or by changing the cache configuration. Consider moving frequently used data to shared memory. This stall type represents about 83.1% of the total average of 41.4 cycles between issuing two instructions.",global,80.24
0,55561,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(4096, 4096, 1)",0,7.5,WarpStateStats,,,,CPIStall,INF,Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.,,
0,55561,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(4096, 4096, 1)",0,7.5,WarpStateStats,,,,ThreadDivergence,OPT,"Instructions are executed in warps, which are groups of 32 threads. Optimal instruction throughput is achieved if all 32 threads of a warp execute the same instruction. The chosen launch configuration, early thread completion, and divergent flow control can significantly lower the number of active threads in a warp per cycle. This kernel achieves an average of 1.0 threads being active per cycle.",global,11.9
0,55561,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(4096, 4096, 1)",0,7.5,Instruction Statistics,Avg. Executed Instructions Per Scheduler,inst,"5,093,083.43",,,,,
0,55561,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(4096, 4096, 1)",0,7.5,Instruction Statistics,Executed Instructions,inst,"285,212,672",,,,,
0,55561,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(4096, 4096, 1)",0,7.5,Instruction Statistics,Avg. Issued Instructions Per Scheduler,inst,"5,093,097.07",,,,,
0,55561,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(4096, 4096, 1)",0,7.5,Instruction Statistics,Issued Instructions,inst,"285,213,436",,,,,
0,55561,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(4096, 4096, 1)",0,7.5,InstructionStats,,,,FPInstructions,OPT,"This kernel executes 0 fused and 16777216 non-fused FP32 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP32 performance could be increased by up to 50% (relative to its current performance). Check the Source page to identify where this kernel executes FP32 instructions.",global,2.618
0,55561,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(4096, 4096, 1)",0,7.5,Launch Statistics,Block Size,,1,,,,,
0,55561,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(4096, 4096, 1)",0,7.5,Launch Statistics,Function Cache Configuration,,CachePreferNone,,,,,
0,55561,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(4096, 4096, 1)",0,7.5,Launch Statistics,Grid Size,,"16,777,216",,,,,
0,55561,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(4096, 4096, 1)",0,7.5,Launch Statistics,Registers Per Thread,register/thread,16,,,,,
0,55561,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(4096, 4096, 1)",0,7.5,Launch Statistics,Shared Memory Configuration Size,byte,"32,768",,,,,
0,55561,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(4096, 4096, 1)",0,7.5,Launch Statistics,Driver Shared Memory Per Block,byte/block,0,,,,,
0,55561,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(4096, 4096, 1)",0,7.5,Launch Statistics,Dynamic Shared Memory Per Block,byte/block,0,,,,,
0,55561,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(4096, 4096, 1)",0,7.5,Launch Statistics,Static Shared Memory Per Block,byte/block,0,,,,,
0,55561,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(4096, 4096, 1)",0,7.5,Launch Statistics,Threads,thread,"16,777,216",,,,,
0,55561,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(4096, 4096, 1)",0,7.5,Launch Statistics,Waves Per SM,,"74,898.29",,,,,
0,55561,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(4096, 4096, 1)",0,7.5,LaunchStats,,,,LaunchConfiguration,OPT,"Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 1 threads per block. Consequently, some threads in a warp are masked off and those hardware resources are unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256 threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to kernels that frequently call __syncthreads(). See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations.",global,96.88
0,55561,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(4096, 4096, 1)",0,7.5,Occupancy,Block Limit SM,block,16,,,,,
0,55561,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(4096, 4096, 1)",0,7.5,Occupancy,Block Limit Registers,block,128,,,,,
0,55561,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(4096, 4096, 1)",0,7.5,Occupancy,Block Limit Shared Mem,block,16,,,,,
0,55561,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(4096, 4096, 1)",0,7.5,Occupancy,Block Limit Warps,block,32,,,,,
0,55561,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(4096, 4096, 1)",0,7.5,Occupancy,Theoretical Active Warps per SM,warp,16,,,,,
0,55561,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(4096, 4096, 1)",0,7.5,Occupancy,Theoretical Occupancy,%,50,,,,,
0,55561,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(4096, 4096, 1)",0,7.5,Occupancy,Achieved Occupancy,%,33.74,,,,,
0,55561,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(4096, 4096, 1)",0,7.5,Occupancy,Achieved Active Warps Per SM,warp,10.80,,,,,
0,55561,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(4096, 4096, 1)",0,7.5,Occupancy,,,,AchievedOccupancy,OPT,The difference between calculated theoretical (50.0%) and measured achieved occupancy (33.7%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy.,global,32.51
0,55561,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(4096, 4096, 1)",0,7.5,Occupancy,,,,TheoreticalOccupancy,OPT,The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared memory.,global,50.0
0,55561,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(4096, 4096, 1)",0,7.5,Source Counters,Branch Instructions Ratio,%,0.06,,,,,
0,55561,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(4096, 4096, 1)",0,7.5,Source Counters,Branch Instructions,inst,"16,777,216",,,,,
0,55561,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(4096, 4096, 1)",0,7.5,Source Counters,Branch Efficiency,%,0,,,,,
0,55561,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(4096, 4096, 1)",0,7.5,Source Counters,Avg. Divergent Branches,,0,,,,,
0,55664,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(2048, 2048, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Frequency,cycle/second,"5,996,926,875.44",,,,,
0,55664,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(2048, 2048, 1)",0,7.5,GPU Speed Of Light Throughput,SM Frequency,cycle/second,"1,394,317,112.21",,,,,
0,55664,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(2048, 2048, 1)",0,7.5,GPU Speed Of Light Throughput,Elapsed Cycles,cycle,"25,426,944",,,,,
0,55664,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(2048, 2048, 1)",0,7.5,GPU Speed Of Light Throughput,Memory Throughput,%,38.34,,,,,
0,55664,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(2048, 2048, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Throughput,%,38.34,,,,,
0,55664,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(2048, 2048, 1)",0,7.5,GPU Speed Of Light Throughput,Duration,nsecond,"18,222,496",,,,,
0,55664,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(2048, 2048, 1)",0,7.5,GPU Speed Of Light Throughput,L1/TEX Cache Throughput,%,19.62,,,,,
0,55664,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(2048, 2048, 1)",0,7.5,GPU Speed Of Light Throughput,L2 Cache Throughput,%,17.43,,,,,
0,55664,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(2048, 2048, 1)",0,7.5,GPU Speed Of Light Throughput,SM Active Cycles,cycle,"22,211,472.79",,,,,
0,55664,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(2048, 2048, 1)",0,7.5,GPU Speed Of Light Throughput,Compute (SM) Throughput,%,11.79,,,,,
0,55664,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(2048, 2048, 1)",0,7.5,SpeedOfLight,,,,SOLBottleneck,OPT,This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.,,
0,55664,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(2048, 2048, 1)",0,7.5,SpeedOfLight_RooflineChart,,,,SOLFPRoofline,INF,The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved  close to 0% of this device's fp32 peak performance and 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.,,
0,55664,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(2048, 2048, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Active,inst/cycle,0.23,,,,,
0,55664,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(2048, 2048, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Elapsed,inst/cycle,0.20,,,,,
0,55664,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(2048, 2048, 1)",0,7.5,Compute Workload Analysis,Issue Slots Busy,%,5.73,,,,,
0,55664,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(2048, 2048, 1)",0,7.5,Compute Workload Analysis,Issued Ipc Active,inst/cycle,0.23,,,,,
0,55664,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(2048, 2048, 1)",0,7.5,Compute Workload Analysis,SM Busy,%,6.29,,,,,
0,55664,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(2048, 2048, 1)",0,7.5,ComputeWorkloadAnalysis,,,,HighPipeUtilization,OPT,All compute pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.,local,95.28
0,55664,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(2048, 2048, 1)",0,7.5,Memory Workload Analysis,Memory Throughput,byte/second,"73,578,074,046.50",,,,,
0,55664,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(2048, 2048, 1)",0,7.5,Memory Workload Analysis,Mem Busy,%,13.07,,,,,
0,55664,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(2048, 2048, 1)",0,7.5,Memory Workload Analysis,Max Bandwidth,%,38.34,,,,,
0,55664,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(2048, 2048, 1)",0,7.5,Memory Workload Analysis,L1/TEX Hit Rate,%,0.04,,,,,
0,55664,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(2048, 2048, 1)",0,7.5,Memory Workload Analysis,L2 Hit Rate,%,33.34,,,,,
0,55664,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(2048, 2048, 1)",0,7.5,Memory Workload Analysis,Mem Pipes Busy,%,11.79,,,,,
0,55664,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(2048, 2048, 1)",0,7.5,MemoryWorkloadAnalysis_Chart,,,,MemoryL2Compression,WRN,The optional metric lts__average_gcomp_input_sector_success_rate.pct could not be found. Collecting it as an additional metric could enable the rule to provide more guidance.,,
0,55664,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(2048, 2048, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for loads from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced loads and try to minimize how many cache lines need to be accessed per memory request.",global,6.536
0,55664,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(2048, 2048, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for stores from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced stores and try to minimize how many cache lines need to be accessed per memory request.",global,3.268
0,55664,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(2048, 2048, 1)",0,7.5,Scheduler Statistics,One or More Eligible,%,6.33,,,,,
0,55664,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(2048, 2048, 1)",0,7.5,Scheduler Statistics,Issued Warp Per Scheduler,,0.06,,,,,
0,55664,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(2048, 2048, 1)",0,7.5,Scheduler Statistics,No Eligible,%,93.67,,,,,
0,55664,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(2048, 2048, 1)",0,7.5,Scheduler Statistics,Active Warps Per Scheduler,warp,3.00,,,,,
0,55664,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(2048, 2048, 1)",0,7.5,Scheduler Statistics,Eligible Warps Per Scheduler,warp,0.07,,,,,
0,55664,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(2048, 2048, 1)",0,7.5,SchedulerStats,,,,IssueSlotUtilization,OPT,"Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 15.8 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of 3.00 active warps per scheduler, but only an average of 0.07 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections.",local,61.66
0,55664,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(2048, 2048, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Issued Instruction,cycle,47.34,,,,,
0,55664,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(2048, 2048, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Executed Instruction,cycle,47.34,,,,,
0,55664,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(2048, 2048, 1)",0,7.5,Warp State Statistics,Avg. Active Threads Per Warp,,4,,,,,
0,55664,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(2048, 2048, 1)",0,7.5,Warp State Statistics,Avg. Not Predicated Off Threads Per Warp,,4,,,,,
0,55664,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(2048, 2048, 1)",0,7.5,WarpStateStats,,,,CPIStall,OPT,"On average, each warp of this kernel spends 40.1 cycles being stalled waiting for a scoreboard dependency on a L1TEX (local, global, surface, texture) operation. Find the instruction producing the data being waited upon to identify the culprit. To reduce the number of cycles waiting on L1TEX data accesses verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit rates by increasing data locality (coalescing), or by changing the cache configuration. Consider moving frequently used data to shared memory. This stall type represents about 84.8% of the total average of 47.3 cycles between issuing two instructions.",global,61.66
0,55664,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(2048, 2048, 1)",0,7.5,WarpStateStats,,,,CPIStall,INF,Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.,,
0,55664,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(2048, 2048, 1)",0,7.5,WarpStateStats,,,,ThreadDivergence,OPT,"Instructions are executed in warps, which are groups of 32 threads. Optimal instruction throughput is achieved if all 32 threads of a warp execute the same instruction. The chosen launch configuration, early thread completion, and divergent flow control can significantly lower the number of active threads in a warp per cycle. This kernel achieves an average of 4.0 threads being active per cycle.",global,10.32
0,55664,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(2048, 2048, 1)",0,7.5,Instruction Statistics,Avg. Executed Instructions Per Scheduler,inst,"1,273,270.86",,,,,
0,55664,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(2048, 2048, 1)",0,7.5,Instruction Statistics,Executed Instructions,inst,"71,303,168",,,,,
0,55664,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(2048, 2048, 1)",0,7.5,Instruction Statistics,Avg. Issued Instructions Per Scheduler,inst,"1,273,284.55",,,,,
0,55664,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(2048, 2048, 1)",0,7.5,Instruction Statistics,Issued Instructions,inst,"71,303,935",,,,,
0,55664,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(2048, 2048, 1)",0,7.5,InstructionStats,,,,FPInstructions,OPT,"This kernel executes 0 fused and 4194304 non-fused FP32 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP32 performance could be increased by up to 50% (relative to its current performance). Check the Source page to identify where this kernel executes FP32 instructions.",global,2.36
0,55664,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(2048, 2048, 1)",0,7.5,Launch Statistics,Block Size,,4,,,,,
0,55664,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(2048, 2048, 1)",0,7.5,Launch Statistics,Function Cache Configuration,,CachePreferNone,,,,,
0,55664,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(2048, 2048, 1)",0,7.5,Launch Statistics,Grid Size,,"4,194,304",,,,,
0,55664,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(2048, 2048, 1)",0,7.5,Launch Statistics,Registers Per Thread,register/thread,16,,,,,
0,55664,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(2048, 2048, 1)",0,7.5,Launch Statistics,Shared Memory Configuration Size,byte,"32,768",,,,,
0,55664,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(2048, 2048, 1)",0,7.5,Launch Statistics,Driver Shared Memory Per Block,byte/block,0,,,,,
0,55664,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(2048, 2048, 1)",0,7.5,Launch Statistics,Dynamic Shared Memory Per Block,byte/block,0,,,,,
0,55664,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(2048, 2048, 1)",0,7.5,Launch Statistics,Static Shared Memory Per Block,byte/block,0,,,,,
0,55664,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(2048, 2048, 1)",0,7.5,Launch Statistics,Threads,thread,"16,777,216",,,,,
0,55664,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(2048, 2048, 1)",0,7.5,Launch Statistics,Waves Per SM,,"18,724.57",,,,,
0,55664,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(2048, 2048, 1)",0,7.5,LaunchStats,,,,LaunchConfiguration,OPT,"Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 4 threads per block. Consequently, some threads in a warp are masked off and those hardware resources are unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256 threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to kernels that frequently call __syncthreads(). See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations.",global,87.5
0,55664,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(2048, 2048, 1)",0,7.5,Occupancy,Block Limit SM,block,16,,,,,
0,55664,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(2048, 2048, 1)",0,7.5,Occupancy,Block Limit Registers,block,128,,,,,
0,55664,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(2048, 2048, 1)",0,7.5,Occupancy,Block Limit Shared Mem,block,16,,,,,
0,55664,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(2048, 2048, 1)",0,7.5,Occupancy,Block Limit Warps,block,32,,,,,
0,55664,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(2048, 2048, 1)",0,7.5,Occupancy,Theoretical Active Warps per SM,warp,16,,,,,
0,55664,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(2048, 2048, 1)",0,7.5,Occupancy,Theoretical Occupancy,%,50,,,,,
0,55664,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(2048, 2048, 1)",0,7.5,Occupancy,Achieved Occupancy,%,34.69,,,,,
0,55664,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(2048, 2048, 1)",0,7.5,Occupancy,Achieved Active Warps Per SM,warp,11.10,,,,,
0,55664,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(2048, 2048, 1)",0,7.5,Occupancy,,,,AchievedOccupancy,OPT,The difference between calculated theoretical (50.0%) and measured achieved occupancy (34.7%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy.,global,30.63
0,55664,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(2048, 2048, 1)",0,7.5,Occupancy,,,,TheoreticalOccupancy,OPT,The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared memory.,global,50.0
0,55664,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(2048, 2048, 1)",0,7.5,Source Counters,Branch Instructions Ratio,%,0.06,,,,,
0,55664,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(2048, 2048, 1)",0,7.5,Source Counters,Branch Instructions,inst,"4,194,304",,,,,
0,55664,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(2048, 2048, 1)",0,7.5,Source Counters,Branch Efficiency,%,0,,,,,
0,55664,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(2048, 2048, 1)",0,7.5,Source Counters,Avg. Divergent Branches,,0,,,,,
0,55664,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(2048, 2048, 1)",0,7.5,SourceCounters,,,,UncoalescedGlobalAccess,OPT,This kernel has uncoalesced global accesses resulting in a total of 12582912 excessive sectors (50% of the total 25165824 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source locations. The CUDA Programming Guide (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) has additional information on reducing uncoalesced device memory accesses.,global,50.0
0,55750,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(1024, 1024, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Frequency,cycle/second,"5,994,083,761.48",,,,,
0,55750,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(1024, 1024, 1)",0,7.5,GPU Speed Of Light Throughput,SM Frequency,cycle/second,"1,377,448,128.66",,,,,
0,55750,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(1024, 1024, 1)",0,7.5,GPU Speed Of Light Throughput,Elapsed Cycles,cycle,"7,945,578",,,,,
0,55750,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(1024, 1024, 1)",0,7.5,GPU Speed Of Light Throughput,Memory Throughput,%,56.68,,,,,
0,55750,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(1024, 1024, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Throughput,%,56.68,,,,,
0,55750,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(1024, 1024, 1)",0,7.5,GPU Speed Of Light Throughput,Duration,nsecond,"5,755,008",,,,,
0,55750,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(1024, 1024, 1)",0,7.5,GPU Speed Of Light Throughput,L1/TEX Cache Throughput,%,30.22,,,,,
0,55750,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(1024, 1024, 1)",0,7.5,GPU Speed Of Light Throughput,L2 Cache Throughput,%,27.61,,,,,
0,55750,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(1024, 1024, 1)",0,7.5,GPU Speed Of Light Throughput,SM Active Cycles,cycle,"8,016,238.79",,,,,
0,55750,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(1024, 1024, 1)",0,7.5,GPU Speed Of Light Throughput,Compute (SM) Throughput,%,9.45,,,,,
0,55750,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(1024, 1024, 1)",0,7.5,SpeedOfLight,,,,SOLBottleneck,OPT,This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.,,
0,55750,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(1024, 1024, 1)",0,7.5,SpeedOfLight_RooflineChart,,,,SOLFPRoofline,INF,The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved  close to 0% of this device's fp32 peak performance and 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.,,
0,55750,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(1024, 1024, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Active,inst/cycle,0.16,,,,,
0,55750,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(1024, 1024, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Elapsed,inst/cycle,0.16,,,,,
0,55750,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(1024, 1024, 1)",0,7.5,Compute Workload Analysis,Issue Slots Busy,%,3.97,,,,,
0,55750,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(1024, 1024, 1)",0,7.5,Compute Workload Analysis,Issued Ipc Active,inst/cycle,0.16,,,,,
0,55750,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(1024, 1024, 1)",0,7.5,Compute Workload Analysis,SM Busy,%,4.36,,,,,
0,55750,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(1024, 1024, 1)",0,7.5,ComputeWorkloadAnalysis,,,,HighPipeUtilization,OPT,All compute pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.,local,96.73
0,55750,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(1024, 1024, 1)",0,7.5,Memory Workload Analysis,Memory Throughput,byte/second,"108,715,686,928.67",,,,,
0,55750,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(1024, 1024, 1)",0,7.5,Memory Workload Analysis,Mem Busy,%,20.73,,,,,
0,55750,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(1024, 1024, 1)",0,7.5,Memory Workload Analysis,Max Bandwidth,%,56.68,,,,,
0,55750,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(1024, 1024, 1)",0,7.5,Memory Workload Analysis,L1/TEX Hit Rate,%,0.03,,,,,
0,55750,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(1024, 1024, 1)",0,7.5,Memory Workload Analysis,L2 Hit Rate,%,33.34,,,,,
0,55750,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(1024, 1024, 1)",0,7.5,Memory Workload Analysis,Mem Pipes Busy,%,9.45,,,,,
0,55750,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(1024, 1024, 1)",0,7.5,MemoryWorkloadAnalysis_Chart,,,,MemoryL2Compression,WRN,The optional metric lts__average_gcomp_input_sector_success_rate.pct could not be found. Collecting it as an additional metric could enable the rule to provide more guidance.,,
0,55750,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(1024, 1024, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for loads from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced loads and try to minimize how many cache lines need to be accessed per memory request.",global,10.36
0,55750,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(1024, 1024, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for stores from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced stores and try to minimize how many cache lines need to be accessed per memory request.",global,5.179
0,55750,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(1024, 1024, 1)",0,7.5,Scheduler Statistics,One or More Eligible,%,4.04,,,,,
0,55750,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(1024, 1024, 1)",0,7.5,Scheduler Statistics,Issued Warp Per Scheduler,,0.04,,,,,
0,55750,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(1024, 1024, 1)",0,7.5,Scheduler Statistics,No Eligible,%,95.96,,,,,
0,55750,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(1024, 1024, 1)",0,7.5,Scheduler Statistics,Active Warps Per Scheduler,warp,3.53,,,,,
0,55750,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(1024, 1024, 1)",0,7.5,Scheduler Statistics,Eligible Warps Per Scheduler,warp,0.04,,,,,
0,55750,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(1024, 1024, 1)",0,7.5,SchedulerStats,,,,IssueSlotUtilization,OPT,"Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 24.7 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of 3.53 active warps per scheduler, but only an average of 0.04 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, avoid possible load imbalances due to highly different execution durations per warp. Reducing stalls indicated on the Warp State Statistics and Source Counters sections can help, too.",local,43.32
0,55750,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(1024, 1024, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Issued Instruction,cycle,87.45,,,,,
0,55750,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(1024, 1024, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Executed Instruction,cycle,87.46,,,,,
0,55750,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(1024, 1024, 1)",0,7.5,Warp State Statistics,Avg. Active Threads Per Warp,,16,,,,,
0,55750,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(1024, 1024, 1)",0,7.5,Warp State Statistics,Avg. Not Predicated Off Threads Per Warp,,16,,,,,
0,55750,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(1024, 1024, 1)",0,7.5,WarpStateStats,,,,CPIStall,OPT,"On average, each warp of this kernel spends 79.9 cycles being stalled waiting for a scoreboard dependency on a L1TEX (local, global, surface, texture) operation. Find the instruction producing the data being waited upon to identify the culprit. To reduce the number of cycles waiting on L1TEX data accesses verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit rates by increasing data locality (coalescing), or by changing the cache configuration. Consider moving frequently used data to shared memory. This stall type represents about 91.4% of the total average of 87.5 cycles between issuing two instructions.",global,43.32
0,55750,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(1024, 1024, 1)",0,7.5,WarpStateStats,,,,CPIStall,INF,Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.,,
0,55750,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(1024, 1024, 1)",0,7.5,WarpStateStats,,,,ThreadDivergence,OPT,"Instructions are executed in warps, which are groups of 32 threads. Optimal instruction throughput is achieved if all 32 threads of a warp execute the same instruction. The chosen launch configuration, early thread completion, and divergent flow control can significantly lower the number of active threads in a warp per cycle. This kernel achieves an average of 16.0 threads being active per cycle.",global,4.723
0,55750,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(1024, 1024, 1)",0,7.5,Instruction Statistics,Avg. Executed Instructions Per Scheduler,inst,"318,317.71",,,,,
0,55750,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(1024, 1024, 1)",0,7.5,Instruction Statistics,Executed Instructions,inst,"17,825,792",,,,,
0,55750,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(1024, 1024, 1)",0,7.5,Instruction Statistics,Avg. Issued Instructions Per Scheduler,inst,"318,331.41",,,,,
0,55750,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(1024, 1024, 1)",0,7.5,Instruction Statistics,Issued Instructions,inst,"17,826,559",,,,,
0,55750,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(1024, 1024, 1)",0,7.5,InstructionStats,,,,FPInstructions,OPT,"This kernel executes 0 fused and 1048576 non-fused FP32 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP32 performance could be increased by up to 50% (relative to its current performance). Check the Source page to identify where this kernel executes FP32 instructions.",global,1.635
0,55750,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(1024, 1024, 1)",0,7.5,Launch Statistics,Block Size,,16,,,,,
0,55750,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(1024, 1024, 1)",0,7.5,Launch Statistics,Function Cache Configuration,,CachePreferNone,,,,,
0,55750,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(1024, 1024, 1)",0,7.5,Launch Statistics,Grid Size,,"1,048,576",,,,,
0,55750,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(1024, 1024, 1)",0,7.5,Launch Statistics,Registers Per Thread,register/thread,16,,,,,
0,55750,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(1024, 1024, 1)",0,7.5,Launch Statistics,Shared Memory Configuration Size,byte,"32,768",,,,,
0,55750,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(1024, 1024, 1)",0,7.5,Launch Statistics,Driver Shared Memory Per Block,byte/block,0,,,,,
0,55750,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(1024, 1024, 1)",0,7.5,Launch Statistics,Dynamic Shared Memory Per Block,byte/block,0,,,,,
0,55750,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(1024, 1024, 1)",0,7.5,Launch Statistics,Static Shared Memory Per Block,byte/block,0,,,,,
0,55750,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(1024, 1024, 1)",0,7.5,Launch Statistics,Threads,thread,"16,777,216",,,,,
0,55750,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(1024, 1024, 1)",0,7.5,Launch Statistics,Waves Per SM,,"4,681.14",,,,,
0,55750,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(1024, 1024, 1)",0,7.5,LaunchStats,,,,LaunchConfiguration,OPT,"Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 16 threads per block. Consequently, some threads in a warp are masked off and those hardware resources are unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256 threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to kernels that frequently call __syncthreads(). See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations.",global,50.0
0,55750,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(1024, 1024, 1)",0,7.5,Occupancy,Block Limit SM,block,16,,,,,
0,55750,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(1024, 1024, 1)",0,7.5,Occupancy,Block Limit Registers,block,128,,,,,
0,55750,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(1024, 1024, 1)",0,7.5,Occupancy,Block Limit Shared Mem,block,16,,,,,
0,55750,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(1024, 1024, 1)",0,7.5,Occupancy,Block Limit Warps,block,32,,,,,
0,55750,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(1024, 1024, 1)",0,7.5,Occupancy,Theoretical Active Warps per SM,warp,16,,,,,
0,55750,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(1024, 1024, 1)",0,7.5,Occupancy,Theoretical Occupancy,%,50,,,,,
0,55750,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(1024, 1024, 1)",0,7.5,Occupancy,Achieved Occupancy,%,43.92,,,,,
0,55750,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(1024, 1024, 1)",0,7.5,Occupancy,Achieved Active Warps Per SM,warp,14.05,,,,,
0,55750,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(1024, 1024, 1)",0,7.5,Occupancy,,,,TheoreticalOccupancy,OPT,The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared memory.,global,43.32
0,55750,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(1024, 1024, 1)",0,7.5,Source Counters,Branch Instructions Ratio,%,0.06,,,,,
0,55750,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(1024, 1024, 1)",0,7.5,Source Counters,Branch Instructions,inst,"1,048,576",,,,,
0,55750,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(1024, 1024, 1)",0,7.5,Source Counters,Branch Efficiency,%,0,,,,,
0,55750,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(1024, 1024, 1)",0,7.5,Source Counters,Avg. Divergent Branches,,0,,,,,
0,55750,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(1024, 1024, 1)",0,7.5,SourceCounters,,,,UncoalescedGlobalAccess,OPT,This kernel has uncoalesced global accesses resulting in a total of 6291456 excessive sectors (50% of the total 12582912 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source locations. The CUDA Programming Guide (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) has additional information on reducing uncoalesced device memory accesses.,global,50.05
0,55834,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(512, 512, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Frequency,cycle/second,"5,959,529,328.85",,,,,
0,55834,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(512, 512, 1)",0,7.5,GPU Speed Of Light Throughput,SM Frequency,cycle/second,"1,369,781,313.84",,,,,
0,55834,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(512, 512, 1)",0,7.5,GPU Speed Of Light Throughput,Elapsed Cycles,cycle,"7,976,680",,,,,
0,55834,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(512, 512, 1)",0,7.5,GPU Speed Of Light Throughput,Memory Throughput,%,30.27,,,,,
0,55834,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(512, 512, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Throughput,%,30.27,,,,,
0,55834,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(512, 512, 1)",0,7.5,GPU Speed Of Light Throughput,Duration,nsecond,"5,811,616",,,,,
0,55834,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(512, 512, 1)",0,7.5,GPU Speed Of Light Throughput,L1/TEX Cache Throughput,%,25.14,,,,,
0,55834,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(512, 512, 1)",0,7.5,GPU Speed Of Light Throughput,L2 Cache Throughput,%,15.33,,,,,
0,55834,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(512, 512, 1)",0,7.5,GPU Speed Of Light Throughput,SM Active Cycles,cycle,"7,926,185.07",,,,,
0,55834,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(512, 512, 1)",0,7.5,GPU Speed Of Light Throughput,Compute (SM) Throughput,%,4.70,,,,,
0,55834,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(512, 512, 1)",0,7.5,SpeedOfLight,,,,SOLBottleneck,OPT,This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.,,
0,55834,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(512, 512, 1)",0,7.5,SpeedOfLight_RooflineChart,,,,SOLFPRoofline,INF,The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved  close to 0% of this device's fp32 peak performance and 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.,,
0,55834,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(512, 512, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Active,inst/cycle,0.08,,,,,
0,55834,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(512, 512, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Elapsed,inst/cycle,0.08,,,,,
0,55834,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(512, 512, 1)",0,7.5,Compute Workload Analysis,Issue Slots Busy,%,2.01,,,,,
0,55834,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(512, 512, 1)",0,7.5,Compute Workload Analysis,Issued Ipc Active,inst/cycle,0.08,,,,,
0,55834,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(512, 512, 1)",0,7.5,Compute Workload Analysis,SM Busy,%,2.20,,,,,
0,55834,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(512, 512, 1)",0,7.5,ComputeWorkloadAnalysis,,,,HighPipeUtilization,OPT,All compute pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.,local,98.35
0,55834,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(512, 512, 1)",0,7.5,Memory Workload Analysis,Memory Throughput,byte/second,"57,719,959,474.27",,,,,
0,55834,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(512, 512, 1)",0,7.5,Memory Workload Analysis,Mem Busy,%,15.33,,,,,
0,55834,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(512, 512, 1)",0,7.5,Memory Workload Analysis,Max Bandwidth,%,30.27,,,,,
0,55834,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(512, 512, 1)",0,7.5,Memory Workload Analysis,L1/TEX Hit Rate,%,50.01,,,,,
0,55834,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(512, 512, 1)",0,7.5,Memory Workload Analysis,L2 Hit Rate,%,35.36,,,,,
0,55834,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(512, 512, 1)",0,7.5,Memory Workload Analysis,Mem Pipes Busy,%,4.70,,,,,
0,55834,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(512, 512, 1)",0,7.5,MemoryWorkloadAnalysis_Chart,,,,MemoryL2Compression,WRN,The optional metric lts__average_gcomp_input_sector_success_rate.pct could not be found. Collecting it as an additional metric could enable the rule to provide more guidance.,,
0,55834,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(512, 512, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for global loads in L1TEX might not be optimal. On average, this kernel accesses 4.0 bytes per thread per memory request; but the address pattern, possibly caused by the stride between threads, results in 8.0 sectors per request, or 8.0*32 = 256.0 bytes of cache data transfers per request. The optimal thread address pattern for 4.0 byte accesses would result in 4.0*32 = 128.0 bytes of cache data transfers per request, to maximize L1TEX cache performance. Check the Source Counters section for uncoalesced global loads.",global,0.3527
0,55834,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(512, 512, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for global stores in L1TEX might not be optimal. On average, this kernel accesses 4.0 bytes per thread per memory request; but the address pattern, possibly caused by the stride between threads, results in 8.0 sectors per request, or 8.0*32 = 256.0 bytes of cache data transfers per request. The optimal thread address pattern for 4.0 byte accesses would result in 4.0*32 = 128.0 bytes of cache data transfers per request, to maximize L1TEX cache performance. Check the Source Counters section for uncoalesced global stores.",global,0.3527
0,55834,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(512, 512, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for loads from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced loads and try to minimize how many cache lines need to be accessed per memory request.",global,5.16
0,55834,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(512, 512, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for stores from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced stores and try to minimize how many cache lines need to be accessed per memory request.",global,2.835
0,55834,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(512, 512, 1)",0,7.5,Scheduler Statistics,One or More Eligible,%,1.99,,,,,
0,55834,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(512, 512, 1)",0,7.5,Scheduler Statistics,Issued Warp Per Scheduler,,0.02,,,,,
0,55834,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(512, 512, 1)",0,7.5,Scheduler Statistics,No Eligible,%,98.01,,,,,
0,55834,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(512, 512, 1)",0,7.5,Scheduler Statistics,Active Warps Per Scheduler,warp,7.84,,,,,
0,55834,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(512, 512, 1)",0,7.5,Scheduler Statistics,Eligible Warps Per Scheduler,warp,0.02,,,,,
0,55834,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(512, 512, 1)",0,7.5,SchedulerStats,,,,IssueSlotUtilization,OPT,"Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 50.2 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of 7.84 active warps per scheduler, but only an average of 0.02 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, avoid possible load imbalances due to highly different execution durations per warp. Reducing stalls indicated on the Warp State Statistics and Source Counters sections can help, too.",local,69.73
0,55834,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(512, 512, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Issued Instruction,cycle,393.53,,,,,
0,55834,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(512, 512, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Executed Instruction,cycle,393.59,,,,,
0,55834,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(512, 512, 1)",0,7.5,Warp State Statistics,Avg. Active Threads Per Warp,,32,,,,,
0,55834,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(512, 512, 1)",0,7.5,Warp State Statistics,Avg. Not Predicated Off Threads Per Warp,,32,,,,,
0,55834,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(512, 512, 1)",0,7.5,WarpStateStats,,,,CPIStall,OPT,"On average, each warp of this kernel spends 383.3 cycles being stalled waiting for a scoreboard dependency on a L1TEX (local, global, surface, texture) operation. Find the instruction producing the data being waited upon to identify the culprit. To reduce the number of cycles waiting on L1TEX data accesses verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit rates by increasing data locality (coalescing), or by changing the cache configuration. Consider moving frequently used data to shared memory. This stall type represents about 97.4% of the total average of 393.5 cycles between issuing two instructions.",global,69.73
0,55834,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(512, 512, 1)",0,7.5,WarpStateStats,,,,CPIStall,INF,Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.,,
0,55834,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(512, 512, 1)",0,7.5,Instruction Statistics,Avg. Executed Instructions Per Scheduler,inst,"159,158.86",,,,,
0,55834,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(512, 512, 1)",0,7.5,Instruction Statistics,Executed Instructions,inst,"8,912,896",,,,,
0,55834,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(512, 512, 1)",0,7.5,Instruction Statistics,Avg. Issued Instructions Per Scheduler,inst,"159,184.05",,,,,
0,55834,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(512, 512, 1)",0,7.5,Instruction Statistics,Issued Instructions,inst,"8,914,307",,,,,
0,55834,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(512, 512, 1)",0,7.5,InstructionStats,,,,FPInstructions,OPT,"This kernel executes 0 fused and 524288 non-fused FP32 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP32 performance could be increased by up to 50% (relative to its current performance). Check the Source page to identify where this kernel executes FP32 instructions.",global,0.8268
0,55834,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(512, 512, 1)",0,7.5,Launch Statistics,Block Size,,64,,,,,
0,55834,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(512, 512, 1)",0,7.5,Launch Statistics,Function Cache Configuration,,CachePreferNone,,,,,
0,55834,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(512, 512, 1)",0,7.5,Launch Statistics,Grid Size,,"262,144",,,,,
0,55834,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(512, 512, 1)",0,7.5,Launch Statistics,Registers Per Thread,register/thread,16,,,,,
0,55834,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(512, 512, 1)",0,7.5,Launch Statistics,Shared Memory Configuration Size,byte,"32,768",,,,,
0,55834,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(512, 512, 1)",0,7.5,Launch Statistics,Driver Shared Memory Per Block,byte/block,0,,,,,
0,55834,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(512, 512, 1)",0,7.5,Launch Statistics,Dynamic Shared Memory Per Block,byte/block,0,,,,,
0,55834,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(512, 512, 1)",0,7.5,Launch Statistics,Static Shared Memory Per Block,byte/block,0,,,,,
0,55834,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(512, 512, 1)",0,7.5,Launch Statistics,Threads,thread,"16,777,216",,,,,
0,55834,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(512, 512, 1)",0,7.5,Launch Statistics,Waves Per SM,,"1,170.29",,,,,
0,55834,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(512, 512, 1)",0,7.5,Occupancy,Block Limit SM,block,16,,,,,
0,55834,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(512, 512, 1)",0,7.5,Occupancy,Block Limit Registers,block,64,,,,,
0,55834,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(512, 512, 1)",0,7.5,Occupancy,Block Limit Shared Mem,block,16,,,,,
0,55834,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(512, 512, 1)",0,7.5,Occupancy,Block Limit Warps,block,16,,,,,
0,55834,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(512, 512, 1)",0,7.5,Occupancy,Theoretical Active Warps per SM,warp,32,,,,,
0,55834,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(512, 512, 1)",0,7.5,Occupancy,Theoretical Occupancy,%,100,,,,,
0,55834,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(512, 512, 1)",0,7.5,Occupancy,Achieved Occupancy,%,97.66,,,,,
0,55834,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(512, 512, 1)",0,7.5,Occupancy,Achieved Active Warps Per SM,warp,31.25,,,,,
0,55834,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(512, 512, 1)",0,7.5,Source Counters,Branch Instructions Ratio,%,0.06,,,,,
0,55834,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(512, 512, 1)",0,7.5,Source Counters,Branch Instructions,inst,"524,288",,,,,
0,55834,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(512, 512, 1)",0,7.5,Source Counters,Branch Efficiency,%,0,,,,,
0,55834,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(512, 512, 1)",0,7.5,Source Counters,Avg. Divergent Branches,,0,,,,,
0,55834,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(512, 512, 1)",0,7.5,SourceCounters,,,,UncoalescedGlobalAccess,OPT,This kernel has uncoalesced global accesses resulting in a total of 6291456 excessive sectors (50% of the total 12582912 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source locations. The CUDA Programming Guide (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) has additional information on reducing uncoalesced device memory accesses.,global,49.23
0,55919,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(256, 256, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Frequency,cycle/second,"5,993,515,558.16",,,,,
0,55919,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(256, 256, 1)",0,7.5,GPU Speed Of Light Throughput,SM Frequency,cycle/second,"1,377,101,146.32",,,,,
0,55919,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(256, 256, 1)",0,7.5,GPU Speed Of Light Throughput,Elapsed Cycles,cycle,"3,923,132",,,,,
0,55919,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(256, 256, 1)",0,7.5,GPU Speed Of Light Throughput,Memory Throughput,%,64.60,,,,,
0,55919,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(256, 256, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Throughput,%,36.90,,,,,
0,55919,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(256, 256, 1)",0,7.5,GPU Speed Of Light Throughput,Duration,nsecond,"2,842,496",,,,,
0,55919,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(256, 256, 1)",0,7.5,GPU Speed Of Light Throughput,L1/TEX Cache Throughput,%,98.09,,,,,
0,55919,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(256, 256, 1)",0,7.5,GPU Speed Of Light Throughput,L2 Cache Throughput,%,64.60,,,,,
0,55919,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(256, 256, 1)",0,7.5,GPU Speed Of Light Throughput,SM Active Cycles,cycle,"3,918,574.07",,,,,
0,55919,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(256, 256, 1)",0,7.5,GPU Speed Of Light Throughput,Compute (SM) Throughput,%,9.56,,,,,
0,55919,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(256, 256, 1)",0,7.5,SpeedOfLight,,,,SOLBottleneck,OPT,Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the L2 bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or whether there are values you can (re)compute.,,
0,55919,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(256, 256, 1)",0,7.5,SpeedOfLight_RooflineChart,,,,SOLFPRoofline,INF,The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved  close to 0% of this device's fp32 peak performance and 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.,,
0,55919,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(256, 256, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Active,inst/cycle,0.16,,,,,
0,55919,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(256, 256, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Elapsed,inst/cycle,0.16,,,,,
0,55919,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(256, 256, 1)",0,7.5,Compute Workload Analysis,Issue Slots Busy,%,4.06,,,,,
0,55919,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(256, 256, 1)",0,7.5,Compute Workload Analysis,Issued Ipc Active,inst/cycle,0.16,,,,,
0,55919,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(256, 256, 1)",0,7.5,Compute Workload Analysis,SM Busy,%,4.46,,,,,
0,55919,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(256, 256, 1)",0,7.5,ComputeWorkloadAnalysis,,,,HighPipeUtilization,OPT,All compute pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.,local,96.66
0,55919,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(256, 256, 1)",0,7.5,Memory Workload Analysis,Memory Throughput,byte/second,"70,769,791,056.87",,,,,
0,55919,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(256, 256, 1)",0,7.5,Memory Workload Analysis,Mem Busy,%,49.05,,,,,
0,55919,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(256, 256, 1)",0,7.5,Memory Workload Analysis,Max Bandwidth,%,64.60,,,,,
0,55919,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(256, 256, 1)",0,7.5,Memory Workload Analysis,L1/TEX Hit Rate,%,79.17,,,,,
0,55919,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(256, 256, 1)",0,7.5,Memory Workload Analysis,L2 Hit Rate,%,82.15,,,,,
0,55919,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(256, 256, 1)",0,7.5,Memory Workload Analysis,Mem Pipes Busy,%,9.56,,,,,
0,55919,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(256, 256, 1)",0,7.5,MemoryWorkloadAnalysis_Chart,,,,MemoryL2Compression,WRN,The optional metric lts__average_gcomp_input_sector_success_rate.pct could not be found. Collecting it as an additional metric could enable the rule to provide more guidance.,,
0,55919,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(256, 256, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for global loads in L1TEX might not be optimal. On average, this kernel accesses 4.0 bytes per thread per memory request; but the address pattern, possibly caused by the stride between threads, results in 16.0 sectors per request, or 16.0*32 = 512.0 bytes of cache data transfers per request. The optimal thread address pattern for 4.0 byte accesses would result in 4.0*32 = 128.0 bytes of cache data transfers per request, to maximize L1TEX cache performance. Check the Source Counters section for uncoalesced global loads.",global,2.152
0,55919,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(256, 256, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for global stores in L1TEX might not be optimal. On average, this kernel accesses 4.0 bytes per thread per memory request; but the address pattern, possibly caused by the stride between threads, results in 16.0 sectors per request, or 16.0*32 = 512.0 bytes of cache data transfers per request. The optimal thread address pattern for 4.0 byte accesses would result in 4.0*32 = 128.0 bytes of cache data transfers per request, to maximize L1TEX cache performance. Check the Source Counters section for uncoalesced global stores.",global,2.152
0,55919,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(256, 256, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for loads from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced loads and try to minimize how many cache lines need to be accessed per memory request.",global,10.43
0,55919,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(256, 256, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for stores from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.1 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced stores and try to minimize how many cache lines need to be accessed per memory request.",global,19.4
0,55919,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(256, 256, 1)",0,7.5,Scheduler Statistics,One or More Eligible,%,4.07,,,,,
0,55919,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(256, 256, 1)",0,7.5,Scheduler Statistics,Issued Warp Per Scheduler,,0.04,,,,,
0,55919,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(256, 256, 1)",0,7.5,Scheduler Statistics,No Eligible,%,95.93,,,,,
0,55919,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(256, 256, 1)",0,7.5,Scheduler Statistics,Active Warps Per Scheduler,warp,6.47,,,,,
0,55919,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(256, 256, 1)",0,7.5,Scheduler Statistics,Eligible Warps Per Scheduler,warp,0.05,,,,,
0,55919,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(256, 256, 1)",0,7.5,SchedulerStats,,,,IssueSlotUtilization,OPT,"Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 24.6 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of 6.47 active warps per scheduler, but only an average of 0.05 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, avoid possible load imbalances due to highly different execution durations per warp. Reducing stalls indicated on the Warp State Statistics and Source Counters sections can help, too.",local,35.4
0,55919,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(256, 256, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Issued Instruction,cycle,159.14,,,,,
0,55919,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(256, 256, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Executed Instruction,cycle,159.17,,,,,
0,55919,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(256, 256, 1)",0,7.5,Warp State Statistics,Avg. Active Threads Per Warp,,32,,,,,
0,55919,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(256, 256, 1)",0,7.5,Warp State Statistics,Avg. Not Predicated Off Threads Per Warp,,32,,,,,
0,55919,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(256, 256, 1)",0,7.5,WarpStateStats,,,,CPIStall,OPT,"On average, each warp of this kernel spends 88.0 cycles being stalled waiting for a scoreboard dependency on a L1TEX (local, global, surface, texture) operation. Find the instruction producing the data being waited upon to identify the culprit. To reduce the number of cycles waiting on L1TEX data accesses verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit rates by increasing data locality (coalescing), or by changing the cache configuration. Consider moving frequently used data to shared memory. This stall type represents about 55.3% of the total average of 159.1 cycles between issuing two instructions.",global,35.4
0,55919,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(256, 256, 1)",0,7.5,WarpStateStats,,,,CPIStall,INF,Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.,,
0,55919,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(256, 256, 1)",0,7.5,Instruction Statistics,Avg. Executed Instructions Per Scheduler,inst,"159,158.86",,,,,
0,55919,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(256, 256, 1)",0,7.5,Instruction Statistics,Executed Instructions,inst,"8,912,896",,,,,
0,55919,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(256, 256, 1)",0,7.5,Instruction Statistics,Avg. Issued Instructions Per Scheduler,inst,"159,190.36",,,,,
0,55919,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(256, 256, 1)",0,7.5,Instruction Statistics,Issued Instructions,inst,"8,914,660",,,,,
0,55919,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(256, 256, 1)",0,7.5,InstructionStats,,,,FPInstructions,OPT,"This kernel executes 0 fused and 524288 non-fused FP32 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP32 performance could be increased by up to 50% (relative to its current performance). Check the Source page to identify where this kernel executes FP32 instructions.",global,1.672
0,55919,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(256, 256, 1)",0,7.5,Launch Statistics,Block Size,,256,,,,,
0,55919,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(256, 256, 1)",0,7.5,Launch Statistics,Function Cache Configuration,,CachePreferNone,,,,,
0,55919,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(256, 256, 1)",0,7.5,Launch Statistics,Grid Size,,"65,536",,,,,
0,55919,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(256, 256, 1)",0,7.5,Launch Statistics,Registers Per Thread,register/thread,16,,,,,
0,55919,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(256, 256, 1)",0,7.5,Launch Statistics,Shared Memory Configuration Size,byte,"32,768",,,,,
0,55919,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(256, 256, 1)",0,7.5,Launch Statistics,Driver Shared Memory Per Block,byte/block,0,,,,,
0,55919,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(256, 256, 1)",0,7.5,Launch Statistics,Dynamic Shared Memory Per Block,byte/block,0,,,,,
0,55919,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(256, 256, 1)",0,7.5,Launch Statistics,Static Shared Memory Per Block,byte/block,0,,,,,
0,55919,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(256, 256, 1)",0,7.5,Launch Statistics,Threads,thread,"16,777,216",,,,,
0,55919,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(256, 256, 1)",0,7.5,Launch Statistics,Waves Per SM,,"1,170.29",,,,,
0,55919,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(256, 256, 1)",0,7.5,Occupancy,Block Limit SM,block,16,,,,,
0,55919,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(256, 256, 1)",0,7.5,Occupancy,Block Limit Registers,block,16,,,,,
0,55919,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(256, 256, 1)",0,7.5,Occupancy,Block Limit Shared Mem,block,16,,,,,
0,55919,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(256, 256, 1)",0,7.5,Occupancy,Block Limit Warps,block,4,,,,,
0,55919,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(256, 256, 1)",0,7.5,Occupancy,Theoretical Active Warps per SM,warp,32,,,,,
0,55919,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(256, 256, 1)",0,7.5,Occupancy,Theoretical Occupancy,%,100,,,,,
0,55919,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(256, 256, 1)",0,7.5,Occupancy,Achieved Occupancy,%,81.45,,,,,
0,55919,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(256, 256, 1)",0,7.5,Occupancy,Achieved Active Warps Per SM,warp,26.06,,,,,
0,55919,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(256, 256, 1)",0,7.5,Occupancy,,,,AchievedOccupancy,OPT,The difference between calculated theoretical (100.0%) and measured achieved occupancy (81.4%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy.,global,18.55
0,55919,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(256, 256, 1)",0,7.5,Source Counters,Branch Instructions Ratio,%,0.06,,,,,
0,55919,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(256, 256, 1)",0,7.5,Source Counters,Branch Instructions,inst,"524,288",,,,,
0,55919,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(256, 256, 1)",0,7.5,Source Counters,Branch Efficiency,%,0,,,,,
0,55919,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(256, 256, 1)",0,7.5,Source Counters,Avg. Divergent Branches,,0,,,,,
0,55919,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(256, 256, 1)",0,7.5,SourceCounters,,,,UncoalescedGlobalAccess,OPT,This kernel has uncoalesced global accesses resulting in a total of 18874368 excessive sectors (75% of the total 25165824 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source locations. The CUDA Programming Guide (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) has additional information on reducing uncoalesced device memory accesses.,global,74.93
0,56005,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(128, 128, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Frequency,cycle/second,"5,965,278,216.72",,,,,
0,56005,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(128, 128, 1)",0,7.5,GPU Speed Of Light Throughput,SM Frequency,cycle/second,"1,370,713,190.41",,,,,
0,56005,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(128, 128, 1)",0,7.5,GPU Speed Of Light Throughput,Elapsed Cycles,cycle,"8,341,471",,,,,
0,56005,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(128, 128, 1)",0,7.5,GPU Speed Of Light Throughput,Memory Throughput,%,59.06,,,,,
0,56005,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(128, 128, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Throughput,%,17.33,,,,,
0,56005,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(128, 128, 1)",0,7.5,GPU Speed Of Light Throughput,Duration,nsecond,"6,075,264",,,,,
0,56005,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(128, 128, 1)",0,7.5,GPU Speed Of Light Throughput,L1/TEX Cache Throughput,%,88.15,,,,,
0,56005,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(128, 128, 1)",0,7.5,GPU Speed Of Light Throughput,L2 Cache Throughput,%,59.06,,,,,
0,56005,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(128, 128, 1)",0,7.5,GPU Speed Of Light Throughput,SM Active Cycles,cycle,"8,138,349.50",,,,,
0,56005,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(128, 128, 1)",0,7.5,GPU Speed Of Light Throughput,Compute (SM) Throughput,%,4.50,,,,,
0,56005,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(128, 128, 1)",0,7.5,SpeedOfLight,,,,SOLBottleneck,OPT,This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.,,
0,56005,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(128, 128, 1)",0,7.5,SpeedOfLight_RooflineChart,,,,SOLFPRoofline,INF,The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved  close to 0% of this device's fp32 peak performance and 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.,,
0,56005,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(128, 128, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Active,inst/cycle,0.08,,,,,
0,56005,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(128, 128, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Elapsed,inst/cycle,0.08,,,,,
0,56005,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(128, 128, 1)",0,7.5,Compute Workload Analysis,Issue Slots Busy,%,1.96,,,,,
0,56005,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(128, 128, 1)",0,7.5,Compute Workload Analysis,Issued Ipc Active,inst/cycle,0.08,,,,,
0,56005,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(128, 128, 1)",0,7.5,Compute Workload Analysis,SM Busy,%,2.15,,,,,
0,56005,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(128, 128, 1)",0,7.5,ComputeWorkloadAnalysis,,,,HighPipeUtilization,OPT,All compute pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.,local,98.39
0,56005,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(128, 128, 1)",0,7.5,Memory Workload Analysis,Memory Throughput,byte/second,"33,087,378,589.64",,,,,
0,56005,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(128, 128, 1)",0,7.5,Memory Workload Analysis,Mem Busy,%,44.08,,,,,
0,56005,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(128, 128, 1)",0,7.5,Memory Workload Analysis,Max Bandwidth,%,59.06,,,,,
0,56005,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(128, 128, 1)",0,7.5,Memory Workload Analysis,L1/TEX Hit Rate,%,90.62,,,,,
0,56005,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(128, 128, 1)",0,7.5,Memory Workload Analysis,L2 Hit Rate,%,90.00,,,,,
0,56005,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(128, 128, 1)",0,7.5,Memory Workload Analysis,Mem Pipes Busy,%,4.50,,,,,
0,56005,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(128, 128, 1)",0,7.5,MemoryWorkloadAnalysis_Chart,,,,MemoryL2Compression,WRN,The optional metric lts__average_gcomp_input_sector_success_rate.pct could not be found. Collecting it as an additional metric could enable the rule to provide more guidance.,,
0,56005,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(128, 128, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for global loads in L1TEX might not be optimal. On average, this kernel accesses 4.0 bytes per thread per memory request; but the address pattern, possibly caused by the stride between threads, results in 32.0 sectors per request, or 32.0*32 = 1024.0 bytes of cache data transfers per request. The optimal thread address pattern for 4.0 byte accesses would result in 4.0*32 = 128.0 bytes of cache data transfers per request, to maximize L1TEX cache performance. Check the Source Counters section for uncoalesced global loads.",global,2.36
0,56005,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(128, 128, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for global stores in L1TEX might not be optimal. On average, this kernel accesses 4.0 bytes per thread per memory request; but the address pattern, possibly caused by the stride between threads, results in 32.0 sectors per request, or 32.0*32 = 1024.0 bytes of cache data transfers per request. The optimal thread address pattern for 4.0 byte accesses would result in 4.0*32 = 128.0 bytes of cache data transfers per request, to maximize L1TEX cache performance. Check the Source Counters section for uncoalesced global stores.",global,2.36
0,56005,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(128, 128, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for loads from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced loads and try to minimize how many cache lines need to be accessed per memory request.",global,4.934
0,56005,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(128, 128, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for stores from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced stores and try to minimize how many cache lines need to be accessed per memory request.",global,19.73
0,56005,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(128, 128, 1)",0,7.5,Scheduler Statistics,One or More Eligible,%,2.06,,,,,
0,56005,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(128, 128, 1)",0,7.5,Scheduler Statistics,Issued Warp Per Scheduler,,0.02,,,,,
0,56005,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(128, 128, 1)",0,7.5,Scheduler Statistics,No Eligible,%,97.94,,,,,
0,56005,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(128, 128, 1)",0,7.5,Scheduler Statistics,Active Warps Per Scheduler,warp,6.21,,,,,
0,56005,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(128, 128, 1)",0,7.5,Scheduler Statistics,Eligible Warps Per Scheduler,warp,0.04,,,,,
0,56005,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(128, 128, 1)",0,7.5,SchedulerStats,,,,IssueSlotUtilization,OPT,"Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 48.5 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of 6.21 active warps per scheduler, but only an average of 0.04 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections.",local,40.94
0,56005,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(128, 128, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Issued Instruction,cycle,301.12,,,,,
0,56005,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(128, 128, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Executed Instruction,cycle,301.18,,,,,
0,56005,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(128, 128, 1)",0,7.5,Warp State Statistics,Avg. Active Threads Per Warp,,32,,,,,
0,56005,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(128, 128, 1)",0,7.5,Warp State Statistics,Avg. Not Predicated Off Threads Per Warp,,32,,,,,
0,56005,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(128, 128, 1)",0,7.5,WarpStateStats,,,,CPIStall,OPT,"On average, each warp of this kernel spends 178.9 cycles being stalled waiting for a scoreboard dependency on a L1TEX (local, global, surface, texture) operation. Find the instruction producing the data being waited upon to identify the culprit. To reduce the number of cycles waiting on L1TEX data accesses verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit rates by increasing data locality (coalescing), or by changing the cache configuration. Consider moving frequently used data to shared memory. This stall type represents about 59.4% of the total average of 301.1 cycles between issuing two instructions.",global,40.94
0,56005,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(128, 128, 1)",0,7.5,WarpStateStats,,,,CPIStall,INF,Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.,,
0,56005,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(128, 128, 1)",0,7.5,Instruction Statistics,Avg. Executed Instructions Per Scheduler,inst,"159,158.86",,,,,
0,56005,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(128, 128, 1)",0,7.5,Instruction Statistics,Executed Instructions,inst,"8,912,896",,,,,
0,56005,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(128, 128, 1)",0,7.5,Instruction Statistics,Avg. Issued Instructions Per Scheduler,inst,"159,190.86",,,,,
0,56005,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(128, 128, 1)",0,7.5,Instruction Statistics,Issued Instructions,inst,"8,914,688",,,,,
0,56005,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(128, 128, 1)",0,7.5,InstructionStats,,,,FPInstructions,OPT,"This kernel executes 0 fused and 524288 non-fused FP32 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP32 performance could be increased by up to 50% (relative to its current performance). Check the Source page to identify where this kernel executes FP32 instructions.",global,0.8053
0,56005,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(128, 128, 1)",0,7.5,Launch Statistics,Block Size,,"1,024",,,,,
0,56005,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(128, 128, 1)",0,7.5,Launch Statistics,Function Cache Configuration,,CachePreferNone,,,,,
0,56005,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(128, 128, 1)",0,7.5,Launch Statistics,Grid Size,,"16,384",,,,,
0,56005,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(128, 128, 1)",0,7.5,Launch Statistics,Registers Per Thread,register/thread,16,,,,,
0,56005,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(128, 128, 1)",0,7.5,Launch Statistics,Shared Memory Configuration Size,byte,"32,768",,,,,
0,56005,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(128, 128, 1)",0,7.5,Launch Statistics,Driver Shared Memory Per Block,byte/block,0,,,,,
0,56005,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(128, 128, 1)",0,7.5,Launch Statistics,Dynamic Shared Memory Per Block,byte/block,0,,,,,
0,56005,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(128, 128, 1)",0,7.5,Launch Statistics,Static Shared Memory Per Block,byte/block,0,,,,,
0,56005,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(128, 128, 1)",0,7.5,Launch Statistics,Threads,thread,"16,777,216",,,,,
0,56005,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(128, 128, 1)",0,7.5,Launch Statistics,Waves Per SM,,"1,170.29",,,,,
0,56005,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(128, 128, 1)",0,7.5,Occupancy,Block Limit SM,block,16,,,,,
0,56005,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(128, 128, 1)",0,7.5,Occupancy,Block Limit Registers,block,4,,,,,
0,56005,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(128, 128, 1)",0,7.5,Occupancy,Block Limit Shared Mem,block,16,,,,,
0,56005,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(128, 128, 1)",0,7.5,Occupancy,Block Limit Warps,block,1,,,,,
0,56005,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(128, 128, 1)",0,7.5,Occupancy,Theoretical Active Warps per SM,warp,32,,,,,
0,56005,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(128, 128, 1)",0,7.5,Occupancy,Theoretical Occupancy,%,100,,,,,
0,56005,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(128, 128, 1)",0,7.5,Occupancy,Achieved Occupancy,%,73.78,,,,,
0,56005,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(128, 128, 1)",0,7.5,Occupancy,Achieved Active Warps Per SM,warp,23.61,,,,,
0,56005,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(128, 128, 1)",0,7.5,Occupancy,,,,AchievedOccupancy,OPT,The difference between calculated theoretical (100.0%) and measured achieved occupancy (73.8%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy.,global,26.22
0,56005,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(128, 128, 1)",0,7.5,Source Counters,Branch Instructions Ratio,%,0.06,,,,,
0,56005,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(128, 128, 1)",0,7.5,Source Counters,Branch Instructions,inst,"524,288",,,,,
0,56005,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(128, 128, 1)",0,7.5,Source Counters,Branch Efficiency,%,0,,,,,
0,56005,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(128, 128, 1)",0,7.5,Source Counters,Avg. Divergent Branches,,0,,,,,
0,56005,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(128, 128, 1)",0,7.5,SourceCounters,,,,UncoalescedGlobalAccess,OPT,This kernel has uncoalesced global accesses resulting in a total of 44040192 excessive sectors (88% of the total 50331648 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source locations. The CUDA Programming Guide (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) has additional information on reducing uncoalesced device memory accesses.,global,87.81
0,56089,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(8192, 8192, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Frequency,cycle/second,"5,996,500,469.26",,,,,
0,56089,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(8192, 8192, 1)",0,7.5,GPU Speed Of Light Throughput,SM Frequency,cycle/second,"1,379,181,758.65",,,,,
0,56089,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(8192, 8192, 1)",0,7.5,GPU Speed Of Light Throughput,Elapsed Cycles,cycle,"396,073,574",,,,,
0,56089,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(8192, 8192, 1)",0,7.5,GPU Speed Of Light Throughput,Memory Throughput,%,19.51,,,,,
0,56089,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(8192, 8192, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Throughput,%,19.51,,,,,
0,56089,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(8192, 8192, 1)",0,7.5,GPU Speed Of Light Throughput,Duration,nsecond,"286,849,888",,,,,
0,56089,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(8192, 8192, 1)",0,7.5,GPU Speed Of Light Throughput,L1/TEX Cache Throughput,%,14.18,,,,,
0,56089,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(8192, 8192, 1)",0,7.5,GPU Speed Of Light Throughput,L2 Cache Throughput,%,8.86,,,,,
0,56089,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(8192, 8192, 1)",0,7.5,GPU Speed Of Light Throughput,SM Active Cycles,cycle,"337,935,433.86",,,,,
0,56089,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(8192, 8192, 1)",0,7.5,GPU Speed Of Light Throughput,Compute (SM) Throughput,%,12.11,,,,,
0,56089,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(8192, 8192, 1)",0,7.5,SpeedOfLight,,,,SOLBottleneck,OPT,This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.,,
0,56089,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(8192, 8192, 1)",0,7.5,SpeedOfLight_RooflineChart,,,,SOLFPRoofline,INF,The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved  close to 0% of this device's fp32 peak performance and 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.,,
0,56089,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(8192, 8192, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Active,inst/cycle,0.24,,,,,
0,56089,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(8192, 8192, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Elapsed,inst/cycle,0.21,,,,,
0,56089,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(8192, 8192, 1)",0,7.5,Compute Workload Analysis,Issue Slots Busy,%,6.03,,,,,
0,56089,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(8192, 8192, 1)",0,7.5,Compute Workload Analysis,Issued Ipc Active,inst/cycle,0.24,,,,,
0,56089,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(8192, 8192, 1)",0,7.5,Compute Workload Analysis,SM Busy,%,6.62,,,,,
0,56089,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(8192, 8192, 1)",0,7.5,ComputeWorkloadAnalysis,,,,HighPipeUtilization,OPT,All compute pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.,local,95.04
0,56089,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(8192, 8192, 1)",0,7.5,Memory Workload Analysis,Memory Throughput,byte/second,"37,433,875,658.34",,,,,
0,56089,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(8192, 8192, 1)",0,7.5,Memory Workload Analysis,Mem Busy,%,6.65,,,,,
0,56089,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(8192, 8192, 1)",0,7.5,Memory Workload Analysis,Max Bandwidth,%,19.51,,,,,
0,56089,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(8192, 8192, 1)",0,7.5,Memory Workload Analysis,L1/TEX Hit Rate,%,0,,,,,
0,56089,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(8192, 8192, 1)",0,7.5,Memory Workload Analysis,L2 Hit Rate,%,33.33,,,,,
0,56089,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(8192, 8192, 1)",0,7.5,Memory Workload Analysis,Mem Pipes Busy,%,12.11,,,,,
0,56089,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(8192, 8192, 1)",0,7.5,MemoryWorkloadAnalysis_Chart,,,,MemoryL2Compression,WRN,The optional metric lts__average_gcomp_input_sector_success_rate.pct could not be found. Collecting it as an additional metric could enable the rule to provide more guidance.,,
0,56089,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(8192, 8192, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for loads from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced loads and try to minimize how many cache lines need to be accessed per memory request.",global,3.323
0,56089,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(8192, 8192, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for stores from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced stores and try to minimize how many cache lines need to be accessed per memory request.",global,1.661
0,56089,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(8192, 8192, 1)",0,7.5,Scheduler Statistics,One or More Eligible,%,6.71,,,,,
0,56089,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(8192, 8192, 1)",0,7.5,Scheduler Statistics,Issued Warp Per Scheduler,,0.07,,,,,
0,56089,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(8192, 8192, 1)",0,7.5,Scheduler Statistics,No Eligible,%,93.29,,,,,
0,56089,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(8192, 8192, 1)",0,7.5,Scheduler Statistics,Active Warps Per Scheduler,warp,2.94,,,,,
0,56089,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(8192, 8192, 1)",0,7.5,Scheduler Statistics,Eligible Warps Per Scheduler,warp,0.07,,,,,
0,56089,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(8192, 8192, 1)",0,7.5,SchedulerStats,,,,IssueSlotUtilization,OPT,"Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 14.9 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of 2.94 active warps per scheduler, but only an average of 0.07 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections.",local,80.49
0,56089,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(8192, 8192, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Issued Instruction,cycle,43.90,,,,,
0,56089,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(8192, 8192, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Executed Instruction,cycle,43.90,,,,,
0,56089,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(8192, 8192, 1)",0,7.5,Warp State Statistics,Avg. Active Threads Per Warp,,1,,,,,
0,56089,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(8192, 8192, 1)",0,7.5,Warp State Statistics,Avg. Not Predicated Off Threads Per Warp,,1,,,,,
0,56089,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(8192, 8192, 1)",0,7.5,WarpStateStats,,,,CPIStall,OPT,"On average, each warp of this kernel spends 36.9 cycles being stalled waiting for a scoreboard dependency on a L1TEX (local, global, surface, texture) operation. Find the instruction producing the data being waited upon to identify the culprit. To reduce the number of cycles waiting on L1TEX data accesses verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit rates by increasing data locality (coalescing), or by changing the cache configuration. Consider moving frequently used data to shared memory. This stall type represents about 84.1% of the total average of 43.9 cycles between issuing two instructions.",global,80.49
0,56089,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(8192, 8192, 1)",0,7.5,WarpStateStats,,,,CPIStall,INF,Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.,,
0,56089,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(8192, 8192, 1)",0,7.5,WarpStateStats,,,,ThreadDivergence,OPT,"Instructions are executed in warps, which are groups of 32 threads. Optimal instruction throughput is achieved if all 32 threads of a warp execute the same instruction. The chosen launch configuration, early thread completion, and divergent flow control can significantly lower the number of active threads in a warp per cycle. This kernel achieves an average of 1.0 threads being active per cycle.",global,11.74
0,56089,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(8192, 8192, 1)",0,7.5,Instruction Statistics,Avg. Executed Instructions Per Scheduler,inst,"20,372,333.71",,,,,
0,56089,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(8192, 8192, 1)",0,7.5,Instruction Statistics,Executed Instructions,inst,"1,140,850,688",,,,,
0,56089,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(8192, 8192, 1)",0,7.5,Instruction Statistics,Avg. Issued Instructions Per Scheduler,inst,"20,372,347.36",,,,,
0,56089,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(8192, 8192, 1)",0,7.5,Instruction Statistics,Issued Instructions,inst,"1,140,851,452",,,,,
0,56089,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(8192, 8192, 1)",0,7.5,InstructionStats,,,,FPInstructions,OPT,"This kernel executes 0 fused and 67108864 non-fused FP32 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP32 performance could be increased by up to 50% (relative to its current performance). Check the Source page to identify where this kernel executes FP32 instructions.",global,2.482
0,56089,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(8192, 8192, 1)",0,7.5,Launch Statistics,Block Size,,1,,,,,
0,56089,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(8192, 8192, 1)",0,7.5,Launch Statistics,Function Cache Configuration,,CachePreferNone,,,,,
0,56089,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(8192, 8192, 1)",0,7.5,Launch Statistics,Grid Size,,"67,108,864",,,,,
0,56089,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(8192, 8192, 1)",0,7.5,Launch Statistics,Registers Per Thread,register/thread,16,,,,,
0,56089,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(8192, 8192, 1)",0,7.5,Launch Statistics,Shared Memory Configuration Size,byte,"32,768",,,,,
0,56089,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(8192, 8192, 1)",0,7.5,Launch Statistics,Driver Shared Memory Per Block,byte/block,0,,,,,
0,56089,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(8192, 8192, 1)",0,7.5,Launch Statistics,Dynamic Shared Memory Per Block,byte/block,0,,,,,
0,56089,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(8192, 8192, 1)",0,7.5,Launch Statistics,Static Shared Memory Per Block,byte/block,0,,,,,
0,56089,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(8192, 8192, 1)",0,7.5,Launch Statistics,Threads,thread,"67,108,864",,,,,
0,56089,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(8192, 8192, 1)",0,7.5,Launch Statistics,Waves Per SM,,"299,593.14",,,,,
0,56089,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(8192, 8192, 1)",0,7.5,LaunchStats,,,,LaunchConfiguration,OPT,"Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 1 threads per block. Consequently, some threads in a warp are masked off and those hardware resources are unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256 threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to kernels that frequently call __syncthreads(). See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations.",global,96.88
0,56089,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(8192, 8192, 1)",0,7.5,Occupancy,Block Limit SM,block,16,,,,,
0,56089,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(8192, 8192, 1)",0,7.5,Occupancy,Block Limit Registers,block,128,,,,,
0,56089,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(8192, 8192, 1)",0,7.5,Occupancy,Block Limit Shared Mem,block,16,,,,,
0,56089,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(8192, 8192, 1)",0,7.5,Occupancy,Block Limit Warps,block,32,,,,,
0,56089,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(8192, 8192, 1)",0,7.5,Occupancy,Theoretical Active Warps per SM,warp,16,,,,,
0,56089,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(8192, 8192, 1)",0,7.5,Occupancy,Theoretical Occupancy,%,50,,,,,
0,56089,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(8192, 8192, 1)",0,7.5,Occupancy,Achieved Occupancy,%,33.88,,,,,
0,56089,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(8192, 8192, 1)",0,7.5,Occupancy,Achieved Active Warps Per SM,warp,10.84,,,,,
0,56089,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(8192, 8192, 1)",0,7.5,Occupancy,,,,AchievedOccupancy,OPT,The difference between calculated theoretical (50.0%) and measured achieved occupancy (33.9%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy.,global,32.24
0,56089,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(8192, 8192, 1)",0,7.5,Occupancy,,,,TheoreticalOccupancy,OPT,The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared memory.,global,50.0
0,56089,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(8192, 8192, 1)",0,7.5,Source Counters,Branch Instructions Ratio,%,0.06,,,,,
0,56089,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(8192, 8192, 1)",0,7.5,Source Counters,Branch Instructions,inst,"67,108,864",,,,,
0,56089,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(8192, 8192, 1)",0,7.5,Source Counters,Branch Efficiency,%,0,,,,,
0,56089,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(8192, 8192, 1)",0,7.5,Source Counters,Avg. Divergent Branches,,0,,,,,
0,56245,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(4096, 4096, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Frequency,cycle/second,"5,991,530,034.15",,,,,
0,56245,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(4096, 4096, 1)",0,7.5,GPU Speed Of Light Throughput,SM Frequency,cycle/second,"1,392,324,150.50",,,,,
0,56245,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(4096, 4096, 1)",0,7.5,GPU Speed Of Light Throughput,Elapsed Cycles,cycle,"156,301,846",,,,,
0,56245,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(4096, 4096, 1)",0,7.5,GPU Speed Of Light Throughput,Memory Throughput,%,24.96,,,,,
0,56245,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(4096, 4096, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Throughput,%,24.96,,,,,
0,56245,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(4096, 4096, 1)",0,7.5,GPU Speed Of Light Throughput,Duration,nsecond,"112,170,464",,,,,
0,56245,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(4096, 4096, 1)",0,7.5,GPU Speed Of Light Throughput,L1/TEX Cache Throughput,%,12.50,,,,,
0,56245,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(4096, 4096, 1)",0,7.5,GPU Speed Of Light Throughput,L2 Cache Throughput,%,11.34,,,,,
0,56245,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(4096, 4096, 1)",0,7.5,GPU Speed Of Light Throughput,SM Active Cycles,cycle,"151,588,896.50",,,,,
0,56245,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(4096, 4096, 1)",0,7.5,GPU Speed Of Light Throughput,Compute (SM) Throughput,%,7.67,,,,,
0,56245,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(4096, 4096, 1)",0,7.5,SpeedOfLight,,,,SOLBottleneck,OPT,This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.,,
0,56245,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(4096, 4096, 1)",0,7.5,SpeedOfLight_RooflineChart,,,,SOLFPRoofline,INF,The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved  close to 0% of this device's fp32 peak performance and 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.,,
0,56245,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(4096, 4096, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Active,inst/cycle,0.13,,,,,
0,56245,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(4096, 4096, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Elapsed,inst/cycle,0.13,,,,,
0,56245,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(4096, 4096, 1)",0,7.5,Compute Workload Analysis,Issue Slots Busy,%,3.36,,,,,
0,56245,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(4096, 4096, 1)",0,7.5,Compute Workload Analysis,Issued Ipc Active,inst/cycle,0.13,,,,,
0,56245,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(4096, 4096, 1)",0,7.5,Compute Workload Analysis,SM Busy,%,3.69,,,,,
0,56245,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(4096, 4096, 1)",0,7.5,ComputeWorkloadAnalysis,,,,HighPipeUtilization,OPT,All compute pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.,local,97.23
0,56245,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(4096, 4096, 1)",0,7.5,Memory Workload Analysis,Memory Throughput,byte/second,"47,863,599,030.85",,,,,
0,56245,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(4096, 4096, 1)",0,7.5,Memory Workload Analysis,Mem Busy,%,8.90,,,,,
0,56245,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(4096, 4096, 1)",0,7.5,Memory Workload Analysis,Max Bandwidth,%,24.96,,,,,
0,56245,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(4096, 4096, 1)",0,7.5,Memory Workload Analysis,L1/TEX Hit Rate,%,0,,,,,
0,56245,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(4096, 4096, 1)",0,7.5,Memory Workload Analysis,L2 Hit Rate,%,33.33,,,,,
0,56245,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(4096, 4096, 1)",0,7.5,Memory Workload Analysis,Mem Pipes Busy,%,7.67,,,,,
0,56245,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(4096, 4096, 1)",0,7.5,MemoryWorkloadAnalysis_Chart,,,,MemoryL2Compression,WRN,The optional metric lts__average_gcomp_input_sector_success_rate.pct could not be found. Collecting it as an additional metric could enable the rule to provide more guidance.,,
0,56245,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(4096, 4096, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for loads from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced loads and try to minimize how many cache lines need to be accessed per memory request.",global,4.252
0,56245,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(4096, 4096, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for stores from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced stores and try to minimize how many cache lines need to be accessed per memory request.",global,2.126
0,56245,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(4096, 4096, 1)",0,7.5,Scheduler Statistics,One or More Eligible,%,3.38,,,,,
0,56245,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(4096, 4096, 1)",0,7.5,Scheduler Statistics,Issued Warp Per Scheduler,,0.03,,,,,
0,56245,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(4096, 4096, 1)",0,7.5,Scheduler Statistics,No Eligible,%,96.62,,,,,
0,56245,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(4096, 4096, 1)",0,7.5,Scheduler Statistics,Active Warps Per Scheduler,warp,3.43,,,,,
0,56245,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(4096, 4096, 1)",0,7.5,Scheduler Statistics,Eligible Warps Per Scheduler,warp,0.03,,,,,
0,56245,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(4096, 4096, 1)",0,7.5,SchedulerStats,,,,IssueSlotUtilization,OPT,"Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 29.6 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of 3.43 active warps per scheduler, but only an average of 0.03 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, avoid possible load imbalances due to highly different execution durations per warp. Reducing stalls indicated on the Warp State Statistics and Source Counters sections can help, too.",local,75.04
0,56245,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(4096, 4096, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Issued Instruction,cycle,101.41,,,,,
0,56245,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(4096, 4096, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Executed Instruction,cycle,101.41,,,,,
0,56245,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(4096, 4096, 1)",0,7.5,Warp State Statistics,Avg. Active Threads Per Warp,,4,,,,,
0,56245,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(4096, 4096, 1)",0,7.5,Warp State Statistics,Avg. Not Predicated Off Threads Per Warp,,4,,,,,
0,56245,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(4096, 4096, 1)",0,7.5,WarpStateStats,,,,CPIStall,OPT,"On average, each warp of this kernel spends 94.4 cycles being stalled waiting for a scoreboard dependency on a L1TEX (local, global, surface, texture) operation. Find the instruction producing the data being waited upon to identify the culprit. To reduce the number of cycles waiting on L1TEX data accesses verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit rates by increasing data locality (coalescing), or by changing the cache configuration. Consider moving frequently used data to shared memory. This stall type represents about 93.1% of the total average of 101.4 cycles between issuing two instructions.",global,75.04
0,56245,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(4096, 4096, 1)",0,7.5,WarpStateStats,,,,CPIStall,INF,Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.,,
0,56245,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(4096, 4096, 1)",0,7.5,WarpStateStats,,,,ThreadDivergence,OPT,"Instructions are executed in warps, which are groups of 32 threads. Optimal instruction throughput is achieved if all 32 threads of a warp execute the same instruction. The chosen launch configuration, early thread completion, and divergent flow control can significantly lower the number of active threads in a warp per cycle. This kernel achieves an average of 4.0 threads being active per cycle.",global,6.713
0,56245,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(4096, 4096, 1)",0,7.5,Instruction Statistics,Avg. Executed Instructions Per Scheduler,inst,"5,093,083.43",,,,,
0,56245,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(4096, 4096, 1)",0,7.5,Instruction Statistics,Executed Instructions,inst,"285,212,672",,,,,
0,56245,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(4096, 4096, 1)",0,7.5,Instruction Statistics,Avg. Issued Instructions Per Scheduler,inst,"5,093,097.07",,,,,
0,56245,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(4096, 4096, 1)",0,7.5,Instruction Statistics,Issued Instructions,inst,"285,213,436",,,,,
0,56245,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(4096, 4096, 1)",0,7.5,InstructionStats,,,,FPInstructions,OPT,"This kernel executes 0 fused and 16777216 non-fused FP32 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP32 performance could be increased by up to 50% (relative to its current performance). Check the Source page to identify where this kernel executes FP32 instructions.",global,1.383
0,56245,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(4096, 4096, 1)",0,7.5,Launch Statistics,Block Size,,4,,,,,
0,56245,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(4096, 4096, 1)",0,7.5,Launch Statistics,Function Cache Configuration,,CachePreferNone,,,,,
0,56245,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(4096, 4096, 1)",0,7.5,Launch Statistics,Grid Size,,"16,777,216",,,,,
0,56245,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(4096, 4096, 1)",0,7.5,Launch Statistics,Registers Per Thread,register/thread,16,,,,,
0,56245,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(4096, 4096, 1)",0,7.5,Launch Statistics,Shared Memory Configuration Size,byte,"32,768",,,,,
0,56245,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(4096, 4096, 1)",0,7.5,Launch Statistics,Driver Shared Memory Per Block,byte/block,0,,,,,
0,56245,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(4096, 4096, 1)",0,7.5,Launch Statistics,Dynamic Shared Memory Per Block,byte/block,0,,,,,
0,56245,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(4096, 4096, 1)",0,7.5,Launch Statistics,Static Shared Memory Per Block,byte/block,0,,,,,
0,56245,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(4096, 4096, 1)",0,7.5,Launch Statistics,Threads,thread,"67,108,864",,,,,
0,56245,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(4096, 4096, 1)",0,7.5,Launch Statistics,Waves Per SM,,"74,898.29",,,,,
0,56245,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(4096, 4096, 1)",0,7.5,LaunchStats,,,,LaunchConfiguration,OPT,"Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 4 threads per block. Consequently, some threads in a warp are masked off and those hardware resources are unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256 threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to kernels that frequently call __syncthreads(). See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations.",global,87.5
0,56245,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(4096, 4096, 1)",0,7.5,Occupancy,Block Limit SM,block,16,,,,,
0,56245,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(4096, 4096, 1)",0,7.5,Occupancy,Block Limit Registers,block,128,,,,,
0,56245,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(4096, 4096, 1)",0,7.5,Occupancy,Block Limit Shared Mem,block,16,,,,,
0,56245,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(4096, 4096, 1)",0,7.5,Occupancy,Block Limit Warps,block,32,,,,,
0,56245,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(4096, 4096, 1)",0,7.5,Occupancy,Theoretical Active Warps per SM,warp,16,,,,,
0,56245,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(4096, 4096, 1)",0,7.5,Occupancy,Theoretical Occupancy,%,50,,,,,
0,56245,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(4096, 4096, 1)",0,7.5,Occupancy,Achieved Occupancy,%,43.04,,,,,
0,56245,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(4096, 4096, 1)",0,7.5,Occupancy,Achieved Active Warps Per SM,warp,13.77,,,,,
0,56245,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(4096, 4096, 1)",0,7.5,Occupancy,,,,TheoreticalOccupancy,OPT,The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared memory.,global,50.0
0,56245,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(4096, 4096, 1)",0,7.5,Source Counters,Branch Instructions Ratio,%,0.06,,,,,
0,56245,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(4096, 4096, 1)",0,7.5,Source Counters,Branch Instructions,inst,"16,777,216",,,,,
0,56245,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(4096, 4096, 1)",0,7.5,Source Counters,Branch Efficiency,%,0,,,,,
0,56245,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(4096, 4096, 1)",0,7.5,Source Counters,Avg. Divergent Branches,,0,,,,,
0,56245,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(4096, 4096, 1)",0,7.5,SourceCounters,,,,UncoalescedGlobalAccess,OPT,This kernel has uncoalesced global accesses resulting in a total of 50331648 excessive sectors (50% of the total 100663296 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source locations. The CUDA Programming Guide (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) has additional information on reducing uncoalesced device memory accesses.,global,49.16
0,56357,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(2048, 2048, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Frequency,cycle/second,"5,983,176,191.19",,,,,
0,56357,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(2048, 2048, 1)",0,7.5,GPU Speed Of Light Throughput,SM Frequency,cycle/second,"1,375,505,200.43",,,,,
0,56357,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(2048, 2048, 1)",0,7.5,GPU Speed Of Light Throughput,Elapsed Cycles,cycle,"80,169,996",,,,,
0,56357,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(2048, 2048, 1)",0,7.5,GPU Speed Of Light Throughput,Memory Throughput,%,24.10,,,,,
0,56357,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(2048, 2048, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Throughput,%,24.10,,,,,
0,56357,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(2048, 2048, 1)",0,7.5,GPU Speed Of Light Throughput,Duration,nsecond,"58,168,992",,,,,
0,56357,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(2048, 2048, 1)",0,7.5,GPU Speed Of Light Throughput,L1/TEX Cache Throughput,%,11.98,,,,,
0,56357,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(2048, 2048, 1)",0,7.5,GPU Speed Of Light Throughput,L2 Cache Throughput,%,10.96,,,,,
0,56357,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(2048, 2048, 1)",0,7.5,GPU Speed Of Light Throughput,SM Active Cycles,cycle,"80,343,288.64",,,,,
0,56357,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(2048, 2048, 1)",0,7.5,GPU Speed Of Light Throughput,Compute (SM) Throughput,%,3.74,,,,,
0,56357,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(2048, 2048, 1)",0,7.5,SpeedOfLight,,,,SOLBottleneck,OPT,This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.,,
0,56357,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(2048, 2048, 1)",0,7.5,SpeedOfLight_RooflineChart,,,,SOLFPRoofline,INF,The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved  close to 0% of this device's fp32 peak performance and 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.,,
0,56357,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(2048, 2048, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Active,inst/cycle,0.06,,,,,
0,56357,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(2048, 2048, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Elapsed,inst/cycle,0.06,,,,,
0,56357,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(2048, 2048, 1)",0,7.5,Compute Workload Analysis,Issue Slots Busy,%,1.58,,,,,
0,56357,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(2048, 2048, 1)",0,7.5,Compute Workload Analysis,Issued Ipc Active,inst/cycle,0.06,,,,,
0,56357,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(2048, 2048, 1)",0,7.5,Compute Workload Analysis,SM Busy,%,1.74,,,,,
0,56357,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(2048, 2048, 1)",0,7.5,ComputeWorkloadAnalysis,,,,HighPipeUtilization,OPT,All compute pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.,local,98.69
0,56357,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(2048, 2048, 1)",0,7.5,Memory Workload Analysis,Memory Throughput,byte/second,"46,147,387,941.67",,,,,
0,56357,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(2048, 2048, 1)",0,7.5,Memory Workload Analysis,Mem Busy,%,8.97,,,,,
0,56357,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(2048, 2048, 1)",0,7.5,Memory Workload Analysis,Max Bandwidth,%,24.10,,,,,
0,56357,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(2048, 2048, 1)",0,7.5,Memory Workload Analysis,L1/TEX Hit Rate,%,0,,,,,
0,56357,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(2048, 2048, 1)",0,7.5,Memory Workload Analysis,L2 Hit Rate,%,33.33,,,,,
0,56357,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(2048, 2048, 1)",0,7.5,Memory Workload Analysis,Mem Pipes Busy,%,3.74,,,,,
0,56357,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(2048, 2048, 1)",0,7.5,MemoryWorkloadAnalysis_Chart,,,,MemoryL2Compression,WRN,The optional metric lts__average_gcomp_input_sector_success_rate.pct could not be found. Collecting it as an additional metric could enable the rule to provide more guidance.,,
0,56357,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(2048, 2048, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for loads from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced loads and try to minimize how many cache lines need to be accessed per memory request.",global,4.108
0,56357,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(2048, 2048, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for stores from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced stores and try to minimize how many cache lines need to be accessed per memory request.",global,2.054
0,56357,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(2048, 2048, 1)",0,7.5,Scheduler Statistics,One or More Eligible,%,1.59,,,,,
0,56357,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(2048, 2048, 1)",0,7.5,Scheduler Statistics,Issued Warp Per Scheduler,,0.02,,,,,
0,56357,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(2048, 2048, 1)",0,7.5,Scheduler Statistics,No Eligible,%,98.41,,,,,
0,56357,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(2048, 2048, 1)",0,7.5,Scheduler Statistics,Active Warps Per Scheduler,warp,3.83,,,,,
0,56357,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(2048, 2048, 1)",0,7.5,Scheduler Statistics,Eligible Warps Per Scheduler,warp,0.02,,,,,
0,56357,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(2048, 2048, 1)",0,7.5,SchedulerStats,,,,IssueSlotUtilization,OPT,"Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 63.0 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of 3.83 active warps per scheduler, but only an average of 0.02 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, avoid possible load imbalances due to highly different execution durations per warp. Reducing stalls indicated on the Warp State Statistics and Source Counters sections can help, too.",local,75.9
0,56357,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(2048, 2048, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Issued Instruction,cycle,241.42,,,,,
0,56357,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(2048, 2048, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Executed Instruction,cycle,241.42,,,,,
0,56357,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(2048, 2048, 1)",0,7.5,Warp State Statistics,Avg. Active Threads Per Warp,,16,,,,,
0,56357,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(2048, 2048, 1)",0,7.5,Warp State Statistics,Avg. Not Predicated Off Threads Per Warp,,16,,,,,
0,56357,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(2048, 2048, 1)",0,7.5,WarpStateStats,,,,CPIStall,OPT,"On average, each warp of this kernel spends 234.5 cycles being stalled waiting for a scoreboard dependency on a L1TEX (local, global, surface, texture) operation. Find the instruction producing the data being waited upon to identify the culprit. To reduce the number of cycles waiting on L1TEX data accesses verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit rates by increasing data locality (coalescing), or by changing the cache configuration. Consider moving frequently used data to shared memory. This stall type represents about 97.1% of the total average of 241.4 cycles between issuing two instructions.",global,75.9
0,56357,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(2048, 2048, 1)",0,7.5,WarpStateStats,,,,CPIStall,INF,Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.,,
0,56357,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(2048, 2048, 1)",0,7.5,WarpStateStats,,,,ThreadDivergence,OPT,"Instructions are executed in warps, which are groups of 32 threads. Optimal instruction throughput is achieved if all 32 threads of a warp execute the same instruction. The chosen launch configuration, early thread completion, and divergent flow control can significantly lower the number of active threads in a warp per cycle. This kernel achieves an average of 16.0 threads being active per cycle.",global,1.872
0,56357,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(2048, 2048, 1)",0,7.5,Instruction Statistics,Avg. Executed Instructions Per Scheduler,inst,"1,273,270.86",,,,,
0,56357,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(2048, 2048, 1)",0,7.5,Instruction Statistics,Executed Instructions,inst,"71,303,168",,,,,
0,56357,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(2048, 2048, 1)",0,7.5,Instruction Statistics,Avg. Issued Instructions Per Scheduler,inst,"1,273,284.50",,,,,
0,56357,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(2048, 2048, 1)",0,7.5,Instruction Statistics,Issued Instructions,inst,"71,303,932",,,,,
0,56357,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(2048, 2048, 1)",0,7.5,InstructionStats,,,,FPInstructions,OPT,"This kernel executes 0 fused and 4194304 non-fused FP32 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP32 performance could be increased by up to 50% (relative to its current performance). Check the Source page to identify where this kernel executes FP32 instructions.",global,0.6526
0,56357,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(2048, 2048, 1)",0,7.5,Launch Statistics,Block Size,,16,,,,,
0,56357,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(2048, 2048, 1)",0,7.5,Launch Statistics,Function Cache Configuration,,CachePreferNone,,,,,
0,56357,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(2048, 2048, 1)",0,7.5,Launch Statistics,Grid Size,,"4,194,304",,,,,
0,56357,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(2048, 2048, 1)",0,7.5,Launch Statistics,Registers Per Thread,register/thread,16,,,,,
0,56357,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(2048, 2048, 1)",0,7.5,Launch Statistics,Shared Memory Configuration Size,byte,"32,768",,,,,
0,56357,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(2048, 2048, 1)",0,7.5,Launch Statistics,Driver Shared Memory Per Block,byte/block,0,,,,,
0,56357,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(2048, 2048, 1)",0,7.5,Launch Statistics,Dynamic Shared Memory Per Block,byte/block,0,,,,,
0,56357,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(2048, 2048, 1)",0,7.5,Launch Statistics,Static Shared Memory Per Block,byte/block,0,,,,,
0,56357,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(2048, 2048, 1)",0,7.5,Launch Statistics,Threads,thread,"67,108,864",,,,,
0,56357,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(2048, 2048, 1)",0,7.5,Launch Statistics,Waves Per SM,,"18,724.57",,,,,
0,56357,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(2048, 2048, 1)",0,7.5,LaunchStats,,,,LaunchConfiguration,OPT,"Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 16 threads per block. Consequently, some threads in a warp are masked off and those hardware resources are unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256 threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to kernels that frequently call __syncthreads(). See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations.",global,50.0
0,56357,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(2048, 2048, 1)",0,7.5,Occupancy,Block Limit SM,block,16,,,,,
0,56357,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(2048, 2048, 1)",0,7.5,Occupancy,Block Limit Registers,block,128,,,,,
0,56357,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(2048, 2048, 1)",0,7.5,Occupancy,Block Limit Shared Mem,block,16,,,,,
0,56357,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(2048, 2048, 1)",0,7.5,Occupancy,Block Limit Warps,block,32,,,,,
0,56357,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(2048, 2048, 1)",0,7.5,Occupancy,Theoretical Active Warps per SM,warp,16,,,,,
0,56357,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(2048, 2048, 1)",0,7.5,Occupancy,Theoretical Occupancy,%,50,,,,,
0,56357,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(2048, 2048, 1)",0,7.5,Occupancy,Achieved Occupancy,%,47.98,,,,,
0,56357,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(2048, 2048, 1)",0,7.5,Occupancy,Achieved Active Warps Per SM,warp,15.35,,,,,
0,56357,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(2048, 2048, 1)",0,7.5,Occupancy,,,,TheoreticalOccupancy,OPT,The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared memory.,global,50.0
0,56357,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(2048, 2048, 1)",0,7.5,Source Counters,Branch Instructions Ratio,%,0.06,,,,,
0,56357,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(2048, 2048, 1)",0,7.5,Source Counters,Branch Instructions,inst,"4,194,304",,,,,
0,56357,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(2048, 2048, 1)",0,7.5,Source Counters,Branch Efficiency,%,0,,,,,
0,56357,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(2048, 2048, 1)",0,7.5,Source Counters,Avg. Divergent Branches,,0,,,,,
0,56357,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(2048, 2048, 1)",0,7.5,SourceCounters,,,,UncoalescedGlobalAccess,OPT,This kernel has uncoalesced global accesses resulting in a total of 25165824 excessive sectors (50% of the total 50331648 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source locations. The CUDA Programming Guide (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) has additional information on reducing uncoalesced device memory accesses.,global,49.49
0,56460,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(1024, 1024, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Frequency,cycle/second,"5,993,422,079.68",,,,,
0,56460,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(1024, 1024, 1)",0,7.5,GPU Speed Of Light Throughput,SM Frequency,cycle/second,"1,393,149,813.89",,,,,
0,56460,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(1024, 1024, 1)",0,7.5,GPU Speed Of Light Throughput,Elapsed Cycles,cycle,"42,006,516",,,,,
0,56460,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(1024, 1024, 1)",0,7.5,GPU Speed Of Light Throughput,Memory Throughput,%,23.22,,,,,
0,56460,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(1024, 1024, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Throughput,%,23.22,,,,,
0,56460,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(1024, 1024, 1)",0,7.5,GPU Speed Of Light Throughput,Duration,nsecond,"30,132,320",,,,,
0,56460,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(1024, 1024, 1)",0,7.5,GPU Speed Of Light Throughput,L1/TEX Cache Throughput,%,18.96,,,,,
0,56460,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(1024, 1024, 1)",0,7.5,GPU Speed Of Light Throughput,L2 Cache Throughput,%,10.55,,,,,
0,56460,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(1024, 1024, 1)",0,7.5,GPU Speed Of Light Throughput,SM Active Cycles,cycle,"41,965,588.21",,,,,
0,56460,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(1024, 1024, 1)",0,7.5,GPU Speed Of Light Throughput,Compute (SM) Throughput,%,3.57,,,,,
0,56460,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(1024, 1024, 1)",0,7.5,SpeedOfLight,,,,SOLBottleneck,OPT,This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.,,
0,56460,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(1024, 1024, 1)",0,7.5,SpeedOfLight_RooflineChart,,,,SOLFPRoofline,INF,The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved  close to 0% of this device's fp32 peak performance and 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.,,
0,56460,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(1024, 1024, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Active,inst/cycle,0.06,,,,,
0,56460,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(1024, 1024, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Elapsed,inst/cycle,0.06,,,,,
0,56460,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(1024, 1024, 1)",0,7.5,Compute Workload Analysis,Issue Slots Busy,%,1.52,,,,,
0,56460,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(1024, 1024, 1)",0,7.5,Compute Workload Analysis,Issued Ipc Active,inst/cycle,0.06,,,,,
0,56460,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(1024, 1024, 1)",0,7.5,Compute Workload Analysis,SM Busy,%,1.67,,,,,
0,56460,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(1024, 1024, 1)",0,7.5,ComputeWorkloadAnalysis,,,,HighPipeUtilization,OPT,All compute pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.,local,98.75
0,56460,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(1024, 1024, 1)",0,7.5,Memory Workload Analysis,Memory Throughput,byte/second,"44,540,602,250.34",,,,,
0,56460,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(1024, 1024, 1)",0,7.5,Memory Workload Analysis,Mem Busy,%,9.48,,,,,
0,56460,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(1024, 1024, 1)",0,7.5,Memory Workload Analysis,Max Bandwidth,%,23.22,,,,,
0,56460,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(1024, 1024, 1)",0,7.5,Memory Workload Analysis,L1/TEX Hit Rate,%,49.99,,,,,
0,56460,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(1024, 1024, 1)",0,7.5,Memory Workload Analysis,L2 Hit Rate,%,34.33,,,,,
0,56460,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(1024, 1024, 1)",0,7.5,Memory Workload Analysis,Mem Pipes Busy,%,3.57,,,,,
0,56460,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(1024, 1024, 1)",0,7.5,MemoryWorkloadAnalysis_Chart,,,,MemoryL2Compression,WRN,The optional metric lts__average_gcomp_input_sector_success_rate.pct could not be found. Collecting it as an additional metric could enable the rule to provide more guidance.,,
0,56460,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(1024, 1024, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for global loads in L1TEX might not be optimal. On average, this kernel accesses 4.0 bytes per thread per memory request; but the address pattern, possibly caused by the stride between threads, results in 8.0 sectors per request, or 8.0*32 = 256.0 bytes of cache data transfers per request. The optimal thread address pattern for 4.0 byte accesses would result in 4.0*32 = 128.0 bytes of cache data transfers per request, to maximize L1TEX cache performance. Check the Source Counters section for uncoalesced global loads.",global,0.2676
0,56460,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(1024, 1024, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for global stores in L1TEX might not be optimal. On average, this kernel accesses 4.0 bytes per thread per memory request; but the address pattern, possibly caused by the stride between threads, results in 8.0 sectors per request, or 8.0*32 = 256.0 bytes of cache data transfers per request. The optimal thread address pattern for 4.0 byte accesses would result in 4.0*32 = 128.0 bytes of cache data transfers per request, to maximize L1TEX cache performance. Check the Source Counters section for uncoalesced global stores.",global,0.2676
0,56460,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(1024, 1024, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for loads from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced loads and try to minimize how many cache lines need to be accessed per memory request.",global,3.957
0,56460,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(1024, 1024, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for stores from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced stores and try to minimize how many cache lines need to be accessed per memory request.",global,2.072
0,56460,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(1024, 1024, 1)",0,7.5,Scheduler Statistics,One or More Eligible,%,1.52,,,,,
0,56460,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(1024, 1024, 1)",0,7.5,Scheduler Statistics,Issued Warp Per Scheduler,,0.02,,,,,
0,56460,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(1024, 1024, 1)",0,7.5,Scheduler Statistics,No Eligible,%,98.48,,,,,
0,56460,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(1024, 1024, 1)",0,7.5,Scheduler Statistics,Active Warps Per Scheduler,warp,7.83,,,,,
0,56460,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(1024, 1024, 1)",0,7.5,Scheduler Statistics,Eligible Warps Per Scheduler,warp,0.02,,,,,
0,56460,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(1024, 1024, 1)",0,7.5,SchedulerStats,,,,IssueSlotUtilization,OPT,"Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 65.9 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of 7.83 active warps per scheduler, but only an average of 0.02 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, avoid possible load imbalances due to highly different execution durations per warp. Reducing stalls indicated on the Warp State Statistics and Source Counters sections can help, too.",local,76.78
0,56460,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(1024, 1024, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Issued Instruction,cycle,516.28,,,,,
0,56460,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(1024, 1024, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Executed Instruction,cycle,516.30,,,,,
0,56460,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(1024, 1024, 1)",0,7.5,Warp State Statistics,Avg. Active Threads Per Warp,,32,,,,,
0,56460,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(1024, 1024, 1)",0,7.5,Warp State Statistics,Avg. Not Predicated Off Threads Per Warp,,32,,,,,
0,56460,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(1024, 1024, 1)",0,7.5,WarpStateStats,,,,CPIStall,OPT,"On average, each warp of this kernel spends 504.7 cycles being stalled waiting for a scoreboard dependency on a L1TEX (local, global, surface, texture) operation. Find the instruction producing the data being waited upon to identify the culprit. To reduce the number of cycles waiting on L1TEX data accesses verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit rates by increasing data locality (coalescing), or by changing the cache configuration. Consider moving frequently used data to shared memory. This stall type represents about 97.8% of the total average of 516.3 cycles between issuing two instructions.",global,76.78
0,56460,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(1024, 1024, 1)",0,7.5,WarpStateStats,,,,CPIStall,INF,Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.,,
0,56460,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(1024, 1024, 1)",0,7.5,Instruction Statistics,Avg. Executed Instructions Per Scheduler,inst,"636,635.43",,,,,
0,56460,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(1024, 1024, 1)",0,7.5,Instruction Statistics,Executed Instructions,inst,"35,651,584",,,,,
0,56460,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(1024, 1024, 1)",0,7.5,Instruction Statistics,Avg. Issued Instructions Per Scheduler,inst,"636,660.57",,,,,
0,56460,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(1024, 1024, 1)",0,7.5,Instruction Statistics,Issued Instructions,inst,"35,652,992",,,,,
0,56460,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(1024, 1024, 1)",0,7.5,InstructionStats,,,,FPInstructions,OPT,"This kernel executes 0 fused and 2097152 non-fused FP32 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP32 performance could be increased by up to 50% (relative to its current performance). Check the Source page to identify where this kernel executes FP32 instructions.",global,0.6247
0,56460,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(1024, 1024, 1)",0,7.5,Launch Statistics,Block Size,,64,,,,,
0,56460,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(1024, 1024, 1)",0,7.5,Launch Statistics,Function Cache Configuration,,CachePreferNone,,,,,
0,56460,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(1024, 1024, 1)",0,7.5,Launch Statistics,Grid Size,,"1,048,576",,,,,
0,56460,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(1024, 1024, 1)",0,7.5,Launch Statistics,Registers Per Thread,register/thread,16,,,,,
0,56460,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(1024, 1024, 1)",0,7.5,Launch Statistics,Shared Memory Configuration Size,byte,"32,768",,,,,
0,56460,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(1024, 1024, 1)",0,7.5,Launch Statistics,Driver Shared Memory Per Block,byte/block,0,,,,,
0,56460,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(1024, 1024, 1)",0,7.5,Launch Statistics,Dynamic Shared Memory Per Block,byte/block,0,,,,,
0,56460,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(1024, 1024, 1)",0,7.5,Launch Statistics,Static Shared Memory Per Block,byte/block,0,,,,,
0,56460,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(1024, 1024, 1)",0,7.5,Launch Statistics,Threads,thread,"67,108,864",,,,,
0,56460,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(1024, 1024, 1)",0,7.5,Launch Statistics,Waves Per SM,,"4,681.14",,,,,
0,56460,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(1024, 1024, 1)",0,7.5,Occupancy,Block Limit SM,block,16,,,,,
0,56460,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(1024, 1024, 1)",0,7.5,Occupancy,Block Limit Registers,block,64,,,,,
0,56460,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(1024, 1024, 1)",0,7.5,Occupancy,Block Limit Shared Mem,block,16,,,,,
0,56460,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(1024, 1024, 1)",0,7.5,Occupancy,Block Limit Warps,block,16,,,,,
0,56460,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(1024, 1024, 1)",0,7.5,Occupancy,Theoretical Active Warps per SM,warp,32,,,,,
0,56460,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(1024, 1024, 1)",0,7.5,Occupancy,Theoretical Occupancy,%,100,,,,,
0,56460,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(1024, 1024, 1)",0,7.5,Occupancy,Achieved Occupancy,%,98.16,,,,,
0,56460,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(1024, 1024, 1)",0,7.5,Occupancy,Achieved Active Warps Per SM,warp,31.41,,,,,
0,56460,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(1024, 1024, 1)",0,7.5,Source Counters,Branch Instructions Ratio,%,0.06,,,,,
0,56460,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(1024, 1024, 1)",0,7.5,Source Counters,Branch Instructions,inst,"2,097,152",,,,,
0,56460,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(1024, 1024, 1)",0,7.5,Source Counters,Branch Efficiency,%,0,,,,,
0,56460,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(1024, 1024, 1)",0,7.5,Source Counters,Avg. Divergent Branches,,0,,,,,
0,56460,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(1024, 1024, 1)",0,7.5,SourceCounters,,,,UncoalescedGlobalAccess,OPT,This kernel has uncoalesced global accesses resulting in a total of 25165824 excessive sectors (50% of the total 50331648 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source locations. The CUDA Programming Guide (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) has additional information on reducing uncoalesced device memory accesses.,global,49.06
0,56556,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(512, 512, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Frequency,cycle/second,"5,983,521,121.85",,,,,
0,56556,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(512, 512, 1)",0,7.5,GPU Speed Of Light Throughput,SM Frequency,cycle/second,"1,387,980,226.97",,,,,
0,56556,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(512, 512, 1)",0,7.5,GPU Speed Of Light Throughput,Elapsed Cycles,cycle,"19,126,225",,,,,
0,56556,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(512, 512, 1)",0,7.5,GPU Speed Of Light Throughput,Memory Throughput,%,43.95,,,,,
0,56556,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(512, 512, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Throughput,%,30.56,,,,,
0,56556,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(512, 512, 1)",0,7.5,GPU Speed Of Light Throughput,Duration,nsecond,"13,760,160",,,,,
0,56556,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(512, 512, 1)",0,7.5,GPU Speed Of Light Throughput,L1/TEX Cache Throughput,%,79.85,,,,,
0,56556,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(512, 512, 1)",0,7.5,GPU Speed Of Light Throughput,L2 Cache Throughput,%,43.95,,,,,
0,56556,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(512, 512, 1)",0,7.5,GPU Speed Of Light Throughput,SM Active Cycles,cycle,"19,083,322.57",,,,,
0,56556,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(512, 512, 1)",0,7.5,GPU Speed Of Light Throughput,Compute (SM) Throughput,%,7.84,,,,,
0,56556,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(512, 512, 1)",0,7.5,SpeedOfLight,,,,SOLBottleneck,OPT,This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.,,
0,56556,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(512, 512, 1)",0,7.5,SpeedOfLight_RooflineChart,,,,SOLFPRoofline,INF,The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved  close to 0% of this device's fp32 peak performance and 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.,,
0,56556,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(512, 512, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Active,inst/cycle,0.13,,,,,
0,56556,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(512, 512, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Elapsed,inst/cycle,0.13,,,,,
0,56556,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(512, 512, 1)",0,7.5,Compute Workload Analysis,Issue Slots Busy,%,3.34,,,,,
0,56556,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(512, 512, 1)",0,7.5,Compute Workload Analysis,Issued Ipc Active,inst/cycle,0.13,,,,,
0,56556,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(512, 512, 1)",0,7.5,Compute Workload Analysis,SM Busy,%,3.66,,,,,
0,56556,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(512, 512, 1)",0,7.5,ComputeWorkloadAnalysis,,,,HighPipeUtilization,OPT,All compute pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.,local,97.25
0,56556,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(512, 512, 1)",0,7.5,Memory Workload Analysis,Memory Throughput,byte/second,"58,512,301,019.76",,,,,
0,56556,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(512, 512, 1)",0,7.5,Memory Workload Analysis,Mem Busy,%,39.92,,,,,
0,56556,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(512, 512, 1)",0,7.5,Memory Workload Analysis,Max Bandwidth,%,43.95,,,,,
0,56556,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(512, 512, 1)",0,7.5,Memory Workload Analysis,L1/TEX Hit Rate,%,79.17,,,,,
0,56556,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(512, 512, 1)",0,7.5,Memory Workload Analysis,L2 Hit Rate,%,80.09,,,,,
0,56556,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(512, 512, 1)",0,7.5,Memory Workload Analysis,Mem Pipes Busy,%,7.84,,,,,
0,56556,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(512, 512, 1)",0,7.5,MemoryWorkloadAnalysis_Chart,,,,MemoryL2Compression,WRN,The optional metric lts__average_gcomp_input_sector_success_rate.pct could not be found. Collecting it as an additional metric could enable the rule to provide more guidance.,,
0,56556,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(512, 512, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for global loads in L1TEX might not be optimal. On average, this kernel accesses 4.0 bytes per thread per memory request; but the address pattern, possibly caused by the stride between threads, results in 16.0 sectors per request, or 16.0*32 = 512.0 bytes of cache data transfers per request. The optimal thread address pattern for 4.0 byte accesses would result in 4.0*32 = 128.0 bytes of cache data transfers per request, to maximize L1TEX cache performance. Check the Source Counters section for uncoalesced global loads.",global,1.764
0,56556,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(512, 512, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for global stores in L1TEX might not be optimal. On average, this kernel accesses 4.0 bytes per thread per memory request; but the address pattern, possibly caused by the stride between threads, results in 16.0 sectors per request, or 16.0*32 = 512.0 bytes of cache data transfers per request. The optimal thread address pattern for 4.0 byte accesses would result in 4.0*32 = 128.0 bytes of cache data transfers per request, to maximize L1TEX cache performance. Check the Source Counters section for uncoalesced global stores.",global,1.764
0,56556,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(512, 512, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for loads from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced loads and try to minimize how many cache lines need to be accessed per memory request.",global,8.665
0,56556,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(512, 512, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for stores from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.1 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced stores and try to minimize how many cache lines need to be accessed per memory request.",global,12.78
0,56556,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(512, 512, 1)",0,7.5,Scheduler Statistics,One or More Eligible,%,3.33,,,,,
0,56556,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(512, 512, 1)",0,7.5,Scheduler Statistics,Issued Warp Per Scheduler,,0.03,,,,,
0,56556,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(512, 512, 1)",0,7.5,Scheduler Statistics,No Eligible,%,96.67,,,,,
0,56556,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(512, 512, 1)",0,7.5,Scheduler Statistics,Active Warps Per Scheduler,warp,6.95,,,,,
0,56556,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(512, 512, 1)",0,7.5,Scheduler Statistics,Eligible Warps Per Scheduler,warp,0.04,,,,,
0,56556,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(512, 512, 1)",0,7.5,SchedulerStats,,,,IssueSlotUtilization,OPT,"Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 30.0 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of 6.95 active warps per scheduler, but only an average of 0.04 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, avoid possible load imbalances due to highly different execution durations per warp. Reducing stalls indicated on the Warp State Statistics and Source Counters sections can help, too.",local,56.05
0,56556,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(512, 512, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Issued Instruction,cycle,208.77,,,,,
0,56556,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(512, 512, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Executed Instruction,cycle,208.78,,,,,
0,56556,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(512, 512, 1)",0,7.5,Warp State Statistics,Avg. Active Threads Per Warp,,32,,,,,
0,56556,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(512, 512, 1)",0,7.5,Warp State Statistics,Avg. Not Predicated Off Threads Per Warp,,32,,,,,
0,56556,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(512, 512, 1)",0,7.5,WarpStateStats,,,,CPIStall,OPT,"On average, each warp of this kernel spends 163.1 cycles being stalled waiting for a scoreboard dependency on a L1TEX (local, global, surface, texture) operation. Find the instruction producing the data being waited upon to identify the culprit. To reduce the number of cycles waiting on L1TEX data accesses verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit rates by increasing data locality (coalescing), or by changing the cache configuration. Consider moving frequently used data to shared memory. This stall type represents about 78.1% of the total average of 208.8 cycles between issuing two instructions.",global,56.05
0,56556,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(512, 512, 1)",0,7.5,WarpStateStats,,,,CPIStall,INF,Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.,,
0,56556,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(512, 512, 1)",0,7.5,Instruction Statistics,Avg. Executed Instructions Per Scheduler,inst,"636,635.43",,,,,
0,56556,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(512, 512, 1)",0,7.5,Instruction Statistics,Executed Instructions,inst,"35,651,584",,,,,
0,56556,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(512, 512, 1)",0,7.5,Instruction Statistics,Avg. Issued Instructions Per Scheduler,inst,"636,666.93",,,,,
0,56556,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(512, 512, 1)",0,7.5,Instruction Statistics,Issued Instructions,inst,"35,653,348",,,,,
0,56556,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(512, 512, 1)",0,7.5,InstructionStats,,,,FPInstructions,OPT,"This kernel executes 0 fused and 2097152 non-fused FP32 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP32 performance could be increased by up to 50% (relative to its current performance). Check the Source page to identify where this kernel executes FP32 instructions.",global,1.374
0,56556,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(512, 512, 1)",0,7.5,Launch Statistics,Block Size,,256,,,,,
0,56556,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(512, 512, 1)",0,7.5,Launch Statistics,Function Cache Configuration,,CachePreferNone,,,,,
0,56556,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(512, 512, 1)",0,7.5,Launch Statistics,Grid Size,,"262,144",,,,,
0,56556,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(512, 512, 1)",0,7.5,Launch Statistics,Registers Per Thread,register/thread,16,,,,,
0,56556,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(512, 512, 1)",0,7.5,Launch Statistics,Shared Memory Configuration Size,byte,"32,768",,,,,
0,56556,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(512, 512, 1)",0,7.5,Launch Statistics,Driver Shared Memory Per Block,byte/block,0,,,,,
0,56556,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(512, 512, 1)",0,7.5,Launch Statistics,Dynamic Shared Memory Per Block,byte/block,0,,,,,
0,56556,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(512, 512, 1)",0,7.5,Launch Statistics,Static Shared Memory Per Block,byte/block,0,,,,,
0,56556,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(512, 512, 1)",0,7.5,Launch Statistics,Threads,thread,"67,108,864",,,,,
0,56556,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(512, 512, 1)",0,7.5,Launch Statistics,Waves Per SM,,"4,681.14",,,,,
0,56556,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(512, 512, 1)",0,7.5,Occupancy,Block Limit SM,block,16,,,,,
0,56556,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(512, 512, 1)",0,7.5,Occupancy,Block Limit Registers,block,16,,,,,
0,56556,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(512, 512, 1)",0,7.5,Occupancy,Block Limit Shared Mem,block,16,,,,,
0,56556,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(512, 512, 1)",0,7.5,Occupancy,Block Limit Warps,block,4,,,,,
0,56556,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(512, 512, 1)",0,7.5,Occupancy,Theoretical Active Warps per SM,warp,32,,,,,
0,56556,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(512, 512, 1)",0,7.5,Occupancy,Theoretical Occupancy,%,100,,,,,
0,56556,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(512, 512, 1)",0,7.5,Occupancy,Achieved Occupancy,%,87.44,,,,,
0,56556,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(512, 512, 1)",0,7.5,Occupancy,Achieved Active Warps Per SM,warp,27.98,,,,,
0,56556,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(512, 512, 1)",0,7.5,Occupancy,,,,AchievedOccupancy,OPT,The difference between calculated theoretical (100.0%) and measured achieved occupancy (87.4%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy.,global,12.56
0,56556,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(512, 512, 1)",0,7.5,Source Counters,Branch Instructions Ratio,%,0.06,,,,,
0,56556,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(512, 512, 1)",0,7.5,Source Counters,Branch Instructions,inst,"2,097,152",,,,,
0,56556,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(512, 512, 1)",0,7.5,Source Counters,Branch Efficiency,%,0,,,,,
0,56556,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(512, 512, 1)",0,7.5,Source Counters,Avg. Divergent Branches,,0,,,,,
0,56556,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(512, 512, 1)",0,7.5,SourceCounters,,,,UncoalescedGlobalAccess,OPT,This kernel has uncoalesced global accesses resulting in a total of 75497472 excessive sectors (75% of the total 100663296 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source locations. The CUDA Programming Guide (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) has additional information on reducing uncoalesced device memory accesses.,global,74.33
0,56658,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(256, 256, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Frequency,cycle/second,"6,012,947,863.66",,,,,
0,56658,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(256, 256, 1)",0,7.5,GPU Speed Of Light Throughput,SM Frequency,cycle/second,"1,382,144,707.12",,,,,
0,56658,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(256, 256, 1)",0,7.5,GPU Speed Of Light Throughput,Elapsed Cycles,cycle,"33,655,173",,,,,
0,56658,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(256, 256, 1)",0,7.5,GPU Speed Of Light Throughput,Memory Throughput,%,58.49,,,,,
0,56658,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(256, 256, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Throughput,%,17.21,,,,,
0,56658,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(256, 256, 1)",0,7.5,GPU Speed Of Light Throughput,Duration,nsecond,"24,309,184",,,,,
0,56658,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(256, 256, 1)",0,7.5,GPU Speed Of Light Throughput,L1/TEX Cache Throughput,%,87.39,,,,,
0,56658,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(256, 256, 1)",0,7.5,GPU Speed Of Light Throughput,L2 Cache Throughput,%,58.49,,,,,
0,56658,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(256, 256, 1)",0,7.5,GPU Speed Of Light Throughput,SM Active Cycles,cycle,"32,869,592.50",,,,,
0,56658,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(256, 256, 1)",0,7.5,GPU Speed Of Light Throughput,Compute (SM) Throughput,%,4.46,,,,,
0,56658,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(256, 256, 1)",0,7.5,SpeedOfLight,,,,SOLBottleneck,OPT,This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.,,
0,56658,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(256, 256, 1)",0,7.5,SpeedOfLight_RooflineChart,,,,SOLFPRoofline,INF,The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved  close to 0% of this device's fp32 peak performance and 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.,,
0,56658,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(256, 256, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Active,inst/cycle,0.08,,,,,
0,56658,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(256, 256, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Elapsed,inst/cycle,0.08,,,,,
0,56658,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(256, 256, 1)",0,7.5,Compute Workload Analysis,Issue Slots Busy,%,1.94,,,,,
0,56658,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(256, 256, 1)",0,7.5,Compute Workload Analysis,Issued Ipc Active,inst/cycle,0.08,,,,,
0,56658,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(256, 256, 1)",0,7.5,Compute Workload Analysis,SM Busy,%,2.13,,,,,
0,56658,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(256, 256, 1)",0,7.5,ComputeWorkloadAnalysis,,,,HighPipeUtilization,OPT,All compute pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.,local,98.4
0,56658,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(256, 256, 1)",0,7.5,Memory Workload Analysis,Memory Throughput,byte/second,"33,115,866,003.56",,,,,
0,56658,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(256, 256, 1)",0,7.5,Memory Workload Analysis,Mem Busy,%,43.69,,,,,
0,56658,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(256, 256, 1)",0,7.5,Memory Workload Analysis,Max Bandwidth,%,58.49,,,,,
0,56658,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(256, 256, 1)",0,7.5,Memory Workload Analysis,L1/TEX Hit Rate,%,90.62,,,,,
0,56658,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(256, 256, 1)",0,7.5,Memory Workload Analysis,L2 Hit Rate,%,90.00,,,,,
0,56658,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(256, 256, 1)",0,7.5,Memory Workload Analysis,Mem Pipes Busy,%,4.46,,,,,
0,56658,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(256, 256, 1)",0,7.5,MemoryWorkloadAnalysis_Chart,,,,MemoryL2Compression,WRN,The optional metric lts__average_gcomp_input_sector_success_rate.pct could not be found. Collecting it as an additional metric could enable the rule to provide more guidance.,,
0,56658,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(256, 256, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for global loads in L1TEX might not be optimal. On average, this kernel accesses 4.0 bytes per thread per memory request; but the address pattern, possibly caused by the stride between threads, results in 32.0 sectors per request, or 32.0*32 = 1024.0 bytes of cache data transfers per request. The optimal thread address pattern for 4.0 byte accesses would result in 4.0*32 = 128.0 bytes of cache data transfers per request, to maximize L1TEX cache performance. Check the Source Counters section for uncoalesced global loads.",global,2.34
0,56658,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(256, 256, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for global stores in L1TEX might not be optimal. On average, this kernel accesses 4.0 bytes per thread per memory request; but the address pattern, possibly caused by the stride between threads, results in 32.0 sectors per request, or 32.0*32 = 1024.0 bytes of cache data transfers per request. The optimal thread address pattern for 4.0 byte accesses would result in 4.0*32 = 128.0 bytes of cache data transfers per request, to maximize L1TEX cache performance. Check the Source Counters section for uncoalesced global stores.",global,2.34
0,56658,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(256, 256, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for loads from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced loads and try to minimize how many cache lines need to be accessed per memory request.",global,4.891
0,56658,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(256, 256, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for stores from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced stores and try to minimize how many cache lines need to be accessed per memory request.",global,19.56
0,56658,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(256, 256, 1)",0,7.5,Scheduler Statistics,One or More Eligible,%,2.05,,,,,
0,56658,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(256, 256, 1)",0,7.5,Scheduler Statistics,Issued Warp Per Scheduler,,0.02,,,,,
0,56658,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(256, 256, 1)",0,7.5,Scheduler Statistics,No Eligible,%,97.95,,,,,
0,56658,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(256, 256, 1)",0,7.5,Scheduler Statistics,Active Warps Per Scheduler,warp,6.10,,,,,
0,56658,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(256, 256, 1)",0,7.5,Scheduler Statistics,Eligible Warps Per Scheduler,warp,0.04,,,,,
0,56658,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(256, 256, 1)",0,7.5,SchedulerStats,,,,IssueSlotUtilization,OPT,"Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 48.7 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of 6.10 active warps per scheduler, but only an average of 0.04 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections.",local,41.51
0,56658,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(256, 256, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Issued Instruction,cycle,297.01,,,,,
0,56658,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(256, 256, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Executed Instruction,cycle,297.03,,,,,
0,56658,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(256, 256, 1)",0,7.5,Warp State Statistics,Avg. Active Threads Per Warp,,32,,,,,
0,56658,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(256, 256, 1)",0,7.5,Warp State Statistics,Avg. Not Predicated Off Threads Per Warp,,32,,,,,
0,56658,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(256, 256, 1)",0,7.5,WarpStateStats,,,,CPIStall,OPT,"On average, each warp of this kernel spends 186.9 cycles being stalled waiting for a scoreboard dependency on a L1TEX (local, global, surface, texture) operation. Find the instruction producing the data being waited upon to identify the culprit. To reduce the number of cycles waiting on L1TEX data accesses verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit rates by increasing data locality (coalescing), or by changing the cache configuration. Consider moving frequently used data to shared memory. This stall type represents about 62.9% of the total average of 297.0 cycles between issuing two instructions.",global,41.51
0,56658,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(256, 256, 1)",0,7.5,WarpStateStats,,,,CPIStall,INF,Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.,,
0,56658,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(256, 256, 1)",0,7.5,Instruction Statistics,Avg. Executed Instructions Per Scheduler,inst,"636,635.43",,,,,
0,56658,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(256, 256, 1)",0,7.5,Instruction Statistics,Executed Instructions,inst,"35,651,584",,,,,
0,56658,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(256, 256, 1)",0,7.5,Instruction Statistics,Avg. Issued Instructions Per Scheduler,inst,"636,667.43",,,,,
0,56658,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(256, 256, 1)",0,7.5,Instruction Statistics,Issued Instructions,inst,"35,653,376",,,,,
0,56658,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(256, 256, 1)",0,7.5,InstructionStats,,,,FPInstructions,OPT,"This kernel executes 0 fused and 2097152 non-fused FP32 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP32 performance could be increased by up to 50% (relative to its current performance). Check the Source page to identify where this kernel executes FP32 instructions.",global,0.7975
0,56658,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(256, 256, 1)",0,7.5,Launch Statistics,Block Size,,"1,024",,,,,
0,56658,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(256, 256, 1)",0,7.5,Launch Statistics,Function Cache Configuration,,CachePreferNone,,,,,
0,56658,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(256, 256, 1)",0,7.5,Launch Statistics,Grid Size,,"65,536",,,,,
0,56658,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(256, 256, 1)",0,7.5,Launch Statistics,Registers Per Thread,register/thread,16,,,,,
0,56658,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(256, 256, 1)",0,7.5,Launch Statistics,Shared Memory Configuration Size,byte,"32,768",,,,,
0,56658,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(256, 256, 1)",0,7.5,Launch Statistics,Driver Shared Memory Per Block,byte/block,0,,,,,
0,56658,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(256, 256, 1)",0,7.5,Launch Statistics,Dynamic Shared Memory Per Block,byte/block,0,,,,,
0,56658,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(256, 256, 1)",0,7.5,Launch Statistics,Static Shared Memory Per Block,byte/block,0,,,,,
0,56658,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(256, 256, 1)",0,7.5,Launch Statistics,Threads,thread,"67,108,864",,,,,
0,56658,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(256, 256, 1)",0,7.5,Launch Statistics,Waves Per SM,,"4,681.14",,,,,
0,56658,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(256, 256, 1)",0,7.5,Occupancy,Block Limit SM,block,16,,,,,
0,56658,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(256, 256, 1)",0,7.5,Occupancy,Block Limit Registers,block,4,,,,,
0,56658,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(256, 256, 1)",0,7.5,Occupancy,Block Limit Shared Mem,block,16,,,,,
0,56658,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(256, 256, 1)",0,7.5,Occupancy,Block Limit Warps,block,1,,,,,
0,56658,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(256, 256, 1)",0,7.5,Occupancy,Theoretical Active Warps per SM,warp,32,,,,,
0,56658,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(256, 256, 1)",0,7.5,Occupancy,Theoretical Occupancy,%,100,,,,,
0,56658,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(256, 256, 1)",0,7.5,Occupancy,Achieved Occupancy,%,72.32,,,,,
0,56658,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(256, 256, 1)",0,7.5,Occupancy,Achieved Active Warps Per SM,warp,23.14,,,,,
0,56658,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(256, 256, 1)",0,7.5,Occupancy,,,,AchievedOccupancy,OPT,The difference between calculated theoretical (100.0%) and measured achieved occupancy (72.3%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy.,global,27.68
0,56658,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(256, 256, 1)",0,7.5,Source Counters,Branch Instructions Ratio,%,0.06,,,,,
0,56658,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(256, 256, 1)",0,7.5,Source Counters,Branch Instructions,inst,"2,097,152",,,,,
0,56658,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(256, 256, 1)",0,7.5,Source Counters,Branch Efficiency,%,0,,,,,
0,56658,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(256, 256, 1)",0,7.5,Source Counters,Avg. Divergent Branches,,0,,,,,
0,56658,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(256, 256, 1)",0,7.5,SourceCounters,,,,UncoalescedGlobalAccess,OPT,This kernel has uncoalesced global accesses resulting in a total of 176160768 excessive sectors (88% of the total 201326592 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source locations. The CUDA Programming Guide (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) has additional information on reducing uncoalesced device memory accesses.,global,87.42
0,56753,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(16384, 16384, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Frequency,cycle/second,"5,995,990,634.47",,,,,
0,56753,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(16384, 16384, 1)",0,7.5,GPU Speed Of Light Throughput,SM Frequency,cycle/second,"1,379,199,367.97",,,,,
0,56753,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(16384, 16384, 1)",0,7.5,GPU Speed Of Light Throughput,Elapsed Cycles,cycle,"1,555,058,428",,,,,
0,56753,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(16384, 16384, 1)",0,7.5,GPU Speed Of Light Throughput,Memory Throughput,%,19.88,,,,,
0,56753,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(16384, 16384, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Throughput,%,19.88,,,,,
0,56753,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(16384, 16384, 1)",0,7.5,GPU Speed Of Light Throughput,Duration,nsecond,"1,126,035,520",,,,,
0,56753,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(16384, 16384, 1)",0,7.5,GPU Speed Of Light Throughput,L1/TEX Cache Throughput,%,13.96,,,,,
0,56753,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(16384, 16384, 1)",0,7.5,GPU Speed Of Light Throughput,L2 Cache Throughput,%,9.03,,,,,
0,56753,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(16384, 16384, 1)",0,7.5,GPU Speed Of Light Throughput,SM Active Cycles,cycle,"1,373,461,866.29",,,,,
0,56753,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(16384, 16384, 1)",0,7.5,GPU Speed Of Light Throughput,Compute (SM) Throughput,%,12.34,,,,,
0,56753,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(16384, 16384, 1)",0,7.5,SpeedOfLight,,,,SOLBottleneck,OPT,This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.,,
0,56753,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(16384, 16384, 1)",0,7.5,SpeedOfLight_RooflineChart,,,,SOLFPRoofline,INF,The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved  close to 0% of this device's fp32 peak performance and 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.,,
0,56753,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(16384, 16384, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Active,inst/cycle,0.24,,,,,
0,56753,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(16384, 16384, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Elapsed,inst/cycle,0.21,,,,,
0,56753,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(16384, 16384, 1)",0,7.5,Compute Workload Analysis,Issue Slots Busy,%,5.93,,,,,
0,56753,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(16384, 16384, 1)",0,7.5,Compute Workload Analysis,Issued Ipc Active,inst/cycle,0.24,,,,,
0,56753,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(16384, 16384, 1)",0,7.5,Compute Workload Analysis,SM Busy,%,6.51,,,,,
0,56753,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(16384, 16384, 1)",0,7.5,ComputeWorkloadAnalysis,,,,HighPipeUtilization,OPT,All compute pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.,local,95.11
0,56753,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(16384, 16384, 1)",0,7.5,Memory Workload Analysis,Memory Throughput,byte/second,"38,144,275,832.44",,,,,
0,56753,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(16384, 16384, 1)",0,7.5,Memory Workload Analysis,Mem Busy,%,6.77,,,,,
0,56753,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(16384, 16384, 1)",0,7.5,Memory Workload Analysis,Max Bandwidth,%,19.88,,,,,
0,56753,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(16384, 16384, 1)",0,7.5,Memory Workload Analysis,L1/TEX Hit Rate,%,0,,,,,
0,56753,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(16384, 16384, 1)",0,7.5,Memory Workload Analysis,L2 Hit Rate,%,33.33,,,,,
0,56753,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(16384, 16384, 1)",0,7.5,Memory Workload Analysis,Mem Pipes Busy,%,12.34,,,,,
0,56753,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(16384, 16384, 1)",0,7.5,MemoryWorkloadAnalysis_Chart,,,,MemoryL2Compression,WRN,The optional metric lts__average_gcomp_input_sector_success_rate.pct could not be found. Collecting it as an additional metric could enable the rule to provide more guidance.,,
0,56753,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(16384, 16384, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for loads from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced loads and try to minimize how many cache lines need to be accessed per memory request.",global,3.386
0,56753,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(16384, 16384, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for stores from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced stores and try to minimize how many cache lines need to be accessed per memory request.",global,1.693
0,56753,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(16384, 16384, 1)",0,7.5,Scheduler Statistics,One or More Eligible,%,6.56,,,,,
0,56753,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(16384, 16384, 1)",0,7.5,Scheduler Statistics,Issued Warp Per Scheduler,,0.07,,,,,
0,56753,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(16384, 16384, 1)",0,7.5,Scheduler Statistics,No Eligible,%,93.44,,,,,
0,56753,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(16384, 16384, 1)",0,7.5,Scheduler Statistics,Active Warps Per Scheduler,warp,2.92,,,,,
0,56753,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(16384, 16384, 1)",0,7.5,Scheduler Statistics,Eligible Warps Per Scheduler,warp,0.07,,,,,
0,56753,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(16384, 16384, 1)",0,7.5,SchedulerStats,,,,IssueSlotUtilization,OPT,"Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 15.2 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of 2.92 active warps per scheduler, but only an average of 0.07 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections.",local,80.12
0,56753,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(16384, 16384, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Issued Instruction,cycle,44.52,,,,,
0,56753,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(16384, 16384, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Executed Instruction,cycle,44.52,,,,,
0,56753,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(16384, 16384, 1)",0,7.5,Warp State Statistics,Avg. Active Threads Per Warp,,1,,,,,
0,56753,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(16384, 16384, 1)",0,7.5,Warp State Statistics,Avg. Not Predicated Off Threads Per Warp,,1,,,,,
0,56753,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(16384, 16384, 1)",0,7.5,WarpStateStats,,,,CPIStall,OPT,"On average, each warp of this kernel spends 37.5 cycles being stalled waiting for a scoreboard dependency on a L1TEX (local, global, surface, texture) operation. Find the instruction producing the data being waited upon to identify the culprit. To reduce the number of cycles waiting on L1TEX data accesses verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit rates by increasing data locality (coalescing), or by changing the cache configuration. Consider moving frequently used data to shared memory. This stall type represents about 84.3% of the total average of 44.5 cycles between issuing two instructions.",global,80.12
0,56753,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(16384, 16384, 1)",0,7.5,WarpStateStats,,,,CPIStall,INF,Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.,,
0,56753,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(16384, 16384, 1)",0,7.5,WarpStateStats,,,,ThreadDivergence,OPT,"Instructions are executed in warps, which are groups of 32 threads. Optimal instruction throughput is achieved if all 32 threads of a warp execute the same instruction. The chosen launch configuration, early thread completion, and divergent flow control can significantly lower the number of active threads in a warp per cycle. This kernel achieves an average of 1.0 threads being active per cycle.",global,11.96
0,56753,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(16384, 16384, 1)",0,7.5,Instruction Statistics,Avg. Executed Instructions Per Scheduler,inst,"81,489,334.86",,,,,
0,56753,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(16384, 16384, 1)",0,7.5,Instruction Statistics,Executed Instructions,inst,"4,563,402,752",,,,,
0,56753,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(16384, 16384, 1)",0,7.5,Instruction Statistics,Avg. Issued Instructions Per Scheduler,inst,"81,489,348.77",,,,,
0,56753,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(16384, 16384, 1)",0,7.5,Instruction Statistics,Issued Instructions,inst,"4,563,403,531",,,,,
0,56753,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(16384, 16384, 1)",0,7.5,InstructionStats,,,,FPInstructions,OPT,"This kernel executes 0 fused and 268435456 non-fused FP32 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP32 performance could be increased by up to 50% (relative to its current performance). Check the Source page to identify where this kernel executes FP32 instructions.",global,2.443
0,56753,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(16384, 16384, 1)",0,7.5,Launch Statistics,Block Size,,1,,,,,
0,56753,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(16384, 16384, 1)",0,7.5,Launch Statistics,Function Cache Configuration,,CachePreferNone,,,,,
0,56753,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(16384, 16384, 1)",0,7.5,Launch Statistics,Grid Size,,"268,435,456",,,,,
0,56753,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(16384, 16384, 1)",0,7.5,Launch Statistics,Registers Per Thread,register/thread,16,,,,,
0,56753,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(16384, 16384, 1)",0,7.5,Launch Statistics,Shared Memory Configuration Size,byte,"32,768",,,,,
0,56753,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(16384, 16384, 1)",0,7.5,Launch Statistics,Driver Shared Memory Per Block,byte/block,0,,,,,
0,56753,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(16384, 16384, 1)",0,7.5,Launch Statistics,Dynamic Shared Memory Per Block,byte/block,0,,,,,
0,56753,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(16384, 16384, 1)",0,7.5,Launch Statistics,Static Shared Memory Per Block,byte/block,0,,,,,
0,56753,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(16384, 16384, 1)",0,7.5,Launch Statistics,Threads,thread,"268,435,456",,,,,
0,56753,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(16384, 16384, 1)",0,7.5,Launch Statistics,Waves Per SM,,"1,198,372.57",,,,,
0,56753,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(16384, 16384, 1)",0,7.5,LaunchStats,,,,LaunchConfiguration,OPT,"Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 1 threads per block. Consequently, some threads in a warp are masked off and those hardware resources are unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256 threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to kernels that frequently call __syncthreads(). See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations.",global,96.88
0,56753,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(16384, 16384, 1)",0,7.5,Occupancy,Block Limit SM,block,16,,,,,
0,56753,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(16384, 16384, 1)",0,7.5,Occupancy,Block Limit Registers,block,128,,,,,
0,56753,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(16384, 16384, 1)",0,7.5,Occupancy,Block Limit Shared Mem,block,16,,,,,
0,56753,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(16384, 16384, 1)",0,7.5,Occupancy,Block Limit Warps,block,32,,,,,
0,56753,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(16384, 16384, 1)",0,7.5,Occupancy,Theoretical Active Warps per SM,warp,16,,,,,
0,56753,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(16384, 16384, 1)",0,7.5,Occupancy,Theoretical Occupancy,%,50,,,,,
0,56753,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(16384, 16384, 1)",0,7.5,Occupancy,Achieved Occupancy,%,33.82,,,,,
0,56753,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(16384, 16384, 1)",0,7.5,Occupancy,Achieved Active Warps Per SM,warp,10.82,,,,,
0,56753,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(16384, 16384, 1)",0,7.5,Occupancy,,,,AchievedOccupancy,OPT,The difference between calculated theoretical (50.0%) and measured achieved occupancy (33.8%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy.,global,32.37
0,56753,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(16384, 16384, 1)",0,7.5,Occupancy,,,,TheoreticalOccupancy,OPT,The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared memory.,global,50.0
0,56753,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(16384, 16384, 1)",0,7.5,Source Counters,Branch Instructions Ratio,%,0.06,,,,,
0,56753,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(16384, 16384, 1)",0,7.5,Source Counters,Branch Instructions,inst,"268,435,456",,,,,
0,56753,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(16384, 16384, 1)",0,7.5,Source Counters,Branch Efficiency,%,0,,,,,
0,56753,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(1, 1, 1)","(16384, 16384, 1)",0,7.5,Source Counters,Avg. Divergent Branches,,0,,,,,
0,57123,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(8192, 8192, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Frequency,cycle/second,"5,998,105,538.50",,,,,
0,57123,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(8192, 8192, 1)",0,7.5,GPU Speed Of Light Throughput,SM Frequency,cycle/second,"1,378,953,694.76",,,,,
0,57123,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(8192, 8192, 1)",0,7.5,GPU Speed Of Light Throughput,Elapsed Cycles,cycle,"704,499,849",,,,,
0,57123,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(8192, 8192, 1)",0,7.5,GPU Speed Of Light Throughput,Memory Throughput,%,21.94,,,,,
0,57123,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(8192, 8192, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Throughput,%,21.94,,,,,
0,57123,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(8192, 8192, 1)",0,7.5,GPU Speed Of Light Throughput,Duration,nsecond,"510,051,008",,,,,
0,57123,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(8192, 8192, 1)",0,7.5,GPU Speed Of Light Throughput,L1/TEX Cache Throughput,%,11.08,,,,,
0,57123,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(8192, 8192, 1)",0,7.5,GPU Speed Of Light Throughput,L2 Cache Throughput,%,9.97,,,,,
0,57123,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(8192, 8192, 1)",0,7.5,GPU Speed Of Light Throughput,SM Active Cycles,cycle,"696,199,522.71",,,,,
0,57123,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(8192, 8192, 1)",0,7.5,GPU Speed Of Light Throughput,Compute (SM) Throughput,%,6.81,,,,,
0,57123,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(8192, 8192, 1)",0,7.5,SpeedOfLight,,,,SOLBottleneck,OPT,This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.,,
0,57123,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(8192, 8192, 1)",0,7.5,SpeedOfLight_RooflineChart,,,,SOLFPRoofline,INF,The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved  close to 0% of this device's fp32 peak performance and 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.,,
0,57123,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(8192, 8192, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Active,inst/cycle,0.12,,,,,
0,57123,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(8192, 8192, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Elapsed,inst/cycle,0.12,,,,,
0,57123,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(8192, 8192, 1)",0,7.5,Compute Workload Analysis,Issue Slots Busy,%,2.93,,,,,
0,57123,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(8192, 8192, 1)",0,7.5,Compute Workload Analysis,Issued Ipc Active,inst/cycle,0.12,,,,,
0,57123,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(8192, 8192, 1)",0,7.5,Compute Workload Analysis,SM Busy,%,3.21,,,,,
0,57123,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(8192, 8192, 1)",0,7.5,ComputeWorkloadAnalysis,,,,HighPipeUtilization,OPT,All compute pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.,local,97.59
0,57123,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(8192, 8192, 1)",0,7.5,Memory Workload Analysis,Memory Throughput,byte/second,"42,104,846,799.95",,,,,
0,57123,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(8192, 8192, 1)",0,7.5,Memory Workload Analysis,Mem Busy,%,7.99,,,,,
0,57123,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(8192, 8192, 1)",0,7.5,Memory Workload Analysis,Max Bandwidth,%,21.94,,,,,
0,57123,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(8192, 8192, 1)",0,7.5,Memory Workload Analysis,L1/TEX Hit Rate,%,0,,,,,
0,57123,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(8192, 8192, 1)",0,7.5,Memory Workload Analysis,L2 Hit Rate,%,33.33,,,,,
0,57123,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(8192, 8192, 1)",0,7.5,Memory Workload Analysis,Mem Pipes Busy,%,6.81,,,,,
0,57123,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(8192, 8192, 1)",0,7.5,MemoryWorkloadAnalysis_Chart,,,,MemoryL2Compression,WRN,The optional metric lts__average_gcomp_input_sector_success_rate.pct could not be found. Collecting it as an additional metric could enable the rule to provide more guidance.,,
0,57123,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(8192, 8192, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for loads from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced loads and try to minimize how many cache lines need to be accessed per memory request.",global,3.739
0,57123,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(8192, 8192, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for stores from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced stores and try to minimize how many cache lines need to be accessed per memory request.",global,1.869
0,57123,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(8192, 8192, 1)",0,7.5,Scheduler Statistics,One or More Eligible,%,2.96,,,,,
0,57123,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(8192, 8192, 1)",0,7.5,Scheduler Statistics,Issued Warp Per Scheduler,,0.03,,,,,
0,57123,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(8192, 8192, 1)",0,7.5,Scheduler Statistics,No Eligible,%,97.04,,,,,
0,57123,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(8192, 8192, 1)",0,7.5,Scheduler Statistics,Active Warps Per Scheduler,warp,3.55,,,,,
0,57123,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(8192, 8192, 1)",0,7.5,Scheduler Statistics,Eligible Warps Per Scheduler,warp,0.03,,,,,
0,57123,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(8192, 8192, 1)",0,7.5,SchedulerStats,,,,IssueSlotUtilization,OPT,"Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 33.8 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of 3.55 active warps per scheduler, but only an average of 0.03 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, avoid possible load imbalances due to highly different execution durations per warp. Reducing stalls indicated on the Warp State Statistics and Source Counters sections can help, too.",local,78.06
0,57123,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(8192, 8192, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Issued Instruction,cycle,119.92,,,,,
0,57123,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(8192, 8192, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Executed Instruction,cycle,119.92,,,,,
0,57123,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(8192, 8192, 1)",0,7.5,Warp State Statistics,Avg. Active Threads Per Warp,,4,,,,,
0,57123,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(8192, 8192, 1)",0,7.5,Warp State Statistics,Avg. Not Predicated Off Threads Per Warp,,4,,,,,
0,57123,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(8192, 8192, 1)",0,7.5,WarpStateStats,,,,CPIStall,OPT,"On average, each warp of this kernel spends 112.9 cycles being stalled waiting for a scoreboard dependency on a L1TEX (local, global, surface, texture) operation. Find the instruction producing the data being waited upon to identify the culprit. To reduce the number of cycles waiting on L1TEX data accesses verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit rates by increasing data locality (coalescing), or by changing the cache configuration. Consider moving frequently used data to shared memory. This stall type represents about 94.1% of the total average of 119.9 cycles between issuing two instructions.",global,78.06
0,57123,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(8192, 8192, 1)",0,7.5,WarpStateStats,,,,CPIStall,INF,Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.,,
0,57123,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(8192, 8192, 1)",0,7.5,WarpStateStats,,,,ThreadDivergence,OPT,"Instructions are executed in warps, which are groups of 32 threads. Optimal instruction throughput is achieved if all 32 threads of a warp execute the same instruction. The chosen launch configuration, early thread completion, and divergent flow control can significantly lower the number of active threads in a warp per cycle. This kernel achieves an average of 4.0 threads being active per cycle.",global,5.962
0,57123,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(8192, 8192, 1)",0,7.5,Instruction Statistics,Avg. Executed Instructions Per Scheduler,inst,"20,372,333.71",,,,,
0,57123,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(8192, 8192, 1)",0,7.5,Instruction Statistics,Executed Instructions,inst,"1,140,850,688",,,,,
0,57123,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(8192, 8192, 1)",0,7.5,Instruction Statistics,Avg. Issued Instructions Per Scheduler,inst,"20,372,347.62",,,,,
0,57123,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(8192, 8192, 1)",0,7.5,Instruction Statistics,Issued Instructions,inst,"1,140,851,467",,,,,
0,57123,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(8192, 8192, 1)",0,7.5,InstructionStats,,,,FPInstructions,OPT,"This kernel executes 0 fused and 67108864 non-fused FP32 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP32 performance could be increased by up to 50% (relative to its current performance). Check the Source page to identify where this kernel executes FP32 instructions.",global,1.205
0,57123,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(8192, 8192, 1)",0,7.5,Launch Statistics,Block Size,,4,,,,,
0,57123,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(8192, 8192, 1)",0,7.5,Launch Statistics,Function Cache Configuration,,CachePreferNone,,,,,
0,57123,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(8192, 8192, 1)",0,7.5,Launch Statistics,Grid Size,,"67,108,864",,,,,
0,57123,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(8192, 8192, 1)",0,7.5,Launch Statistics,Registers Per Thread,register/thread,16,,,,,
0,57123,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(8192, 8192, 1)",0,7.5,Launch Statistics,Shared Memory Configuration Size,byte,"32,768",,,,,
0,57123,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(8192, 8192, 1)",0,7.5,Launch Statistics,Driver Shared Memory Per Block,byte/block,0,,,,,
0,57123,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(8192, 8192, 1)",0,7.5,Launch Statistics,Dynamic Shared Memory Per Block,byte/block,0,,,,,
0,57123,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(8192, 8192, 1)",0,7.5,Launch Statistics,Static Shared Memory Per Block,byte/block,0,,,,,
0,57123,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(8192, 8192, 1)",0,7.5,Launch Statistics,Threads,thread,"268,435,456",,,,,
0,57123,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(8192, 8192, 1)",0,7.5,Launch Statistics,Waves Per SM,,"299,593.14",,,,,
0,57123,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(8192, 8192, 1)",0,7.5,LaunchStats,,,,LaunchConfiguration,OPT,"Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 4 threads per block. Consequently, some threads in a warp are masked off and those hardware resources are unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256 threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to kernels that frequently call __syncthreads(). See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations.",global,87.5
0,57123,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(8192, 8192, 1)",0,7.5,Occupancy,Block Limit SM,block,16,,,,,
0,57123,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(8192, 8192, 1)",0,7.5,Occupancy,Block Limit Registers,block,128,,,,,
0,57123,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(8192, 8192, 1)",0,7.5,Occupancy,Block Limit Shared Mem,block,16,,,,,
0,57123,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(8192, 8192, 1)",0,7.5,Occupancy,Block Limit Warps,block,32,,,,,
0,57123,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(8192, 8192, 1)",0,7.5,Occupancy,Theoretical Active Warps per SM,warp,16,,,,,
0,57123,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(8192, 8192, 1)",0,7.5,Occupancy,Theoretical Occupancy,%,50,,,,,
0,57123,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(8192, 8192, 1)",0,7.5,Occupancy,Achieved Occupancy,%,44.27,,,,,
0,57123,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(8192, 8192, 1)",0,7.5,Occupancy,Achieved Active Warps Per SM,warp,14.16,,,,,
0,57123,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(8192, 8192, 1)",0,7.5,Occupancy,,,,TheoreticalOccupancy,OPT,The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared memory.,global,50.0
0,57123,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(8192, 8192, 1)",0,7.5,Source Counters,Branch Instructions Ratio,%,0.06,,,,,
0,57123,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(8192, 8192, 1)",0,7.5,Source Counters,Branch Instructions,inst,"67,108,864",,,,,
0,57123,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(8192, 8192, 1)",0,7.5,Source Counters,Branch Efficiency,%,0,,,,,
0,57123,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(8192, 8192, 1)",0,7.5,Source Counters,Avg. Divergent Branches,,0,,,,,
0,57123,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(2, 2, 1)","(8192, 8192, 1)",0,7.5,SourceCounters,,,,UncoalescedGlobalAccess,OPT,This kernel has uncoalesced global accesses resulting in a total of 201326592 excessive sectors (50% of the total 402653184 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source locations. The CUDA Programming Guide (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) has additional information on reducing uncoalesced device memory accesses.,global,47.87
0,57356,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(4096, 4096, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Frequency,cycle/second,"5,982,173,604.73",,,,,
0,57356,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(4096, 4096, 1)",0,7.5,GPU Speed Of Light Throughput,SM Frequency,cycle/second,"1,390,236,700.05",,,,,
0,57356,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(4096, 4096, 1)",0,7.5,GPU Speed Of Light Throughput,Elapsed Cycles,cycle,"341,731,059",,,,,
0,57356,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(4096, 4096, 1)",0,7.5,GPU Speed Of Light Throughput,Memory Throughput,%,22.84,,,,,
0,57356,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(4096, 4096, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Throughput,%,22.84,,,,,
0,57356,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(4096, 4096, 1)",0,7.5,GPU Speed Of Light Throughput,Duration,nsecond,"245,575,616",,,,,
0,57356,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(4096, 4096, 1)",0,7.5,GPU Speed Of Light Throughput,L1/TEX Cache Throughput,%,11.23,,,,,
0,57356,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(4096, 4096, 1)",0,7.5,GPU Speed Of Light Throughput,L2 Cache Throughput,%,10.37,,,,,
0,57356,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(4096, 4096, 1)",0,7.5,GPU Speed Of Light Throughput,SM Active Cycles,cycle,"341,641,261.14",,,,,
0,57356,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(4096, 4096, 1)",0,7.5,GPU Speed Of Light Throughput,Compute (SM) Throughput,%,3.51,,,,,
0,57356,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(4096, 4096, 1)",0,7.5,SpeedOfLight,,,,SOLBottleneck,OPT,This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.,,
0,57356,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(4096, 4096, 1)",0,7.5,SpeedOfLight_RooflineChart,,,,SOLFPRoofline,INF,The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved  close to 0% of this device's fp32 peak performance and 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.,,
0,57356,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(4096, 4096, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Active,inst/cycle,0.06,,,,,
0,57356,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(4096, 4096, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Elapsed,inst/cycle,0.06,,,,,
0,57356,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(4096, 4096, 1)",0,7.5,Compute Workload Analysis,Issue Slots Busy,%,1.49,,,,,
0,57356,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(4096, 4096, 1)",0,7.5,Compute Workload Analysis,Issued Ipc Active,inst/cycle,0.06,,,,,
0,57356,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(4096, 4096, 1)",0,7.5,Compute Workload Analysis,SM Busy,%,1.64,,,,,
0,57356,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(4096, 4096, 1)",0,7.5,ComputeWorkloadAnalysis,,,,HighPipeUtilization,OPT,All compute pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.,local,98.77
0,57356,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(4096, 4096, 1)",0,7.5,Memory Workload Analysis,Memory Throughput,byte/second,"43,724,764,334.91",,,,,
0,57356,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(4096, 4096, 1)",0,7.5,Memory Workload Analysis,Mem Busy,%,8.59,,,,,
0,57356,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(4096, 4096, 1)",0,7.5,Memory Workload Analysis,Max Bandwidth,%,22.84,,,,,
0,57356,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(4096, 4096, 1)",0,7.5,Memory Workload Analysis,L1/TEX Hit Rate,%,0,,,,,
0,57356,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(4096, 4096, 1)",0,7.5,Memory Workload Analysis,L2 Hit Rate,%,33.33,,,,,
0,57356,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(4096, 4096, 1)",0,7.5,Memory Workload Analysis,Mem Pipes Busy,%,3.51,,,,,
0,57356,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(4096, 4096, 1)",0,7.5,MemoryWorkloadAnalysis_Chart,,,,MemoryL2Compression,WRN,The optional metric lts__average_gcomp_input_sector_success_rate.pct could not be found. Collecting it as an additional metric could enable the rule to provide more guidance.,,
0,57356,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(4096, 4096, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for loads from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced loads and try to minimize how many cache lines need to be accessed per memory request.",global,3.89
0,57356,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(4096, 4096, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for stores from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced stores and try to minimize how many cache lines need to be accessed per memory request.",global,1.945
0,57356,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(4096, 4096, 1)",0,7.5,Scheduler Statistics,One or More Eligible,%,1.49,,,,,
0,57356,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(4096, 4096, 1)",0,7.5,Scheduler Statistics,Issued Warp Per Scheduler,,0.01,,,,,
0,57356,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(4096, 4096, 1)",0,7.5,Scheduler Statistics,No Eligible,%,98.51,,,,,
0,57356,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(4096, 4096, 1)",0,7.5,Scheduler Statistics,Active Warps Per Scheduler,warp,3.85,,,,,
0,57356,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(4096, 4096, 1)",0,7.5,Scheduler Statistics,Eligible Warps Per Scheduler,warp,0.01,,,,,
0,57356,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(4096, 4096, 1)",0,7.5,SchedulerStats,,,,IssueSlotUtilization,OPT,"Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 67.1 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of 3.85 active warps per scheduler, but only an average of 0.01 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, avoid possible load imbalances due to highly different execution durations per warp. Reducing stalls indicated on the Warp State Statistics and Source Counters sections can help, too.",local,77.16
0,57356,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(4096, 4096, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Issued Instruction,cycle,258.06,,,,,
0,57356,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(4096, 4096, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Executed Instruction,cycle,258.06,,,,,
0,57356,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(4096, 4096, 1)",0,7.5,Warp State Statistics,Avg. Active Threads Per Warp,,16,,,,,
0,57356,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(4096, 4096, 1)",0,7.5,Warp State Statistics,Avg. Not Predicated Off Threads Per Warp,,16,,,,,
0,57356,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(4096, 4096, 1)",0,7.5,WarpStateStats,,,,CPIStall,OPT,"On average, each warp of this kernel spends 251.0 cycles being stalled waiting for a scoreboard dependency on a L1TEX (local, global, surface, texture) operation. Find the instruction producing the data being waited upon to identify the culprit. To reduce the number of cycles waiting on L1TEX data accesses verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit rates by increasing data locality (coalescing), or by changing the cache configuration. Consider moving frequently used data to shared memory. This stall type represents about 97.3% of the total average of 258.1 cycles between issuing two instructions.",global,77.16
0,57356,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(4096, 4096, 1)",0,7.5,WarpStateStats,,,,CPIStall,INF,Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.,,
0,57356,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(4096, 4096, 1)",0,7.5,WarpStateStats,,,,ThreadDivergence,OPT,"Instructions are executed in warps, which are groups of 32 threads. Optimal instruction throughput is achieved if all 32 threads of a warp execute the same instruction. The chosen launch configuration, early thread completion, and divergent flow control can significantly lower the number of active threads in a warp per cycle. This kernel achieves an average of 16.0 threads being active per cycle.",global,1.755
0,57356,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(4096, 4096, 1)",0,7.5,Instruction Statistics,Avg. Executed Instructions Per Scheduler,inst,"5,093,083.43",,,,,
0,57356,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(4096, 4096, 1)",0,7.5,Instruction Statistics,Executed Instructions,inst,"285,212,672",,,,,
0,57356,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(4096, 4096, 1)",0,7.5,Instruction Statistics,Avg. Issued Instructions Per Scheduler,inst,"5,093,097.39",,,,,
0,57356,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(4096, 4096, 1)",0,7.5,Instruction Statistics,Issued Instructions,inst,"285,213,454",,,,,
0,57356,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(4096, 4096, 1)",0,7.5,InstructionStats,,,,FPInstructions,OPT,"This kernel executes 0 fused and 16777216 non-fused FP32 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP32 performance could be increased by up to 50% (relative to its current performance). Check the Source page to identify where this kernel executes FP32 instructions.",global,0.6138
0,57356,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(4096, 4096, 1)",0,7.5,Launch Statistics,Block Size,,16,,,,,
0,57356,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(4096, 4096, 1)",0,7.5,Launch Statistics,Function Cache Configuration,,CachePreferNone,,,,,
0,57356,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(4096, 4096, 1)",0,7.5,Launch Statistics,Grid Size,,"16,777,216",,,,,
0,57356,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(4096, 4096, 1)",0,7.5,Launch Statistics,Registers Per Thread,register/thread,16,,,,,
0,57356,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(4096, 4096, 1)",0,7.5,Launch Statistics,Shared Memory Configuration Size,byte,"32,768",,,,,
0,57356,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(4096, 4096, 1)",0,7.5,Launch Statistics,Driver Shared Memory Per Block,byte/block,0,,,,,
0,57356,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(4096, 4096, 1)",0,7.5,Launch Statistics,Dynamic Shared Memory Per Block,byte/block,0,,,,,
0,57356,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(4096, 4096, 1)",0,7.5,Launch Statistics,Static Shared Memory Per Block,byte/block,0,,,,,
0,57356,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(4096, 4096, 1)",0,7.5,Launch Statistics,Threads,thread,"268,435,456",,,,,
0,57356,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(4096, 4096, 1)",0,7.5,Launch Statistics,Waves Per SM,,"74,898.29",,,,,
0,57356,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(4096, 4096, 1)",0,7.5,LaunchStats,,,,LaunchConfiguration,OPT,"Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 16 threads per block. Consequently, some threads in a warp are masked off and those hardware resources are unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256 threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to kernels that frequently call __syncthreads(). See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations.",global,50.0
0,57356,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(4096, 4096, 1)",0,7.5,Occupancy,Block Limit SM,block,16,,,,,
0,57356,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(4096, 4096, 1)",0,7.5,Occupancy,Block Limit Registers,block,128,,,,,
0,57356,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(4096, 4096, 1)",0,7.5,Occupancy,Block Limit Shared Mem,block,16,,,,,
0,57356,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(4096, 4096, 1)",0,7.5,Occupancy,Block Limit Warps,block,32,,,,,
0,57356,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(4096, 4096, 1)",0,7.5,Occupancy,Theoretical Active Warps per SM,warp,16,,,,,
0,57356,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(4096, 4096, 1)",0,7.5,Occupancy,Theoretical Occupancy,%,50,,,,,
0,57356,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(4096, 4096, 1)",0,7.5,Occupancy,Achieved Occupancy,%,48.27,,,,,
0,57356,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(4096, 4096, 1)",0,7.5,Occupancy,Achieved Active Warps Per SM,warp,15.45,,,,,
0,57356,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(4096, 4096, 1)",0,7.5,Occupancy,,,,TheoreticalOccupancy,OPT,The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared memory.,global,50.0
0,57356,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(4096, 4096, 1)",0,7.5,Source Counters,Branch Instructions Ratio,%,0.06,,,,,
0,57356,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(4096, 4096, 1)",0,7.5,Source Counters,Branch Instructions,inst,"16,777,216",,,,,
0,57356,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(4096, 4096, 1)",0,7.5,Source Counters,Branch Efficiency,%,0,,,,,
0,57356,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(4096, 4096, 1)",0,7.5,Source Counters,Avg. Divergent Branches,,0,,,,,
0,57356,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(4, 4, 1)","(4096, 4096, 1)",0,7.5,SourceCounters,,,,UncoalescedGlobalAccess,OPT,This kernel has uncoalesced global accesses resulting in a total of 100663296 excessive sectors (50% of the total 201326592 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source locations. The CUDA Programming Guide (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) has additional information on reducing uncoalesced device memory accesses.,global,49.0
0,57539,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(2048, 2048, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Frequency,cycle/second,"5,985,087,406.61",,,,,
0,57539,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(2048, 2048, 1)",0,7.5,GPU Speed Of Light Throughput,SM Frequency,cycle/second,"1,391,126,118.41",,,,,
0,57539,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(2048, 2048, 1)",0,7.5,GPU Speed Of Light Throughput,Elapsed Cycles,cycle,"169,714,722",,,,,
0,57539,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(2048, 2048, 1)",0,7.5,GPU Speed Of Light Throughput,Memory Throughput,%,22.99,,,,,
0,57539,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(2048, 2048, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Throughput,%,22.99,,,,,
0,57539,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(2048, 2048, 1)",0,7.5,GPU Speed Of Light Throughput,Duration,nsecond,"121,909,312",,,,,
0,57539,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(2048, 2048, 1)",0,7.5,GPU Speed Of Light Throughput,L1/TEX Cache Throughput,%,18.76,,,,,
0,57539,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(2048, 2048, 1)",0,7.5,GPU Speed Of Light Throughput,L2 Cache Throughput,%,10.44,,,,,
0,57539,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(2048, 2048, 1)",0,7.5,GPU Speed Of Light Throughput,SM Active Cycles,cycle,"169,762,175.50",,,,,
0,57539,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(2048, 2048, 1)",0,7.5,GPU Speed Of Light Throughput,Compute (SM) Throughput,%,3.53,,,,,
0,57539,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(2048, 2048, 1)",0,7.5,SpeedOfLight,,,,SOLBottleneck,OPT,This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.,,
0,57539,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(2048, 2048, 1)",0,7.5,SpeedOfLight_RooflineChart,,,,SOLFPRoofline,INF,The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved  close to 0% of this device's fp32 peak performance and 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.,,
0,57539,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(2048, 2048, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Active,inst/cycle,0.06,,,,,
0,57539,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(2048, 2048, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Elapsed,inst/cycle,0.06,,,,,
0,57539,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(2048, 2048, 1)",0,7.5,Compute Workload Analysis,Issue Slots Busy,%,1.50,,,,,
0,57539,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(2048, 2048, 1)",0,7.5,Compute Workload Analysis,Issued Ipc Active,inst/cycle,0.06,,,,,
0,57539,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(2048, 2048, 1)",0,7.5,Compute Workload Analysis,SM Busy,%,1.65,,,,,
0,57539,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(2048, 2048, 1)",0,7.5,ComputeWorkloadAnalysis,,,,HighPipeUtilization,OPT,All compute pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.,local,98.76
0,57539,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(2048, 2048, 1)",0,7.5,Memory Workload Analysis,Memory Throughput,byte/second,"44,039,119,702.36",,,,,
0,57539,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(2048, 2048, 1)",0,7.5,Memory Workload Analysis,Mem Busy,%,9.38,,,,,
0,57539,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(2048, 2048, 1)",0,7.5,Memory Workload Analysis,Max Bandwidth,%,22.99,,,,,
0,57539,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(2048, 2048, 1)",0,7.5,Memory Workload Analysis,L1/TEX Hit Rate,%,50.00,,,,,
0,57539,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(2048, 2048, 1)",0,7.5,Memory Workload Analysis,L2 Hit Rate,%,34.16,,,,,
0,57539,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(2048, 2048, 1)",0,7.5,Memory Workload Analysis,Mem Pipes Busy,%,3.53,,,,,
0,57539,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(2048, 2048, 1)",0,7.5,MemoryWorkloadAnalysis_Chart,,,,MemoryL2Compression,WRN,The optional metric lts__average_gcomp_input_sector_success_rate.pct could not be found. Collecting it as an additional metric could enable the rule to provide more guidance.,,
0,57539,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(2048, 2048, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for global loads in L1TEX might not be optimal. On average, this kernel accesses 4.0 bytes per thread per memory request; but the address pattern, possibly caused by the stride between threads, results in 8.0 sectors per request, or 8.0*32 = 256.0 bytes of cache data transfers per request. The optimal thread address pattern for 4.0 byte accesses would result in 4.0*32 = 128.0 bytes of cache data transfers per request, to maximize L1TEX cache performance. Check the Source Counters section for uncoalesced global loads.",global,0.265
0,57539,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(2048, 2048, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for global stores in L1TEX might not be optimal. On average, this kernel accesses 4.0 bytes per thread per memory request; but the address pattern, possibly caused by the stride between threads, results in 8.0 sectors per request, or 8.0*32 = 256.0 bytes of cache data transfers per request. The optimal thread address pattern for 4.0 byte accesses would result in 4.0*32 = 128.0 bytes of cache data transfers per request, to maximize L1TEX cache performance. Check the Source Counters section for uncoalesced global stores.",global,0.265
0,57539,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(2048, 2048, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for loads from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced loads and try to minimize how many cache lines need to be accessed per memory request.",global,3.916
0,57539,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(2048, 2048, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for stores from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced stores and try to minimize how many cache lines need to be accessed per memory request.",global,2.041
0,57539,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(2048, 2048, 1)",0,7.5,Scheduler Statistics,One or More Eligible,%,1.50,,,,,
0,57539,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(2048, 2048, 1)",0,7.5,Scheduler Statistics,Issued Warp Per Scheduler,,0.02,,,,,
0,57539,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(2048, 2048, 1)",0,7.5,Scheduler Statistics,No Eligible,%,98.50,,,,,
0,57539,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(2048, 2048, 1)",0,7.5,Scheduler Statistics,Active Warps Per Scheduler,warp,7.85,,,,,
0,57539,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(2048, 2048, 1)",0,7.5,Scheduler Statistics,Eligible Warps Per Scheduler,warp,0.02,,,,,
0,57539,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(2048, 2048, 1)",0,7.5,SchedulerStats,,,,IssueSlotUtilization,OPT,"Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 66.6 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of 7.85 active warps per scheduler, but only an average of 0.02 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, avoid possible load imbalances due to highly different execution durations per warp. Reducing stalls indicated on the Warp State Statistics and Source Counters sections can help, too.",local,77.01
0,57539,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(2048, 2048, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Issued Instruction,cycle,522.63,,,,,
0,57539,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(2048, 2048, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Executed Instruction,cycle,522.64,,,,,
0,57539,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(2048, 2048, 1)",0,7.5,Warp State Statistics,Avg. Active Threads Per Warp,,32,,,,,
0,57539,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(2048, 2048, 1)",0,7.5,Warp State Statistics,Avg. Not Predicated Off Threads Per Warp,,32,,,,,
0,57539,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(2048, 2048, 1)",0,7.5,WarpStateStats,,,,CPIStall,OPT,"On average, each warp of this kernel spends 511.0 cycles being stalled waiting for a scoreboard dependency on a L1TEX (local, global, surface, texture) operation. Find the instruction producing the data being waited upon to identify the culprit. To reduce the number of cycles waiting on L1TEX data accesses verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit rates by increasing data locality (coalescing), or by changing the cache configuration. Consider moving frequently used data to shared memory. This stall type represents about 97.8% of the total average of 522.6 cycles between issuing two instructions.",global,77.01
0,57539,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(2048, 2048, 1)",0,7.5,WarpStateStats,,,,CPIStall,INF,Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.,,
0,57539,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(2048, 2048, 1)",0,7.5,Instruction Statistics,Avg. Executed Instructions Per Scheduler,inst,"2,546,541.71",,,,,
0,57539,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(2048, 2048, 1)",0,7.5,Instruction Statistics,Executed Instructions,inst,"142,606,336",,,,,
0,57539,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(2048, 2048, 1)",0,7.5,Instruction Statistics,Avg. Issued Instructions Per Scheduler,inst,"2,546,567.45",,,,,
0,57539,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(2048, 2048, 1)",0,7.5,Instruction Statistics,Issued Instructions,inst,"142,607,777",,,,,
0,57539,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(2048, 2048, 1)",0,7.5,InstructionStats,,,,FPInstructions,OPT,"This kernel executes 0 fused and 8388608 non-fused FP32 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP32 performance could be increased by up to 50% (relative to its current performance). Check the Source page to identify where this kernel executes FP32 instructions.",global,0.6177
0,57539,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(2048, 2048, 1)",0,7.5,Launch Statistics,Block Size,,64,,,,,
0,57539,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(2048, 2048, 1)",0,7.5,Launch Statistics,Function Cache Configuration,,CachePreferNone,,,,,
0,57539,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(2048, 2048, 1)",0,7.5,Launch Statistics,Grid Size,,"4,194,304",,,,,
0,57539,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(2048, 2048, 1)",0,7.5,Launch Statistics,Registers Per Thread,register/thread,16,,,,,
0,57539,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(2048, 2048, 1)",0,7.5,Launch Statistics,Shared Memory Configuration Size,byte,"32,768",,,,,
0,57539,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(2048, 2048, 1)",0,7.5,Launch Statistics,Driver Shared Memory Per Block,byte/block,0,,,,,
0,57539,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(2048, 2048, 1)",0,7.5,Launch Statistics,Dynamic Shared Memory Per Block,byte/block,0,,,,,
0,57539,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(2048, 2048, 1)",0,7.5,Launch Statistics,Static Shared Memory Per Block,byte/block,0,,,,,
0,57539,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(2048, 2048, 1)",0,7.5,Launch Statistics,Threads,thread,"268,435,456",,,,,
0,57539,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(2048, 2048, 1)",0,7.5,Launch Statistics,Waves Per SM,,"18,724.57",,,,,
0,57539,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(2048, 2048, 1)",0,7.5,Occupancy,Block Limit SM,block,16,,,,,
0,57539,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(2048, 2048, 1)",0,7.5,Occupancy,Block Limit Registers,block,64,,,,,
0,57539,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(2048, 2048, 1)",0,7.5,Occupancy,Block Limit Shared Mem,block,16,,,,,
0,57539,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(2048, 2048, 1)",0,7.5,Occupancy,Block Limit Warps,block,16,,,,,
0,57539,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(2048, 2048, 1)",0,7.5,Occupancy,Theoretical Active Warps per SM,warp,32,,,,,
0,57539,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(2048, 2048, 1)",0,7.5,Occupancy,Theoretical Occupancy,%,100,,,,,
0,57539,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(2048, 2048, 1)",0,7.5,Occupancy,Achieved Occupancy,%,98.19,,,,,
0,57539,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(2048, 2048, 1)",0,7.5,Occupancy,Achieved Active Warps Per SM,warp,31.42,,,,,
0,57539,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(2048, 2048, 1)",0,7.5,Source Counters,Branch Instructions Ratio,%,0.06,,,,,
0,57539,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(2048, 2048, 1)",0,7.5,Source Counters,Branch Instructions,inst,"8,388,608",,,,,
0,57539,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(2048, 2048, 1)",0,7.5,Source Counters,Branch Efficiency,%,0,,,,,
0,57539,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(2048, 2048, 1)",0,7.5,Source Counters,Avg. Divergent Branches,,0,,,,,
0,57539,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(8, 8, 1)","(2048, 2048, 1)",0,7.5,SourceCounters,,,,UncoalescedGlobalAccess,OPT,This kernel has uncoalesced global accesses resulting in a total of 100663296 excessive sectors (50% of the total 201326592 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source locations. The CUDA Programming Guide (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) has additional information on reducing uncoalesced device memory accesses.,global,48.78
0,57703,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(1024, 1024, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Frequency,cycle/second,"5,996,228,046.62",,,,,
0,57703,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(1024, 1024, 1)",0,7.5,GPU Speed Of Light Throughput,SM Frequency,cycle/second,"1,390,778,538.55",,,,,
0,57703,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(1024, 1024, 1)",0,7.5,GPU Speed Of Light Throughput,Elapsed Cycles,cycle,"85,954,435",,,,,
0,57703,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(1024, 1024, 1)",0,7.5,GPU Speed Of Light Throughput,Memory Throughput,%,36.53,,,,,
0,57703,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(1024, 1024, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Throughput,%,27.20,,,,,
0,57703,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(1024, 1024, 1)",0,7.5,GPU Speed Of Light Throughput,Duration,nsecond,"61,727,168",,,,,
0,57703,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(1024, 1024, 1)",0,7.5,GPU Speed Of Light Throughput,L1/TEX Cache Throughput,%,70.90,,,,,
0,57703,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(1024, 1024, 1)",0,7.5,GPU Speed Of Light Throughput,L2 Cache Throughput,%,36.53,,,,,
0,57703,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(1024, 1024, 1)",0,7.5,GPU Speed Of Light Throughput,SM Active Cycles,cycle,"85,830,206.07",,,,,
0,57703,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(1024, 1024, 1)",0,7.5,GPU Speed Of Light Throughput,Compute (SM) Throughput,%,6.98,,,,,
0,57703,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(1024, 1024, 1)",0,7.5,SpeedOfLight,,,,SOLBottleneck,OPT,This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.,,
0,57703,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(1024, 1024, 1)",0,7.5,SpeedOfLight_RooflineChart,,,,SOLFPRoofline,INF,The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved  close to 0% of this device's fp32 peak performance and 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.,,
0,57703,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(1024, 1024, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Active,inst/cycle,0.12,,,,,
0,57703,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(1024, 1024, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Elapsed,inst/cycle,0.12,,,,,
0,57703,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(1024, 1024, 1)",0,7.5,Compute Workload Analysis,Issue Slots Busy,%,2.97,,,,,
0,57703,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(1024, 1024, 1)",0,7.5,Compute Workload Analysis,Issued Ipc Active,inst/cycle,0.12,,,,,
0,57703,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(1024, 1024, 1)",0,7.5,Compute Workload Analysis,SM Busy,%,3.26,,,,,
0,57703,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(1024, 1024, 1)",0,7.5,ComputeWorkloadAnalysis,,,,HighPipeUtilization,OPT,All compute pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.,local,97.56
0,57703,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(1024, 1024, 1)",0,7.5,Memory Workload Analysis,Memory Throughput,byte/second,"52,182,650,466.00",,,,,
0,57703,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(1024, 1024, 1)",0,7.5,Memory Workload Analysis,Mem Busy,%,35.45,,,,,
0,57703,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(1024, 1024, 1)",0,7.5,Memory Workload Analysis,Max Bandwidth,%,36.53,,,,,
0,57703,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(1024, 1024, 1)",0,7.5,Memory Workload Analysis,L1/TEX Hit Rate,%,79.17,,,,,
0,57703,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(1024, 1024, 1)",0,7.5,Memory Workload Analysis,L2 Hit Rate,%,79.12,,,,,
0,57703,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(1024, 1024, 1)",0,7.5,Memory Workload Analysis,Mem Pipes Busy,%,6.98,,,,,
0,57703,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(1024, 1024, 1)",0,7.5,MemoryWorkloadAnalysis_Chart,,,,MemoryL2Compression,WRN,The optional metric lts__average_gcomp_input_sector_success_rate.pct could not be found. Collecting it as an additional metric could enable the rule to provide more guidance.,,
0,57703,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(1024, 1024, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for global loads in L1TEX might not be optimal. On average, this kernel accesses 4.0 bytes per thread per memory request; but the address pattern, possibly caused by the stride between threads, results in 16.0 sectors per request, or 16.0*32 = 512.0 bytes of cache data transfers per request. The optimal thread address pattern for 4.0 byte accesses would result in 4.0*32 = 128.0 bytes of cache data transfers per request, to maximize L1TEX cache performance. Check the Source Counters section for uncoalesced global loads.",global,1.57
0,57703,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(1024, 1024, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for global stores in L1TEX might not be optimal. On average, this kernel accesses 4.0 bytes per thread per memory request; but the address pattern, possibly caused by the stride between threads, results in 16.0 sectors per request, or 16.0*32 = 512.0 bytes of cache data transfers per request. The optimal thread address pattern for 4.0 byte accesses would result in 4.0*32 = 128.0 bytes of cache data transfers per request, to maximize L1TEX cache performance. Check the Source Counters section for uncoalesced global stores.",global,1.57
0,57703,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(1024, 1024, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for loads from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced loads and try to minimize how many cache lines need to be accessed per memory request.",global,7.709
0,57703,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(1024, 1024, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for stores from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.1 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced stores and try to minimize how many cache lines need to be accessed per memory request.",global,10.43
0,57703,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(1024, 1024, 1)",0,7.5,Scheduler Statistics,One or More Eligible,%,2.97,,,,,
0,57703,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(1024, 1024, 1)",0,7.5,Scheduler Statistics,Issued Warp Per Scheduler,,0.03,,,,,
0,57703,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(1024, 1024, 1)",0,7.5,Scheduler Statistics,No Eligible,%,97.03,,,,,
0,57703,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(1024, 1024, 1)",0,7.5,Scheduler Statistics,Active Warps Per Scheduler,warp,7.08,,,,,
0,57703,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(1024, 1024, 1)",0,7.5,Scheduler Statistics,Eligible Warps Per Scheduler,warp,0.03,,,,,
0,57703,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(1024, 1024, 1)",0,7.5,SchedulerStats,,,,IssueSlotUtilization,OPT,"Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 33.7 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of 7.08 active warps per scheduler, but only an average of 0.03 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, avoid possible load imbalances due to highly different execution durations per warp. Reducing stalls indicated on the Warp State Statistics and Source Counters sections can help, too.",local,63.47
0,57703,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(1024, 1024, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Issued Instruction,cycle,238.79,,,,,
0,57703,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(1024, 1024, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Executed Instruction,cycle,238.79,,,,,
0,57703,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(1024, 1024, 1)",0,7.5,Warp State Statistics,Avg. Active Threads Per Warp,,32,,,,,
0,57703,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(1024, 1024, 1)",0,7.5,Warp State Statistics,Avg. Not Predicated Off Threads Per Warp,,32,,,,,
0,57703,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(1024, 1024, 1)",0,7.5,WarpStateStats,,,,CPIStall,OPT,"On average, each warp of this kernel spends 190.5 cycles being stalled waiting for a scoreboard dependency on a L1TEX (local, global, surface, texture) operation. Find the instruction producing the data being waited upon to identify the culprit. To reduce the number of cycles waiting on L1TEX data accesses verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit rates by increasing data locality (coalescing), or by changing the cache configuration. Consider moving frequently used data to shared memory. This stall type represents about 79.8% of the total average of 238.8 cycles between issuing two instructions.",global,63.47
0,57703,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(1024, 1024, 1)",0,7.5,WarpStateStats,,,,CPIStall,INF,Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.,,
0,57703,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(1024, 1024, 1)",0,7.5,Instruction Statistics,Avg. Executed Instructions Per Scheduler,inst,"2,546,541.71",,,,,
0,57703,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(1024, 1024, 1)",0,7.5,Instruction Statistics,Executed Instructions,inst,"142,606,336",,,,,
0,57703,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(1024, 1024, 1)",0,7.5,Instruction Statistics,Avg. Issued Instructions Per Scheduler,inst,"2,546,573.21",,,,,
0,57703,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(1024, 1024, 1)",0,7.5,Instruction Statistics,Issued Instructions,inst,"142,608,100",,,,,
0,57703,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(1024, 1024, 1)",0,7.5,InstructionStats,,,,FPInstructions,OPT,"This kernel executes 0 fused and 8388608 non-fused FP32 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP32 performance could be increased by up to 50% (relative to its current performance). Check the Source page to identify where this kernel executes FP32 instructions.",global,1.222
0,57703,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(1024, 1024, 1)",0,7.5,Launch Statistics,Block Size,,256,,,,,
0,57703,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(1024, 1024, 1)",0,7.5,Launch Statistics,Function Cache Configuration,,CachePreferNone,,,,,
0,57703,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(1024, 1024, 1)",0,7.5,Launch Statistics,Grid Size,,"1,048,576",,,,,
0,57703,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(1024, 1024, 1)",0,7.5,Launch Statistics,Registers Per Thread,register/thread,16,,,,,
0,57703,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(1024, 1024, 1)",0,7.5,Launch Statistics,Shared Memory Configuration Size,byte,"32,768",,,,,
0,57703,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(1024, 1024, 1)",0,7.5,Launch Statistics,Driver Shared Memory Per Block,byte/block,0,,,,,
0,57703,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(1024, 1024, 1)",0,7.5,Launch Statistics,Dynamic Shared Memory Per Block,byte/block,0,,,,,
0,57703,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(1024, 1024, 1)",0,7.5,Launch Statistics,Static Shared Memory Per Block,byte/block,0,,,,,
0,57703,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(1024, 1024, 1)",0,7.5,Launch Statistics,Threads,thread,"268,435,456",,,,,
0,57703,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(1024, 1024, 1)",0,7.5,Launch Statistics,Waves Per SM,,"18,724.57",,,,,
0,57703,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(1024, 1024, 1)",0,7.5,Occupancy,Block Limit SM,block,16,,,,,
0,57703,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(1024, 1024, 1)",0,7.5,Occupancy,Block Limit Registers,block,16,,,,,
0,57703,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(1024, 1024, 1)",0,7.5,Occupancy,Block Limit Shared Mem,block,16,,,,,
0,57703,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(1024, 1024, 1)",0,7.5,Occupancy,Block Limit Warps,block,4,,,,,
0,57703,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(1024, 1024, 1)",0,7.5,Occupancy,Theoretical Active Warps per SM,warp,32,,,,,
0,57703,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(1024, 1024, 1)",0,7.5,Occupancy,Theoretical Occupancy,%,100,,,,,
0,57703,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(1024, 1024, 1)",0,7.5,Occupancy,Achieved Occupancy,%,88.97,,,,,
0,57703,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(1024, 1024, 1)",0,7.5,Occupancy,Achieved Active Warps Per SM,warp,28.47,,,,,
0,57703,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(1024, 1024, 1)",0,7.5,Occupancy,,,,AchievedOccupancy,OPT,The difference between calculated theoretical (100.0%) and measured achieved occupancy (89.0%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy.,global,11.03
0,57703,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(1024, 1024, 1)",0,7.5,Source Counters,Branch Instructions Ratio,%,0.06,,,,,
0,57703,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(1024, 1024, 1)",0,7.5,Source Counters,Branch Instructions,inst,"8,388,608",,,,,
0,57703,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(1024, 1024, 1)",0,7.5,Source Counters,Branch Efficiency,%,0,,,,,
0,57703,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(1024, 1024, 1)",0,7.5,Source Counters,Avg. Divergent Branches,,0,,,,,
0,57703,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(16, 16, 1)","(1024, 1024, 1)",0,7.5,SourceCounters,,,,UncoalescedGlobalAccess,OPT,This kernel has uncoalesced global accesses resulting in a total of 301989888 excessive sectors (75% of the total 402653184 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source locations. The CUDA Programming Guide (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) has additional information on reducing uncoalesced device memory accesses.,global,72.23
0,57871,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(512, 512, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Frequency,cycle/second,"5,941,157,804.91",,,,,
0,57871,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(512, 512, 1)",0,7.5,GPU Speed Of Light Throughput,SM Frequency,cycle/second,"1,380,574,991.01",,,,,
0,57871,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(512, 512, 1)",0,7.5,GPU Speed Of Light Throughput,Elapsed Cycles,cycle,"133,652,329",,,,,
0,57871,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(512, 512, 1)",0,7.5,GPU Speed Of Light Throughput,Memory Throughput,%,59.58,,,,,
0,57871,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(512, 512, 1)",0,7.5,GPU Speed Of Light Throughput,DRAM Throughput,%,17.52,,,,,
0,57871,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(512, 512, 1)",0,7.5,GPU Speed Of Light Throughput,Duration,nsecond,"96,711,008",,,,,
0,57871,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(512, 512, 1)",0,7.5,GPU Speed Of Light Throughput,L1/TEX Cache Throughput,%,87.97,,,,,
0,57871,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(512, 512, 1)",0,7.5,GPU Speed Of Light Throughput,L2 Cache Throughput,%,59.58,,,,,
0,57871,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(512, 512, 1)",0,7.5,GPU Speed Of Light Throughput,SM Active Cycles,cycle,"130,414,760.43",,,,,
0,57871,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(512, 512, 1)",0,7.5,GPU Speed Of Light Throughput,Compute (SM) Throughput,%,4.49,,,,,
0,57871,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(512, 512, 1)",0,7.5,SpeedOfLight,,,,SOLBottleneck,OPT,This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.,,
0,57871,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(512, 512, 1)",0,7.5,SpeedOfLight_RooflineChart,,,,SOLFPRoofline,INF,The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved  close to 0% of this device's fp32 peak performance and 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.,,
0,57871,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(512, 512, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Active,inst/cycle,0.08,,,,,
0,57871,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(512, 512, 1)",0,7.5,Compute Workload Analysis,Executed Ipc Elapsed,inst/cycle,0.08,,,,,
0,57871,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(512, 512, 1)",0,7.5,Compute Workload Analysis,Issue Slots Busy,%,1.95,,,,,
0,57871,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(512, 512, 1)",0,7.5,Compute Workload Analysis,Issued Ipc Active,inst/cycle,0.08,,,,,
0,57871,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(512, 512, 1)",0,7.5,Compute Workload Analysis,SM Busy,%,2.14,,,,,
0,57871,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(512, 512, 1)",0,7.5,ComputeWorkloadAnalysis,,,,HighPipeUtilization,OPT,All compute pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.,local,98.39
0,57871,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(512, 512, 1)",0,7.5,Memory Workload Analysis,Memory Throughput,byte/second,"33,306,125,730.80",,,,,
0,57871,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(512, 512, 1)",0,7.5,Memory Workload Analysis,Mem Busy,%,43.99,,,,,
0,57871,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(512, 512, 1)",0,7.5,Memory Workload Analysis,Max Bandwidth,%,59.58,,,,,
0,57871,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(512, 512, 1)",0,7.5,Memory Workload Analysis,L1/TEX Hit Rate,%,90.62,,,,,
0,57871,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(512, 512, 1)",0,7.5,Memory Workload Analysis,L2 Hit Rate,%,90.00,,,,,
0,57871,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(512, 512, 1)",0,7.5,Memory Workload Analysis,Mem Pipes Busy,%,4.49,,,,,
0,57871,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(512, 512, 1)",0,7.5,MemoryWorkloadAnalysis_Chart,,,,MemoryL2Compression,WRN,The optional metric lts__average_gcomp_input_sector_success_rate.pct could not be found. Collecting it as an additional metric could enable the rule to provide more guidance.,,
0,57871,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(512, 512, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for global loads in L1TEX might not be optimal. On average, this kernel accesses 4.0 bytes per thread per memory request; but the address pattern, possibly caused by the stride between threads, results in 32.0 sectors per request, or 32.0*32 = 1024.0 bytes of cache data transfers per request. The optimal thread address pattern for 4.0 byte accesses would result in 4.0*32 = 128.0 bytes of cache data transfers per request, to maximize L1TEX cache performance. Check the Source Counters section for uncoalesced global loads.",global,2.356
0,57871,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(512, 512, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for global stores in L1TEX might not be optimal. On average, this kernel accesses 4.0 bytes per thread per memory request; but the address pattern, possibly caused by the stride between threads, results in 32.0 sectors per request, or 32.0*32 = 1024.0 bytes of cache data transfers per request. The optimal thread address pattern for 4.0 byte accesses would result in 4.0*32 = 128.0 bytes of cache data transfers per request, to maximize L1TEX cache performance. Check the Source Counters section for uncoalesced global stores.",global,2.356
0,57871,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(512, 512, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for loads from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced loads and try to minimize how many cache lines need to be accessed per memory request.",global,4.973
0,57871,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(512, 512, 1)",0,7.5,MemoryWorkloadAnalysis_Tables,,,,MemoryCacheAccessPattern,OPT,"The memory access pattern for stores from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced stores and try to minimize how many cache lines need to be accessed per memory request.",global,19.89
0,57871,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(512, 512, 1)",0,7.5,Scheduler Statistics,One or More Eligible,%,2.07,,,,,
0,57871,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(512, 512, 1)",0,7.5,Scheduler Statistics,Issued Warp Per Scheduler,,0.02,,,,,
0,57871,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(512, 512, 1)",0,7.5,Scheduler Statistics,No Eligible,%,97.93,,,,,
0,57871,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(512, 512, 1)",0,7.5,Scheduler Statistics,Active Warps Per Scheduler,warp,6.11,,,,,
0,57871,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(512, 512, 1)",0,7.5,Scheduler Statistics,Eligible Warps Per Scheduler,warp,0.04,,,,,
0,57871,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(512, 512, 1)",0,7.5,SchedulerStats,,,,IssueSlotUtilization,OPT,"Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 48.4 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of 6.11 active warps per scheduler, but only an average of 0.04 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections.",local,40.42
0,57871,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(512, 512, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Issued Instruction,cycle,295.88,,,,,
0,57871,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(512, 512, 1)",0,7.5,Warp State Statistics,Warp Cycles Per Executed Instruction,cycle,295.89,,,,,
0,57871,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(512, 512, 1)",0,7.5,Warp State Statistics,Avg. Active Threads Per Warp,,32,,,,,
0,57871,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(512, 512, 1)",0,7.5,Warp State Statistics,Avg. Not Predicated Off Threads Per Warp,,32,,,,,
0,57871,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(512, 512, 1)",0,7.5,WarpStateStats,,,,CPIStall,OPT,"On average, each warp of this kernel spends 186.2 cycles being stalled waiting for a scoreboard dependency on a L1TEX (local, global, surface, texture) operation. Find the instruction producing the data being waited upon to identify the culprit. To reduce the number of cycles waiting on L1TEX data accesses verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit rates by increasing data locality (coalescing), or by changing the cache configuration. Consider moving frequently used data to shared memory. This stall type represents about 62.9% of the total average of 295.9 cycles between issuing two instructions.",global,40.42
0,57871,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(512, 512, 1)",0,7.5,WarpStateStats,,,,CPIStall,INF,Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.,,
0,57871,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(512, 512, 1)",0,7.5,Instruction Statistics,Avg. Executed Instructions Per Scheduler,inst,"2,546,541.71",,,,,
0,57871,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(512, 512, 1)",0,7.5,Instruction Statistics,Executed Instructions,inst,"142,606,336",,,,,
0,57871,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(512, 512, 1)",0,7.5,Instruction Statistics,Avg. Issued Instructions Per Scheduler,inst,"2,546,573.71",,,,,
0,57871,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(512, 512, 1)",0,7.5,Instruction Statistics,Issued Instructions,inst,"142,608,128",,,,,
0,57871,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(512, 512, 1)",0,7.5,InstructionStats,,,,FPInstructions,OPT,"This kernel executes 0 fused and 8388608 non-fused FP32 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP32 performance could be increased by up to 50% (relative to its current performance). Check the Source page to identify where this kernel executes FP32 instructions.",global,0.804
0,57871,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(512, 512, 1)",0,7.5,Launch Statistics,Block Size,,"1,024",,,,,
0,57871,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(512, 512, 1)",0,7.5,Launch Statistics,Function Cache Configuration,,CachePreferNone,,,,,
0,57871,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(512, 512, 1)",0,7.5,Launch Statistics,Grid Size,,"262,144",,,,,
0,57871,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(512, 512, 1)",0,7.5,Launch Statistics,Registers Per Thread,register/thread,16,,,,,
0,57871,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(512, 512, 1)",0,7.5,Launch Statistics,Shared Memory Configuration Size,byte,"32,768",,,,,
0,57871,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(512, 512, 1)",0,7.5,Launch Statistics,Driver Shared Memory Per Block,byte/block,0,,,,,
0,57871,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(512, 512, 1)",0,7.5,Launch Statistics,Dynamic Shared Memory Per Block,byte/block,0,,,,,
0,57871,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(512, 512, 1)",0,7.5,Launch Statistics,Static Shared Memory Per Block,byte/block,0,,,,,
0,57871,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(512, 512, 1)",0,7.5,Launch Statistics,Threads,thread,"268,435,456",,,,,
0,57871,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(512, 512, 1)",0,7.5,Launch Statistics,Waves Per SM,,"18,724.57",,,,,
0,57871,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(512, 512, 1)",0,7.5,Occupancy,Block Limit SM,block,16,,,,,
0,57871,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(512, 512, 1)",0,7.5,Occupancy,Block Limit Registers,block,4,,,,,
0,57871,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(512, 512, 1)",0,7.5,Occupancy,Block Limit Shared Mem,block,16,,,,,
0,57871,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(512, 512, 1)",0,7.5,Occupancy,Block Limit Warps,block,1,,,,,
0,57871,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(512, 512, 1)",0,7.5,Occupancy,Theoretical Active Warps per SM,warp,32,,,,,
0,57871,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(512, 512, 1)",0,7.5,Occupancy,Theoretical Occupancy,%,100,,,,,
0,57871,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(512, 512, 1)",0,7.5,Occupancy,Achieved Occupancy,%,72.49,,,,,
0,57871,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(512, 512, 1)",0,7.5,Occupancy,Achieved Active Warps Per SM,warp,23.20,,,,,
0,57871,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(512, 512, 1)",0,7.5,Occupancy,,,,AchievedOccupancy,OPT,The difference between calculated theoretical (100.0%) and measured achieved occupancy (72.5%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy.,global,27.51
0,57871,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(512, 512, 1)",0,7.5,Source Counters,Branch Instructions Ratio,%,0.06,,,,,
0,57871,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(512, 512, 1)",0,7.5,Source Counters,Branch Instructions,inst,"8,388,608",,,,,
0,57871,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(512, 512, 1)",0,7.5,Source Counters,Branch Efficiency,%,0,,,,,
0,57871,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(512, 512, 1)",0,7.5,Source Counters,Avg. Divergent Branches,,0,,,,,
0,57871,MatAdd,127.0.0.1,"MatAdd(float *, float *, float *)",1,7,"(32, 32, 1)","(512, 512, 1)",0,7.5,SourceCounters,,,,UncoalescedGlobalAccess,OPT,This kernel has uncoalesced global accesses resulting in a total of 704643072 excessive sectors (88% of the total 805306368 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source locations. The CUDA Programming Guide (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) has additional information on reducing uncoalesced device memory accesses.,global,87.61
